{
 "awd_id": "1525609",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Improving Memory Performance on Fused Architectures through Compiler and Runtime Innovations",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 470000.0,
 "awd_amount": 470000.0,
 "awd_min_amd_letter_date": "2015-07-27",
 "awd_max_amd_letter_date": "2015-07-27",
 "awd_abstract_narration": "During the past decade, accelerators such as Graphics Processing Units (GPUs) have entered the area of general-purpose computing. They are now widely used for achieving high performance in scientific simulation, business analytics, image processing, and many other application domains. Their effectiveness however has been largely constrained by narrow and slow interconnections to multicore CPUs. Instead of such disjoint memories for multicore CPUs on one side and GPUs on the other, contemporary architectures are adopting an integrated design: Conventional CPUs and co-accelerators are integrated on the same die with access to the same memory. The integration provides new opportunities for synergistic execution on CPUs and GPUs, but can also intensify resource contention within the memory hierarchy. The implications yet remain to be understood.\r\n\r\nThis project aims to systematically explore the new challenges and opportunities of the integration, especially for compilers and runtime systems in governing program transformations and maintaining them at runtime for data locality, task partitioning and scheduling. The PIs propose to advance the state of the art by promoting synergistic execution in support of data sharing while creating spheres of isolation between CPU and GPU execution to mitigate resource contention of non-shared data. The proposed techniques include a set of novel compiler transformations, concurrent program control and data abstractions, and systems mechanisms that foster\r\nsharing and reduce cross-boundary contention depending on memory access patterns with respect to shared hardware resources.  This synergy between compiler techniques and the runtime system has the potential to significantly improve performance and power guarantees for co-scheduling program fragments on fused architectures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xipeng",
   "pi_last_name": "Shen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xipeng Shen",
   "pi_email_addr": "xshen5@ncsu.edu",
   "nsf_id": "000180293",
   "pi_start_date": "2015-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Frank",
   "pi_last_name": "Mueller",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Frank Mueller",
   "pi_email_addr": "fmuelle@ncsu.edu",
   "nsf_id": "000484031",
   "pi_start_date": "2015-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "890 Oval Dr.",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276958206",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 470000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>During the past decade, accelerators such as Graphics Processing Units(GPUs) have entered the area of general-purpose computing. Whilediscrete accelerators have significant potential to speed upcomputation, their effectiveness is poised by narrow and slowinterconnections to multicore CPUs. Instead of such disjoint memoriesfor multicore CPUs on one side and GPUs on the other, contemporaryarchitectures are adopting an integrated design: Conventional CPUs areco-hosted accelerators on the same die with access to the same memory,albeit with different coherence models.</p>\n<p><br />Intellectual Merits:&nbsp;<br />This project has revealed a set of novel implicationsof fused architectures by studying their effects, qualifying theircauses and quantifying the impacts on performance and powerefficiency. It has advanced the state-of-the-art by promotingsynergistic execution in support of data sharing while creatingspheres of isolation between CPU and GPU execution to mitigateresource contention of non-shared data. It in addition has developednovel compiler transformations, concurrent program control anddata abstractions, and systems mechanisms that foster sharing and reduce cross-boundary contention depending on memory access patterns with respect to shared hardware resources. &nbsp;This synergybetween compiler techniques and the runtime system has the potential to significantly improve performance and power guarantees forco-scheduling programs fragments on fused architectures. During the period of this project, the team have&nbsp;produced dozens of peer-reviewed journal or conference research papers, and released an open-source software.&nbsp;</p>\n<p><br />Broader Impact:<br />This project has the potential to transformcompiler infrastructure, internal representations and runtime systemsto create a synergistic development environment with significantperformance and power improvements and a new sensitivity for sharingvs. isolation decisions suitable for synergistic co-deployment ofprograms crossing boundaries on innovative fused architectures. &nbsp;With the support of this grant, the research team have graduated six Ph.Ds and two Masters during the period of the project.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/22/2020<br>\n\t\t\t\t\tModified by: Frank&nbsp;Mueller</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1525609/1525609_10380509_1600467468810_GPUcorundegration--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1525609/1525609_10380509_1600467468810_GPUcorundegration--rgov-800width.jpg\" title=\"GPU-Degradation\"><img src=\"/por/images/Reports/POR/2020/1525609/1525609_10380509_1600467468810_GPUcorundegration--rgov-66x44.jpg\" alt=\"GPU-Degradation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">GPU Co-run Performance Degradations on CPU-GPU Fused Architecture.</div>\n<div class=\"imageCredit\">Xipeng Shen</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Xipeng&nbsp;Shen</div>\n<div class=\"imageTitle\">GPU-Degradation</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1525609/1525609_10380509_1600467510315_CPU_corunDegradation_fused--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1525609/1525609_10380509_1600467510315_CPU_corunDegradation_fused--rgov-800width.jpg\" title=\"CPU-Degradation\"><img src=\"/por/images/Reports/POR/2020/1525609/1525609_10380509_1600467510315_CPU_corunDegradation_fused--rgov-66x44.jpg\" alt=\"CPU-Degradation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">CPU Co-run Performance Degradations on CPU-GPU Fused Architecture</div>\n<div class=\"imageCredit\">Xipeng Shen</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Xipeng&nbsp;Shen</div>\n<div class=\"imageTitle\">CPU-Degradation</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nDuring the past decade, accelerators such as Graphics Processing Units(GPUs) have entered the area of general-purpose computing. Whilediscrete accelerators have significant potential to speed upcomputation, their effectiveness is poised by narrow and slowinterconnections to multicore CPUs. Instead of such disjoint memoriesfor multicore CPUs on one side and GPUs on the other, contemporaryarchitectures are adopting an integrated design: Conventional CPUs areco-hosted accelerators on the same die with access to the same memory,albeit with different coherence models.\n\n\nIntellectual Merits: \nThis project has revealed a set of novel implicationsof fused architectures by studying their effects, qualifying theircauses and quantifying the impacts on performance and powerefficiency. It has advanced the state-of-the-art by promotingsynergistic execution in support of data sharing while creatingspheres of isolation between CPU and GPU execution to mitigateresource contention of non-shared data. It in addition has developednovel compiler transformations, concurrent program control anddata abstractions, and systems mechanisms that foster sharing and reduce cross-boundary contention depending on memory access patterns with respect to shared hardware resources.  This synergybetween compiler techniques and the runtime system has the potential to significantly improve performance and power guarantees forco-scheduling programs fragments on fused architectures. During the period of this project, the team have produced dozens of peer-reviewed journal or conference research papers, and released an open-source software. \n\n\nBroader Impact:\nThis project has the potential to transformcompiler infrastructure, internal representations and runtime systemsto create a synergistic development environment with significantperformance and power improvements and a new sensitivity for sharingvs. isolation decisions suitable for synergistic co-deployment ofprograms crossing boundaries on innovative fused architectures.  With the support of this grant, the research team have graduated six Ph.Ds and two Masters during the period of the project. \n\n \n\n\t\t\t\t\tLast Modified: 09/22/2020\n\n\t\t\t\t\tSubmitted by: Frank Mueller"
 }
}