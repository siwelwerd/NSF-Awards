{
 "awd_id": "1514211",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Medium: Collaborative: Security and Privacy for Wearable and Continuous Sensing Platforms",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "James Joshi",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 399659.0,
 "awd_amount": 399659.0,
 "awd_min_amd_letter_date": "2015-06-29",
 "awd_max_amd_letter_date": "2015-06-29",
 "awd_abstract_narration": "This research project studies security and privacy for wearable devices.  Wearable computing is poised to become widely deployed throughout society.  These devices offer many benefits to end users in terms of realtime access to information and the augmentation of human memory, but they are also likely to introduce new and complex privacy and security problems.  People who use wearable devices need assurances that their privacy will be respected, and we also need ways to minimize the potential for wearable devices to intrude on the privacy of bystanders and others.  This project is identifying the risks in greater depth and developing new technologies and techniques to protect against these risks.  The project is building a scientific and engineering basis for making wearable computing trustworthy; the growing adoption of wearable computing makes this research important to society.\r\n\r\nSeveral unique features of wearable computing pose new challenges that require novel research.  It seems likely that continuous audio and video capture will enable many valuable uses of wearable computing, but they open up new attack vectors through these new input channels.  Audio and video capture also present new privacy challenges; for instance, third-party applications may need access to this data, but the data is sometimes highly sensitive (e.g., capturing intimate moments, sensitive documents, embarrassing social situations, etc.).  This project studies: how to empower users and enable them to control how apps on wearable devices can access audio and video resources, how to use privilege separation and the least-privilege principle to mitigate risks associated with third-party applications that run on wearable devices, how operating systems for wearable devices can be architected to prevent applications from collecting extraneous data, and new threats from wearable computing and how each of these threats could be countered with secure platform designs.  To protect privacy, the researchers are conducting user studies to improve our understanding of what data users find most sensitive; the findings from these user studies  is helping the researchers to design techniques to prevent applications from accessing sensitive data inappropriately.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Serge",
   "pi_last_name": "Egelman",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Serge M Egelman",
   "pi_email_addr": "egelman@icsi.berkeley.edu",
   "nsf_id": "000553035",
   "pi_start_date": "2015-06-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "International Computer Science Institute",
  "inst_street_address": "2150 SHATTUCK AVE",
  "inst_street_address_2": "SUITE 250",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106662900",
  "inst_zip_code": "947041345",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "INTERNATIONAL COMPUTER SCIENCE INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GSRMP1QCXU74"
 },
 "perf_inst": {
  "perf_inst_name": "International Computer Science Institute",
  "perf_str_addr": "1947 Center St STE 600",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947044115",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 399659.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><div class=\"page\" title=\"Page 1\">\n<div class=\"layoutArea\">\n<div class=\"column\">\n<p><span>We are becoming increasingly surrounded by devices that continuously capture ambient audio and video. For instance, while the &ldquo;wearable computer&rdquo; started as an experimental research prototype in the late 1960s, the recent demand for devices like smart watches, wearable fitness monitors, and in-home voice assistants suggests that wearable computers may become as ubiquitous as cellphones. These devices offer many benefits to end-users in terms of realtime access to information, the augmentation of human memory, and new interaction modalities, but they are also likely to introduce new and complex privacy and security problems. In this research we explored the new privacy and security threats that these devices are enabling, as well as proposed solutions to those threats.</span></p>\n<span id=\"docs-internal-guid-2775ccd6-7fff-90b6-7c6f-285803bb1236\">\n<p dir=\"ltr\"><span>Broadly speaking, we examined privacy and security concerns surrounding wearable and continuous sensing devices (e.g., those found in \"smart homes\"), through both user studies and the development of new technical designs. We studied three classes of problems:</span></p>\n<ol>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Device&shy;-to-&shy;user: How do we communicate to users when third&shy;-party applications running on continuous sensing platforms are accessing potentially sensitive user data?</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Environment-to-&shy;device: How can we protect devices and users from new security threats that are enabled by continuous sensing?</span></p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\"><span>Device&shy;-to-device: How do devices securely communicate with each other without violating users' security or privacy?</span></p>\n</li>\n</ol></span>\n<p>Some of our significant results were as follows:</p>\n<p><strong>Multi-user smart homes:</strong> From our prototype design and in-home user study, we found that for some of our participants, positive household social norms and relationship dynamics obviated the need for technical access controls. We also found that participants&rsquo; varied access control desires required our prototype to support complex combinations of access control options. Among our recommendations, we suggest that researchers improve the usability of smart home access controls by developing more usable configuration interfaces (such as natural language policy creation), and design smart home platforms that reduce tensions and conflicts by leveraging and scaffolding positive household norms.</p>\n<p><strong>Smart home end-user programming: </strong>From our analysis of errors that users can make in commercial end user programming interfaces for smart homes, we found that for most of the platforms we analyze, they either disallow errors by lacking the features that would make the error possible in the first place (e.g., the ability to have trigger conjunctions, i.e., &ldquo;if x and y, then&rdquo;) or they disallow errors that do not make logical sense. By contrast, interfaces currently do nothing to prevent errors that fall into a grey area: they are logically sensible but may not have been intended by the user. We observe that while some errors can be automatically detected and prevented based on logic alone, others rely fundamentally on the user&rsquo;s intention. We propose strategies that trigger-action programming interfaces and researchers should explore in future work to help users avoid these types of errors. For example, by leveraging a corpus of common rules from many users, a platform may be able to detect and suggest possible omissions in a user&rsquo;s ruleset.</p>\n<p><strong>Commercial smart homes: </strong>From our analysis of commercially available smart home platforms, we found that smart homes are converging on design choices related to smart home&rsquo;s reliability (e.g., local processing and local control), but that their approaches for access control and privacy are different; that access control and data sharing policies in some smart homes could enable occupants to spy on other occupants; and that alternate modes of interaction (e.g., voice-controlled devices) add convenience but could undermine access control policies in the smart home. From our evaluation of these design points and failure cases, we surface key issues around access control and privacy, the usability challenges of automation, and tensions between interoperability and reliability.</p>\n<p><strong>Smart home privacy:</strong> We surveyed owners of Amazon and Google smart speakers and found that almost half did not know that their recordings were being permanently stored and that they could review them; only a quarter reported reviewing interactions, and very few had ever deleted any. While participants did not consider their own recordings especially sensitive, they were more protective of others&rsquo; recordings (such as children and guests) and were strongly opposed to use of their data by third parties or for advertising. They also considered permanent retention, the status quo, unsatisfactory.</p>\n<p><strong>Privacy and security for older adults: </strong>We examined the privacy and security perceptions of older adults, because this population is understudied and also often have these devices placed in their environments without their knowledge or consent. Our work adds depth to current models of how older adults&rsquo; limited technical knowledge, experience, and age-related declines in ability amplify vulnerability to certain risks; we found that health, living situation, and finances play a notable role as well. We also found that older adults often experience usability issues or technical uncertainties in mitigating those risks&mdash;and that managing privacy and security concerns frequently consists of limiting or avoiding technology use.</p>\n<p>&nbsp;</p>\n</div>\n</div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2019<br>\n\t\t\t\t\tModified by: Serge&nbsp;M&nbsp;Egelman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\n\nWe are becoming increasingly surrounded by devices that continuously capture ambient audio and video. For instance, while the \"wearable computer\" started as an experimental research prototype in the late 1960s, the recent demand for devices like smart watches, wearable fitness monitors, and in-home voice assistants suggests that wearable computers may become as ubiquitous as cellphones. These devices offer many benefits to end-users in terms of realtime access to information, the augmentation of human memory, and new interaction modalities, but they are also likely to introduce new and complex privacy and security problems. In this research we explored the new privacy and security threats that these devices are enabling, as well as proposed solutions to those threats.\n\nBroadly speaking, we examined privacy and security concerns surrounding wearable and continuous sensing devices (e.g., those found in \"smart homes\"), through both user studies and the development of new technical designs. We studied three classes of problems:\n\n\nDevice&shy;-to-&shy;user: How do we communicate to users when third&shy;-party applications running on continuous sensing platforms are accessing potentially sensitive user data?\n\n\nEnvironment-to-&shy;device: How can we protect devices and users from new security threats that are enabled by continuous sensing?\n\n\nDevice&shy;-to-device: How do devices securely communicate with each other without violating users' security or privacy?\n\n\n\nSome of our significant results were as follows:\n\nMulti-user smart homes: From our prototype design and in-home user study, we found that for some of our participants, positive household social norms and relationship dynamics obviated the need for technical access controls. We also found that participants\u2019 varied access control desires required our prototype to support complex combinations of access control options. Among our recommendations, we suggest that researchers improve the usability of smart home access controls by developing more usable configuration interfaces (such as natural language policy creation), and design smart home platforms that reduce tensions and conflicts by leveraging and scaffolding positive household norms.\n\nSmart home end-user programming: From our analysis of errors that users can make in commercial end user programming interfaces for smart homes, we found that for most of the platforms we analyze, they either disallow errors by lacking the features that would make the error possible in the first place (e.g., the ability to have trigger conjunctions, i.e., \"if x and y, then\") or they disallow errors that do not make logical sense. By contrast, interfaces currently do nothing to prevent errors that fall into a grey area: they are logically sensible but may not have been intended by the user. We observe that while some errors can be automatically detected and prevented based on logic alone, others rely fundamentally on the user\u2019s intention. We propose strategies that trigger-action programming interfaces and researchers should explore in future work to help users avoid these types of errors. For example, by leveraging a corpus of common rules from many users, a platform may be able to detect and suggest possible omissions in a user\u2019s ruleset.\n\nCommercial smart homes: From our analysis of commercially available smart home platforms, we found that smart homes are converging on design choices related to smart home\u2019s reliability (e.g., local processing and local control), but that their approaches for access control and privacy are different; that access control and data sharing policies in some smart homes could enable occupants to spy on other occupants; and that alternate modes of interaction (e.g., voice-controlled devices) add convenience but could undermine access control policies in the smart home. From our evaluation of these design points and failure cases, we surface key issues around access control and privacy, the usability challenges of automation, and tensions between interoperability and reliability.\n\nSmart home privacy: We surveyed owners of Amazon and Google smart speakers and found that almost half did not know that their recordings were being permanently stored and that they could review them; only a quarter reported reviewing interactions, and very few had ever deleted any. While participants did not consider their own recordings especially sensitive, they were more protective of others\u2019 recordings (such as children and guests) and were strongly opposed to use of their data by third parties or for advertising. They also considered permanent retention, the status quo, unsatisfactory.\n\nPrivacy and security for older adults: We examined the privacy and security perceptions of older adults, because this population is understudied and also often have these devices placed in their environments without their knowledge or consent. Our work adds depth to current models of how older adults\u2019 limited technical knowledge, experience, and age-related declines in ability amplify vulnerability to certain risks; we found that health, living situation, and finances play a notable role as well. We also found that older adults often experience usability issues or technical uncertainties in mitigating those risks&mdash;and that managing privacy and security concerns frequently consists of limiting or avoiding technology use.\n\n \n\n\n\n\n\t\t\t\t\tLast Modified: 11/25/2019\n\n\t\t\t\t\tSubmitted by: Serge M Egelman"
 }
}