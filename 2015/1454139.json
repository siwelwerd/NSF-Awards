{
 "awd_id": "1454139",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CAREER: Cooperative Control and Decision-Making for Human-Agent Collaborative Teams",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Harry Dankowicz",
 "awd_eff_date": "2015-02-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 569999.0,
 "awd_min_amd_letter_date": "2015-01-12",
 "awd_max_amd_letter_date": "2021-07-06",
 "awd_abstract_narration": "This Faculty Early Career Development (CAREER) Program grant addresses control and decision-making for human-robot collaborative teams. The project has two main research thrusts. The first thrust examines a team consisting of a skilled human with knowledge of a certain manufacturing or sensing task, and a partially trained robot assistant that is capable of endless repetition without boredom or fatigue. The workload balance between the human and robot is governed by the trust that the human has for the robot, which is modeled mathematically as a function of the rate of improvement in performance and the rate of decrease in number of mistakes. Innovative trust-based algorithms will provide a balanced human experience and guaranteed team performance. The second research thrust will create novel planning strategies incorporating mathematical models of regret, an emotion central to human rational decision-making. Regret-based automatic decision-making aids will provide more human-like decisions for more natural human-robot interaction. Results from both thrusts of the project will ultimately enable transformative human-robot interaction technologies benefitting the U.S. economy and quality of life. The educational initiatives of this project will broaden participation of underrepresented groups in manufacturing and robotics research.\r\n\r\nThe technical approach entails the integration of trust into cooperative control and regret into decision-making for human-agent collaborative teams. To explore new fundamental understanding of trust and realize effective control allocation, the first thrust will develop new dynamic trust models based on qualitative results from human factors research, and novel trust-based control strategies for human-agent collaborative teams modeled by switched systems. Non-conservative multiple Lyapunov functions based analysis will be developed to provide state-dependent switching control of the manual and autonomous modes. The second thrust features the development of a regret-based Bayesian sequential decision-making framework that selects between the manual and autonomous mode in a way such that suboptimal decisions will be made to avoid the possible regret of making a wrong decision. Both thrusts include experimental validations using a heterogeneous multi-robot test bed and a humanoid manufacturing robot with human-in-the-loop. Results from this research will foster a new interface between control theory and human factors.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yue",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yue Wang",
   "pi_email_addr": "yue6@clemson.edu",
   "nsf_id": "000617858",
   "pi_start_date": "2015-01-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Clemson University",
  "inst_street_address": "201 SIKES HALL",
  "inst_street_address_2": "",
  "inst_city_name": "CLEMSON",
  "inst_state_code": "SC",
  "inst_state_name": "South Carolina",
  "inst_phone_num": "8646562424",
  "inst_zip_code": "296340001",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "SC03",
  "org_lgl_bus_name": "CLEMSON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "H2BMNX7DSKU8"
 },
 "perf_inst": {
  "perf_inst_name": "Clemson University",
  "perf_str_addr": "300 BRACKETT Hall",
  "perf_city_name": "Clemson",
  "perf_st_code": "SC",
  "perf_st_name": "South Carolina",
  "perf_zip_code": "296340001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "SC03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "164200",
   "pgm_ele_name": "Special Initiatives"
  },
  {
   "pgm_ele_code": "756900",
   "pgm_ele_name": "Dynamics, Control and System D"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "030E",
   "pgm_ref_txt": "CONTROL SYSTEMS"
  },
  {
   "pgm_ref_code": "034E",
   "pgm_ref_txt": "Dynamical systems"
  },
  {
   "pgm_ref_code": "091Z",
   "pgm_ref_txt": "Data Initiatives"
  },
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 500000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 69999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The primary outcomes of this project are the cooperative robot control and decision-making algorithms in human-agent collaborative teams for collaborative manufacturing, mobile sensor network, and autonomous driving applications. In particular, we focused on the social and psychological aspects of human-robot interaction on top of the physical aspect (e.g., safety, collision avoidance). More specifically, our contributions include:</span></p>\n<p><span>&nbsp;</span>1. Computational models and machine learning approaches for human-to-robot trust.</p>\n<p>2. Computational models and elicitation framework for human's regret/rejoice during decision-making under risk when working with robotic systems.</p>\n<p>3. Trust-based shared control strategies for mobile robots.</p>\n<p>4. Path planning and controller for robot manipulators in human-robot collaboration in manufacturing tasks (e.g., pick and place, handover, cooperative manipulation).</p>\n<p>5. Application of regret model in human-robot collaborative search and autonomous vehicle lane changing in mixed traffic.</p>\n<p>6. Deep reinforcement learning approaches that leverage system model knowledge to achieve better human-robot collaboration.</p>\n<p><span>Under partial support of this award, the PI has supervised two postdocs, three Ph.D. students, and three master's students. As a result, we have published 14 journal papers, 22 peer-reviewed conference papers, 3 Ph.D.&nbsp;</span>dissertations, 3 Master theses, 2 edited books, and 4 book chapters.&nbsp;The PI and her students also delivered numerous conference and seminar talks to disseminate the results.</p>\n<p>We created an interactive and friendly multi-robot laboratory with state-of-the-art mobile robots, industrial manipulators, motion capture system, and human input devices, serving as a base for research, education, and outreach in the Department of Mechanical Engineering at Clemson University.</p>\n<p>We created a new undergraduate creative inquiry course on human-robot collaborative manufacturing, which involved undergraduate students from different departments participating in interdisciplinary research. We also created a new graduate course on the control of robots and human-robot interaction systems, providing fundamental knowledge in robot modeling, control, and motion planning in manufacturing applications.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/23/2022<br>\n\t\t\t\t\tModified by: Yue&nbsp;Wang</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982101012_Picture1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982101012_Picture1--rgov-800width.jpg\" title=\"shared_control\"><img src=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982101012_Picture1--rgov-66x44.jpg\" alt=\"shared_control\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A human operator remotely controls a drone to track a ground mobile robot using our trust-based shared control strategy.</div>\n<div class=\"imageCredit\">Hamed Saeidi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yue&nbsp;Wang</div>\n<div class=\"imageTitle\">shared_control</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982247795_Picture2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982247795_Picture2--rgov-800width.jpg\" title=\"hybrid_manufacturing_cell\"><img src=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982247795_Picture2--rgov-66x44.jpg\" alt=\"hybrid_manufacturing_cell\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A human participant collaborates with a Baxter robot to perform assembly tasks in a hybrid manufacturing cell.</div>\n<div class=\"imageCredit\">Behzad Sadrfaridpour</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yue&nbsp;Wang</div>\n<div class=\"imageTitle\">hybrid_manufacturing_cell</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982380930_Picture3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982380930_Picture3--rgov-800width.jpg\" title=\"human_robot_comanipulation\"><img src=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982380930_Picture3--rgov-66x44.jpg\" alt=\"human_robot_comanipulation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A human participant co-manipulates a box with a UR5 robot with a mobile base</div>\n<div class=\"imageCredit\">Zhanrui Liao</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yue&nbsp;Wang</div>\n<div class=\"imageTitle\">human_robot_comanipulation</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982494641_Picture4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982494641_Picture4--rgov-800width.jpg\" title=\"driving_simulator\"><img src=\"/por/images/Reports/POR/2022/1454139/1454139_10346984_1663982494641_Picture4--rgov-66x44.jpg\" alt=\"driving_simulator\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A human participant performs driving tasks for data collection to learn our regret model</div>\n<div class=\"imageCredit\">Longsheng Jiang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yue&nbsp;Wang</div>\n<div class=\"imageTitle\">driving_simulator</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe primary outcomes of this project are the cooperative robot control and decision-making algorithms in human-agent collaborative teams for collaborative manufacturing, mobile sensor network, and autonomous driving applications. In particular, we focused on the social and psychological aspects of human-robot interaction on top of the physical aspect (e.g., safety, collision avoidance). More specifically, our contributions include:\n\n 1. Computational models and machine learning approaches for human-to-robot trust.\n\n2. Computational models and elicitation framework for human's regret/rejoice during decision-making under risk when working with robotic systems.\n\n3. Trust-based shared control strategies for mobile robots.\n\n4. Path planning and controller for robot manipulators in human-robot collaboration in manufacturing tasks (e.g., pick and place, handover, cooperative manipulation).\n\n5. Application of regret model in human-robot collaborative search and autonomous vehicle lane changing in mixed traffic.\n\n6. Deep reinforcement learning approaches that leverage system model knowledge to achieve better human-robot collaboration.\n\nUnder partial support of this award, the PI has supervised two postdocs, three Ph.D. students, and three master's students. As a result, we have published 14 journal papers, 22 peer-reviewed conference papers, 3 Ph.D. dissertations, 3 Master theses, 2 edited books, and 4 book chapters. The PI and her students also delivered numerous conference and seminar talks to disseminate the results.\n\nWe created an interactive and friendly multi-robot laboratory with state-of-the-art mobile robots, industrial manipulators, motion capture system, and human input devices, serving as a base for research, education, and outreach in the Department of Mechanical Engineering at Clemson University.\n\nWe created a new undergraduate creative inquiry course on human-robot collaborative manufacturing, which involved undergraduate students from different departments participating in interdisciplinary research. We also created a new graduate course on the control of robots and human-robot interaction systems, providing fundamental knowledge in robot modeling, control, and motion planning in manufacturing applications. \n\n \n\n\t\t\t\t\tLast Modified: 09/23/2022\n\n\t\t\t\t\tSubmitted by: Yue Wang"
 }
}