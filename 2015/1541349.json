{
 "awd_id": "1541349",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "CC*DNI DIBBs: The Pacific Research Platform",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927092",
 "po_email": "alsuarez@nsf.gov",
 "po_sign_block_name": "Alejandro Suarez",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 5000000.0,
 "awd_amount": 8197182.0,
 "awd_min_amd_letter_date": "2015-07-30",
 "awd_max_amd_letter_date": "2022-01-12",
 "awd_abstract_narration": "Research in data-intensive fields is increasingly multi-investigator and multi-institutional, depending on ever more rapid access to ultra-large heterogeneous and widely distributed datasets. The Pacific Research Platform (PRP) is a multi-institutional extensible deployment that establishes a science-driven high-capacity data-centric 'freeway system.' The PRP spans all 10 campuses of the University of California, as well as the major California private research universities, four supercomputer centers, and several universities outside California. Fifteen multi-campus data-intensive application teams act as drivers of the PRP, providing feedback to the technical design staff over the five years of the project. These application areas include particle physics, astronomy/astrophysics, earth sciences, biomedicine, and scalable multimedia, providing models for many other applications.\r\n \r\nThe PRP builds on prior NSF and Department of Energy (DOE) investments. The basic model adopted by the PRP is 'The Science DMZ,' being prototyped by the DOE ESnet. (A Science DMZ is defined as 'a portion of the network, built at or near the campus local network perimeter that is designed such that the equipment, configuration, and security policies are optimized for high-performance scientific applications rather than for general-purpose business systems'). In the last three years, NSF has funded over 100 U.S. campuses through Campus Cyberinfrastructure - Network Infrastructure and Engineering (CC-NIE) grants to aggressively upgrade their network capacity for greatly enhanced science data access, creating Science DMZs within each campus.  The PRP partnership extends the NSF-funded campus Science DMZs to a regional model that allows high-speed data-intensive networking, facilitating researchers moving data between their laboratories and their collaborators' sites, supercomputer centers or data repositories, and enabling that data to traverse multiple heterogeneous networks without performance degradation over campus, regional, national, and international distances. The PRP's data sharing architecture, with end-to-end 10-40-100Gb/s connections, provides long-distance virtual co-location of data with computing resources, with enhanced security options.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Larry",
   "pi_last_name": "Smarr",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Larry L Smarr",
   "pi_email_addr": "lsmarr@ucsd.edu",
   "nsf_id": "000396797",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Philip",
   "pi_last_name": "Papadopoulos",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Philip M Papadopoulos",
   "pi_email_addr": "ppapadopoulos@ucsd.edu",
   "nsf_id": "000462781",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Frank",
   "pi_last_name": "Wuerthwein",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Frank Wuerthwein",
   "pi_email_addr": "fkw@ucsd.edu",
   "nsf_id": "000144338",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Thomas",
   "pi_last_name": "DeFanti",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Thomas A DeFanti",
   "pi_email_addr": "tdefanti@ucsd.edu",
   "nsf_id": "000072525",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Camille",
   "pi_last_name": "Crittenden",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Camille Crittenden",
   "pi_email_addr": "ccrittenden@berkeley.edu",
   "nsf_id": "000693732",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  },
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8048",
   "pgm_ref_txt": "Data Infrstr Bldg Blocks-DIBBs"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "",
   "app_name": "",
   "app_symb_id": "",
   "fund_code": "01002223DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0121",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002122DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 5000000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1149262.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 1015968.0
  },
  {
   "fund_oblg_fiscal_yr": 2021,
   "fund_oblg_amt": 999952.0
  },
  {
   "fund_oblg_fiscal_yr": 2022,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Pacific Research Platform (PRP) is a distributed data-sharing hardware and software infrastructure, with end-to-end 10?100Gb/s connections, which has enabled regionwide, nationwide, and worldwide virtual co-location of data with computing. The original goal of the PRP was to interconnect campus Science DMZ network systems, as designed in 2010 by the Department of Energy's ESnet, and funded by NSF on many U.S. campuses, resulting in a many-campus regional DMZ model supporting data-intensive science. This goal was accomplished in the first two years of the grant and then expanded to enable researchers to quickly and easily move data between collaborator labs, supercomputer centers, instruments, and data repositories, creating a big-data freeway that allows the data to traverse multiple, heterogeneous networks with minimal performance degradation.</p>\n<p>The endpoints on the campus Science DMZs are Data Transfer Nodes (DTNs), which the PRP designed as rack-mounted PC devices called Flash I/O Network Appliances (FIONAs), each of which is capable of holding up to 8 GPUs or FPGA add-in boards and up to 240TB of data. FIONAs are optimized for 10-200Gbps data transfers over Internet2 or the Quilt's regional optical Research and Education networks. The PRP team adopted the Cloud Native Computing Foundation's open-source <em>Kubernetes</em> container orchestration system to manage end-user or system software containers across Nautilus, the distributed hypercluster of FIONAs. This enables fast data transfer and interoperability among data stores and instruments within the PRP, while also attracting connections from institutions outside the PRP. This software/hardware/software engineering task of creating the PRP's Nautilus was even more successful than originally envisioned, largely because of the rapid rise and adoption of open-source software, such as Kubernetes, Rook, Ceph, JupyterLab, Admiralty, to name a few. The PRP team members became early adopters and contributors to these software systems. Nautilus has become a regional, national, and international model of their usefulness.</p>\n<p>The PRP and, subsequently, the Toward the National Research Platform (TNRP) projects have been supported by the National Science Foundation (NSF) awards CNS-1730158, ACI-1540112, ACI-1541349, OAC-1826967, OAC-2112167, and CNS-2120019, and the platform is set to expand to all parts of the United States with the National Research Platform (NRP). These grants, together with hardware contributions from Nautilus users across the country, have expanded the Nautilus high-performance data-intensive cyberinfrastructure to nearly 15,000 CPU-cores, 930 GPUs, and 4 Petabytes of storage, supporting over 700 namespace computational projects from researchers in over 90 campuses, including, 16 Minority Serving Institutions (MSIs) in 39 of 50 states, plus Washington DC and Puerto Rico.</p>\n<p>The PRP's Nautilus cluster is having broader impacts beyond just cyberinfrastructure. It is also being used directly and indirectly as part of educational experiences at PRP partner campuses, including as part of courses on cloud computing, deep learning for AI, and machine learning. In one case, the Educational Information and Technology Services office at UC San Diego cloned a 124-GPU cluster of Kubernetes-orchestrated FIONAs that are used exclusively by students to meet the computational lab requirements for formal courses and undergraduate research.&nbsp; This UCSD Data Science/Machine Learning Platform (DSMLP) GPU cluster is supporting over 30 courses and 12,000 students per academic year. This approach has been replicated by San Diego State University, a Minority Serving Institution, to support machine learning and data analysis courses.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/18/2022<br>\n\t\t\t\t\tModified by: Larry&nbsp;L&nbsp;Smarr</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Pacific Research Platform (PRP) is a distributed data-sharing hardware and software infrastructure, with end-to-end 10?100Gb/s connections, which has enabled regionwide, nationwide, and worldwide virtual co-location of data with computing. The original goal of the PRP was to interconnect campus Science DMZ network systems, as designed in 2010 by the Department of Energy's ESnet, and funded by NSF on many U.S. campuses, resulting in a many-campus regional DMZ model supporting data-intensive science. This goal was accomplished in the first two years of the grant and then expanded to enable researchers to quickly and easily move data between collaborator labs, supercomputer centers, instruments, and data repositories, creating a big-data freeway that allows the data to traverse multiple, heterogeneous networks with minimal performance degradation.\n\nThe endpoints on the campus Science DMZs are Data Transfer Nodes (DTNs), which the PRP designed as rack-mounted PC devices called Flash I/O Network Appliances (FIONAs), each of which is capable of holding up to 8 GPUs or FPGA add-in boards and up to 240TB of data. FIONAs are optimized for 10-200Gbps data transfers over Internet2 or the Quilt's regional optical Research and Education networks. The PRP team adopted the Cloud Native Computing Foundation's open-source Kubernetes container orchestration system to manage end-user or system software containers across Nautilus, the distributed hypercluster of FIONAs. This enables fast data transfer and interoperability among data stores and instruments within the PRP, while also attracting connections from institutions outside the PRP. This software/hardware/software engineering task of creating the PRP's Nautilus was even more successful than originally envisioned, largely because of the rapid rise and adoption of open-source software, such as Kubernetes, Rook, Ceph, JupyterLab, Admiralty, to name a few. The PRP team members became early adopters and contributors to these software systems. Nautilus has become a regional, national, and international model of their usefulness.\n\nThe PRP and, subsequently, the Toward the National Research Platform (TNRP) projects have been supported by the National Science Foundation (NSF) awards CNS-1730158, ACI-1540112, ACI-1541349, OAC-1826967, OAC-2112167, and CNS-2120019, and the platform is set to expand to all parts of the United States with the National Research Platform (NRP). These grants, together with hardware contributions from Nautilus users across the country, have expanded the Nautilus high-performance data-intensive cyberinfrastructure to nearly 15,000 CPU-cores, 930 GPUs, and 4 Petabytes of storage, supporting over 700 namespace computational projects from researchers in over 90 campuses, including, 16 Minority Serving Institutions (MSIs) in 39 of 50 states, plus Washington DC and Puerto Rico.\n\nThe PRP's Nautilus cluster is having broader impacts beyond just cyberinfrastructure. It is also being used directly and indirectly as part of educational experiences at PRP partner campuses, including as part of courses on cloud computing, deep learning for AI, and machine learning. In one case, the Educational Information and Technology Services office at UC San Diego cloned a 124-GPU cluster of Kubernetes-orchestrated FIONAs that are used exclusively by students to meet the computational lab requirements for formal courses and undergraduate research.  This UCSD Data Science/Machine Learning Platform (DSMLP) GPU cluster is supporting over 30 courses and 12,000 students per academic year. This approach has been replicated by San Diego State University, a Minority Serving Institution, to support machine learning and data analysis courses.\n\n\t\t\t\t\tLast Modified: 11/18/2022\n\n\t\t\t\t\tSubmitted by: Larry L Smarr"
 }
}