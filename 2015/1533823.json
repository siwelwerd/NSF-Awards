{
 "awd_id": "1533823",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AitF: FULL: Collaborative Research: Provably Efficient GPU Algorithms",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 416000.0,
 "awd_min_amd_letter_date": "2015-08-13",
 "awd_max_amd_letter_date": "2017-06-26",
 "awd_abstract_narration": "Graphics processing units (GPUs) were originally developed as specialized hardware exclusively for graphics rendering. In recent years they have become massively parallel systems with hundreds of processing cores supporting thousands of threads. Given their computational potential, they are now used to support general-purpose computation via high-level programming languages.  As a result, they have become a standard platform for high-performance computing (HPC) simulations in natural sciences.\r\n\r\nHowever, there is still very little understanding of what types of algorithms translate into efficient GPU programs, and many implementations rely on a limited number of design patterns and many rounds of trial-and-error. There is a need for simple but accurate algorithmic models to get a wider algorithmic community involved in GPU computing. The project will develop such a model, intended to have the transformative effect of enabling algorithms researchers to focus their efforts on creating algorithms for GPUs in a way that is currently not possible, increasing the algorithmic knowledgebase in GPU computing. Over time, more efficient algorithms will lead to better utilization of computing resources and reuse of code implemented as libraries. Such a model for GPUs will also enable teaching GPU computing to a wider group of students, similarly to how sequential and PRAM algorithms are currently taught.\r\n\r\nThis project will study the algorithmic aspects of GPU computing and will develop a simple but accurate theoretical model for GPUs, that will define clear guidelines and complexity metrics for algorithm evaluation. The PIs will develop and implement algorithms that will improve the state of the art code base of general purpose computation on GPUs in the areas of combinatorial algorithms, computational geometry, visualization, search algorithms, and data structures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nodari",
   "pi_last_name": "Sitchinava",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nodari Sitchinava",
   "pi_email_addr": "nodari@hawaii.edu",
   "nsf_id": "000666629",
   "pi_start_date": "2015-08-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Hawaii",
  "inst_street_address": "2425 CAMPUS RD SINCLAIR RM 1",
  "inst_street_address_2": "",
  "inst_city_name": "HONOLULU",
  "inst_state_code": "HI",
  "inst_state_name": "Hawaii",
  "inst_phone_num": "8089567800",
  "inst_zip_code": "968222247",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "HI01",
  "org_lgl_bus_name": "UNIVERSITY OF HAWAII",
  "org_prnt_uei_num": "",
  "org_uei_num": "NSCKLFSSABF2"
 },
 "perf_inst": {
  "perf_inst_name": "University of Hawaii",
  "perf_str_addr": "1680 East West Rd, POST 306B",
  "perf_city_name": "Honolulu",
  "perf_st_code": "HI",
  "perf_st_name": "Hawaii",
  "perf_zip_code": "968222234",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "HI01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723900",
   "pgm_ele_name": "Algorithms in the Field"
  },
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "915000",
   "pgm_ele_name": "EPSCoR Co-Funding"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "012Z",
   "pgm_ref_txt": "AitF FULL Projects"
  },
  {
   "pgm_ref_code": "7934",
   "pgm_ref_txt": "PARAL/DISTRIBUTED ALGORITHMS"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 400000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Graphics processing units (GPUs) were originally created to render graphics on the computer screens. However, in the past decade they have been adapted for more general purpose computations, and are widely used for scientific simulations and machine learning applications.<br /><br />Modern GPUs contain thousands of processing units and hierarchical memory design, making it challenging to design software that effectively utilizes all the computing resources of the hardware.&nbsp; This research project developed a theory for characterizing the performance of algorithms designed for GPUs, thus, allowing the researchers predict the performance of their algorithms even before they are implemented and tested on GPUs.<br /><br />The following major outcomes have been achieved in the course of this project:<br /><br />1. The PIs developed methodologies for designing and analyzing parallel algorithms for GPUs. <br /><br />2. The PIs discovered and published a number of algorithmic techniques for provably-efficient utilization of GPUs' large number of processing units and memory hierarchy.<br /><br />3. The PIs designed, implemented and published new algorithms and data structures that run faster than the existing state of the art implementations on GPUs.<br /><br />The outcomes are significant, because GPUs have become a standard high-performance computing tool for advancing scientific discoveries and training deep neural networks for the AI. The techniques developed in the course of this project move the optimization of GPU software to the design phase, rather than implementation and testing phase, speeding up the software development. As the scientific community adopts the produced software libraries, the applications running these libraries will run faster and more efficiently. <br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/20/2021<br>\n\t\t\t\t\tModified by: Nodari&nbsp;Sitchinava</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nGraphics processing units (GPUs) were originally created to render graphics on the computer screens. However, in the past decade they have been adapted for more general purpose computations, and are widely used for scientific simulations and machine learning applications.\n\nModern GPUs contain thousands of processing units and hierarchical memory design, making it challenging to design software that effectively utilizes all the computing resources of the hardware.  This research project developed a theory for characterizing the performance of algorithms designed for GPUs, thus, allowing the researchers predict the performance of their algorithms even before they are implemented and tested on GPUs.\n\nThe following major outcomes have been achieved in the course of this project:\n\n1. The PIs developed methodologies for designing and analyzing parallel algorithms for GPUs. \n\n2. The PIs discovered and published a number of algorithmic techniques for provably-efficient utilization of GPUs' large number of processing units and memory hierarchy.\n\n3. The PIs designed, implemented and published new algorithms and data structures that run faster than the existing state of the art implementations on GPUs.\n\nThe outcomes are significant, because GPUs have become a standard high-performance computing tool for advancing scientific discoveries and training deep neural networks for the AI. The techniques developed in the course of this project move the optimization of GPU software to the design phase, rather than implementation and testing phase, speeding up the software development. As the scientific community adopts the produced software libraries, the applications running these libraries will run faster and more efficiently. \n\n\n\n\n\t\t\t\t\tLast Modified: 01/20/2021\n\n\t\t\t\t\tSubmitted by: Nodari Sitchinava"
 }
}