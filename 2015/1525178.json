{
 "awd_id": "1525178",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF:  Small:  Causal Foundations of Statistical Fault Localization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 497500.0,
 "awd_amount": 497500.0,
 "awd_min_amd_letter_date": "2015-06-16",
 "awd_max_amd_letter_date": "2021-07-14",
 "awd_abstract_narration": "The goal of this research is to improve the effectiveness of automated techniques that seek to locate the faults in software that caused observed failures (malfunctions) to occur during testing or operational use, so the faults can be repaired.  This goal is important because properly functioning software is critical in business, communications, national security, transportation, science, and many other activities.  The desired improvements are to be achieved by employing methodology that has been developed recently, across several disciplines, to enable the causal effects of various kinds of treatments, exposures, or interventions (e.g., medical treatments) upon outcomes of interest (e.g., diseases) to be estimated accurately and without bias.  If successful, the proposed research has the potential to help software developers to efficiently localize and repair faults in their products, thereby preventing harms such as economic loss, injury, and even death. The research will also help to disseminate sound causal inference methodology in the software engineering community.\r\n \r\nMore specifically, the research will investigate and improve the foundations of causal statistical fault localization (CSFL), including the form of causal models, the abstraction of causal states, and the handling of iteration.  A value-based approach to CSFL will be developed, which involves profiling and analyzing the values of program variables, and this will be integrated with predicate-based CSFL, in order to more accurately estimate the failure-causing effects of program elements.  A new approach to CSFL will be explored that employs multilevel statistical models to integrate execution data of different types and granularity levels, both for a given program version and across versions.  Meta-analysis techniques will be applied to the set of suspiciousness scores obtained with CSFL, in order to take account of features of the score distribution and of factors that predict the credibility if individual scores.\r\nAlso to be investigated is how the problem of selection bias affects SFL techniques in different settings and how it can be mitigated.  Finally, the research will explore the potential value of case-control methodology for improving the cost-effectiveness of SFL in scenarios where software failures are infrequent.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "H. Andy",
   "pi_last_name": "Podgurski",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "H. Andy Podgurski",
   "pi_email_addr": "podgurski@case.edu",
   "nsf_id": "000108485",
   "pi_start_date": "2015-06-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Case Western Reserve University",
  "inst_street_address": "10900 EUCLID AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CLEVELAND",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "2163684510",
  "inst_zip_code": "441064901",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "OH11",
  "org_lgl_bus_name": "CASE WESTERN RESERVE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJMKEF7EJW69"
 },
 "perf_inst": {
  "perf_inst_name": "Case Western Reserve University",
  "perf_str_addr": "10900 Euclid Ave.",
  "perf_city_name": "Cleveland",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "441067071",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "OH11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 497500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project we have developed several value-based causal statistical fault localization (VB-CSFL) techniques, namely NUMFL-DLRM, NUMFL-QRM, NUMFL-CBPS, CounterFault, and Unival, and we have shown via empirical studies that they perform better than a variety of competing techniques, with the most recent technique, Unival, performing best of all.&nbsp; &nbsp;These techniques are based on the application of causal inference methodology and causal models of programs to program execution and failure data, and they are intended to localize the causes of program failures to specific parts of a program so that they can be fixed by software developers.&nbsp; They use data on the values taken on by program variables together with failure/success labels to do this.</p>\n<p>NUMFL-DLRM, NUMFL-QRM, NUMFL-CBPS are based on generalized propensity scores (GPS), which generalize to numeric treatment variables the standard propensity scores commonly used in causal inference with dichotomous treatment variables.&nbsp; A generalized propensity score is and estimate of the probability of a given treatment value given the values of covariates.&nbsp; &nbsp;CounterFault and Unival, on the other hand, are based on prediction of counterfactual outcomes with the aid of machine learning models trained with outcome, treatment, and covariate data.&nbsp; In our proposed value-based CSFL techniques, the outcome variable is an indicator of program failures, the treatment variable is a program variable that is assigned a value at a given statement, and the covariates are the program variables whose values are used in that statement.&nbsp;&nbsp;</p>\n<p>Unlike most statistical&nbsp; fault localization techniques, which are based on analysis of code-coverage profiles and produce misleading results due to confounding bias, our VB-CSFL techniques analyze variable-value profiles using sound causal-inference techniques in order to minimize confounding.&nbsp; Unival&nbsp;transforms the program under analysis so that branch and loop predicate outcomes become variable values, so that it can be applied to both variable assignments and predicates.&nbsp; It essentially bins or clusters variable values and selects representative values from each bin.&nbsp; This helps to ensure that an important propery for causal inference, known as positivity, holds.&nbsp; It is satisfied if the probability of each possible treatment value is positive given a set of possible&nbsp;covariate values.&nbsp; Unival uses execution data from a set of executions to train a machine learning model for predicting execution success or failure based on the values used and defined at a statement.&nbsp; It then uses this model to predict the counterfactual execution outcomes (pass/fail) under changes to the value computed at the statement.&nbsp; That is, Unival simulates the effects of value replacement.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/06/2022<br>\n\t\t\t\t\tModified by: H. Andy&nbsp;Podgurski</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project we have developed several value-based causal statistical fault localization (VB-CSFL) techniques, namely NUMFL-DLRM, NUMFL-QRM, NUMFL-CBPS, CounterFault, and Unival, and we have shown via empirical studies that they perform better than a variety of competing techniques, with the most recent technique, Unival, performing best of all.   These techniques are based on the application of causal inference methodology and causal models of programs to program execution and failure data, and they are intended to localize the causes of program failures to specific parts of a program so that they can be fixed by software developers.  They use data on the values taken on by program variables together with failure/success labels to do this.\n\nNUMFL-DLRM, NUMFL-QRM, NUMFL-CBPS are based on generalized propensity scores (GPS), which generalize to numeric treatment variables the standard propensity scores commonly used in causal inference with dichotomous treatment variables.  A generalized propensity score is and estimate of the probability of a given treatment value given the values of covariates.   CounterFault and Unival, on the other hand, are based on prediction of counterfactual outcomes with the aid of machine learning models trained with outcome, treatment, and covariate data.  In our proposed value-based CSFL techniques, the outcome variable is an indicator of program failures, the treatment variable is a program variable that is assigned a value at a given statement, and the covariates are the program variables whose values are used in that statement.  \n\nUnlike most statistical  fault localization techniques, which are based on analysis of code-coverage profiles and produce misleading results due to confounding bias, our VB-CSFL techniques analyze variable-value profiles using sound causal-inference techniques in order to minimize confounding.  Unival transforms the program under analysis so that branch and loop predicate outcomes become variable values, so that it can be applied to both variable assignments and predicates.  It essentially bins or clusters variable values and selects representative values from each bin.  This helps to ensure that an important propery for causal inference, known as positivity, holds.  It is satisfied if the probability of each possible treatment value is positive given a set of possible covariate values.  Unival uses execution data from a set of executions to train a machine learning model for predicting execution success or failure based on the values used and defined at a statement.  It then uses this model to predict the counterfactual execution outcomes (pass/fail) under changes to the value computed at the statement.  That is, Unival simulates the effects of value replacement.\n\n \n\n\t\t\t\t\tLast Modified: 01/06/2022\n\n\t\t\t\t\tSubmitted by: H. Andy Podgurski"
 }
}