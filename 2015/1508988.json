{
 "awd_id": "1508988",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "UNS:Fluorescence light-field imaging with a lensless flexible fiber bundle",
 "cfda_num": "47.041",
 "org_code": "07020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leon Esterowitz",
 "awd_eff_date": "2015-06-01",
 "awd_exp_date": "2019-11-30",
 "tot_intn_awd_amt": 299997.0,
 "awd_amount": 299997.0,
 "awd_min_amd_letter_date": "2015-05-23",
 "awd_max_amd_letter_date": "2015-05-23",
 "awd_abstract_narration": "PI: Mertz, Jerome\r\nProposal: 1508988\r\n\r\nThe objective of this proposal is to build an ultraminiaturized imaging device that can be used to image at arbitrary depths within tissue, and to reach confined regions in samples that are difficult to access.\r\n\r\nA key feature of the device is that it will be able to focus to variable depths, even though it is lensless in design and contains no moving parts. The device can be used with any type of luminous object, such as fluorescence, bioluminescence or even white-light illuminated scenes.  The device is based on an invention the PI recently patented that enables high-throughput imaging through a single optical fiber. This uses the principle of a spread-spectrum encoder (SSE), wherein light-ray directions entering a fiber are converted into unique, broadband, fingerprint spectral codes that then propagate through the fiber to be detected and decoded at the other end. Because image information (i.e. ray directions) is converted into spectral information, this information becomes insensitive to fiber bending or motion, so that the technique can readily be used for microendoscopy applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CBET",
 "org_div_long_name": "Division of Chemical, Bioengineering, Environmental, and Transport Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jerome",
   "pi_last_name": "Mertz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jerome Mertz",
   "pi_email_addr": "jmertz@bu.edu",
   "nsf_id": "000090055",
   "pi_start_date": "2015-05-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Trustees of Boston University",
  "inst_street_address": "1 SILBER WAY",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173534365",
  "inst_zip_code": "022151703",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "TRUSTEES OF BOSTON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "THL6A6JLE1S7"
 },
 "perf_inst": {
  "perf_inst_name": "Trustees of Boston University",
  "perf_str_addr": "44 Cummington Mall",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021151300",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723600",
   "pgm_ele_name": "BioP-Biophotonics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "005E",
   "pgm_ref_txt": "Neuro-photonics"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 299997.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>There is an ever pressing need for parallel advances in imaging technology to address current limitations such as restricted depth penetration, capacity for volumetric imaging, etc.. Our goal has been to develop a miniaturized endoscope capable of performing fast 3D imaging in thick tissue. The range of applications of such a device is potentially considerable, particularly considering the rapid advances in optogenetics and genetic engineering of fluorescent proteins. For this grant, our focus has been on the development of an endomicroscope suitable for brain imaging in preclinical animal models, such as rodents.</p>\n<p>Our miniaturization strategy is based on a strategy we developed to transmit an image through a <span style=\"text-decoration: underline;\">single</span> optical fiber. &nbsp;Normally, image transmission through a single optical fiber is impossible because spatial information is scrambled upon propagation through the fiber. In our case, spatial (image) information is first converted into spectral information using the principle of spread-spectrum encoding (SSE) borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion (decoding) of the detected spectrum at the fiber output. In other words, no camera is involved, only a spectrograph (a device that measures the color-content of light). The light color-content is then decoded into an image with a computer. Importantly, no lens is involved as well, which is crucial for enabling miniaturization. &nbsp;</p>\n<p>We have demonstrated that the idea of using SSE to encode image information works reasonably well, but is hampered by two constraints. &nbsp;The first constraint is that the challenge of miniaturization of a SSE encoder to the size of a single fiber (a few tens of microns) is considerable, although not insurmountable. The second constraint is that the &ldquo;codes&rdquo; created by a SSE encoder, particularly when it is miniaturized, are redundant (overlapping) to a large degree, meaning that it is difficult to transmit a large number of independent pixels through a single fiber. In our case, we managed to transmit up to 80 pixels, corresponding to a 9x9 image. We emphasize that such imaging was performed though a single fiber, which, previously had been impossible for self-luminous objects.</p>\n<p>To address the problem of image transmission with few pixels, we proposed to parallelize our device and perform imaging through a thin fiber bundle instead of a single fiber. In addition, to address the problem of overlapping codes, we are developed, and are actively continuing to develop, new decoding algorithms based on the use of machine learning. The field of machine learning is rapidly evolving, and our research is ongoing. This NSF grant served as a critical Launchpad for this effort, which led to three publications, the training of two students, and an important advancement in our goal toward minimally invasive endoscopic imaging for biomedical applications.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/03/2020<br>\n\t\t\t\t\tModified by: Jerome&nbsp;Mertz</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThere is an ever pressing need for parallel advances in imaging technology to address current limitations such as restricted depth penetration, capacity for volumetric imaging, etc.. Our goal has been to develop a miniaturized endoscope capable of performing fast 3D imaging in thick tissue. The range of applications of such a device is potentially considerable, particularly considering the rapid advances in optogenetics and genetic engineering of fluorescent proteins. For this grant, our focus has been on the development of an endomicroscope suitable for brain imaging in preclinical animal models, such as rodents.\n\nOur miniaturization strategy is based on a strategy we developed to transmit an image through a single optical fiber.  Normally, image transmission through a single optical fiber is impossible because spatial information is scrambled upon propagation through the fiber. In our case, spatial (image) information is first converted into spectral information using the principle of spread-spectrum encoding (SSE) borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion (decoding) of the detected spectrum at the fiber output. In other words, no camera is involved, only a spectrograph (a device that measures the color-content of light). The light color-content is then decoded into an image with a computer. Importantly, no lens is involved as well, which is crucial for enabling miniaturization.  \n\nWe have demonstrated that the idea of using SSE to encode image information works reasonably well, but is hampered by two constraints.  The first constraint is that the challenge of miniaturization of a SSE encoder to the size of a single fiber (a few tens of microns) is considerable, although not insurmountable. The second constraint is that the \"codes\" created by a SSE encoder, particularly when it is miniaturized, are redundant (overlapping) to a large degree, meaning that it is difficult to transmit a large number of independent pixels through a single fiber. In our case, we managed to transmit up to 80 pixels, corresponding to a 9x9 image. We emphasize that such imaging was performed though a single fiber, which, previously had been impossible for self-luminous objects.\n\nTo address the problem of image transmission with few pixels, we proposed to parallelize our device and perform imaging through a thin fiber bundle instead of a single fiber. In addition, to address the problem of overlapping codes, we are developed, and are actively continuing to develop, new decoding algorithms based on the use of machine learning. The field of machine learning is rapidly evolving, and our research is ongoing. This NSF grant served as a critical Launchpad for this effort, which led to three publications, the training of two students, and an important advancement in our goal toward minimally invasive endoscopic imaging for biomedical applications.\n\n\t\t\t\t\tLast Modified: 03/03/2020\n\n\t\t\t\t\tSubmitted by: Jerome Mertz"
 }
}