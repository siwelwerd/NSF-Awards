{
 "awd_id": "1538374",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Stability Analysis of Large-Scale Nonlinear Systems using Parallel Computation",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032925365",
 "po_email": "jberg@nsf.gov",
 "po_sign_block_name": "Jordan Berg",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 280000.0,
 "awd_amount": 280000.0,
 "awd_min_amd_letter_date": "2015-08-26",
 "awd_max_amd_letter_date": "2015-08-26",
 "awd_abstract_narration": "As engineered systems grow in complexity, the difficulty of safe and reliable operation of these systems becomes more challenging. For example, consider the $15 billion international nuclear fusion reactor being built in Cadarache, France. Although the world has known for 60 years that it is possible to produce energy from nuclear fusion by heating plasma in a magnetic field, physicists have never been able to control the magnetic field accurately enough to produce significant amounts of power. The reason is that even the simplest models of magneto hydrodynamics involve more than 20 coupled nonlinear differential equations. Although algorithms for control have made great strides in recent years, control of systems of this complexity is still out of reach. This project will design new algorithms for control which use supercomputers and massively parallel computation in an attempt to enable the safe and reliable design of controllers for large complex systems such as describe plasma in a reactor.\r\n\r\nAt the heart of the project is a new way of using convex optimization to parameterize Lyapunov functions (a measure of energy). Specifically, while the well-known sum-of-squares parameterization of positive polynomials is convex, reliable and accurate for small-scale systems, it cannot be readily adapted to supercomputers and other forms of massively parallel computation. The essence of this project, then is to look for alternative mathematical parameterizations of Lyapunov functions which are convex and furthermore are amenable to parallel computation. Such alternatives exist in classical mathematical results by Handelman, Polya and Bernstein. The scope of work is to use those results to create parallel codes, which can study multiple coupled nonlinear equations and determine the best possible Lyapunov function fit within the mathematical Language of polynomials. The project will test these algorithms on cluster and parallel graphics processor computing machines and will be able to study nonlinear differential equations with up to 20 states. These algorithms will then be applied to discretized nonlinear partial differential equation representations of the magneto-hydrodynamics of plasma in a nuclear fusion reactor to obtain a function of energy which can then be used to design and test magnetic and radio frequency controllers which will reduce or eliminate magneto hydrodynamic instabilities. The algorithms developed can also be applied to any large nonlinear system, implying they can be used to improve understanding and control in applications such as chemical reactors, gene regulatory networks and communication satellites.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Peet",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Peet",
   "pi_email_addr": "mpeet@asu.edu",
   "nsf_id": "000511753",
   "pi_start_date": "2015-08-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "ERC 253",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852876106",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "756900",
   "pgm_ele_name": "Dynamics, Control and System D"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "030E",
   "pgm_ref_txt": "CONTROL SYSTEMS"
  },
  {
   "pgm_ref_code": "031E",
   "pgm_ref_txt": "MECHATRONICS"
  },
  {
   "pgm_ref_code": "032E",
   "pgm_ref_txt": "SENSORS AND ACTUATORS"
  },
  {
   "pgm_ref_code": "033E",
   "pgm_ref_txt": "Smart and responsive structures"
  },
  {
   "pgm_ref_code": "034E",
   "pgm_ref_txt": "Dynamical systems"
  },
  {
   "pgm_ref_code": "035E",
   "pgm_ref_txt": "NOISE, ACOUSTICS, VIBRATIONS"
  },
  {
   "pgm_ref_code": "8024",
   "pgm_ref_txt": "Complex Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 280000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Machine learning (ML) is the inductive reasoning step used in the synthesis of Artificial Intelligence (AI) to create models of the environment. By contrast analysis and control comprise a deductive reasoning step. Current algorithms for ML such as deep neural networks are very effective even with large data sets. However, deductive reasoning algorithms are not so advanced.&nbsp; In this project, convex optimization was used to create a set of algorithms which may be used for deductive reasoning for a large set of decision problems. Because these algorithm uses parallel computing, they can scale to large or complex models of the environment.</p>\n<p>In this project, these algorithms were applied to several decision problems. One of the problems was to deduce patterns in environmental data, much as the mind develops specialized filters for shapes, voices, people, etc. These optimized pattern filters, represented as kernels, can then be used by the AI to create specialized ML algorithms.</p>\n<p>In another application, models of the environment were used to deduce maximal regions of safety and find optimal paths around obstacles for wheeled and aerial vehicles. These algorithms were also applied to optimizing the operation of home batteries such as for a plug-in hybrid or a Tesla Powerwall.</p>\n<p>A third application considered a variation on the inductive reasoning of ML to random events such as traffic density, consumer preferences, and electricity consumption. In standard ML algorithms, the induced hypothesis is one of certainty - e.g. small cars drive 50mph (note: A gaussian distribution is sometimes used in ML to represent random events). By contrast algorithms developed in this project allow the AI to hypothesize arbitrary probability distributions - e.g. small green cars move at 40-60mph with 20\\% chance,&nbsp; less that 40mph with 40\\% chance and&nbsp; greater than 60mph with 40\\% chance. These types of models allows the AI to develop improved models of the environment.</p>\n<p>To summarize, this project has reduced the gap between inductive and deductive reasoning for AI. The algorithms developed are based on convex optimization and scale to large and complex datasets. These algorithms have been applied to analysis and control of complex nonlinear decision problems such as automated vehicle guidance, renewable energy integration via batteries, and bioinformatics. This project has supported multiple graduate students and a major collaborative effort between ASU, NASA, and the University of Campinas in Brasil. We conclude that continued synergy between ML and decision problems is crucial for creating the next generation of AI.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2019<br>\n\t\t\t\t\tModified by: Matthew&nbsp;Peet</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1538374/1538374_10392507_1575267590418_path_planning--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1538374/1538374_10392507_1575267590418_path_planning--rgov-800width.jpg\" title=\"Path Planning with Obstacle Avoidance\"><img src=\"/por/images/Reports/POR/2019/1538374/1538374_10392507_1575267590418_path_planning--rgov-66x44.jpg\" alt=\"Path Planning with Obstacle Avoidance\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An optimal path planning algorithm for a nonlinear model of Dubin's car. Vehicle terminates in blue safety zone.</div>\n<div class=\"imageCredit\">M. Jones and M. Peet. A Generalization of Bellman\ufffds Equation for Path Planning, Obstacle Avoidance and Invariant Set Estimation</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Matthew&nbsp;Peet</div>\n<div class=\"imageTitle\">Path Planning with Obstacle Avoidance</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1538374/1538374_10392507_1575267959547_YinYang_Raw--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1538374/1538374_10392507_1575267959547_YinYang_Raw--rgov-800width.jpg\" title=\"Sliced Normal Probability Distribution\"><img src=\"/por/images/Reports/POR/2019/1538374/1538374_10392507_1575267959547_YinYang_Raw--rgov-66x44.jpg\" alt=\"Sliced Normal Probability Distribution\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An estimate of the probability distribution of a sequence of random events learned from a large dataset using convex optimization.</div>\n<div class=\"imageCredit\">B. Colbert, L. Crespo, and M. Peet. Improving the Uncertainty Quantification of Sliced Normal Distributions by Scaling the Covariance Matrix ACC 2020</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Matthew&nbsp;Peet</div>\n<div class=\"imageTitle\">Sliced Normal Probability Distribution</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nMachine learning (ML) is the inductive reasoning step used in the synthesis of Artificial Intelligence (AI) to create models of the environment. By contrast analysis and control comprise a deductive reasoning step. Current algorithms for ML such as deep neural networks are very effective even with large data sets. However, deductive reasoning algorithms are not so advanced.  In this project, convex optimization was used to create a set of algorithms which may be used for deductive reasoning for a large set of decision problems. Because these algorithm uses parallel computing, they can scale to large or complex models of the environment.\n\nIn this project, these algorithms were applied to several decision problems. One of the problems was to deduce patterns in environmental data, much as the mind develops specialized filters for shapes, voices, people, etc. These optimized pattern filters, represented as kernels, can then be used by the AI to create specialized ML algorithms.\n\nIn another application, models of the environment were used to deduce maximal regions of safety and find optimal paths around obstacles for wheeled and aerial vehicles. These algorithms were also applied to optimizing the operation of home batteries such as for a plug-in hybrid or a Tesla Powerwall.\n\nA third application considered a variation on the inductive reasoning of ML to random events such as traffic density, consumer preferences, and electricity consumption. In standard ML algorithms, the induced hypothesis is one of certainty - e.g. small cars drive 50mph (note: A gaussian distribution is sometimes used in ML to represent random events). By contrast algorithms developed in this project allow the AI to hypothesize arbitrary probability distributions - e.g. small green cars move at 40-60mph with 20\\% chance,  less that 40mph with 40\\% chance and  greater than 60mph with 40\\% chance. These types of models allows the AI to develop improved models of the environment.\n\nTo summarize, this project has reduced the gap between inductive and deductive reasoning for AI. The algorithms developed are based on convex optimization and scale to large and complex datasets. These algorithms have been applied to analysis and control of complex nonlinear decision problems such as automated vehicle guidance, renewable energy integration via batteries, and bioinformatics. This project has supported multiple graduate students and a major collaborative effort between ASU, NASA, and the University of Campinas in Brasil. We conclude that continued synergy between ML and decision problems is crucial for creating the next generation of AI.\n\n\t\t\t\t\tLast Modified: 12/02/2019\n\n\t\t\t\t\tSubmitted by: Matthew Peet"
 }
}