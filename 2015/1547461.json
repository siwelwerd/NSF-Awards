{
 "awd_id": "1547461",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EARS: Utilizing Diverse Spectrum Bands in Cellular Networks - A Unified Information Learning and  Decision Making Approach",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alexander Sprintson",
 "awd_eff_date": "2016-01-01",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 353831.0,
 "awd_amount": 353831.0,
 "awd_min_amd_letter_date": "2015-09-15",
 "awd_max_amd_letter_date": "2015-09-15",
 "awd_abstract_narration": "Driven by the skyrocketing demand for high data-rate mobile services and enabled by regulatory and technology advances, cellular service providers are augmenting or in the processing of  augmenting their own licensed spectrum with a variety of supplemental bands, including unlicensed bands, lightly-licensed bands, secondary bands, and high frequency bands. This project studies how to effectively utilize such bands, in particular, how to learn the service availability and quality on different spectrum bands, and how to effectively use these bands under budget constraints. To address this challenge, the researchers propose a joint information learning and decision making framework with context and under budget. This mathematical framework connects two important yet mostly independently studied research areas, information learning and optimal decision making. The investigation provides important insights in understanding, designing, and analyzing joint information learning and decision making algorithms. In addition, because the generality and importance of such problems, the proposed approaches can be applied in other areas, such as wireless network control, crowd-sourcing, and online-ad allocation.\r\n\r\nWhile an intuitive approach, it is challenging to design the joint learning and decision algorithms and to analyze their performance because budget constraints introduce coupling among contexts and across time; and the information learning and  decision making  are closely coupled and jointly evolving processes. This project consists of three main thrusts: 1) General framework: The researchers strive for not only the fundamental understanding of joint learning and decision, but also algorithms with practical simplicity and theoretical performance guarantees. Such algorithms enable efficient supplemental spectrum utilization in cellular networks; 2) Sparsity and Structure: Context information, such as time, location, and application type, provides useful information in selecting the appropriate supplemental bands. However, the learning curve (cost) increases as the number of context-action pairs increases. The researchers develop algorithms that can accelerate the learning by exploiting the domain knowledge, system structure, and compressing techniques; and 3) Practical Issues: When considering the dynamic spectrum accessing in real wireless networks, practical issues arise. In particular, the researchers study non-stationary systems where the system statistics vary over time, and warm-start systems where certain prior information is available.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xin",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xin Liu",
   "pi_email_addr": "liu@cs.ucdavis.edu",
   "nsf_id": "000289050",
   "pi_start_date": "2015-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California",
  "perf_str_addr": "One Shields Ave.",
  "perf_city_name": "Davis",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956165291",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "797600",
   "pgm_ele_name": "EARS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7976",
   "pgm_ref_txt": "EARS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 353831.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>To achieve the goal of efficient spectrum utilization, in this project, we investigate a joint information-learning and decision-making framework. The key challenge is to understand and balance the fundamental exploration-exploitation tradeoff in joint information learning and decision making under various conditions. Our investigation provides important insights in understanding, designing, and analyzing joint information learning and decision-making algorithms, both from theoretical aspects and in practical application scenarios.</p>\n<p>In this project, we propose and investigate opportunistic learning. Our key motivation is that the cost or regret of performing a suboptimal action varies under different environmental conditions, such as network load. When the load is low, so is the cost/regret of performing a suboptimal action (e.g., trying a suboptimal network configuration when the traffic load is). We propose an Adaptive Upper-Confidence-Bound (AdaUCB) algorithm to adaptively balance the exploration-exploitation tradeoff for opportunistic bandits. We theoretically analyze the performance guarantees of AdaUCB that proves the effectiveness of opportunistic learning. Furthermore, based on both synthetic data and real-world traces, experimental results show that AdaUCB significantly outperforms other bandit algorithms, such as UCB and TS (Thompson Sampling), under large load fluctuations.</p>\n<p>Furthermore, we develop a number of joint learning and decision-making algorithms for cellular network configuration. Cellular network configuration plays a critical role in efficient spectrum utilization and network performance. In current practice, network configuration depends heavily on field experience of engineers and often remains static for a long period of time. This practice is far from optimal. To address this limitation, we have developed various learning-based approaches that integrate information learning and decision making. We face the challenges of learning a highly complex function with a relatively small number of samples at each base station, which highlights the importance of balancing the fundamental exploration-exploitation tradeoff in joint information learning and decision making. Fortunately, in cellular networks, base stations (BSs) often have similarities even though they are not identical. To leverage such similarities, we develop a number of algorithms.</p>\n<p>1) We develop a neural-network-based model that learns the function between the network configuration and the network performance. Based on the learned function, we formulate a global network configuration optimization problem. To solve this high-dimensional nonconcave maximization problem, we design a Gibbs-sampling based algorithm that converges to an optimal solution. Furthermore, we design an online scheme that updates the learned utility function and solves the corresponding maximization problem efficiently to adapt to network dynamics. The advantage of this approach is its ability to handle interference among cells. The limitation is that it treats all cells identify.</p>\n<p>2) We propose a collaborative learning approach to leverage data from different cells to boost the learning efficiency and to improve network performance. Specifically, we formulate the problem as a transferable contextual bandit problem, and prove that by transfer learning, one could significantly reduce the regret bound. Based on the theoretical result, we further develop a practical algorithm that decomposes a cell?s policy into a common homogeneous policy learned by all cells? data and a cell-specific policy that captures each individual cell?s heterogeneous behavior. In a live field test, conducted on a real metropolitan cellular network consisting 1700+ cells to optimize 5 parameters for 2 weeks, our proposed algorithm shows a significant performance improvement of 20%. This is the only algorithm evaluated in large field test.</p>\n<p>3) We develop a kernel-based multi-BS contextual bandit algorithm based on multi-task learning. We define the task/BS similarity space as the conditional probability space, and measure the similarity between the tasks using conditional kernel embedding. Then we train a prediction function &nbsp;based on kernel ridge regression using data from all BSs. Last, based on the value and uncertainty of the prediction, we calculate the upper confident bound (UCB) of each arm for each BS to guide its configuration. We evaluate the effectiveness of our algorithm based on a simulator built by real traces collected in cellular network operation, and show a 35% performance improvement (measured in terms of regret). Furthermore, we present theoretical analysis of the proposed algorithm in terms of regret and multi-task-learning efficiency: our proposed algorithm achieves a square-root regret bound and the regret bound is tighter when the BSs/tasks are similar. The algorithm provides a systematic way to identify and leverage similarities.</p>\n<p>Furthermore, using the insights obtained from the cellular network configuration problem, we also study configuration optimization in large software systems. Similarly, a key challenge is to effectively balance the tradeoff of exploration and exploitation in joint information learning and decision making. This is especially important because obtaining additional samples is expensive. Along this line, we develop a number of algorithms based on various learning techniques and domain knowledge, including using a smaller testbed to obtain coarse-grained training samples in a larger quantify and leveraging comparison-based models that are more robust to estimation errors.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/10/2020<br>\n\t\t\t\t\tModified by: Xin&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTo achieve the goal of efficient spectrum utilization, in this project, we investigate a joint information-learning and decision-making framework. The key challenge is to understand and balance the fundamental exploration-exploitation tradeoff in joint information learning and decision making under various conditions. Our investigation provides important insights in understanding, designing, and analyzing joint information learning and decision-making algorithms, both from theoretical aspects and in practical application scenarios.\n\nIn this project, we propose and investigate opportunistic learning. Our key motivation is that the cost or regret of performing a suboptimal action varies under different environmental conditions, such as network load. When the load is low, so is the cost/regret of performing a suboptimal action (e.g., trying a suboptimal network configuration when the traffic load is). We propose an Adaptive Upper-Confidence-Bound (AdaUCB) algorithm to adaptively balance the exploration-exploitation tradeoff for opportunistic bandits. We theoretically analyze the performance guarantees of AdaUCB that proves the effectiveness of opportunistic learning. Furthermore, based on both synthetic data and real-world traces, experimental results show that AdaUCB significantly outperforms other bandit algorithms, such as UCB and TS (Thompson Sampling), under large load fluctuations.\n\nFurthermore, we develop a number of joint learning and decision-making algorithms for cellular network configuration. Cellular network configuration plays a critical role in efficient spectrum utilization and network performance. In current practice, network configuration depends heavily on field experience of engineers and often remains static for a long period of time. This practice is far from optimal. To address this limitation, we have developed various learning-based approaches that integrate information learning and decision making. We face the challenges of learning a highly complex function with a relatively small number of samples at each base station, which highlights the importance of balancing the fundamental exploration-exploitation tradeoff in joint information learning and decision making. Fortunately, in cellular networks, base stations (BSs) often have similarities even though they are not identical. To leverage such similarities, we develop a number of algorithms.\n\n1) We develop a neural-network-based model that learns the function between the network configuration and the network performance. Based on the learned function, we formulate a global network configuration optimization problem. To solve this high-dimensional nonconcave maximization problem, we design a Gibbs-sampling based algorithm that converges to an optimal solution. Furthermore, we design an online scheme that updates the learned utility function and solves the corresponding maximization problem efficiently to adapt to network dynamics. The advantage of this approach is its ability to handle interference among cells. The limitation is that it treats all cells identify.\n\n2) We propose a collaborative learning approach to leverage data from different cells to boost the learning efficiency and to improve network performance. Specifically, we formulate the problem as a transferable contextual bandit problem, and prove that by transfer learning, one could significantly reduce the regret bound. Based on the theoretical result, we further develop a practical algorithm that decomposes a cell?s policy into a common homogeneous policy learned by all cells? data and a cell-specific policy that captures each individual cell?s heterogeneous behavior. In a live field test, conducted on a real metropolitan cellular network consisting 1700+ cells to optimize 5 parameters for 2 weeks, our proposed algorithm shows a significant performance improvement of 20%. This is the only algorithm evaluated in large field test.\n\n3) We develop a kernel-based multi-BS contextual bandit algorithm based on multi-task learning. We define the task/BS similarity space as the conditional probability space, and measure the similarity between the tasks using conditional kernel embedding. Then we train a prediction function  based on kernel ridge regression using data from all BSs. Last, based on the value and uncertainty of the prediction, we calculate the upper confident bound (UCB) of each arm for each BS to guide its configuration. We evaluate the effectiveness of our algorithm based on a simulator built by real traces collected in cellular network operation, and show a 35% performance improvement (measured in terms of regret). Furthermore, we present theoretical analysis of the proposed algorithm in terms of regret and multi-task-learning efficiency: our proposed algorithm achieves a square-root regret bound and the regret bound is tighter when the BSs/tasks are similar. The algorithm provides a systematic way to identify and leverage similarities.\n\nFurthermore, using the insights obtained from the cellular network configuration problem, we also study configuration optimization in large software systems. Similarly, a key challenge is to effectively balance the tradeoff of exploration and exploitation in joint information learning and decision making. This is especially important because obtaining additional samples is expensive. Along this line, we develop a number of algorithms based on various learning techniques and domain knowledge, including using a smaller testbed to obtain coarse-grained training samples in a larger quantify and leveraging comparison-based models that are more robust to estimation errors.\n\n \n\n\t\t\t\t\tLast Modified: 03/10/2020\n\n\t\t\t\t\tSubmitted by: Xin Liu"
 }
}