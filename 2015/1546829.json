{
 "awd_id": "1546829",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Automated Content-Based Detection of Public Online Harrassment",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928950",
 "po_email": "rwachter@nsf.gov",
 "po_sign_block_name": "Ralph Wachter",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2016-12-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2015-07-09",
 "awd_max_amd_letter_date": "2015-07-09",
 "awd_abstract_narration": "Public, online harassment takes many forms, but at its core are posts that are  offensive, threatening, and intimidating.  It is not an isolated problem. The Pew Research Center found 73% of people had witnessed harassment online, and a full 40% of people had experienced harassment directly. This research develops a method for analyzing the things people post online, and automatically detecting which posts fall into the category of severe public online harassment -- messages posted simply to disrupt, offend, or threaten others. This helps websites better limit what messages are posted and reduce the amount of harassment people experience online.\r\n\r\nThe researchers develop a corpus of online comments from a number of media outlets and social media platforms where each post is labeled as harassing or non-harassing. Then, they apply a set of computational linguistic techniques that describe features of the message, including types of words and language structure, which is passed to rule-based and machine learning artificial intelligence systems for classification. The goal is to develop models that can automatically detect the public online harassment messages with high accuracy.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jennifer",
   "pi_last_name": "Golbeck",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Jennifer A Golbeck",
   "pi_email_addr": "jgolbeck@umd.edu",
   "nsf_id": "000303189",
   "pi_start_date": "2015-07-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207420001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was designed to start analyzing comments online that constitute harassment. While this is something most of us can identify when we see it, it is important to have clear definitions and examples so researchers can proceed focused on the same problem.</p>\n<p>We created and defined a set of sub-types of online harassment, including threats, hate speech, and targeted harassment. Researchers working on this project underwent training to come to a consensus about what comments constituted harassment. This was done through group discussions; the definition was not dictated, but rather arose through reading and considering many comments. The details of these definitions are part of our products from this work and will help other researchers work from a common set of definitions when they undertake their own projects.</p>\n<p>&nbsp;We then collected and labeled 35,000 comments as harassing or not. Each comment was labeled by at least two people and only given a label when there was majority agreement.</p>\n<p>This data will be useful for future research because it will help organizations design algorithms that can automatically detect harassing comments. This would support features like a harassment filter that a user could turn on to block these types of comments on social media or in comment sections on news sites. It will also help researchers who want to analyze the structure of harassing language which may lead to improved algorithms and understanding down the line.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/01/2017<br>\n\t\t\t\t\tModified by: Jennifer&nbsp;A&nbsp;Golbeck</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project was designed to start analyzing comments online that constitute harassment. While this is something most of us can identify when we see it, it is important to have clear definitions and examples so researchers can proceed focused on the same problem.\n\nWe created and defined a set of sub-types of online harassment, including threats, hate speech, and targeted harassment. Researchers working on this project underwent training to come to a consensus about what comments constituted harassment. This was done through group discussions; the definition was not dictated, but rather arose through reading and considering many comments. The details of these definitions are part of our products from this work and will help other researchers work from a common set of definitions when they undertake their own projects.\n\n We then collected and labeled 35,000 comments as harassing or not. Each comment was labeled by at least two people and only given a label when there was majority agreement.\n\nThis data will be useful for future research because it will help organizations design algorithms that can automatically detect harassing comments. This would support features like a harassment filter that a user could turn on to block these types of comments on social media or in comment sections on news sites. It will also help researchers who want to analyze the structure of harassing language which may lead to improved algorithms and understanding down the line.\n\n\t\t\t\t\tLast Modified: 03/01/2017\n\n\t\t\t\t\tSubmitted by: Jennifer A Golbeck"
 }
}