{
 "awd_id": "1522765",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research:  Random Dynamics on Networks",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2015-08-15",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2015-08-10",
 "awd_max_amd_letter_date": "2017-08-17",
 "awd_abstract_narration": "Transport and distribution networks come in a number of forms, from animal cardiovascular and respiratory systems to communication and industrial infrastructures. Practical issues abound: prediction of local spikes, estimation of perfusion, and impact of structural changes such as vessel occlusion. The complexity of such phenomena can be illustrated by the well-known Braess' paradox: adding links to a transportation network might not improve the operation of the system! In spite of recent successes, our understanding of network flows is usually limited to small deterministic problems, while most applications correspond to large uncertain ones. The goal of this project is to enable improved predictions in biological and technological transport and diffusion networks. For instance, can one predict how cerebral blood flow will be affected if one of the carotids becomes narrow or blocked? Will the vasculature allow for re-routing? If so, with what probability and how fast? \r\n \r\nThe main challenge in this research project is the presence of uncertainties. For many applications, only partial information about the systems is available. For instance the size or even the presence of a specific vessel might be uncertain or the status of a router unknown. The analysis of such problems requires the creation of novel mathematical tools and numerical methods to describe how uncertainties propagate through vast and complex networks. The computational tools to be constructed will provide information, usually probabilistic in nature, regarding phenomena that are difficult, expensive, or impossible to measure.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pierre",
   "pi_last_name": "Gremaud",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Pierre A Gremaud",
   "pi_email_addr": "gremaud@math.ncsu.edu",
   "nsf_id": "000382636",
   "pi_start_date": "2015-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "2701 Sullivan Drive",
  "perf_city_name": "Raleigh",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276958205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 79784.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 82050.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 88166.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The initial goals of this project were to develop predictive models for transport problems on networks, the two main challenges being (i) how to handle&nbsp;&nbsp;</span><span>large scale&nbsp;</span><span>networks and (ii) how to deal with&nbsp;</span><span>uncertainties&nbsp;</span><span>about the network structures. These two challenges are encountered in most applications of interest from both the life sciences (as in blood flow circulation) and within the realm of technical applications (as in power grids).</span></p>\n<p>Agregation method or dimension reduction often <em>must</em> take place to obtain models that are amenable to computational study.&nbsp; As there is no generic approach to creating smaller, surrogate models, we started to study how to determine, among the input parameters of a large original model, which ones are \"important\". A significant part of our results therefore pertains to global sensitivity analysis.&nbsp;</p>\n<p>A natural approach, initiated by Sobol, is to consider the uncertain input parameters of a model as random variables and to assign to each parameter or group of parameters its relative contribution to the variance of the output. In that approach, uncertainty is roughly equated with variance. As part of this project, we have obtained&nbsp; significant advances in global sensitivity analysis.&nbsp;</p>\n<p>1. Most global sensitivity analysis methods yield confusing and often useless results if the input parameters are correlated; unfortunately, correlated inputs <em>is</em> the general case in practice. Switching the framework from probability to approximation theory, we have extended Sobol's original indices to the generic case of correlated parameters. In addition, this new framework also provides a direct and explicit link between sensitivity analysis and dimension reduction.</p>\n<p>2. All global sensivity analysis approaches require the knowledge of the input parameters' probability distributions. This is a delicate step as not only is this information rarely available (even nominal values are often unclear), the distribution choices have an effect of the sensitivity analysis. To answer this challenge, we have developped approaches which, at essentially no additional cost, can make use of the samples needed for the original sensitivity analysis results and allow to quantify the robustness of the sensitivity analysis to the distribution \"guesses\".</p>\n<p>3. We have developed new methods to perform sensitivity analysis of time-dependent quantities of interest. The challenge is here that the \"yardstick\" (for instance, the variance of the quantity of interest) changes with time. Our approach resolves this issue and, additionally, respect causality.</p>\n<p>4. We have shown how to do sensitivity analysis for stochastic models. The challenge is here that there are two sources of randomness: one attached the intrinsic stochasticty of the models, the other is attached to the uncertainties on the parameters themselves. Mathematically, the two operations of \"taking a moment\" and \"doing sensivitivity analysis\" do not commute. We consider instead the sensitivity indices themselves as random variables&nbsp; and compute their statistical properties.&nbsp;</p>\n<p>On the application side, we have concentrated on two types of problems. First, we have considered state-of-the-art neurovascular models. These are large models taking into account phenomena ranging from detailed chemistry to neuron firing models. The goal of the physiologists is to reach a better understanding of the complex control mechanisms governing blood flow in general and, more specifically, of how the radii of key arteries react to various stimuli. Mathematically, these models correspond to large systems of differential-algebraic equations with hundreds of uncertain parameters. We have developed multistep methods to first trim down the number of parameters to a size allowing for global sensitivity analysis and then employ appropriate sensitivy analysis techniques. This first screening step consists in identify the non-important parameters; in that sense, and in the words in another researcher, <em>non-importance is important! </em>Our methods and results have allowed for the effective&nbsp; refinement of several neurovascular coupling models.&nbsp;</p>\n<p>A second type of applications we considered are chemical reaction networks. These problems are widely studied because of their practical importance. Essentially, the goal is there to predict the evolution of a collection molecules of multiple species susceptible to undergo a certain number of reactions. These problems admit microscopic stochastic&nbsp; discrete-time models, mesoscopic stochastic continuous-time models and macroscopic deterministic models; each step in this progression corresponds to decreasing costs and but also to poorer information. It is worth noting that the deterministic model/surrogate (reaction rate equation model) is not obtained from the stochastic ones through averaging. Instead, the limiting process involved here is the thermodynamic limit. We have shown that the two operations of taking the thermodynamic limit and computing Sobol sensivity indices commute. The consequence of this is that a simple deterministic model can in this case be used to perform sensitivity analysis of costly microscopic models.&nbsp;</p>\n<p>Sensitivity analysis of complex models is routinely done on simplified surrogate models with the <em>hope </em>that the results will be correct. Our results on chemical reaction networks are the first of their type proving the validity of the approach in a specific setting.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/01/2019<br>\n\t\t\t\t\tModified by: Pierre&nbsp;A&nbsp;Gremaud</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe initial goals of this project were to develop predictive models for transport problems on networks, the two main challenges being (i) how to handle  large scale networks and (ii) how to deal with uncertainties about the network structures. These two challenges are encountered in most applications of interest from both the life sciences (as in blood flow circulation) and within the realm of technical applications (as in power grids).\n\nAgregation method or dimension reduction often must take place to obtain models that are amenable to computational study.  As there is no generic approach to creating smaller, surrogate models, we started to study how to determine, among the input parameters of a large original model, which ones are \"important\". A significant part of our results therefore pertains to global sensitivity analysis. \n\nA natural approach, initiated by Sobol, is to consider the uncertain input parameters of a model as random variables and to assign to each parameter or group of parameters its relative contribution to the variance of the output. In that approach, uncertainty is roughly equated with variance. As part of this project, we have obtained  significant advances in global sensitivity analysis. \n\n1. Most global sensitivity analysis methods yield confusing and often useless results if the input parameters are correlated; unfortunately, correlated inputs is the general case in practice. Switching the framework from probability to approximation theory, we have extended Sobol's original indices to the generic case of correlated parameters. In addition, this new framework also provides a direct and explicit link between sensitivity analysis and dimension reduction.\n\n2. All global sensivity analysis approaches require the knowledge of the input parameters' probability distributions. This is a delicate step as not only is this information rarely available (even nominal values are often unclear), the distribution choices have an effect of the sensitivity analysis. To answer this challenge, we have developped approaches which, at essentially no additional cost, can make use of the samples needed for the original sensitivity analysis results and allow to quantify the robustness of the sensitivity analysis to the distribution \"guesses\".\n\n3. We have developed new methods to perform sensitivity analysis of time-dependent quantities of interest. The challenge is here that the \"yardstick\" (for instance, the variance of the quantity of interest) changes with time. Our approach resolves this issue and, additionally, respect causality.\n\n4. We have shown how to do sensitivity analysis for stochastic models. The challenge is here that there are two sources of randomness: one attached the intrinsic stochasticty of the models, the other is attached to the uncertainties on the parameters themselves. Mathematically, the two operations of \"taking a moment\" and \"doing sensivitivity analysis\" do not commute. We consider instead the sensitivity indices themselves as random variables  and compute their statistical properties. \n\nOn the application side, we have concentrated on two types of problems. First, we have considered state-of-the-art neurovascular models. These are large models taking into account phenomena ranging from detailed chemistry to neuron firing models. The goal of the physiologists is to reach a better understanding of the complex control mechanisms governing blood flow in general and, more specifically, of how the radii of key arteries react to various stimuli. Mathematically, these models correspond to large systems of differential-algebraic equations with hundreds of uncertain parameters. We have developed multistep methods to first trim down the number of parameters to a size allowing for global sensitivity analysis and then employ appropriate sensitivy analysis techniques. This first screening step consists in identify the non-important parameters; in that sense, and in the words in another researcher, non-importance is important! Our methods and results have allowed for the effective  refinement of several neurovascular coupling models. \n\nA second type of applications we considered are chemical reaction networks. These problems are widely studied because of their practical importance. Essentially, the goal is there to predict the evolution of a collection molecules of multiple species susceptible to undergo a certain number of reactions. These problems admit microscopic stochastic  discrete-time models, mesoscopic stochastic continuous-time models and macroscopic deterministic models; each step in this progression corresponds to decreasing costs and but also to poorer information. It is worth noting that the deterministic model/surrogate (reaction rate equation model) is not obtained from the stochastic ones through averaging. Instead, the limiting process involved here is the thermodynamic limit. We have shown that the two operations of taking the thermodynamic limit and computing Sobol sensivity indices commute. The consequence of this is that a simple deterministic model can in this case be used to perform sensitivity analysis of costly microscopic models. \n\nSensitivity analysis of complex models is routinely done on simplified surrogate models with the hope that the results will be correct. Our results on chemical reaction networks are the first of their type proving the validity of the approach in a specific setting. \n\n\t\t\t\t\tLast Modified: 12/01/2019\n\n\t\t\t\t\tSubmitted by: Pierre A Gremaud"
 }
}