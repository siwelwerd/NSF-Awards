{
 "awd_id": "1456154",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Representation and Deep Learning for Free Text Applications",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2015-03-01",
 "awd_exp_date": "2019-05-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 943539.0,
 "awd_min_amd_letter_date": "2015-02-18",
 "awd_max_amd_letter_date": "2019-03-04",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase II project derives from an enhanced capability for automated processing of free text and other structured data.  Motivation for this approach comes from neural networks and, in turn, it has applications to neural modeling and our understanding of how the brain processes information.  In the software industry, commercial innovation continues to revolve around automated processing of web pages, which plays a key role in creating many new companies.  Therefore, the ability to automate decision-making from free text is increasing in importance. A better way to represent text for use with machine learning will open new capabilities wherever the structure of sentences must be taken into account.  This has the potential to lead to new startup ventures, thereby resulting in new products and services. A successful project will result in platform technology that can provide a substantial competitive edge to companies that take advantage of it, provide new and better capabilities for consumers, and help advance the nation's lead in technological innovation.\r\n\r\nThis Small Business Innovation Research (SBIR) Phase II project seeks to further develop new ways to process textual material so that computers can better learn applications related to natural language.  Applications include sentiment analysis (assigning either positive or negative views to a body of text), summarization of documents, and classification of documents using multiple labels from a fixed set of many classes.  The project will further develop new techniques to improve performance, and prototype components for transforming text and applying computerized learning methods. The new techniques represent words simultaneously with document structure using a single high-dimensional vector (for example, a list of 1,000 numbers).  The project is aimed at improving computational capabilities involving documents, web pages, and other text as well as providing new techniques that can be applied to automated translation, better computer understanding of images, and genomic information.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Gallant",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen Gallant",
   "pi_email_addr": "sgallant@mmres.com",
   "nsf_id": "000646509",
   "pi_start_date": "2015-02-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Textician, LLC",
  "inst_street_address": "51 FENNO ST",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6176424959",
  "inst_zip_code": "021386717",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "TEXTICIAN, LLC",
  "org_prnt_uei_num": "",
  "org_uei_num": "N1GDCE2JLLH9"
 },
 "perf_inst": {
  "perf_inst_name": "MULTIMODEL RESEARCH LLC",
  "perf_str_addr": "51 Fenno St.",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021386737",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "165E",
   "pgm_ref_txt": "SBIR Phase IIB"
  },
  {
   "pgm_ref_code": "169E",
   "pgm_ref_txt": "SBIR Tech Enhan Partner (TECP)"
  },
  {
   "pgm_ref_code": "5373",
   "pgm_ref_txt": "SMALL BUSINESS PHASE II"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  },
  {
   "pgm_ref_code": "8039",
   "pgm_ref_txt": "Information, Communication & Computing"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 690450.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 138089.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 115000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Free-text includes news stories, Doctor&rsquo;s notes, web pages, financial analyst reports and many other sources.&nbsp; Such text is quite important; for example, it comprises an estimated 70% of the information in our Electronic Health Records.&nbsp; Text is easy for humans to work with but it is hard for computers to use, because of synonyms, varying text lengths, and the many subtleties of language.</p>\n<p>Our project focused upon making text more usable for predictive models by computer.&nbsp; The technology we developed represents text of varying lengths by a single list of 300 numbers, where information is distributed over all of the numbers (much like a hologram negative).&nbsp; This representation makes different length text examples look like a single row in a conventional database, which greatly eases follow-on machine learning.</p>\n<p>An important application of our technology is Computer-Assisted Coding (CAC).&nbsp; This involves summarizing a patient&rsquo;s Electronic Health Record by selecting medical (ICD-10) codes from about 50,000 such codes.&nbsp; This selection of ICD-10 codes is required for reimbursement for services, as well as for generating overall medical statistics.&nbsp; Tens of thousands of skilled medical coders are involved in summarizing free text by ICD-10 medical codes.</p>\n<p>Our technology and software can predict likely codes to help and speed human coders by learning from past examples of human-generated codes.&nbsp; Using our representations of text to help machine learning algorithms create CAC software is enormously easier than employing hundreds of thousands of human-generated rules to get CAC software.&nbsp; It is also more flexible, easier to maintain, faster, and more accurate.</p>\n<p>Another example is learning to predict sepsis and other diseases from the text for past cases in a patient&rsquo;s Electronic Health Record.&nbsp; As part of this project we worked with colleagues at Baystate Health (Springfield, MA) to demonstrate the ability to predict severe sepsis from just text in the EHR.</p>\n<p>Technology and software developed in this SBIR project are being used to suggest disease codes, with current implementations underway in several hospitals.</p>\n<p>-- The broader technical impact of this R&amp;D is encouraging further use of machine learning with text for healthcare, financial and other applications</p>\n<p>&nbsp;--The broader social impact is improved utilization for medical text, leading to better care and reduced healthcare costs.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/05/2019<br>\n\t\t\t\t\tModified by: Stephen&nbsp;Gallant</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nFree-text includes news stories, Doctor?s notes, web pages, financial analyst reports and many other sources.  Such text is quite important; for example, it comprises an estimated 70% of the information in our Electronic Health Records.  Text is easy for humans to work with but it is hard for computers to use, because of synonyms, varying text lengths, and the many subtleties of language.\n\nOur project focused upon making text more usable for predictive models by computer.  The technology we developed represents text of varying lengths by a single list of 300 numbers, where information is distributed over all of the numbers (much like a hologram negative).  This representation makes different length text examples look like a single row in a conventional database, which greatly eases follow-on machine learning.\n\nAn important application of our technology is Computer-Assisted Coding (CAC).  This involves summarizing a patient?s Electronic Health Record by selecting medical (ICD-10) codes from about 50,000 such codes.  This selection of ICD-10 codes is required for reimbursement for services, as well as for generating overall medical statistics.  Tens of thousands of skilled medical coders are involved in summarizing free text by ICD-10 medical codes.\n\nOur technology and software can predict likely codes to help and speed human coders by learning from past examples of human-generated codes.  Using our representations of text to help machine learning algorithms create CAC software is enormously easier than employing hundreds of thousands of human-generated rules to get CAC software.  It is also more flexible, easier to maintain, faster, and more accurate.\n\nAnother example is learning to predict sepsis and other diseases from the text for past cases in a patient?s Electronic Health Record.  As part of this project we worked with colleagues at Baystate Health (Springfield, MA) to demonstrate the ability to predict severe sepsis from just text in the EHR.\n\nTechnology and software developed in this SBIR project are being used to suggest disease codes, with current implementations underway in several hospitals.\n\n-- The broader technical impact of this R&amp;D is encouraging further use of machine learning with text for healthcare, financial and other applications\n\n --The broader social impact is improved utilization for medical text, leading to better care and reduced healthcare costs.\n\n\t\t\t\t\tLast Modified: 06/05/2019\n\n\t\t\t\t\tSubmitted by: Stephen Gallant"
 }
}