{
 "awd_id": "1527568",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Size, Uncertainty, and Imprecision in Algorithmic Game Theory and Economics",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2015-07-29",
 "awd_max_amd_letter_date": "2015-07-29",
 "awd_abstract_narration": "Non-Technical Description\r\n\r\nAs is well known, settings with many interacting participants sometimes work well, for example in market economies, and other times can lead to poor outcomes, as in the Tragedy of the Commons. The hypothesis driving this project is that as the number of participants increases, if these participants have varied interests, then the poor outcomes will be mitigated, i.e. the Tragedy of the Commons becomes increasingly less tragic.  \r\n\r\nTo make this precise, one needs to be able to quantify the quality of the outcomes. One standard approach is to measure the social welfare, which is simply the sum of the values the participants achieve. The intent in this project is to compare the ideal social welfare to the social welfare that actually occurs. The ratio of these values is called the Price of Anarchy. The aim is to show that as the number of participants increases, these values will become increasingly close, i.e. that the Price of Anarchy approaches the ideal value of 1. Of course, this is only going to be true under appropriate conditions and one of the goals of the project is to identify such conditions.  \r\n\r\nWhy is this interesting? First, for settings with positive results, this will help explain why good results are achieved. Second, for other settings, it may indicate why poor outcomes are likely. In addition, it may suggest how to design or constrain settings so as to achieve improved results.  \r\n\r\nOne or more PhD students will participate in this project. In addition, the PI hopes to interest more junior students. A prime means to this end is to teach inviting undergraduate courses. One specific tool here is to create compelling course videos to complement classroom instruction and this is part of the plan for this project. Of course, such videos are valuable in their own right.\r\n\r\nTechnical Description\r\n\r\nA main concern of this project is to understand the impact of self-interested behavior (a.k.a. strategic behavior) on shared outcomes.  The PI wants to understand for which settings and to what extent size and uncertainty reduce the losses due to strategic behavior. These types of questions have been previously studied in the Economics literature, but by and large the ensuing results are in-the-limit statements. The intent for this project is to obtain quantified tradeoffs. Furthermore the aim is to identify settings for which these are polynomial tradeoffs, with the implication that the loss reduction is evident at moderate sizes.\r\n\r\nBy uncertainty, the PI is not simply referring to Bayesian settings, where there is uncertainty about participants' desires (utilities) -- in such settings, participants' utilities are given by draws from known distributions. There is a need for additional uncertainty, either as to the number of participants or to the resources being shared. In practice, it seems reasonable that this information would not be known exactly in large settings; furthermore, some such uncertainty appears to be necessary for positive results.\r\n\r\nSpecific questions the PI will seek to answer include:\r\n\r\n1. Is price-taking a plausible behavior in (some classes of) market economies, i.e. are the gains from strategic behavior small when the economy is large? A follow-up question is whether the resulting outcome, which may include small-gain strategic behavior, is close to the optimal outcome. (This is not an immediate implication of a positive answer to the first question.)\r\n\r\n2. For auctions with many copies of each good and many buyers, does uncertainty reduce the gains from strategic behavior, and again, is the resulting outcome close to optimal? In other words, does the Price of Anarchy for these settings tend to 1 as the setting size grows?\r\n\r\n3. Do results shown for market economies comprising idealized arbitrarily divisible goods extend approximately to indivisible goods, again when the setting sizes are large?\r\n\r\n4.  The outcomes being considered in 1-3 above are stable outcomes, a.k.a. equilibria, which have the property that no participant wishes they had used a different strategy. These are viewed as plausible outcomes, but leaves unanswered the question of how they are found. A natural approach is to consider dynamic behavior. Of course, this may change the ensuing outcomes. This leads to asking: for what settings do natural dynamics converge toward equilibria? Complicating matters further, one can imagine that settings change over time, leading to the question: for what not-too-rapidly changing settings can drifting (changing) equilibria be tracked? The PI will be seeking quantified relations between the rate of change and the closeness to equilibrium.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Cole",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Richard Cole",
   "pi_email_addr": "cole@cs.nyu.edu",
   "nsf_id": "000153865",
   "pi_start_date": "2015-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7932",
   "pgm_ref_txt": "COMPUT GAME THEORY & ECON"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many aspects of life involve the allocation of scarce resources, be it because they have a cost in money (their price), a cost in time (they require waiting in line), or because there is only a fractional chance of receiving the resource as it given out via a lottery. This project seeks to understand how well scarce resources are used as compared to what is possible. It asks how and when good outcomes can be achieved. In addition, it seeks to better understand some of the underlying computational tools.</p>\n<p>In many settings where there is competition for scarce resources, allocations are made by means of a lottery (often called randomization). Such settings include enrollment in high-ranking schools, the choice of dorm rooms at university, jury duty summons, and of course, choosing the winners of lotteries. In joint work with Rediet Abebe, Vasilis Gkatzelis and Jason Hartline, we looked at whether the overall quality of outcomes when assigning goods, such as public housing units, could be improved by a combination of randomization and asking for relative preferences, say on a scale of 1&ndash;10, which contrasts with existing methods that only ask for a rank ordering (i.e. the first choice, the second choice, etc.). The answer is &ldquo;yes&rdquo; by a considerable margin in some circumstances, but not in all. An interesting and unexpected finding was that sometimes additional competition, in the form of more people seeking housing, could, because of differing preferences, improve the outcome for some individuals.</p>\n<p>There is widespread acknowledgement that diversity, say of teams in the workplace, can lead to better outcomes. This project investigated whether diversity of another sort could be helpful in the context of traffic congestion. It is well known that many people will allow extra time when going to an airport so that the risk of missing their flight is small, while others take the view that if they never miss a flight they are leaving too much time. This range of tolerance of variability in travel time presumably applies to other travel such as daily commutes. In joint work with Thanasis Lianeas and Evdokia Nikolova, we looked at the effect on congestion of varied tolerances of uncertain delays, and identified conditions in which having no variability in delay tolerance led to the greatest perceived congestion cost; i.e. a range of tolerance of uncertainty would only lead to better outcomes.</p>\n<p>Most allocations occur via prices, i.e. by buying goods. A fundamental question is how are the `right&rsquo; prices found, by which we mean prices that balance supply and demand. Because economies are dynamic, that is circumstances change, prices need to adjust over time. In joint work with Yun Kuen Cheung and PhD student Yixin Tao, we sought to understand the behavior of two adjustment schemes: tatonnement, in which prices adjust in the intuitive way &ndash; if there is too much (resp. too little) demand, prices increase (resp. decrease)&mdash;and proportional response: here buyers adjust their spending toward goods that provide greater relative value. Interestingly, this work relied on close connections between precise versions of these processes and gradient descent, a classic algorithm for finding optimal values of a special class of well-behaved functions called convex functions.</p>\n<p>The PI, along with Cheung and Tao, then devoted significant effort to better understand the performance of a related form of gradient descent, called asynchronous coordinate descent, an algorithm which has received considerable attention in scientific computing and machine learning. The outcome of this work was an essentially complete characterization of how many computing units could work effectively in parallel on carrying out this algorithm (the potential gain from parallelism is to obtain solutions more quickly, which is valuable when dealing with very large problems, as is common in machine learning applications).</p>\n<p>In sum, this project has sought to quantify the effects of behaviors that exist in society (ranging from choosing commuting routes to how price adjust in economies), and in a quite distinct direction, how to design mechanisms to achieve good outcomes.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2019<br>\n\t\t\t\t\tModified by: Richard&nbsp;Cole</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany aspects of life involve the allocation of scarce resources, be it because they have a cost in money (their price), a cost in time (they require waiting in line), or because there is only a fractional chance of receiving the resource as it given out via a lottery. This project seeks to understand how well scarce resources are used as compared to what is possible. It asks how and when good outcomes can be achieved. In addition, it seeks to better understand some of the underlying computational tools.\n\nIn many settings where there is competition for scarce resources, allocations are made by means of a lottery (often called randomization). Such settings include enrollment in high-ranking schools, the choice of dorm rooms at university, jury duty summons, and of course, choosing the winners of lotteries. In joint work with Rediet Abebe, Vasilis Gkatzelis and Jason Hartline, we looked at whether the overall quality of outcomes when assigning goods, such as public housing units, could be improved by a combination of randomization and asking for relative preferences, say on a scale of 1&ndash;10, which contrasts with existing methods that only ask for a rank ordering (i.e. the first choice, the second choice, etc.). The answer is \"yes\" by a considerable margin in some circumstances, but not in all. An interesting and unexpected finding was that sometimes additional competition, in the form of more people seeking housing, could, because of differing preferences, improve the outcome for some individuals.\n\nThere is widespread acknowledgement that diversity, say of teams in the workplace, can lead to better outcomes. This project investigated whether diversity of another sort could be helpful in the context of traffic congestion. It is well known that many people will allow extra time when going to an airport so that the risk of missing their flight is small, while others take the view that if they never miss a flight they are leaving too much time. This range of tolerance of variability in travel time presumably applies to other travel such as daily commutes. In joint work with Thanasis Lianeas and Evdokia Nikolova, we looked at the effect on congestion of varied tolerances of uncertain delays, and identified conditions in which having no variability in delay tolerance led to the greatest perceived congestion cost; i.e. a range of tolerance of uncertainty would only lead to better outcomes.\n\nMost allocations occur via prices, i.e. by buying goods. A fundamental question is how are the `right\u2019 prices found, by which we mean prices that balance supply and demand. Because economies are dynamic, that is circumstances change, prices need to adjust over time. In joint work with Yun Kuen Cheung and PhD student Yixin Tao, we sought to understand the behavior of two adjustment schemes: tatonnement, in which prices adjust in the intuitive way &ndash; if there is too much (resp. too little) demand, prices increase (resp. decrease)&mdash;and proportional response: here buyers adjust their spending toward goods that provide greater relative value. Interestingly, this work relied on close connections between precise versions of these processes and gradient descent, a classic algorithm for finding optimal values of a special class of well-behaved functions called convex functions.\n\nThe PI, along with Cheung and Tao, then devoted significant effort to better understand the performance of a related form of gradient descent, called asynchronous coordinate descent, an algorithm which has received considerable attention in scientific computing and machine learning. The outcome of this work was an essentially complete characterization of how many computing units could work effectively in parallel on carrying out this algorithm (the potential gain from parallelism is to obtain solutions more quickly, which is valuable when dealing with very large problems, as is common in machine learning applications).\n\nIn sum, this project has sought to quantify the effects of behaviors that exist in society (ranging from choosing commuting routes to how price adjust in economies), and in a quite distinct direction, how to design mechanisms to achieve good outcomes.\n\n \n\n\t\t\t\t\tLast Modified: 11/25/2019\n\n\t\t\t\t\tSubmitted by: Richard Cole"
 }
}