{
 "awd_id": "1464432",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CPS: Intuitive Human-in-the-Loop Control for Medical Cyber-Physical Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "David Corman",
 "awd_eff_date": "2015-05-15",
 "awd_exp_date": "2018-04-30",
 "tot_intn_awd_amt": 174689.0,
 "awd_amount": 203297.0,
 "awd_min_amd_letter_date": "2015-05-07",
 "awd_max_amd_letter_date": "2016-08-10",
 "awd_abstract_narration": "Human-in-the-loop control strategies in which the user performs a task better, and feels more confident to do so, is an important area of research for cyber-physical systems. Humans are very adept at learning to control complex systems, particularly those with non-intuitive kinematic constraints (e.g., cars, bicycles, wheelchairs, steerable needles). With the advent of cyber-physical systems, (physical systems integrated with cyber control layer), human control is no longer constrained to system inputs. Users can also control system outputs through a number of different teleoperation mappings. Given all this flexibility, what is the most intuitive way for a human user to control an arbitrary system and how is intuitiveness quantified?\r\n\r\nThe project focuses on human-in-the-loop control for medical needles, which steer with bicycle-like kinematics. These needles could be used in a variety of medical interventions including tissue biopsy, tumor ablation, abscess drainage, and local drug delivery. We have explored a variety of teleoperation mappings for human control of these steerable needles; yet, we have found inconsistencies between objective performance metrics (e.g., task time and error), and post-experimental surveys on comfort or ease-of use. Users occasionally report a preference for control mappings, which objectively degrade performance, and vice versa. It is important to measure the real-time engagement of the user with the physical system in order to capture the nuances of how different control mappings affect physical effort, mental workload, distraction, drowsiness, and emotional response. Physiological sensors such as electroencephalography (EEG), galvanic skin response (GSR), and electromyography (EMG), can be used to provide these real-time measurements and to quantitatively classify the intuitiveness of new teleoperation algorithms.\r\n\r\nBroader Impacts:  Intuitive and natural human-in-the-loop control interfaces will improve human health and well being, through applications in surgery and rehabilitation. The results of this study will be disseminated publicly on the investigator's laboratory website, a conference workshop, and a new medical robotics seminar to be held jointly between UT Dallas and UT Southwestern Medical Center. Outreach activities, lab tours, and mentoring of underrepresented students at all levels, will broaden participation in STEM. Additionally, the proximity of the investigator?s hospital-based lab to medical professionals will engage non-engineers in design and innovation\r\n",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ann",
   "pi_last_name": "Majewicz Fey",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ann Majewicz Fey",
   "pi_email_addr": "Ann.MajewiczFey@utexas.edu",
   "nsf_id": "000678765",
   "pi_start_date": "2015-05-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Dallas",
  "inst_street_address": "800 WEST CAMPBELL RD.",
  "inst_street_address_2": "SP2.25",
  "inst_city_name": "RICHARDSON",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9728832313",
  "inst_zip_code": "750803021",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "TX24",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT DALLAS",
  "org_prnt_uei_num": "",
  "org_uei_num": "EJCVPNN1WFS5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Dallas",
  "perf_str_addr": "800 W. Campbell Rd.",
  "perf_city_name": "Richardson",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "750803021",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "TX24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 188681.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 14616.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"normal1\">The goal of this project was to develop methods to model and predict the difficulty, or intuitiveness, of a human-robot control task using only information that could be obtained in real-time from the human operator (i.e., without task-dependent knowledge). We identified a variety of metrics that could be computed from user kinematic motions, as well as user physiological response (e.g., heart rate, electroencephalography (EEG), galvanic skin response (GSR), and electromyography (EMG)). These metrics showed high accuracy in being able to predict the difficulty of a control task. We evaluated our model in a variety of human-in-the-loop scenarios, showing the ability of our model to generalize across other human-robot control tasks.</p>\n<p class=\"normal1\"><strong>Intellectual Merit:</strong>&nbsp;Human-in-the-loop control strategies in which the user performs a task better, and feels more confident to do so, is an important area of research for cyber-physical systems. Humans are very adept at learning to control complex systems; however, it is not obvious how to quantify the intuitiveness of the control interface for the human operator. This project has provided the field of cyber-physical systems with a theoretical and experimental framework for measuring task difficulty in real-time using only human-centric measurements (i.e., motion and physiological data).</p>\n<p class=\"normal1\"><strong>Broader Impacts:</strong>&nbsp;Intuitive and natural human-in-the-loop control interfaces will improve human health and well-being through applications in surgery and rehabilitation. The results of this project were disseminated through software and data made publicly available on the PI&rsquo;s laboratory website. Outreach programs, public lab tours, and mentoring of female and minority graduate students, undergraduate students, and high school students broadened participation of underrepresented groups in engineering.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/29/2018<br>\n\t\t\t\t\tModified by: Ann&nbsp;Majewicz Fey</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535485591829_Experiment_demo--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535485591829_Experiment_demo--rgov-800width.jpg\" title=\"Experimental Setup for Intuitiveness Modeling Study\"><img src=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535485591829_Experiment_demo--rgov-66x44.jpg\" alt=\"Experimental Setup for Intuitiveness Modeling Study\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Human subjects performed a variety of human-in-the-loop control tasks with a simulated robotic system. User-centric kinematic and physiological response was recorded to predict task difficulty.</div>\n<div class=\"imageCredit\">Ziheng Wang</div>\n<div class=\"imageSubmitted\">Ann&nbsp;Majewicz Fey</div>\n<div class=\"imageTitle\">Experimental Setup for Intuitiveness Modeling Study</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535485434913_Workframe--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535485434913_Workframe--rgov-800width.jpg\" title=\"Intuitiveness Modeling Framework\"><img src=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535485434913_Workframe--rgov-66x44.jpg\" alt=\"Intuitiveness Modeling Framework\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Framework for modeling intuitiveness during human-in-the-loop robot control tasks.</div>\n<div class=\"imageCredit\">Ziheng Wang</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Ann&nbsp;Majewicz Fey</div>\n<div class=\"imageTitle\">Intuitiveness Modeling Framework</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535569167557_UGProjects--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535569167557_UGProjects--rgov-800width.jpg\" title=\"Undergraduate Projects\"><img src=\"/por/images/Reports/POR/2018/1464432/1464432_10362441_1535569167557_UGProjects--rgov-66x44.jpg\" alt=\"Undergraduate Projects\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A variety of undergraduate projects were supported by this award through an REU Supplement.</div>\n<div class=\"imageCredit\">Ann Majewicz Fey</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Ann&nbsp;Majewicz Fey</div>\n<div class=\"imageTitle\">Undergraduate Projects</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "The goal of this project was to develop methods to model and predict the difficulty, or intuitiveness, of a human-robot control task using only information that could be obtained in real-time from the human operator (i.e., without task-dependent knowledge). We identified a variety of metrics that could be computed from user kinematic motions, as well as user physiological response (e.g., heart rate, electroencephalography (EEG), galvanic skin response (GSR), and electromyography (EMG)). These metrics showed high accuracy in being able to predict the difficulty of a control task. We evaluated our model in a variety of human-in-the-loop scenarios, showing the ability of our model to generalize across other human-robot control tasks.\nIntellectual Merit: Human-in-the-loop control strategies in which the user performs a task better, and feels more confident to do so, is an important area of research for cyber-physical systems. Humans are very adept at learning to control complex systems; however, it is not obvious how to quantify the intuitiveness of the control interface for the human operator. This project has provided the field of cyber-physical systems with a theoretical and experimental framework for measuring task difficulty in real-time using only human-centric measurements (i.e., motion and physiological data).\nBroader Impacts: Intuitive and natural human-in-the-loop control interfaces will improve human health and well-being through applications in surgery and rehabilitation. The results of this project were disseminated through software and data made publicly available on the PI?s laboratory website. Outreach programs, public lab tours, and mentoring of female and minority graduate students, undergraduate students, and high school students broadened participation of underrepresented groups in engineering.\n\n \n\n\t\t\t\t\tLast Modified: 08/29/2018\n\n\t\t\t\t\tSubmitted by: Ann Majewicz Fey"
 }
}