{
 "awd_id": "1451173",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Doctoral Dissertation Research: Investigating cognitive and communicative pressures on natural language lexicons",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Badecker",
 "awd_eff_date": "2015-03-15",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 11984.0,
 "awd_amount": 11984.0,
 "awd_min_amd_letter_date": "2015-03-11",
 "awd_max_amd_letter_date": "2015-03-11",
 "awd_abstract_narration": "Understanding how humans produce and comprehend language is a critical step in understanding high-level human cognition and the human brain more generally. Moreover, basic research into human language has been, and will continue to be, useful for building computational natural language processing systems that enable humans to interact naturally with computers. The lexicons of the world's thousands of languages--that is, the sets of words that exist in any given language--offer a particularly rich source of insight into the language production and comprehension mechanism. The words of any given language have undergone thousands of years of evolution, sometimes changing dramatically over one or two generations as sounds change, new words are invented or borrowed from other languages, and old words die. What all languages have in common, however, is that they enable their speakers to successfully communicate with one another. Therefore, a language's lexicon is necessarily constrained by the cognitive and communicative demands of speakers. Consequently, studying the statistical properties of lexicons, the ways that lexicons evolve, and the process by which words are formed is a promising avenue for answering fundamental questions about human cognition.\r\n\r\nBuilding on previous work by this research group showing that lexicons tend to be structured for efficient communication, this research will harness the power of large cross-linguistic data sets available through the Internet, including Wikipedia and Google Books, in order to study the lexicons of a large number of world languages (~100). Specifically, this analysis will focus on how words cluster or spread out in phonetic space, exploring competing demands for words to consist of easy-to-pronounce and easy-to-comprehend sequences but also to be phonetically distinct from one another. A second major component of this work is a series of human-participant behavioral experiments that, in a controlled laboratory setting and in a smaller number of languages, explore the mechanisms that underlie how words change over time. Finally, a computational model will be used to integrate the insights of the statistical analyses and behavioral experiments in order to explore and predict how words enter and exit the lexicon over time. This research program has implications not just for higher-level human cognition but for any engineering applications that require human-computer interaction involving natural language and also for any applications that require building a cognitively tractable communication system that allows people to communicate efficiently.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edward",
   "pi_last_name": "Gibson",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Edward A Gibson",
   "pi_email_addr": "egibson@mit.edu",
   "nsf_id": "000215436",
   "pi_start_date": "2015-03-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kyle",
   "pi_last_name": "Mahowald",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kyle Mahowald",
   "pi_email_addr": "mahowald@utexas.edu",
   "nsf_id": "000673923",
   "pi_start_date": "2015-03-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Mass Ave",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "837400",
   "pgm_ele_name": "DDRI Linguistics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 11984.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>A major question in natural language concerns how and why languages have the words that they do, as opposed to some other set of words. Imagine a language that uses the word &lsquo;feb&rsquo; to refer to the concept hot, and that the language now needs a word for the concept warm. If the language used the word &lsquo;fep&rsquo; for warm, it would be easy to confuse with &lsquo;feb&rsquo; (hot) since the two words differ only in the voicing of the final consonant and would often occur in similar contexts (i.e. when talking about temperature). However, the similarity of &lsquo;feb&rsquo; and &lsquo;fep&rsquo; could make it easier for a language learner to learn that those sound sequences are both associated with temperature, and the learner would not have to spend much time learning to articulate new sound sequences since &lsquo;feb&rsquo; and &lsquo;fep&rsquo; share most of their phonological structure. On the other hand, if the language used the word &lsquo;zoz&rsquo; for the concept warm, it is unlikely to be phonetically confused with &lsquo;feb&rsquo; (hot), but the learner might have to learn to articulate a new set of sounds and would need to remember two quite different sound sequences that refer to similar concepts.</p>\n<p>In this work, we showed that, broadly, lexicons prefer similarity among wordforms. We used a statistical analysis of a large-scale corpus from Wikipedia to show that a) the most common words in a language tend to be the easiest to produce; b) semantically related words (like <em>hot</em> and <em>cold</em>) are also more likely to be phonetically similar; and c) the lexicon is &ldquo;clumpier&rdquo; in phonetic space than would be expected based on chance alone.</p>\n<p>As part of this dissertation work, we also published two papers answering methodological questions in psychology and linguistics. The first, a meta-analysis of syntactic priming in production, analyzes 30 years of syntactic priming experiments and shows that syntactic priming appears to be a real, robust effect but that many experiments are underpowered. The second proposes a novel method for attaining linguistic acceptability judgments, which are a major method of inquiry in linguistics.</p>\n<p>More broadly, this work has the potential for impact in three distinct domains. First, the statistical techniques presented in the work on meta-analysis and acceptability judgments can serve as guidelines for how to obtain and use quantitative data to answer linguistic questions. Second, the basic research into the lexicon can be used to inform computational systems that seek to produce and comprehend natural languages. Third, the work on the phonological structure of the lexicon, specifically work on what makes sound sequences easier or harder to learn and remember, could be used to inform our understanding of language disorders that affect lexical representation, such as dyslexia.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/07/2016<br>\n\t\t\t\t\tModified by: Edward&nbsp;A&nbsp;Gibson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nA major question in natural language concerns how and why languages have the words that they do, as opposed to some other set of words. Imagine a language that uses the word ?feb? to refer to the concept hot, and that the language now needs a word for the concept warm. If the language used the word ?fep? for warm, it would be easy to confuse with ?feb? (hot) since the two words differ only in the voicing of the final consonant and would often occur in similar contexts (i.e. when talking about temperature). However, the similarity of ?feb? and ?fep? could make it easier for a language learner to learn that those sound sequences are both associated with temperature, and the learner would not have to spend much time learning to articulate new sound sequences since ?feb? and ?fep? share most of their phonological structure. On the other hand, if the language used the word ?zoz? for the concept warm, it is unlikely to be phonetically confused with ?feb? (hot), but the learner might have to learn to articulate a new set of sounds and would need to remember two quite different sound sequences that refer to similar concepts.\n\nIn this work, we showed that, broadly, lexicons prefer similarity among wordforms. We used a statistical analysis of a large-scale corpus from Wikipedia to show that a) the most common words in a language tend to be the easiest to produce; b) semantically related words (like hot and cold) are also more likely to be phonetically similar; and c) the lexicon is \"clumpier\" in phonetic space than would be expected based on chance alone.\n\nAs part of this dissertation work, we also published two papers answering methodological questions in psychology and linguistics. The first, a meta-analysis of syntactic priming in production, analyzes 30 years of syntactic priming experiments and shows that syntactic priming appears to be a real, robust effect but that many experiments are underpowered. The second proposes a novel method for attaining linguistic acceptability judgments, which are a major method of inquiry in linguistics.\n\nMore broadly, this work has the potential for impact in three distinct domains. First, the statistical techniques presented in the work on meta-analysis and acceptability judgments can serve as guidelines for how to obtain and use quantitative data to answer linguistic questions. Second, the basic research into the lexicon can be used to inform computational systems that seek to produce and comprehend natural languages. Third, the work on the phonological structure of the lexicon, specifically work on what makes sound sequences easier or harder to learn and remember, could be used to inform our understanding of language disorders that affect lexical representation, such as dyslexia.\n\n \n\n\t\t\t\t\tLast Modified: 09/07/2016\n\n\t\t\t\t\tSubmitted by: Edward A Gibson"
 }
}