{
 "awd_id": "1535669",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I/UCRC FRP:  Collaborative Research: Scalable and Power-Efficient Compressive Sensing CMOS Image Sensors and Reconstruction Circuits",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Dmitri Perkins",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2017-09-30",
 "tot_intn_awd_amt": 100000.0,
 "awd_amount": 100000.0,
 "awd_min_amd_letter_date": "2015-09-18",
 "awd_max_amd_letter_date": "2015-09-18",
 "awd_abstract_narration": "This project will develop foundations for novel design of low-power and high-resolution image sensors, beyond the state-of-the-art. The potential outcome of this research is two orders of magnitude power reduction and ability to achieve real-time image reconstruction. The research activities have the potential to make significant impact on number of different industries. Image sensors have been used in extremely wide range of applications to directly enhance the quality of human life, including communication, entertainment, security, medical diagnosis and many others.  The PI's will involve a number of graduate and undergraduate students from under-represented groups. \r\n\r\nThis project will systematically investigate the optimal designs of all major blocks used in image sensors. The project aims to develop novel design ideas for compressive sensing, resulting in potential order-of-magnitude improvements in trade-offs between energy use and performance. The research will be conducted within the I/UCRC Center for Embedded Systems and the project has Center's strong support, and active participation from its member companies, which will pave the way for the transition of the project outcomes into commercial products that will benefit society at large.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sarma",
   "pi_last_name": "Vrudhula",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sarma Vrudhula",
   "pi_email_addr": "vrudhula@asu.edu",
   "nsf_id": "000124788",
   "pi_start_date": "2015-09-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jae-sun",
   "pi_last_name": "Seo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jae-sun Seo",
   "pi_email_addr": "js3528@cornell.edu",
   "nsf_id": "000929203",
   "pi_start_date": "2015-09-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "P.O. Box 876011",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852876011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "576100",
   "pgm_ele_name": "IUCRC-Indust-Univ Coop Res Ctr"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5761",
   "pgm_ref_txt": "INDUSTRY/UNIV COOP RES CENTERS"
  },
  {
   "pgm_ref_code": "8039",
   "pgm_ref_txt": "Information, Communication & Computing"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 100000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Currently in the field of custom ASIC and FPGA design, signal reconstruction, feature extraction, and deep neural network operations all involve heavy computation and memory requirements for real-time operation. This project pursued a holistic optimization towards an energy-efficient, real-time end-to-end embedded system design with hardware-efficient sparsity and iterative loop optimization for the aforementioned computation tasks on CMOS ASIC and FPGA frameworks. The combination of the developed techniques will pave the way for such techniques to be widely adopted in various real-world data processing systems with significant energy reduction. Throughout the two years of this project, we accomplished designing custom algorithms and hardware for sparse approximation, sparsification, and iterative loop optimization, which is a core technology for both signal/image reconstruction and sparse deep neural network implementations.</p>\n<p>In one of research outcomes, we investigated the design of a hardware-efficient sparse weight matrix for deep neural network (DNN), which could be also used as the dictionary in sparse coding and reconstruction. We developed a hardware-centric methodology to design low power DNNs with significantly smaller memory footprint and computation resource requirements. We achieved this by judiciously eliminating connections in large blocks of weights. The corresponding technique, termed coarse-grain sparsification (CGS), introduces hardware-aware sparsity during the DNN training, which led to hardware-efficient weight memory compression, with minimal degradation in classification accuracy. When the DNNs are trained with 75% of the weights dropped and classified with 5-6 bit weight precision, the weight memory requirement is reduced by ~20X compared to their fully-connected counterparts with double precision, while maintaining similar performance in keyword detection accuracy, word error rate, and sentence error rate.</p>\n<p>In another research outcome, we investigated a DNN compiler that automatically generates customized FPGA hardware (from a software code) for the inference tasks of various DNNs, in order to enable high-level fast prototyping of CNNs from software to FPGA and still keep the benefits of low-level hardware optimization. Given a CNN algorithm, its structure is abstracted to a directed acyclic graph (DAG) and then complied with custom RTL modules in the library. The proposed methodology is demonstrated with end-to-end FPGA implementations of various DNN algorithms (e.g. NiN, VGG-16, ResNet-50, and ResNet-152) on standalone FPGAs. The performance and overhead of the automated compilation are evaluated. The compiled FPGA accelerators exhibit superior performance compared to state-of-the- art automation-based works by &gt;2X for various DNNs.</p>\n<p>This project has provided several opportunities training and professional development. The PIs mentored one M.S student and one Ph.D student throughout this project to design matrix sparsification algorithm and custom hardware design. This involved a number of training activities, including designing new architecture/circuits, conducting simulations and formulating test cases, analyzing experimental results, writing manuscripts for conference publications and preparing poster presentations at the NSF I/UCRC IAB meetings.</p>\n<p>The research results of this project have been disseminated in several ways. First, the intermediate research outcomes and knowledge have been disseminated by Vrudhula at the bi-annual IAB meeting of the NSF I/UCRC Center for Embedded Systems. Second, the research outcomes were published at IEEE/ACM hardware conferences including ICCAD 2016, FPGA 2017, ISCAS 2017, and FPL 2017. Finally, the research results have been part of three tutorials that have been co-organized and presented by Seo at FPL 2016, ASP-DAC 2017, and IJCNN 2017. These tutorials have been disseminated to reach the audience of hardware designers who have not been fully aware of these research activities, and enhanced the research interest of the audience.</p>\n<p>This project will have an impact on the software/algorithm co-design and co-optimization, which is rapidly developing field and is of interest to a broad range of researchers in both academia and industry. This is due to the fact that many algorithms that eventually need to be implemented on hardware for real-time operation interacting with sensors and the external world. From now on it will be important for the software/algorithm developers to also understand the consequences of certain algorithm functions onto the complexity of hardware implementation. This way, further software-hardware co-design and co-optimization will be considered and enhanced in the final system design.</p>\n<p>Furthermore, the energy-efficient sparsification and loop optimization techniques developed in this project can significantly improve the real-time operation of the computation-intensive signal/image reconstruction operations, benefiting imaging (such as CT and MRI) based medical diagnosis and treatment. This not only allows doctors to see the image more quickly for diagnosis but also makes it possible to use the compressively sensed image to guide operation. The energy-efficiency of the developed circuits will enable to perform image reconstruction on portable devices, which makes the compressively sensed image based diagnosis and treatment instruments more accessible to remote areas.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2017<br>\n\t\t\t\t\tModified by: Jae-Sun&nbsp;Seo</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nCurrently in the field of custom ASIC and FPGA design, signal reconstruction, feature extraction, and deep neural network operations all involve heavy computation and memory requirements for real-time operation. This project pursued a holistic optimization towards an energy-efficient, real-time end-to-end embedded system design with hardware-efficient sparsity and iterative loop optimization for the aforementioned computation tasks on CMOS ASIC and FPGA frameworks. The combination of the developed techniques will pave the way for such techniques to be widely adopted in various real-world data processing systems with significant energy reduction. Throughout the two years of this project, we accomplished designing custom algorithms and hardware for sparse approximation, sparsification, and iterative loop optimization, which is a core technology for both signal/image reconstruction and sparse deep neural network implementations.\n\nIn one of research outcomes, we investigated the design of a hardware-efficient sparse weight matrix for deep neural network (DNN), which could be also used as the dictionary in sparse coding and reconstruction. We developed a hardware-centric methodology to design low power DNNs with significantly smaller memory footprint and computation resource requirements. We achieved this by judiciously eliminating connections in large blocks of weights. The corresponding technique, termed coarse-grain sparsification (CGS), introduces hardware-aware sparsity during the DNN training, which led to hardware-efficient weight memory compression, with minimal degradation in classification accuracy. When the DNNs are trained with 75% of the weights dropped and classified with 5-6 bit weight precision, the weight memory requirement is reduced by ~20X compared to their fully-connected counterparts with double precision, while maintaining similar performance in keyword detection accuracy, word error rate, and sentence error rate.\n\nIn another research outcome, we investigated a DNN compiler that automatically generates customized FPGA hardware (from a software code) for the inference tasks of various DNNs, in order to enable high-level fast prototyping of CNNs from software to FPGA and still keep the benefits of low-level hardware optimization. Given a CNN algorithm, its structure is abstracted to a directed acyclic graph (DAG) and then complied with custom RTL modules in the library. The proposed methodology is demonstrated with end-to-end FPGA implementations of various DNN algorithms (e.g. NiN, VGG-16, ResNet-50, and ResNet-152) on standalone FPGAs. The performance and overhead of the automated compilation are evaluated. The compiled FPGA accelerators exhibit superior performance compared to state-of-the- art automation-based works by &gt;2X for various DNNs.\n\nThis project has provided several opportunities training and professional development. The PIs mentored one M.S student and one Ph.D student throughout this project to design matrix sparsification algorithm and custom hardware design. This involved a number of training activities, including designing new architecture/circuits, conducting simulations and formulating test cases, analyzing experimental results, writing manuscripts for conference publications and preparing poster presentations at the NSF I/UCRC IAB meetings.\n\nThe research results of this project have been disseminated in several ways. First, the intermediate research outcomes and knowledge have been disseminated by Vrudhula at the bi-annual IAB meeting of the NSF I/UCRC Center for Embedded Systems. Second, the research outcomes were published at IEEE/ACM hardware conferences including ICCAD 2016, FPGA 2017, ISCAS 2017, and FPL 2017. Finally, the research results have been part of three tutorials that have been co-organized and presented by Seo at FPL 2016, ASP-DAC 2017, and IJCNN 2017. These tutorials have been disseminated to reach the audience of hardware designers who have not been fully aware of these research activities, and enhanced the research interest of the audience.\n\nThis project will have an impact on the software/algorithm co-design and co-optimization, which is rapidly developing field and is of interest to a broad range of researchers in both academia and industry. This is due to the fact that many algorithms that eventually need to be implemented on hardware for real-time operation interacting with sensors and the external world. From now on it will be important for the software/algorithm developers to also understand the consequences of certain algorithm functions onto the complexity of hardware implementation. This way, further software-hardware co-design and co-optimization will be considered and enhanced in the final system design.\n\nFurthermore, the energy-efficient sparsification and loop optimization techniques developed in this project can significantly improve the real-time operation of the computation-intensive signal/image reconstruction operations, benefiting imaging (such as CT and MRI) based medical diagnosis and treatment. This not only allows doctors to see the image more quickly for diagnosis but also makes it possible to use the compressively sensed image to guide operation. The energy-efficiency of the developed circuits will enable to perform image reconstruction on portable devices, which makes the compressively sensed image based diagnosis and treatment instruments more accessible to remote areas.\n\n\t\t\t\t\tLast Modified: 12/30/2017\n\n\t\t\t\t\tSubmitted by: Jae-Sun Seo"
 }
}