{
 "awd_id": "1456077",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CompCog: Broad-coverage probabilistic models of communication in context",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": "7032927238",
 "po_email": "btuller@nsf.gov",
 "po_sign_block_name": "Betty Tuller",
 "awd_eff_date": "2015-08-15",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 427940.0,
 "awd_amount": 427940.0,
 "awd_min_amd_letter_date": "2015-08-11",
 "awd_max_amd_letter_date": "2015-08-11",
 "awd_abstract_narration": "People often mean more than they say. To take an example, imagine Adam says \"I could use a cup of coffee\" and Bob responds by saying \"There's a place called Joe's around the corner.\" We understand this as a coherent exchange even though Adam's utterance wasn't phrased overtly as a question and Bob didn't explicitly say that Joe's sells coffee. Extracting this rich additional meaning requires us to consider sentences in light of both the context they are used in and the cooperative motivations of Adam and Bob in using language (what are called \"pragmatic inferences\"). This project is devoted to constructing formal models of these pragmatic inferences. Modeling pragmatic inference is a major scientific challenge in the study of language and the human mind and a key to the future development of autonomous intelligent systems that can communicate with humans using natural language. Machines that can do robust language understanding in context will pave the way for societally beneficial technological applications such as adaptive intelligent tutoring and assistive technologies. \r\n\r\nThe technical core of the project involves developing and extending models of pragmatic reasoning, drawing on ideas and insights from decision theory, probabilistic models of cognition, bounded rationality, and linguistics.  In particular, the work extends the recently developed family of \"rational speech act\" models, which provides a set of formal tools that can be used to address basic challenges in psycholinguistics concerning how major principles of pragmatic inference fall out of simple assumptions about cooperativity and shared context among conversation participants. This enterprise has the potential to fill a major open theoretical gap in our scientific understanding of human language and social cognition. Project work includes developing computational Bayesian models of semantic composition and pragmatic inference and testing those models using controlled psycholinguistic experiments.  The work will also yield new models and publicly available datasets and will contribute to interdisciplinary connections by creating and reinforcing links between linguistics, psychology, and computer science.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Frank",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Michael C Frank",
   "pi_email_addr": "mcfrank@stanford.edu",
   "nsf_id": "000179112",
   "pi_start_date": "2015-08-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Potts",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher G Potts",
   "pi_email_addr": "cgpotts@stanford.edu",
   "nsf_id": "000113396",
   "pi_start_date": "2015-08-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "210 Panama Street",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "131100",
   "pgm_ele_name": "Linguistics"
  },
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1311",
   "pgm_ref_txt": "LINGUISTICS"
  },
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "9179",
   "pgm_ref_txt": "GRADUATE INVOLVEMENT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 427940.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-31d8ac2f-7fff-0366-82ee-cb8b17f3e305\">\n<p dir=\"ltr\"><span>It's a truism of human communication that people often mean more than they say. In the linguist Stephen Levinson's analogy, the literal (semantic) content of our utterances is just a \"sketch\" of the information that is actually exchanged. The process of interpreting and enriching these utterances in context is *pragmatic inference*. Despite widespread agreement about the fundamental resources and goals of pragmatic inference, remarkably little progress has been made in developing computational models that precisely characterize how it emerges. This stands as a major scientific challenge and a major obstacle to developing robust technologies that depend on natural language (e.g., smart-home devices, intelligent tutoring systems). However, recent probabilistic models of cognition have marked a large step forward. Such models have achieved good quantitative fits to experimental data, provided unified explanations for a variety of complex linguistic and developmental patterns, and been incorporated into artificial agents that communicate with each other to solve real-world tasks. In this project, we sought to extend and test these models. We developed scalable deep learning versions of them that can process naturalistic language in complex environments, and we also released data set and algorithms to facilitate additional technology development. In addition, we charted new ways to analyze non-literal language (for example, metaphor, hyperbole, sarcasm), which are common in human communication and incredibly challenging for computational models. Finally, we achieved a range of new results in understanding human language learning in these domains. The resulting set of advances helps lay the foundation for language processing technologies that reason about communication in context.</span></p>\n<br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/29/2019<br>\n\t\t\t\t\tModified by: Michael&nbsp;C&nbsp;Frank</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nIt's a truism of human communication that people often mean more than they say. In the linguist Stephen Levinson's analogy, the literal (semantic) content of our utterances is just a \"sketch\" of the information that is actually exchanged. The process of interpreting and enriching these utterances in context is *pragmatic inference*. Despite widespread agreement about the fundamental resources and goals of pragmatic inference, remarkably little progress has been made in developing computational models that precisely characterize how it emerges. This stands as a major scientific challenge and a major obstacle to developing robust technologies that depend on natural language (e.g., smart-home devices, intelligent tutoring systems). However, recent probabilistic models of cognition have marked a large step forward. Such models have achieved good quantitative fits to experimental data, provided unified explanations for a variety of complex linguistic and developmental patterns, and been incorporated into artificial agents that communicate with each other to solve real-world tasks. In this project, we sought to extend and test these models. We developed scalable deep learning versions of them that can process naturalistic language in complex environments, and we also released data set and algorithms to facilitate additional technology development. In addition, we charted new ways to analyze non-literal language (for example, metaphor, hyperbole, sarcasm), which are common in human communication and incredibly challenging for computational models. Finally, we achieved a range of new results in understanding human language learning in these domains. The resulting set of advances helps lay the foundation for language processing technologies that reason about communication in context.\n\n\n\n \n\n\t\t\t\t\tLast Modified: 10/29/2019\n\n\t\t\t\t\tSubmitted by: Michael C Frank"
 }
}