{
 "awd_id": "1537987",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Active Statistical Learning: Ensembles, Manifolds, and Optimal Experimental Design",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922443",
 "po_email": "gaklutke@nsf.gov",
 "po_sign_block_name": "Georgia-Ann Klutke",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2015-08-07",
 "awd_max_amd_letter_date": "2015-08-07",
 "awd_abstract_narration": "In numerous industries such as manufacturing, health care or energy production, current sensor technology can generate enormous quantities of measurements of an object at low cost. Each measurement consists of several instances of interrelated variables, and the goal is to use the data to build a computer model that permits one to predict the class of an object (such as the health condition of a patient or the quality of a manufactured part). Along with the sensor data, the class labels for some objects are needed to train the computer model. While the sensor variables can frequently be obtained rapidly and inexpensively (e.g., medical images or chemical analyses) the class label associated with each object might require human effort that is time-consuming and expensive. Therefore, care should be taken to select the objects to label that are most informative for building the predictive computer model. Often one selects objects iteratively, where the class labels from the previously selected batch guides the next batch of objects to label. This is the purpose of a so-called active learning strategy. The purpose of this research is to find new active learning methods that accelerate model building and provide better predictions in systems where large datasets of attribute measurements are available. This will result in more efficient and productive systems that will benefit the U.S. economy and society.\r\n\r\nExisting active learning methods are often based on strong assumptions for the joint input/output distribution or use a distance-based approach. These methods are susceptible to noise in the input space, assume numerical inputs only, and often work poorly in high dimensions. In applications, data sets are often large, noisy, contain missing values and mixed variable types. In this research, a non-parametric approach to the active learning problem is planned to address these challenges. The algorithm is based on a batch diversification strategy applied to an ensemble of decision trees. A novel active learning strategy that considers the geometric structure of the manifold where the unlabeled data resides will also be considered. The geometric properties of the data space may result in more informative active learning solutions. This is a collaborative effort between Arizona State University, Pennsylvania State University, and Intel Corporation with complementary expertise in machine learning and optimal design. The participation of Intel will help ensure the successful dissemination and broad applicability of the results.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Enrique",
   "pi_last_name": "Del Castillo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Enrique Del Castillo",
   "pi_email_addr": "exd13@psu.edu",
   "nsf_id": "000485085",
   "pi_start_date": "2015-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Pennsylvania State Univ University Park",
  "inst_street_address": "201 OLD MAIN",
  "inst_street_address_2": "",
  "inst_city_name": "UNIVERSITY PARK",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "8148651372",
  "inst_zip_code": "168021503",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "PA15",
  "org_lgl_bus_name": "THE PENNSYLVANIA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPM2J7MSCF61"
 },
 "perf_inst": {
  "perf_inst_name": "Pennsylvania State Univ University Park",
  "perf_str_addr": "310 Leonhard Building",
  "perf_city_name": "University Park",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "168026817",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "PA",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "006Y00",
   "pgm_ele_name": "OE Operations Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "071E",
   "pgm_ref_txt": "MFG ENTERPRISE OPERATIONS"
  },
  {
   "pgm_ref_code": "078E",
   "pgm_ref_txt": "ENTERPRISE DESIGN & LOGISTICS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Intellectual merit</p>\n<p>This project is related to the field of supervised Machine Learning and its application to engineering problems. A classical supervised Machine Learning problem consists of data (which could be as simple as numbers, or as complicated as images) and the corresponding labels associated with each data item, for instance, we could have images (data) and some text that describes what the image contains (label). Supervised Machine Learning algorithms are meant to find relations between the data points and their labels with the goal of predicting the label for an unlabeled data point. In order to be successful, machine learning algorithms need considerable amounts of data and their corresponding labels to be trained properly. The labels in the training datasets are usually assigned by humans or some measuring equipment, and frequently are expensive to acquire. It is therefore important to select the training data carefully. The problem of deciding among a set of unlabeled points which are the most useful for the algorithm to learn from, and therefore, the data items that should be labeled, is called the Active Learning problem.</p>\n<p>The Active Learning problem in Machine Learning is analogous to a classic problem in the field of Statistics, namely, optimal experimental design. Suppose one has to conduct a series of tests on an engineering process (e.g., some machine) in order to improve the process response (e.g., some measure of the quality or performance of a process). For doing this one tries different settings of controllable variables and the collection of such settings constitute an experimental design. When experimentation is expensive it is important to plan the tests carefully, in order to obtain as much information with the minimum number of tests. The analogy with Active Learning algorithms is clear: data items constitute the different experimental settings and the labels are the response values once the test is conducted.</p>\n<p>In the present research, a connection was established between the fields of Active Learning and Optimal Experimental Design. Certain mathematical theorems that guarantee an experimental design is optimal in some well-defined sense were extended for application in Active Learning. The underlying problem is difficult since the spaces where the data occur are quite different: while simple input variables constitute vectors in Euclidean space and most of statistical analysis occurs in these familiar spaces, the type of data one analyzes in machine learning usually lies in curved spaces within a very high dimensional space, the so-called manifolds. The curvature means Pythagoras theorem cannot be used so most standard statistical methods break down. A specific example of manifold data are digital images, where each image may be in a space of very high dimension (as many dimensions as pixels in the picture, for a B&amp;W image), when in reality if the images relates to a subject narrowly defined (classical example, human faces) the data can be explained by using just a few dimensions in a much lower dimensional, but curved, space. The advantage of this nonlinear dimensionality reduction is that machine learning algorithms can learn much faster if the number of coordinates one deals with is reduced.</p>\n<p>Broader impacts</p>\n<p>Applications of machine learning techniques are well known and occur throughout the engineering, sciences and business disciplines. The research conducted although foundational, has further applicability in industrial inspection systems for quality control and adaptive control systems.</p>\n<p>Outcomes</p>\n<p>The main result of this research was a theory of optimal experimental designs for data on manifolds and a corresponding algorithm which was proven to converge to the optimal design. The algorithm can be used for active learning of manifold data, and was demonstrated on image data. One of the surprising results is that both labeled and unlabeled data can be used to accelerate learning. That is, both images already labeled and also images with no labels can be incorporated into the algorithm to learn faster.</p>\n<p>For demonstration purposes, we consider a simple machine learning problem where the algorithm must learn the angle of view of images that display different objects taken at different angles or poses. For instance, in the figure included, images of a toy car were selected so that the machine learning algorithm learns and predicts the pose angle from them in future (unlabeled) images. Our proposed algorithm picked only a few well separated images for labeling from a large set of pictures where the car appears in different poses, with selected poses almost orthogonal to the camera (right 4 images). This set provides maximum learning for the corresponding active learning method. A standard optimal experimental design method (D-optimal, left 4 images) does not consider the manifold structure of the data, and therefore cannot learn as fast, since it selects instances for labeling that are not as well dispersed.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/22/2019<br>\n\t\t\t\t\tModified by: Enrique&nbsp;Del Castillo</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1537987/1537987_10385094_1574433456521_Cars--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1537987/1537987_10385094_1574433456521_Cars--rgov-800width.jpg\" title=\"Example\"><img src=\"/por/images/Reports/POR/2019/1537987/1537987_10385094_1574433456521_Cars--rgov-66x44.jpg\" alt=\"Example\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An active learning example: learning the angle of orientation of an object on an image. Left: classical design of experiments selects images for learning that do not provide fast learning; Right: the proposed method considers the data manifold structure and provides a well dispersed set of images.</div>\n<div class=\"imageCredit\">Hang Li and E. del Castillo</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Enrique&nbsp;Del Castillo</div>\n<div class=\"imageTitle\">Example</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nIntellectual merit\n\nThis project is related to the field of supervised Machine Learning and its application to engineering problems. A classical supervised Machine Learning problem consists of data (which could be as simple as numbers, or as complicated as images) and the corresponding labels associated with each data item, for instance, we could have images (data) and some text that describes what the image contains (label). Supervised Machine Learning algorithms are meant to find relations between the data points and their labels with the goal of predicting the label for an unlabeled data point. In order to be successful, machine learning algorithms need considerable amounts of data and their corresponding labels to be trained properly. The labels in the training datasets are usually assigned by humans or some measuring equipment, and frequently are expensive to acquire. It is therefore important to select the training data carefully. The problem of deciding among a set of unlabeled points which are the most useful for the algorithm to learn from, and therefore, the data items that should be labeled, is called the Active Learning problem.\n\nThe Active Learning problem in Machine Learning is analogous to a classic problem in the field of Statistics, namely, optimal experimental design. Suppose one has to conduct a series of tests on an engineering process (e.g., some machine) in order to improve the process response (e.g., some measure of the quality or performance of a process). For doing this one tries different settings of controllable variables and the collection of such settings constitute an experimental design. When experimentation is expensive it is important to plan the tests carefully, in order to obtain as much information with the minimum number of tests. The analogy with Active Learning algorithms is clear: data items constitute the different experimental settings and the labels are the response values once the test is conducted.\n\nIn the present research, a connection was established between the fields of Active Learning and Optimal Experimental Design. Certain mathematical theorems that guarantee an experimental design is optimal in some well-defined sense were extended for application in Active Learning. The underlying problem is difficult since the spaces where the data occur are quite different: while simple input variables constitute vectors in Euclidean space and most of statistical analysis occurs in these familiar spaces, the type of data one analyzes in machine learning usually lies in curved spaces within a very high dimensional space, the so-called manifolds. The curvature means Pythagoras theorem cannot be used so most standard statistical methods break down. A specific example of manifold data are digital images, where each image may be in a space of very high dimension (as many dimensions as pixels in the picture, for a B&amp;W image), when in reality if the images relates to a subject narrowly defined (classical example, human faces) the data can be explained by using just a few dimensions in a much lower dimensional, but curved, space. The advantage of this nonlinear dimensionality reduction is that machine learning algorithms can learn much faster if the number of coordinates one deals with is reduced.\n\nBroader impacts\n\nApplications of machine learning techniques are well known and occur throughout the engineering, sciences and business disciplines. The research conducted although foundational, has further applicability in industrial inspection systems for quality control and adaptive control systems.\n\nOutcomes\n\nThe main result of this research was a theory of optimal experimental designs for data on manifolds and a corresponding algorithm which was proven to converge to the optimal design. The algorithm can be used for active learning of manifold data, and was demonstrated on image data. One of the surprising results is that both labeled and unlabeled data can be used to accelerate learning. That is, both images already labeled and also images with no labels can be incorporated into the algorithm to learn faster.\n\nFor demonstration purposes, we consider a simple machine learning problem where the algorithm must learn the angle of view of images that display different objects taken at different angles or poses. For instance, in the figure included, images of a toy car were selected so that the machine learning algorithm learns and predicts the pose angle from them in future (unlabeled) images. Our proposed algorithm picked only a few well separated images for labeling from a large set of pictures where the car appears in different poses, with selected poses almost orthogonal to the camera (right 4 images). This set provides maximum learning for the corresponding active learning method. A standard optimal experimental design method (D-optimal, left 4 images) does not consider the manifold structure of the data, and therefore cannot learn as fast, since it selects instances for labeling that are not as well dispersed.\n\n \n\n\t\t\t\t\tLast Modified: 11/22/2019\n\n\t\t\t\t\tSubmitted by: Enrique Del Castillo"
 }
}