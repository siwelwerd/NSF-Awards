{
 "awd_id": "1546206",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Collaborative Research: F: From Data Geometries to Information Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2016-01-01",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 500000.0,
 "awd_amount": 500000.0,
 "awd_min_amd_letter_date": "2015-09-15",
 "awd_max_amd_letter_date": "2015-09-15",
 "awd_abstract_narration": "Big Data often results from multiple sources, giving collections that contain multiple, often partial, \"views\" of the same object, space, or phenomenon from various observers.  Extracting information robustly from such data sets calls for a joint analysis of a large collection of data sets.  The project is developing a novel geometric framework for modeling, structure detection, and information extraction from a collection of large related data sets, with an emphasis on the relationships between data.  While this approach clearly applies to data with a clear geometric character (e.g., objects in images), the work is also applied to datasets as diverse as computer networks (identifying common structure in subnets) and Massive Open Online Course homework data (automatically carrying grader annotations to similar problems in other students' homeworks).\r\n\r\nThe novel framework is based on the construction of maps between the objects under considerations (point clouds, graphs, images, etc...), and on the analysis of the networks of maps that result as a way of extracting information, generating latent models for the data, and transporting or inferring functional / semantic information. These tasks define a new field of map processing between data sets and require tool sets with new ideas from functional analysis, non-convex optimization, and homological algebra in mathematics, and geometric algorithms, machine learning, optimization, and approximation algorithms in computer science.  Sophisticated algorithmic techniques for attacking the large-scale non-linear optimization problems that emerge within the framework will also be investigated.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Leonidas",
   "pi_last_name": "Guibas",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Leonidas J Guibas",
   "pi_email_addr": "guibas@cs.stanford.edu",
   "nsf_id": "000467730",
   "pi_start_date": "2015-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Emmanuel",
   "pi_last_name": "Candes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emmanuel Candes",
   "pi_email_addr": "candes@stanford.edu",
   "nsf_id": "000487480",
   "pi_start_date": "2015-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "450 Serra Mall",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943052004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 500000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overall goal of this project has been to develop a novel geometric framework for model building, structure detection, and information extraction from a large&nbsp;collection of related data sets -- with a focus on the relationships between data, or between the variables describing the data. We have pursued an approach based on the construction of maps between the objects under considerations (point clouds, graphs, images, etc.), and on the analysis of the networks of maps that result, as a way of extracting information, generating latent models for the data, and transporting or inferring functional / semantic information. The effort resulted in progress on under-determined systems and exact/approximate recovery conditions for spaces and maps, a new understanding regarding the geometry of convex and non-convex optimization problems related to matching geometric and information spaces, as well as novel algorithms for organizing geometric data and for the recovery of sparse structures based not only on distances/similarities but also on map consistency criteria.</p>\n<p>To illustrate, one specific area where we have made major progress is joint data alignment or matching via map synchronization.&nbsp; For example, imagine that we have to assemble information about an object from multiple images taken of that object, as in 3D reconstruction or cryoelectron microscopy.&nbsp; To do so we need to jointly recover the camera orientations associated with each image. Typically, one obtains a noisy estimate of relative transformation between a pair of images using raw features. Transformation synchronization is then the task of making all these pairwise estimates globally consistent. This is a challenging optimization problem on which we have obtained both a deeper theoretical understanding as well as state-of-the-art practical algorithms. Our analysis is based on the notion of enforcing cycle consistency in the map network. We select cycles to optimize via a stability score based on a condition number of the Hessian matrix of the induced optimization problem, combining semidefinite programming and importance sampling.</p>\n<p>We have also explored further applications of these ideas to problems in medical and biological data analysis. For example, using diffusion imaging data and tractography algorithms, we have analyzed the 3D shape variability of white matter fiber bundles in the brain aiming to differentiate pathologies from healthy forms across individuals, as well as assess disease progression within one individual. As another example, we have looked at the identification of a subset of relevant explanatory variables in joint data analysis, using a knockoff framework. In such a framework one constructs fake variables, knockoffs, which can then be used as controls for the true variables.&nbsp; We have obtained a Metropolis-Hastings formulation of an exact knockoff sampler and used it to develop a novel Digital Twin Test that allows us to establish causality from trio data in genetic studies.</p>\n<p>We expect that the techniques developed under this project can have many other applications in scientific, engineering, and medical data analysis.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/27/2020<br>\n\t\t\t\t\tModified by: Leonidas&nbsp;J&nbsp;Guibas</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe overall goal of this project has been to develop a novel geometric framework for model building, structure detection, and information extraction from a large collection of related data sets -- with a focus on the relationships between data, or between the variables describing the data. We have pursued an approach based on the construction of maps between the objects under considerations (point clouds, graphs, images, etc.), and on the analysis of the networks of maps that result, as a way of extracting information, generating latent models for the data, and transporting or inferring functional / semantic information. The effort resulted in progress on under-determined systems and exact/approximate recovery conditions for spaces and maps, a new understanding regarding the geometry of convex and non-convex optimization problems related to matching geometric and information spaces, as well as novel algorithms for organizing geometric data and for the recovery of sparse structures based not only on distances/similarities but also on map consistency criteria.\n\nTo illustrate, one specific area where we have made major progress is joint data alignment or matching via map synchronization.  For example, imagine that we have to assemble information about an object from multiple images taken of that object, as in 3D reconstruction or cryoelectron microscopy.  To do so we need to jointly recover the camera orientations associated with each image. Typically, one obtains a noisy estimate of relative transformation between a pair of images using raw features. Transformation synchronization is then the task of making all these pairwise estimates globally consistent. This is a challenging optimization problem on which we have obtained both a deeper theoretical understanding as well as state-of-the-art practical algorithms. Our analysis is based on the notion of enforcing cycle consistency in the map network. We select cycles to optimize via a stability score based on a condition number of the Hessian matrix of the induced optimization problem, combining semidefinite programming and importance sampling.\n\nWe have also explored further applications of these ideas to problems in medical and biological data analysis. For example, using diffusion imaging data and tractography algorithms, we have analyzed the 3D shape variability of white matter fiber bundles in the brain aiming to differentiate pathologies from healthy forms across individuals, as well as assess disease progression within one individual. As another example, we have looked at the identification of a subset of relevant explanatory variables in joint data analysis, using a knockoff framework. In such a framework one constructs fake variables, knockoffs, which can then be used as controls for the true variables.  We have obtained a Metropolis-Hastings formulation of an exact knockoff sampler and used it to develop a novel Digital Twin Test that allows us to establish causality from trio data in genetic studies.\n\nWe expect that the techniques developed under this project can have many other applications in scientific, engineering, and medical data analysis.\n\n\t\t\t\t\tLast Modified: 03/27/2020\n\n\t\t\t\t\tSubmitted by: Leonidas J Guibas"
 }
}