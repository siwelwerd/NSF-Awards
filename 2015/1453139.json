{
 "awd_id": "1453139",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER:Software Requirements Evolution in a Multi-Jurisdictional Socio-Technical Ecosystem",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927841",
 "po_email": "sgreensp@nsf.gov",
 "po_sign_block_name": "Sol Greenspan",
 "awd_eff_date": "2015-09-15",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 635050.0,
 "awd_min_amd_letter_date": "2015-01-30",
 "awd_max_amd_letter_date": "2020-03-18",
 "awd_abstract_narration": "Pervasive and distributed computing decreases development time by allowing engineers to reuse software in third-party components, platforms and cloud-based services. Consequently, this software is subject to multiple policies and regulations that impose legal requirements on the behavior of these complex systems. Legal requirements create evolutionary pressure on system design as developers roll out new product features, enter new markets that cross geo-political boundaries, or when existing laws change or new laws are created. In response, software engineers must reconcile legal requirements with their system design to ensure their software complies with policy and law; a problem even more challenging when innovation occurs in the absence of existing law.\r\n\r\nThis research aims to address this problem by analyzing corpora of regulations that govern software: (1) to develop a set of heuristics and semi-formal, domain-specific languages needed to express and reason about legal requirements for the purpose of determining requirements coverage; (2) to empirically measure gaps among policies and regulations from different jurisdictions that indicate requirements trade-offs, trends and potential disruptions due to changing requirements; and (3) to enable developers to rationalize and select alternate requirements evolutions based on models of changing coverage. The outcomes include new theory to explain and predict requirements evolution across jurisdictions, and tools and techniques that regulators, legal professionals and software engineers can use to reduce the burden of responding to a globally evolving regulatory landscape. These outcomes will be evaluated using mixed-methods research that combines formal methods, information retrieval and human subject experiments aimed at furthering our understanding of how professionals express and interpret requirements and how they reconcile conflicting requirements in the presence of ambiguity and conflicting business and regulatory goals. In addition to training and education, the broader impact of this research aims to harmonize regulatory goals with software systems, to engage the professions of software engineering and law that have historically worked separately, and to inform policy and lawmakers about the impact of regulations on software design and development.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Travis",
   "pi_last_name": "Breaux",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Travis Breaux",
   "pi_email_addr": "breaux@cs.cmu.edu",
   "nsf_id": "000572505",
   "pi_start_date": "2015-01-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Avenue WQED Building",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7944",
   "pgm_ref_txt": "SOFTWARE ENG & FORMAL METHODS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 112636.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 104647.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 269388.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 132379.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This CAREER project examined ways to express and reason about legal and policy requirements, to measure gaps among laws and policies, and to rationalize alternative requirements evolutions due to changing legal and policy coverage. The outcomes of this project advanced understanding of law and legal compliance with respect to software engineering with the aim to improve compliance with law and better achieve societal goals.<br /><br />Intellectual Merit. This CAREER project developed tools and techniques based on a theory of permissions, obligations and prohibitions inspired by a previously NSF-supported study of legal requirements acquisition in healthcare (Breaux, Vail &amp; Anton, 2006). The new tools include a language to express legally governed data collection, use and sharing practices as formal policies modeled in Description Logic (Breaux, Smullen &amp; Hibshi, 2015). The tools support reasoning over ambiguous and incomplete policies, and tracing data flow from collection practices to use and sharing practices, which helps determine with whom collected data can be shared under any given policy. The tools support checking policies for compliance with legal privacy properties, including the first formalization of the Collection Limitation and Use Limitation principles from the Fair Information Practice Principles (FIPPs). The FIPPs were first introduced in 1973 in the US and underpin major US corporate and government privacy policies as well as international privacy regulation. The novel ability to trace data flow across multiple policies, written using different vocabularies, and to check for conflicts with these privacy principles can reduce privacy risk by avoiding the unexpected or unauthorized re-purposing of personal data. The project also yielded new linguistic theory and tools to extract legal definitions from policies using techniques in natural language processing, including typed dependencies (Bhatia et al., 2016) and constituency parse trees (Evans et al., 2017). The extracted definitions were formalized in Description Logic and used to discover conflicting interpretations of \"standard\" terminology critical to regulating data practices, and to define a broader marketplace surveillance of personal information usage across multiple industries.<br /><br />This project further produced a framework to measure privacy risk when apps collect and share policy-governed personal information (Bhatia et al. 2016; Bhatia &amp; Breaux, 2018). Privacy risk is a factor in regulating the processing of personal information by increasing protections for data that is viewed as more sensitive or vulnerable. Unlike security risk, privacy risk is difficult to measure because the risk is exogenous and anthropic, meaning it affects people outside the control of the system, and it is contextual, meaning it can be influenced by changes in when, how and why data is collected and processed. The project adapted construal level theory from psychology to measure the likelihood of privacy harms based on perceived social and physical distances to the harm, and methods for measuring risk from judgement and decision-making to situate risk against the perceived benefits of sharing personal data. The resulting risk measurement tool discovers risks that are not perceivable by commonly used discomfort-based metrics, and it measures risk sensitivity to fluctuating perceptions of privacy harm likelihood.<br /><br />Finally, this project examined the effects of policy evolution on software system design and accountability to ensure individuals have consented to the collection and processing of their personal data (Robol et al., 2021). Privacy regulations, such as HIPAA, COPPA, CCPA and GDPR, require consent prior to the collection and processing of personal data. Under different laws, individuals can revoke their consent, which may separately cease any future data collection or processing, or cease both collection and processing. As policies change, individuals may change their consent preferences, thus increasing the complexity of deciding what data is accessible by a company or government agency at any given time. This project introduced a novel formalization and language that guarantees that logged data practices will not violate the privacy policy or individual consent at any given time, independent of policy changes and changes to individual consent preferences.<br /><br />Broader Impacts: The CAREER project enabled interdisciplinary collaborations, engaging law and computer science students to develop shared understanding on how to interpret law, policy and software requirements across domains. The project contributed to diversity in computer science: PI Breaux trained four female undergraduate REU students, one who received an NSF Graduate Research Fellowship, and three female PhD students, one of whom became a full-time faculty member. His publications under this award have spanned disciplines, including law, software engineering, human computer interaction and natural language processing. In addition, the project results on privacy risk assessment were adopted by the Department of Homeland Security and National Security Agency, and used to inform the National Institute of Standards and Technology Privacy Framework. Finally, the project outcomes were used by other NSF-funded projects to verify policy compliance in mobile applications using static and dynamic code analysis (Slavin et al. 2016, Wang et al. 2018).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/15/2021<br>\n\t\t\t\t\tModified by: Travis&nbsp;Breaux</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis CAREER project examined ways to express and reason about legal and policy requirements, to measure gaps among laws and policies, and to rationalize alternative requirements evolutions due to changing legal and policy coverage. The outcomes of this project advanced understanding of law and legal compliance with respect to software engineering with the aim to improve compliance with law and better achieve societal goals.\n\nIntellectual Merit. This CAREER project developed tools and techniques based on a theory of permissions, obligations and prohibitions inspired by a previously NSF-supported study of legal requirements acquisition in healthcare (Breaux, Vail &amp; Anton, 2006). The new tools include a language to express legally governed data collection, use and sharing practices as formal policies modeled in Description Logic (Breaux, Smullen &amp; Hibshi, 2015). The tools support reasoning over ambiguous and incomplete policies, and tracing data flow from collection practices to use and sharing practices, which helps determine with whom collected data can be shared under any given policy. The tools support checking policies for compliance with legal privacy properties, including the first formalization of the Collection Limitation and Use Limitation principles from the Fair Information Practice Principles (FIPPs). The FIPPs were first introduced in 1973 in the US and underpin major US corporate and government privacy policies as well as international privacy regulation. The novel ability to trace data flow across multiple policies, written using different vocabularies, and to check for conflicts with these privacy principles can reduce privacy risk by avoiding the unexpected or unauthorized re-purposing of personal data. The project also yielded new linguistic theory and tools to extract legal definitions from policies using techniques in natural language processing, including typed dependencies (Bhatia et al., 2016) and constituency parse trees (Evans et al., 2017). The extracted definitions were formalized in Description Logic and used to discover conflicting interpretations of \"standard\" terminology critical to regulating data practices, and to define a broader marketplace surveillance of personal information usage across multiple industries.\n\nThis project further produced a framework to measure privacy risk when apps collect and share policy-governed personal information (Bhatia et al. 2016; Bhatia &amp; Breaux, 2018). Privacy risk is a factor in regulating the processing of personal information by increasing protections for data that is viewed as more sensitive or vulnerable. Unlike security risk, privacy risk is difficult to measure because the risk is exogenous and anthropic, meaning it affects people outside the control of the system, and it is contextual, meaning it can be influenced by changes in when, how and why data is collected and processed. The project adapted construal level theory from psychology to measure the likelihood of privacy harms based on perceived social and physical distances to the harm, and methods for measuring risk from judgement and decision-making to situate risk against the perceived benefits of sharing personal data. The resulting risk measurement tool discovers risks that are not perceivable by commonly used discomfort-based metrics, and it measures risk sensitivity to fluctuating perceptions of privacy harm likelihood.\n\nFinally, this project examined the effects of policy evolution on software system design and accountability to ensure individuals have consented to the collection and processing of their personal data (Robol et al., 2021). Privacy regulations, such as HIPAA, COPPA, CCPA and GDPR, require consent prior to the collection and processing of personal data. Under different laws, individuals can revoke their consent, which may separately cease any future data collection or processing, or cease both collection and processing. As policies change, individuals may change their consent preferences, thus increasing the complexity of deciding what data is accessible by a company or government agency at any given time. This project introduced a novel formalization and language that guarantees that logged data practices will not violate the privacy policy or individual consent at any given time, independent of policy changes and changes to individual consent preferences.\n\nBroader Impacts: The CAREER project enabled interdisciplinary collaborations, engaging law and computer science students to develop shared understanding on how to interpret law, policy and software requirements across domains. The project contributed to diversity in computer science: PI Breaux trained four female undergraduate REU students, one who received an NSF Graduate Research Fellowship, and three female PhD students, one of whom became a full-time faculty member. His publications under this award have spanned disciplines, including law, software engineering, human computer interaction and natural language processing. In addition, the project results on privacy risk assessment were adopted by the Department of Homeland Security and National Security Agency, and used to inform the National Institute of Standards and Technology Privacy Framework. Finally, the project outcomes were used by other NSF-funded projects to verify policy compliance in mobile applications using static and dynamic code analysis (Slavin et al. 2016, Wang et al. 2018).\n\n\t\t\t\t\tLast Modified: 12/15/2021\n\n\t\t\t\t\tSubmitted by: Travis Breaux"
 }
}