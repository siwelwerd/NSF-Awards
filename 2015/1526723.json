{
 "awd_id": "1526723",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Bayesian Modeling of Situated Communicative Goals",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 499945.0,
 "awd_amount": 499945.0,
 "awd_min_amd_letter_date": "2015-08-05",
 "awd_max_amd_letter_date": "2016-06-10",
 "awd_abstract_narration": "This multidisciplinary project undertakes a program of research in natural language generation (NLG), the subfield of artificial intelligence that aims to construct intuitive, accessible utterances to communicate the data, knowledge and reasoning of computational systems.  NLG capabilities have an important role in facilitating new, more natural interaction with computers, both in current applications such as mobile information access and in emerging ones such as personal assistants and human-robot interaction.  NLG systems remain inflexible and difficult to build, however.  This research aims to addresses this problem by developing techniques to train NLG systems to match human language use.  The project is a close collaboration that links psychological experiments, designed to uncover the strategies human speakers use, to computational experiments, which apply these strategies in NLG systems using machine learning.\r\n\r\nThe theoretical framework at the center of this project is Bayesian cognitive modeling, a probabilistic approach that explains human information processing in terms of decision making under uncertainty.  Applied to language use, Bayesian cognitive modeling involves estimating the communicative goals speakers adopt, the knowledge and meanings available to speakers, and the choices speakers make to express needed information in suitable linguistic terms.  Such knowledge and strategies can then be used to drive NLG systems.  The specific research of the project investigates three key domains for applying NLG to construct messages to describe real-world situations: making lexical choices, constructing complex linguistic structures compositionally, and fulfilling multiple overlapping communicative goals.  The project explores each domain through interrelated activities carried out by an interdisciplinary team of computer scientists and psychologists: to formalize speaker choices using a range of Bayesian cognitive models; to fit the models to visually-grounded language corpora using machine learning; to evaluate the empirical scope of goal-directed reasoning by comparing the learned models both to attested human choices and to baseline learned models; and to assess how well the models match human comprehension of linguistic meaning.  The intellectual merits of the project lie in bridging the gap between traditional goal-directed rational models of human behavior and state-of-the-art computational methods that instantiate templates or reproduce likely patterns.  In addition to the societal impacts of the technology, the broader impacts of the project include the construction of data resources, models and modeling tools that will be distributed to facilitate further research, and contributions to ongoing initiatives for education in cognitive science at Rutgers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Stone",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew D Stone",
   "pi_email_addr": "matthew.stone@rutgers.edu",
   "nsf_id": "000246829",
   "pi_start_date": "2015-08-05",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Pernille",
   "pi_last_name": "Hemmer",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pernille Hemmer",
   "pi_email_addr": "pernille.hemmer@rutgers.edu",
   "nsf_id": "000516786",
   "pi_start_date": "2015-08-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers, The State University of New Jersey",
  "perf_str_addr": "110 Frelinghuysen Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725200",
   "pgm_ele_name": "Perception, Action & Cognition"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7252",
   "pgm_ref_txt": "Perception, Action and Cognition"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 161730.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 338215.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project used psycholinguistic methods to study how people describe the world through language, and used machine learning methods to create computer systems that can behave in similar ways. Our experiments helped characterize the ways people identify colors, abstract quantities, locations in space, the contents of images and steps in plans.&nbsp; We built systems that can recognize the strategies that speakers are following and systems that can follow similar strategies to communicate real-world information effectively with people.&nbsp; The associated image shows a signature example, where we taught a robotic arm the different motions required to point recognizably at objects and to point recognizably at the locations that are relevant to carry out complex plans. The work is presented at AAAI 2020, the annual conference on Artificial Intelligence. Our methods depend on philosophical and linguistic insights, which show how in ordinary communication, people rely on the grammar of their native language and mutual expectations about coherent discourse to succeed in sharing their ideas with one another. Conversely, the critical results from our linguistic and philosophical work show how sophisticated computational models can help to substantiate and refine our common-sense ideas about language, meaning and communication.</p>\n<p>&nbsp;</p>\n<p>The project resulted in a range of publications across a range of scientific disciplines, particularly computational linguistics, AI, cognitive science and linguistics.&nbsp; It contributed to three PhD dissertations and offered research experiences to four undergraduates who are continuing on to research careers.&nbsp; We made a number of data sets, models and code bases available to the community.&nbsp; And we worked with companies to find better ways to interact intelligently with smart devices and to make visual content on the internet more accessible to a broad range of users.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/07/2020<br>\n\t\t\t\t\tModified by: Matthew&nbsp;D&nbsp;Stone</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1526723/1526723_10383758_1578446143874_spatial-referential--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1526723/1526723_10383758_1578446143874_spatial-referential--rgov-800width.jpg\" title=\"Locating vs referential pointing\"><img src=\"/por/images/Reports/POR/2020/1526723/1526723_10383758_1578446143874_spatial-referential--rgov-66x44.jpg\" alt=\"Locating vs referential pointing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Viewers understand pointing differently depending on the information the agent is trying to convey.</div>\n<div class=\"imageCredit\">Alikhani et al AAAI 2020</div>\n<div class=\"imageSubmitted\">Matthew&nbsp;D&nbsp;Stone</div>\n<div class=\"imageTitle\">Locating vs referential pointing</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project used psycholinguistic methods to study how people describe the world through language, and used machine learning methods to create computer systems that can behave in similar ways. Our experiments helped characterize the ways people identify colors, abstract quantities, locations in space, the contents of images and steps in plans.  We built systems that can recognize the strategies that speakers are following and systems that can follow similar strategies to communicate real-world information effectively with people.  The associated image shows a signature example, where we taught a robotic arm the different motions required to point recognizably at objects and to point recognizably at the locations that are relevant to carry out complex plans. The work is presented at AAAI 2020, the annual conference on Artificial Intelligence. Our methods depend on philosophical and linguistic insights, which show how in ordinary communication, people rely on the grammar of their native language and mutual expectations about coherent discourse to succeed in sharing their ideas with one another. Conversely, the critical results from our linguistic and philosophical work show how sophisticated computational models can help to substantiate and refine our common-sense ideas about language, meaning and communication.\n\n \n\nThe project resulted in a range of publications across a range of scientific disciplines, particularly computational linguistics, AI, cognitive science and linguistics.  It contributed to three PhD dissertations and offered research experiences to four undergraduates who are continuing on to research careers.  We made a number of data sets, models and code bases available to the community.  And we worked with companies to find better ways to interact intelligently with smart devices and to make visual content on the internet more accessible to a broad range of users.\n\n \n\n\t\t\t\t\tLast Modified: 01/07/2020\n\n\t\t\t\t\tSubmitted by: Matthew D Stone"
 }
}