{
 "awd_id": "1533560",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: EXPL: CCA: Merging Parallel Run-times and Operating Systems",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 298669.0,
 "awd_amount": 350669.0,
 "awd_min_amd_letter_date": "2015-06-25",
 "awd_max_amd_letter_date": "2020-02-20",
 "awd_abstract_narration": "Title: XPS: EXPL: CCA: Merging Parallel Run-times and Operating Systems\r\n\r\nParallelism, the ability to do break down larger tasks into smaller tasks that can be done simultaneously, is essential for applications to continue to become exponentially faster over time. Considerable effort has been placed and is being placed into research on how to achieve parallelism within hardware, programming languages, compilers, and algorithms. However, application software also depends on systems software, particularly the operating system kernel. Currently, the application software and the operating system kernel are very distinct domains with a high barrier between them, and only the operating system kernel has full access to the hardware. While this design exists for very good reasons, it may now limit the parallelism and thus the performance possible in applications. This project investigates an alternative design in which the application software and the operating system kernel are merged into one entity. The intellectual merits are several. First, such a design has not been previously studied in the context of parallelism---this project will determine if it is a good idea. Second, the design resonates with modern languages and run-time systems that are designed specifically with parallelism in mind---such systems can leverage the opportunity to use the operating system kernel and the hardware in new ways. Finally, the project team is well poised to carry out the investigation given their prior work in operating systems and virtualization for high performance computing. The project's broader significance and importance are based on the extent to which the alternative design can enhance performance and the amount of exploitable parallelism. If this is considerable, then the alternative design may be widely adopted and thus contribute to keeping computing performance, as experienced even by end-users, on its exponential track.\r\n\r\nThe project is primarily concerned with allowing modern parallel run-time systems (and their applications) to be re-conceptualized as kernels in their own right. By being a kernel, a run-time can access the full hardware capabilities of the machine, and it can implement exactly the kernel abstractions that it needs to achieve its goals. The team is designing, implementing, and evaluating a kernel framework to support the porting and construction of parallel run-time systems for this model. Using a set of several current run-time systems and several different kinds of parallel hardware, the team is also investigating what kernel abstractions are useful within this model, as well as how to leverage kernel-only hardware features to better support the run-time systems. Both mature run-times which are to be ported to the model and nascent run-times that can be co-designed with the model are under consideration.  The project also integrates with another effort that is investigating a virtualization approach that may make it possible to support the new model simultaneously with the old model.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Dinda",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Peter A Dinda",
   "pi_email_addr": "pdinda@northwestern.edu",
   "nsf_id": "000341788",
   "pi_start_date": "2015-06-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602083118",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 298669.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 12000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 12000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 12000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-9f763cbb-7fff-0bdf-ce95-934b0026ac19\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The goal of this project was to deeply consider a new way to structure parallel systems.&nbsp; Parallelism lies at the heart of how to deliver the high computing performance necessary for science and engineering, but it is also something that is increasingly playing an important role for everyone as a substrate for machine learning.&nbsp; Indeed, even the average smartphone is now a parallel computer.&nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project studied the Hybrid Runtime (HRT) model, in which the traditional boundaries between the parallel application, runtime and operating system kernel are eliminated.&nbsp; This affords the application and runtime access to all hardware features, including privileged ones, and the ability to align kernel-level abstractions directly with their needs. &nbsp; However, the HRT model comes at the cost of needing to develop kernel-level code, which presents significantly greater challenges than those of traditional user-level code.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">It was generally found that this tradeoff is a reasonable one. &nbsp; The HRT model is an appropriate and effective model for the parallel systems community. &nbsp; The project developed proof-of-concept HRTs for three parallel models (Legion, NESL, and OpenMP) that showed performance gains on modern large scale processors such as the Intel Xeon Phi.&nbsp; &nbsp; A range of kernel-only uses of hardware mechanisms were designed, built, and evaluated, including runtime-specialized uses of hardware interrupt masking and routing, and asynchronous event notification via hardware interrupts.&nbsp; &nbsp; Numerous kernel abstractions were also considered, including runtime-specialized hard real-time scheduling, specialized lightweight threads, and alternatives to memory protection via paging.&nbsp; Debugging of HRTs was also studied, resulting in some progress, but also many additional questions.&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The project's approach was largely empirical. &nbsp; The project developed its own kernel (and virtualization) framework for HRTs, and then used it as the basis for the research.&nbsp; The kernel framework, Nautilus, is designed for modern x86 computers, but it can also work on more esoteric processor variants such as the Xeon Phi, and on architectural simulators. &nbsp; Nautilus is open-source and publicly available. &nbsp; More broadly, the software developed in pursuing this research has been made publically available with open-source licensing (typically MIT, BSD, or GPL licenses).&nbsp;&nbsp;&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Significant training opportunities resulted from the project.&nbsp; 7 Ph.D. students, 6 MS students, 8 REU students,&nbsp; 6 undergraduates, and one high school student have been involved in the project.&nbsp; One Ph.D.graduated and started a tenure-track faculty position where he trains others. &nbsp; &nbsp; 3 M.S. students joined Ph.D. programs, while 3 undergraduates are in the process of applying.&nbsp; Northwestern&rsquo;s undergraduate operating systems course was entirely redesigned, leveraging the Nautilus kernel framework to create labs. &nbsp; A Northwestern graduate course in kernel and other low-level software development was created, and has so far trained over 100 students in this esoteric topic.&nbsp;&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The positive results of this exploratory project has, so far, resulted in two follow-on projects (along with two other institutions) that are trying to expand the HRT model to include parallel languages and theory, compilers, and malleable hardware.&nbsp; &nbsp; The Nautilus codebase described above is a key part of enabling this work.</span></p>\n<p><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/08/2020<br>\n\t\t\t\t\tModified by: Peter&nbsp;A&nbsp;Dinda</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "The goal of this project was to deeply consider a new way to structure parallel systems.  Parallelism lies at the heart of how to deliver the high computing performance necessary for science and engineering, but it is also something that is increasingly playing an important role for everyone as a substrate for machine learning.  Indeed, even the average smartphone is now a parallel computer.    \n\n \nThe project studied the Hybrid Runtime (HRT) model, in which the traditional boundaries between the parallel application, runtime and operating system kernel are eliminated.  This affords the application and runtime access to all hardware features, including privileged ones, and the ability to align kernel-level abstractions directly with their needs.   However, the HRT model comes at the cost of needing to develop kernel-level code, which presents significantly greater challenges than those of traditional user-level code. \n\n \nIt was generally found that this tradeoff is a reasonable one.   The HRT model is an appropriate and effective model for the parallel systems community.   The project developed proof-of-concept HRTs for three parallel models (Legion, NESL, and OpenMP) that showed performance gains on modern large scale processors such as the Intel Xeon Phi.    A range of kernel-only uses of hardware mechanisms were designed, built, and evaluated, including runtime-specialized uses of hardware interrupt masking and routing, and asynchronous event notification via hardware interrupts.    Numerous kernel abstractions were also considered, including runtime-specialized hard real-time scheduling, specialized lightweight threads, and alternatives to memory protection via paging.  Debugging of HRTs was also studied, resulting in some progress, but also many additional questions.  \n\n \nThe project's approach was largely empirical.   The project developed its own kernel (and virtualization) framework for HRTs, and then used it as the basis for the research.  The kernel framework, Nautilus, is designed for modern x86 computers, but it can also work on more esoteric processor variants such as the Xeon Phi, and on architectural simulators.   Nautilus is open-source and publicly available.   More broadly, the software developed in pursuing this research has been made publically available with open-source licensing (typically MIT, BSD, or GPL licenses).    \n\n \nSignificant training opportunities resulted from the project.  7 Ph.D. students, 6 MS students, 8 REU students,  6 undergraduates, and one high school student have been involved in the project.  One Ph.D.graduated and started a tenure-track faculty position where he trains others.     3 M.S. students joined Ph.D. programs, while 3 undergraduates are in the process of applying.  Northwestern\u2019s undergraduate operating systems course was entirely redesigned, leveraging the Nautilus kernel framework to create labs.   A Northwestern graduate course in kernel and other low-level software development was created, and has so far trained over 100 students in this esoteric topic.  \n\n \nThe positive results of this exploratory project has, so far, resulted in two follow-on projects (along with two other institutions) that are trying to expand the HRT model to include parallel languages and theory, compilers, and malleable hardware.    The Nautilus codebase described above is a key part of enabling this work.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 11/08/2020\n\n\t\t\t\t\tSubmitted by: Peter A Dinda"
 }
}