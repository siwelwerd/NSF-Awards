{
 "awd_id": "1540888",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SL-CN: Project LENS: Leveraging Expertise in Neurotechnologies to Study Individual Differences in Multimedia Learning",
 "cfda_num": "47.075",
 "org_code": "04010000",
 "po_phone": "7032927878",
 "po_email": "slim@nsf.gov",
 "po_sign_block_name": "Soo-Siang Lim",
 "awd_eff_date": "2015-09-15",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 765000.0,
 "awd_amount": 817500.0,
 "awd_min_amd_letter_date": "2015-09-01",
 "awd_max_amd_letter_date": "2017-06-07",
 "awd_abstract_narration": "The use of multimedia in STEM education is undergoing a remarkable growth. Such growth has been so rapid that it has far outstripped the abilities of research to keep pace with its application.  Project LENS is designed to establish a Science of Learning Collaborative Network (SL-CN) consisting of the Educational Neuroscience Laboratory and Center for the Study of Emotion and Attention at the University of Florida, the Laboratory for Visual Learning at the University of Massachusetts Boston, and the Educational Neuropsychology Laboratory at Washington State University. The network brings together scholars from the following disciplines: STEM Education, Cognitive and Developmental Psychology, Neuroscience, Educational Technology, Computer Science, and Educational Measurement. Experts from the Project LENS network will employ novel methods and neuroimaging technologies to investigate multimedia learning in order to address the gap in knowledge developing in this field. \r\n\r\nThe purpose of this collaborative network is to capitalize on the strengths of each node leveraging expertise in cognitive neurotechnologies (Electroencephalography, functional Near Infrared Spectroscopy, and eye tracking) to enable a rigorous interdisciplinary research ecosystem. Project LENS will advance fundamental research about learning through integrative neurocognitive conceptual and empirical approaches. \r\n\r\nThis interdisciplinary team will advance the science of learning in several ways, including: 1) While most existing multimedia learning research focuses on cognitive load and learning without much consideration of individual learner characteristics, these investigators propose a paradigm shift to put the diversity of learners and their individual differences in the center of multimedia learning research; 2) While the few existing studies that use the individual differences paradigm focus primarily on the role of working memory capacity, this project takes a broader approach and study individual differences at a more precise level, exploring the role of such attentional and cognitive variables as visual attention span, inhibitory control etc.  3) The integrative and interdisciplinary research approaches used in this project will reduce educational researchers? reliance on self-reports in the study of attention, cognition and learning and promote the use of relevant cognitive neuroscience frameworks and tools to improve the science of learning; and 4) the accumulated data on individual differences will lay important groundwork for the construction of comprehensive computational models that can be used to personalize and adapt multimedia learning. \r\n\r\nIn addition to advancing the understanding of designing multimedia learning, the network's webinars, guest presentations, and composite mentorship of graduate students will enhance learning, teaching, and student advisement within and across our network nodes. The project will broaden participation of underrepresented groups by focusing on the diverse community college student population with a wide range of demographic, attentional, and cognitive differences, and by recruiting research assistants from groups that are currently underrepresented in STEM. The purpose of Project LENS is to enhance infrastructure for research and education, which would be accomplished by establishing collaborations and partnerships in the science of learning.  Project LENS addresses at least three national initiatives: a) the BRAIN initiative (2014), b) American Graduation Initiative (2015), and c) US House Resolution on Dyslexia (#456, 113th Congress).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SMA",
 "org_div_long_name": "SBE Office of Multidisciplinary Activities",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pavlo",
   "pi_last_name": "Antonenko",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pavlo Antonenko",
   "pi_email_addr": "p.antonenko@coe.ufl.edu",
   "nsf_id": "000624547",
   "pi_start_date": "2015-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Schneps",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Schneps",
   "pi_email_addr": "mschneps@me.com",
   "nsf_id": "000120612",
   "pi_start_date": "2015-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Marc",
   "pi_last_name": "Pomplun",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Marc Pomplun",
   "pi_email_addr": "marc@cs.umb.edu",
   "nsf_id": "000090280",
   "pi_start_date": "2015-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Keil",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas Keil",
   "pi_email_addr": "akeil@ufl.edu",
   "nsf_id": "000077306",
   "pi_start_date": "2015-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Lamb",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Richard L Lamb",
   "pi_email_addr": "richard.lamb@uga.edu",
   "nsf_id": "000656425",
   "pi_start_date": "2015-09-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "UNIVERSITY OF FLORIDA",
  "perf_str_addr": "1 UNIVERSITY OF FLORIDA",
  "perf_city_name": "Gainesville",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326112002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "004Y00",
   "pgm_ele_name": "Science of Learning"
  },
  {
   "pgm_ele_code": "727800",
   "pgm_ele_name": "SCIENCE OF LEARN CTRS- CENTERS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1340",
   "pgm_ref_txt": "ENGINEERING EDUCATION"
  },
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "7956",
   "pgm_ref_txt": "SBE Interdisciplinary Research"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8090",
   "pgm_ref_txt": "STEM-C Partnerships"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 765000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 52500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our project connects several education, psychology, and computer science labs and researchers from across the US around the goal of improving learning with multimedia. Multimedia learning environments leverage multiple media such as text, images, video and modalities like auditory, visual, touch and so on. Most today's tools for learning and teaching rely on multimedia and so it is important for both researchers and educators to understand how multimedia tools help or &nbsp;hinder learning for people with differences in attention and reasoning.</p>\n<p>Our research explored how undergraduate students learn the important stereochemistry concept of chirality when molecule models are provided either as two-dimensional images (dash-wedge models) or three-dimensional images (ball-stick models, Figure 1). One hundred and twenty students from three US community colleges participated in this study. All were new to organic chemistry. We used neurocognitive tests to determine the attentional and cognitive differences among our study participants and then asked them to complete a chirality task on the computer. The task involved comparing pairs of molecules in either the 2D condition or the 3D condition by mentally rotating one of the two models and aligning it with the other model to determine whether the two models represented the same molecule or not. As the participants worked on this task, we tracked their eye movements (visual attention behavior), and brainwave patterns and hemoglobin oxygenation (mental effort).</p>\n<p>This study produced a number of interesting results that help advance the science of learning. First, we found that participants did not do well comparing molecule models in either the 2D or 3D format (accuracy rate of about 65%). Comparing 3D models took significantly longer and did not result in improved accuracy, which implies that chemistry educators may be better off teaching stereochemistry using 2D models. We also found that female participants tended to have lower accuracy on this task than males and that language abilities predicted learning for women. This was a surprising finding because the chirality task is image-based (visuospatial) and does not use words. A possible explanation for this finding is that female learners may rely on verbal descriptors of visuospatial model components much more than males. Thus, educators need to keep this in mind as they introduce visuospatial tasks in their classrooms. Importantly, task accuracy in both female and male participants was predicted by their ability to store and manipulate information in working memory. This finding suggests that that working memory training activities should be integrated across K-12 and higher education curricula to improve working memory skills that support student learning. The research described in this paragraph was recognized as impactful and our team received the Best Paper Award at the 2018 meeting of the American Educational Research Association, Special Interest Group: Instructional Technology.&nbsp;&nbsp;</p>\n<p>Eye tracking, brainwave, and hemoglobin oxygenation measures helped us explore why some participants did better on this chemistry task than others. We found that high performers produced focused their gaze more on both 2D and 3D models than low performers (Figure 2). They also fixated more on 3D models than on 2D models, which explains why it took them longer to learn with 3D models. High performers also focused longer on the first model they saw before switching their attention to the second model. This behavior is consistent with how experts compare molecules. Instead of switching back and forth between the two models (inefficient behavior), experts take in model #1 and create a mental representation of it, which they then compare to the second model they see. This is a more efficient way to perform this visuospatial task than the rapid visual search and match process characteristic of novice learners, which results in lower task accuracy and longer completion times. Low performers also exhibited higher binocular disparity, or the ability to quickly focus both eyes on a visual target (Figure 3). Brainwave and hemoglobin oxygenation data showed that learning with 3D models resulted in increased mental effort, evidenced by higher and longer alpha wave desynchronization (Figure 4). Combined, these findings explain why learning stereochemistry may be more efficient and effective when using 2D models of molecules, a result that is counter to many educators' intuitive belief that 3D models are better tools for learning.</p>\n<p>To advance the science of multimedia learning, our team conducts workshops, webinars, and symposia that attract hundreds of researchers and educators. Our team collaborates with many research labs, K-12 schools, and community colleges to study effective design of 21<sup>st</sup> century multimedia learning tools that consider important differences among learners. We are currently exploring a) how to leverage gaze-driven displays to train attention and to adapt learning in real time based on students' eye movement patterns, b) how to design more effective math learning games for young children, and c) how to reduce math and statistics anxiety in learners from elementary to graduate school.&nbsp; &nbsp;&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2021<br>\n\t\t\t\t\tModified by: Pasha&nbsp;Antonenko</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286637575_fig.1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286637575_fig.1--rgov-800width.jpg\" title=\"Stereochemistry task used in our study\"><img src=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286637575_fig.1--rgov-66x44.jpg\" alt=\"Stereochemistry task used in our study\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">2D and 3D models of molecules used in the stereochemistry task in our study</div>\n<div class=\"imageCredit\">SL-CN LENS</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Pasha&nbsp;Antonenko</div>\n<div class=\"imageTitle\">Stereochemistry task used in our study</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286760375_fig.2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286760375_fig.2--rgov-800width.jpg\" title=\"Eye tracking results\"><img src=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286760375_fig.2--rgov-66x44.jpg\" alt=\"Eye tracking results\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Eye tracking results from our stereochemistry study</div>\n<div class=\"imageCredit\">SLCN-LENS</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Pasha&nbsp;Antonenko</div>\n<div class=\"imageTitle\">Eye tracking results</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286839088_fig.3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286839088_fig.3--rgov-800width.jpg\" title=\"Binocular disparity differences\"><img src=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638286839088_fig.3--rgov-66x44.jpg\" alt=\"Binocular disparity differences\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Differences in binocular disparity among low performers and high performers</div>\n<div class=\"imageCredit\">SLCN-LENS</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Pasha&nbsp;Antonenko</div>\n<div class=\"imageTitle\">Binocular disparity differences</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638287020733_fig.4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638287020733_fig.4--rgov-800width.jpg\" title=\"Brainwave dynamics\"><img src=\"/por/images/Reports/POR/2021/1540888/1540888_10394599_1638287020733_fig.4--rgov-66x44.jpg\" alt=\"Brainwave dynamics\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Differences in brainwave patterns in the 2D and 3D condition in the stereochemistry study</div>\n<div class=\"imageCredit\">SLCN-LENS</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Pasha&nbsp;Antonenko</div>\n<div class=\"imageTitle\">Brainwave dynamics</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nOur project connects several education, psychology, and computer science labs and researchers from across the US around the goal of improving learning with multimedia. Multimedia learning environments leverage multiple media such as text, images, video and modalities like auditory, visual, touch and so on. Most today's tools for learning and teaching rely on multimedia and so it is important for both researchers and educators to understand how multimedia tools help or  hinder learning for people with differences in attention and reasoning.\n\nOur research explored how undergraduate students learn the important stereochemistry concept of chirality when molecule models are provided either as two-dimensional images (dash-wedge models) or three-dimensional images (ball-stick models, Figure 1). One hundred and twenty students from three US community colleges participated in this study. All were new to organic chemistry. We used neurocognitive tests to determine the attentional and cognitive differences among our study participants and then asked them to complete a chirality task on the computer. The task involved comparing pairs of molecules in either the 2D condition or the 3D condition by mentally rotating one of the two models and aligning it with the other model to determine whether the two models represented the same molecule or not. As the participants worked on this task, we tracked their eye movements (visual attention behavior), and brainwave patterns and hemoglobin oxygenation (mental effort).\n\nThis study produced a number of interesting results that help advance the science of learning. First, we found that participants did not do well comparing molecule models in either the 2D or 3D format (accuracy rate of about 65%). Comparing 3D models took significantly longer and did not result in improved accuracy, which implies that chemistry educators may be better off teaching stereochemistry using 2D models. We also found that female participants tended to have lower accuracy on this task than males and that language abilities predicted learning for women. This was a surprising finding because the chirality task is image-based (visuospatial) and does not use words. A possible explanation for this finding is that female learners may rely on verbal descriptors of visuospatial model components much more than males. Thus, educators need to keep this in mind as they introduce visuospatial tasks in their classrooms. Importantly, task accuracy in both female and male participants was predicted by their ability to store and manipulate information in working memory. This finding suggests that that working memory training activities should be integrated across K-12 and higher education curricula to improve working memory skills that support student learning. The research described in this paragraph was recognized as impactful and our team received the Best Paper Award at the 2018 meeting of the American Educational Research Association, Special Interest Group: Instructional Technology.  \n\nEye tracking, brainwave, and hemoglobin oxygenation measures helped us explore why some participants did better on this chemistry task than others. We found that high performers produced focused their gaze more on both 2D and 3D models than low performers (Figure 2). They also fixated more on 3D models than on 2D models, which explains why it took them longer to learn with 3D models. High performers also focused longer on the first model they saw before switching their attention to the second model. This behavior is consistent with how experts compare molecules. Instead of switching back and forth between the two models (inefficient behavior), experts take in model #1 and create a mental representation of it, which they then compare to the second model they see. This is a more efficient way to perform this visuospatial task than the rapid visual search and match process characteristic of novice learners, which results in lower task accuracy and longer completion times. Low performers also exhibited higher binocular disparity, or the ability to quickly focus both eyes on a visual target (Figure 3). Brainwave and hemoglobin oxygenation data showed that learning with 3D models resulted in increased mental effort, evidenced by higher and longer alpha wave desynchronization (Figure 4). Combined, these findings explain why learning stereochemistry may be more efficient and effective when using 2D models of molecules, a result that is counter to many educators' intuitive belief that 3D models are better tools for learning.\n\nTo advance the science of multimedia learning, our team conducts workshops, webinars, and symposia that attract hundreds of researchers and educators. Our team collaborates with many research labs, K-12 schools, and community colleges to study effective design of 21st century multimedia learning tools that consider important differences among learners. We are currently exploring a) how to leverage gaze-driven displays to train attention and to adapt learning in real time based on students' eye movement patterns, b) how to design more effective math learning games for young children, and c) how to reduce math and statistics anxiety in learners from elementary to graduate school.    \n\n\t\t\t\t\tLast Modified: 11/30/2021\n\n\t\t\t\t\tSubmitted by: Pasha Antonenko"
 }
}