{
 "awd_id": "1464104",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CSR: Towards Understanding and Mitigating the Impact of Web Robot Traffic on Web Systems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2015-05-01",
 "awd_exp_date": "2019-04-30",
 "tot_intn_awd_amt": 150294.0,
 "awd_amount": 174319.0,
 "awd_min_amd_letter_date": "2015-03-03",
 "awd_max_amd_letter_date": "2015-11-05",
 "awd_abstract_narration": "This CSR-CRII project responds to the sudden rise of Web robot (a.k.a. Web crawler) traffic on Web systems around the world - from approximately 20% of all requests a decade ago to over 60% today. Because present Web systems' optimizations assume that the traffic serviced exhibit human-like patterns that robots do not, present robot activity on the Web may silently degrade performance, energy efficiency, and scalability of Web systems. As the Web continues to evolve towards a social platform where individuals upload extemporaneous thoughts and observations that only carry instantaneous value to organizations, and where the Internet of Things concept is expected to introduce millions of devices that collect data from the Web and submit requests to online services automatically, robot traffic will only rapidly increase in volume and intensity. For this reason, it is essential that we understand the impact of Web robot traffic on modern Web systems and devise technologies capable of mitigating their impact on system performance, energy efficiency, and scalability.\r\n\r\nThis effort will synthesize our present understanding of robot traffic with machine learning tools, statistical analysis, and data science methods not previously considered in the context of Web traffic analysis and user behavioral modeling. It will improve our ability to understand the impact of robot traffic on Web systems by: (i) devising automatic methods to classify robots by their functionality and by the demands they impose; and (ii) develop novel robot traffic generators, tailored to a specific profile of robot types that can test how a system reacts to robot traffic of varying intensity and functional type mixtures. The project will also explore a prototype robot-resilient caching system that could lead to immediate performance payoffs for existing Web systems. The project will result in preliminary analytical models, empirical results, and prototype analysis software leading to longer-term research endeavors. Recent data from Web systems that provide services across many Web domains are immediately available for the project.\r\n\r\nThe results of the project potentially may transform the way Web systems from single servers to large clouds are designed and optimized mitigating performance, energy efficiency, and the financial cost of servicing robots. Students to work on this project will be strategically recruited to broaden participation. Educational activities will provide students useful yet infrequently taught traffic analysis and Web systems security fostering stronger ties between knowledge engineering and cybersecurity student and research communities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Derek",
   "pi_last_name": "Doran",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Derek E Doran",
   "pi_email_addr": "derek.doran@wright.edu",
   "nsf_id": "000552088",
   "pi_start_date": "2015-03-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Wright State University",
  "inst_street_address": "3640 COLONEL GLENN HWY",
  "inst_street_address_2": "",
  "inst_city_name": "DAYTON",
  "inst_state_code": "OH",
  "inst_state_name": "Ohio",
  "inst_phone_num": "9377752425",
  "inst_zip_code": "454350002",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "OH10",
  "org_lgl_bus_name": "WRIGHT STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NPT2UNTNHJZ1"
 },
 "perf_inst": {
  "perf_inst_name": "Wright State University",
  "perf_str_addr": "3640 Colonel Glenn Highway",
  "perf_city_name": "Dayton",
  "perf_st_code": "OH",
  "perf_st_name": "Ohio",
  "perf_zip_code": "454350001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "OH10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 150294.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 24025.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has advanced our understanding about the shape, nature, and implications of web robot traffic on web systems. Specific contributions of this project include a new method based on fuzzy methods to identify benign and malicious web robot traffic, an extension of fuzzy rough set theory to automtically select the ideal features to identify web robots customized to a particular web server, the creation of a web robot traffic generator able to produce streams of synthetic robots to perform web systems performance and capacity planning, intelligent caching systems for web servers that mitigate the negative impact web robot traffic has on them, and the relaization that request type analysis may be sufficient to identify hidden web robot traffic streams on a web server. The project applied our developments in web crawling and characterization to carry out a large scale, successful comprehensive crawl of the English language Tor dark web that to the best of our knowledge has ever performed. This crawl led to important insights into the structure, nature of content, and relationships behind the types of information stored on the dark web. Our work on automatic feature selection for web robot traffic was reported on by techXplore.</p>\n<p>The project has supported 6 graduate students and 5 undergraduate, including two female PhD students and one female undergraduate student. Two MS students graduated with funding from this project. Both students are now data scientists at Cisco Systems and LexisNexis Special Services, respectively. Another MS student transferred to our PhD program and has moved onto a new project. Yet another MS student, who is now a DoD SMART Fellow, transitioned to a new project before graduating. He is now a PhD student at Perdue. Both funded PhD students are minority women. One of these students were funded under this effort for her first years of her PhD program before transferring. Her publications under this project led to multiple machine learning internships, including at NEC Research Labs and Amazon. These are exceptional outcomes for PhD students at Wright State University. Both women PhD students are Anita Borg scholars of the Grace Hopper Celebration for Women in Computing and CRA-W grad cohort scholars. They are also regular participants of Ohio Celebration of Women in Computing events. One of the five undergraduate students supported by this project have moved on into graduate studies, another is completing a BS honors thesis with the intention of continuing to graduate school. The remaining students landed excellent research engineering positions in the greater Dayton, OH area.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/22/2019<br>\n\t\t\t\t\tModified by: Derek&nbsp;E&nbsp;Doran</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555973867460_robots_ndeg_vis--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555973867460_robots_ndeg_vis--rgov-800width.jpg\" title=\"Robot Session Graph\"><img src=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555973867460_robots_ndeg_vis--rgov-66x44.jpg\" alt=\"Robot Session Graph\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Network of web pages visited on the wright.edu domain by web crawlers with pages colored by modularity class. This project quantifies the differences between this network structure against one for humans.</div>\n<div class=\"imageCredit\">Kyle Brown and Derek Doran</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Derek&nbsp;E&nbsp;Doran</div>\n<div class=\"imageTitle\">Robot Session Graph</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555973917164_humans_ndeg_vis--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555973917164_humans_ndeg_vis--rgov-800width.jpg\" title=\"Human Session Graph\"><img src=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555973917164_humans_ndeg_vis--rgov-66x44.jpg\" alt=\"Human Session Graph\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Network of web pages visited on the wright.edu domain by humans with pages colored by modularity class. This project quantifies the differences between this network structure against one for robots.</div>\n<div class=\"imageCredit\">Kyle Brown and Derek Doran</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Derek&nbsp;E&nbsp;Doran</div>\n<div class=\"imageTitle\">Human Session Graph</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974122156_ScreenShot2019-04-22at7.01.40PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974122156_ScreenShot2019-04-22at7.01.40PM--rgov-800width.jpg\" title=\"Intelligent Caching Architecture\"><img src=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974122156_ScreenShot2019-04-22at7.01.40PM--rgov-66x44.jpg\" alt=\"Intelligent Caching Architecture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">An intelligent caching architecture that learns to admit or evict resources based on the origin of a request (human or robot) with sequence patterns captured by each traffic type with deep learning.</div>\n<div class=\"imageCredit\">Howard Nathan Rude and Derek Doran</div>\n<div class=\"imageSubmitted\">Derek&nbsp;E&nbsp;Doran</div>\n<div class=\"imageTitle\">Intelligent Caching Architecture</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974665646_ScreenShot2019-04-22at7.07.31PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974665646_ScreenShot2019-04-22at7.07.31PM--rgov-800width.jpg\" title=\"Statistics of Real and Synthetic Web Robot Traffic\"><img src=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974665646_ScreenShot2019-04-22at7.07.31PM--rgov-66x44.jpg\" alt=\"Statistics of Real and Synthetic Web Robot Traffic\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Multiple statistical tests and experiments confirm that the crucial properties of web traffic seen in a web robot traffic generator match well with real observations from a web server in Pavia, Italy.</div>\n<div class=\"imageCredit\">Kyle Brown and Derek Doran</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Derek&nbsp;E&nbsp;Doran</div>\n<div class=\"imageTitle\">Statistics of Real and Synthetic Web Robot Traffic</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974924780_ScreenShot2019-04-22at7.13.34PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974924780_ScreenShot2019-04-22at7.13.34PM--rgov-800width.jpg\" title=\"Relationships between Tor pages conditioned by content type\"><img src=\"/por/images/Reports/POR/2019/1464104/1464104_10352638_1555974924780_ScreenShot2019-04-22at7.13.34PM--rgov-66x44.jpg\" alt=\"Relationships between Tor pages conditioned by content type\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Experiences in engineering and studying Web robots enabled what may be the most comprehensive crawl of the Tor dark web to date. Visualized are links between Tor domains conditioned by the type of content hosted on each page.</div>\n<div class=\"imageCredit\">Mahdieh Zabihimayvan and Derek Doran</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Derek&nbsp;E&nbsp;Doran</div>\n<div class=\"imageTitle\">Relationships between Tor pages conditioned by content type</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project has advanced our understanding about the shape, nature, and implications of web robot traffic on web systems. Specific contributions of this project include a new method based on fuzzy methods to identify benign and malicious web robot traffic, an extension of fuzzy rough set theory to automtically select the ideal features to identify web robots customized to a particular web server, the creation of a web robot traffic generator able to produce streams of synthetic robots to perform web systems performance and capacity planning, intelligent caching systems for web servers that mitigate the negative impact web robot traffic has on them, and the relaization that request type analysis may be sufficient to identify hidden web robot traffic streams on a web server. The project applied our developments in web crawling and characterization to carry out a large scale, successful comprehensive crawl of the English language Tor dark web that to the best of our knowledge has ever performed. This crawl led to important insights into the structure, nature of content, and relationships behind the types of information stored on the dark web. Our work on automatic feature selection for web robot traffic was reported on by techXplore.\n\nThe project has supported 6 graduate students and 5 undergraduate, including two female PhD students and one female undergraduate student. Two MS students graduated with funding from this project. Both students are now data scientists at Cisco Systems and LexisNexis Special Services, respectively. Another MS student transferred to our PhD program and has moved onto a new project. Yet another MS student, who is now a DoD SMART Fellow, transitioned to a new project before graduating. He is now a PhD student at Perdue. Both funded PhD students are minority women. One of these students were funded under this effort for her first years of her PhD program before transferring. Her publications under this project led to multiple machine learning internships, including at NEC Research Labs and Amazon. These are exceptional outcomes for PhD students at Wright State University. Both women PhD students are Anita Borg scholars of the Grace Hopper Celebration for Women in Computing and CRA-W grad cohort scholars. They are also regular participants of Ohio Celebration of Women in Computing events. One of the five undergraduate students supported by this project have moved on into graduate studies, another is completing a BS honors thesis with the intention of continuing to graduate school. The remaining students landed excellent research engineering positions in the greater Dayton, OH area. \n\n \n\n\t\t\t\t\tLast Modified: 04/22/2019\n\n\t\t\t\t\tSubmitted by: Derek E Doran"
 }
}