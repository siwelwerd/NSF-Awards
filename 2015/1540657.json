{
 "awd_id": "1540657",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BSF: 2014324: Streaming Algorithms for Fundamental Computations in Numerical Linear Algebra",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tracy Kimbrel",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 40000.0,
 "awd_amount": 40000.0,
 "awd_min_amd_letter_date": "2015-08-06",
 "awd_max_amd_letter_date": "2015-08-06",
 "awd_abstract_narration": "Streaming algorithms that use every input datum once (single-pass) or scan the input a small number of times (multiple passes) are gaining importance due to the increasing volumes of data that are available for business, scientific, and security applications. Performing large-scale data analysis and machine learning often requires addressing numerical linear algebra primitives, such as least squares regression, singular value decompositions, least absolute deviations regression, and canonical correlation analysis.  In this proposal, the PIs aim to improve significantly the theory and practice of streaming algorithms for these fundamental linear algebra kernels.  The new algorithms will provide faster and more accurate kernels for the ubiquitous big data applications, reducing resource use (hardware and energy) of machine learning applications, and will make security applications that rely critically on accuracy provably trustworthy.  In addition, they will enable improved exploitation of data in physical, chemical, and biomedical applications.\r\n\r\nThe computations that will be considered are performed either using inexact incremental single-pass algorithms, or by expensive multi-pass algorithms. Although existing inexact algorithms often work well enough in practice, the worst-case behavior of applications relying on these building blocks has not been characterized. This is especially troubling in the security and anomaly-detection areas, where a malicious party could conceivably exploit such inexactness. The PIs will develop a set of provably-accurate single-pass algorithms for numerical linear algebra. They will also explore alternative algorithmic routes, mainly multi-pass randomized algorithms, both for the core problems (least squares regression regression and singular value decomposition) and for the more challenging ones (least absolute deviations regression and canonical correlations). They will characterize the accuracy/performance tradeoffs associated with these computations, where performance refers mostly to the number of passes but also to the total computational effort (including communication). The PIs will carry out this investigation using benchmarks from significant applications, as well as theoretical lower bounds on single-pass algorithms.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Mahoney",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michael Mahoney",
   "pi_email_addr": "mmahoney@icsi.berkeley.edu",
   "nsf_id": "000661349",
   "pi_start_date": "2015-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "International Computer Science Institute",
  "inst_street_address": "2150 SHATTUCK AVE",
  "inst_street_address_2": "SUITE 250",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106662900",
  "inst_zip_code": "947041345",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "INTERNATIONAL COMPUTER SCIENCE INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GSRMP1QCXU74"
 },
 "perf_inst": {
  "perf_inst_name": "International Computer Science Institute",
  "perf_str_addr": "1947 Center St STE 600",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947044115",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "2878",
   "pgm_ref_txt": "SPECIAL PROJECTS - CCF"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 40000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project involved travel and collaboration to develop improved streaming and pass efficient and communication aware and avoiding algorithms for basic linear algebra problems of interest in machine learning and data science. &nbsp;This included least squares and least absolute deviations regression, ridge-regularized and lasso-regularized variants of these basic regression problems, and stochastic second order optimization variants of these basic algorithms. &nbsp;For example, we parallelized the Least Angle Regression (LARS) algorithm for fitting linear regression models to high-dimensional data. &nbsp;We considered two parallel and communication avoiding versions of the basic LARS algorithm. &nbsp;The two algorithms apply to data that have different layout patterns (one is appropriate for row-partitioned data, and the other is appropriate for column-partitioned data), and they have different asymptotic costs and practical performance. &nbsp;These algorithms are fundamental for the big data revolution which is transforming computer science, machine learning, and artificial intelligence. &nbsp;Although existing inexact algorithms appear to work well in practice (based on experimental assessments in various application domains), the worst-case behavior of applications relying on such building blocks has not been characterized. &nbsp;This is especially troubling in the security and anomaly-detection areas, where a malicious party could conceivably exploit the inexactness of current algorithms. &nbsp;In addition, these algorithms will provide faster and more accurate kernels for the ubiquitous big data applications, reducing resources use (hardware and energy) of machine learning applications, and will make security applications that rely critically on accuracy provably trustworthy.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/06/2019<br>\n\t\t\t\t\tModified by: Michael&nbsp;Mahoney</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project involved travel and collaboration to develop improved streaming and pass efficient and communication aware and avoiding algorithms for basic linear algebra problems of interest in machine learning and data science.  This included least squares and least absolute deviations regression, ridge-regularized and lasso-regularized variants of these basic regression problems, and stochastic second order optimization variants of these basic algorithms.  For example, we parallelized the Least Angle Regression (LARS) algorithm for fitting linear regression models to high-dimensional data.  We considered two parallel and communication avoiding versions of the basic LARS algorithm.  The two algorithms apply to data that have different layout patterns (one is appropriate for row-partitioned data, and the other is appropriate for column-partitioned data), and they have different asymptotic costs and practical performance.  These algorithms are fundamental for the big data revolution which is transforming computer science, machine learning, and artificial intelligence.  Although existing inexact algorithms appear to work well in practice (based on experimental assessments in various application domains), the worst-case behavior of applications relying on such building blocks has not been characterized.  This is especially troubling in the security and anomaly-detection areas, where a malicious party could conceivably exploit the inexactness of current algorithms.  In addition, these algorithms will provide faster and more accurate kernels for the ubiquitous big data applications, reducing resources use (hardware and energy) of machine learning applications, and will make security applications that rely critically on accuracy provably trustworthy.\n\n\t\t\t\t\tLast Modified: 10/06/2019\n\n\t\t\t\t\tSubmitted by: Michael Mahoney"
 }
}