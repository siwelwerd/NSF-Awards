{
 "awd_id": "1513378",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SEMIPARAMETRIC INFERENCE WITH HIGH-DIMENSIONAL DATA",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2015-07-29",
 "awd_max_amd_letter_date": "2017-08-16",
 "awd_abstract_narration": "Big Data is an area of intense current interest in statistical research and practice due to the rapid development of information technologies and their applications to modern scientific experiments. High-dimensional statistical methods typically provide crucial elements and ideas in engineering solutions for complex Big Data problems. Important fields with an abundance of such problems include bioinformatics, signal processing, neural imaging, communications and social networks, text mining and more. In many such applications, the nominal complexity of the problem, typically measured by the dimension of the data such as genetic components in bioinformatics, brain regions or voxels in neural imaging, or computers and routers in the Internet, is much greater than number of sample points or the information content of the data. The research project will identify and characterize high-dimensional statistical models and problems in which efficient statistical inference are feasible, and will develop new methodologies and algorithms to carry out such efficient statistical inference with high-dimensional data. The proposed research is motivated by and will be directly applicable to real life problems in the aforementioned areas where modern information technologies prosper. Furthermore, the proposed research will have significant educational impact. \r\n\r\nA longstanding challenge in high-dimensional data is to identify problems where regular statistical inference is feasible without relying on model selection consistency theory. Consistent model selection allows reduction of the nominal complexity of the problem to a manageable level by identifying all relevant features. However, model selection consistency typically requires uniformly strong signal to separate relevant features from irrelevant ones. Unfortunately, such uniform signal strength assumption is seldom supported by either the data or the underlying science, especially in biological, medical and sociological applications. The PI has proposed a semi-low-dimensional approach of statistical inference and successfully applied it to construct regular p-values and confidence intervals in high-dimensional regression and graphical models. This approach corrects the bias of model selectors just as semiparametric approach corrects the bias of nonparametric estimators. The proposed research will further develop this approach in high-dimensional data analysis and tackle new problems in ways not visible just a few years ago. It will focus on efficient statistical inference with semisupervised data and problems involving many high-dimensional or complex components, including confidence regions and significant tests for composite and multivariate features with high-dimensional data. The project will develop practical methods, efficient algorithms, statistical software, and solid theory directly relevant to common applications involving many high-dimensional or complex components.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Cun-Hui",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Cun-Hui Zhang",
   "pi_email_addr": "czhang@stat.rutgers.edu",
   "nsf_id": "000185504",
   "pi_start_date": "2015-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "Department of Statistics",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548019",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 88867.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 104744.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 106389.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The major goal of the project is develop new methodologies and algorithms for statistical inference with high-dimensional data. Specifically, the projects aims to develop efficient confidence regions and significant tests for (1) composite and multivariate features with high-dimensional data; (2) semi-supervised data; and (3) inference involving many high-dimensional or complex components. The project has made significant progress in developing methods and theory in high-dimensional bootstrap, compressed sensing, statistical inference with high-dimensional data, nonparametric estimation, tensor recovery and shape constrained inference. The PI has presented his project-related work in many conferences and seminars. Specifically, the project has develop methods and theory for shape restricted inference, high-dimensional bootstrap, statistical inference of treatment effects in randomized experiments, sparse recovery with very sparse random projection, chi-square type confidence regions, p-values for groups of moderately large number of effects, and a number of related problems. The results in the following topics are most significant:&nbsp; 1. Block estimation approach to multiple isotonic regression in general dimension and its&nbsp; optimality and variable selection consistency. 2. Bootstrap methodologies for statistical inference of many means and many regression coefficients in high-dimensional models and its proven accuracy and advantages over other methods. 3. A principled way for investigators to analyze randomized experiments when the number of covariates is large. 4. Confidence regions and approximate chi-squared tests for variable groups in high-dimensional linear regression. 5. Tuning-free pointwise confidence intervals in the multiple isotonic regression model. 6. Second Order Stein methods for statistical inference with high-dimensional data, including SURE for SURE and other applications. 7. Sorted concave penalized estimation to combine the advantages of concave and sorted penalizations. 8. High-dimensional nonparametric additive regression. The key outcomes of the project include publications in top journals including Proceedings of the National Academy of Sciences U.S.A., Foundations of Computational Mathematics, the Annals of Statistics, Journal of American Statistical Association, and Statistica Sinica. The project has created opportunities of training and professional development through Ph.D. thesis supervision, short courses outside Rutgers University, and collaboration with young researchers. Project results have been disseminated to communities of interest by publications in top journals in statistics and machine learning, preprints on arXiv, and presentations in conferences, seminars, and short courses.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/08/2020<br>\n\t\t\t\t\tModified by: Cun-Hui&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe major goal of the project is develop new methodologies and algorithms for statistical inference with high-dimensional data. Specifically, the projects aims to develop efficient confidence regions and significant tests for (1) composite and multivariate features with high-dimensional data; (2) semi-supervised data; and (3) inference involving many high-dimensional or complex components. The project has made significant progress in developing methods and theory in high-dimensional bootstrap, compressed sensing, statistical inference with high-dimensional data, nonparametric estimation, tensor recovery and shape constrained inference. The PI has presented his project-related work in many conferences and seminars. Specifically, the project has develop methods and theory for shape restricted inference, high-dimensional bootstrap, statistical inference of treatment effects in randomized experiments, sparse recovery with very sparse random projection, chi-square type confidence regions, p-values for groups of moderately large number of effects, and a number of related problems. The results in the following topics are most significant:  1. Block estimation approach to multiple isotonic regression in general dimension and its  optimality and variable selection consistency. 2. Bootstrap methodologies for statistical inference of many means and many regression coefficients in high-dimensional models and its proven accuracy and advantages over other methods. 3. A principled way for investigators to analyze randomized experiments when the number of covariates is large. 4. Confidence regions and approximate chi-squared tests for variable groups in high-dimensional linear regression. 5. Tuning-free pointwise confidence intervals in the multiple isotonic regression model. 6. Second Order Stein methods for statistical inference with high-dimensional data, including SURE for SURE and other applications. 7. Sorted concave penalized estimation to combine the advantages of concave and sorted penalizations. 8. High-dimensional nonparametric additive regression. The key outcomes of the project include publications in top journals including Proceedings of the National Academy of Sciences U.S.A., Foundations of Computational Mathematics, the Annals of Statistics, Journal of American Statistical Association, and Statistica Sinica. The project has created opportunities of training and professional development through Ph.D. thesis supervision, short courses outside Rutgers University, and collaboration with young researchers. Project results have been disseminated to communities of interest by publications in top journals in statistics and machine learning, preprints on arXiv, and presentations in conferences, seminars, and short courses. \n\n \n\n\t\t\t\t\tLast Modified: 06/08/2020\n\n\t\t\t\t\tSubmitted by: Cun-Hui Zhang"
 }
}