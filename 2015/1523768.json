{
 "awd_id": "1523768",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Statistical Inference via Convex Optimization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 460111.0,
 "awd_amount": 460111.0,
 "awd_min_amd_letter_date": "2015-07-30",
 "awd_max_amd_letter_date": "2015-07-30",
 "awd_abstract_narration": "In a variety of applications in modern science and technology, there is a strong need in accurate statistical inferences from massive sets of high-dimensional data. To meet this need, it is a must to develop novel methods combining provably (nearly) optimal statistical performance with computational efficiency and scalability. The project aims at designing innovative Convex Optimization based inference techniques meeting the above requirements and utilizing these techniques in important applications (Positron Emission Tomography, Nanoscale Fluorescent Microscopy, Quantum Statistics,...). Challenges to be addressed combined with clear \"applied appeal\" make the project a good training ground for Ph.D. students. Project?s outcomes could make a valuable contribution to the computational tools of \"Big Data.\"\r\n\r\nThe approach is based on designing statistical tests with near-optimal risk for multiple composite hypotheses in a class of statistical models where observation is: (a) affine image of unknown vector (\"signal\") corrupted by Gaussian noise; (b) random  vector with independent Poisson entries, the underlying parameters being affine functions of the signal;  (c) random variable taking finitely many values with probabilities affinely depending on the signal; (d) direct products of models (a) - (c). While restrictive with respect to the allowed models, the approach is highly permissive with respect to the number and the structure of the hypotheses. The proposed efficiently computable and scalable tests and their risks stem from optimal solutions to explicit convex programs, and can be used as building blocks in more complicated inferential problems. The research agenda includes the design of sequential tests and dynamical tests; change point detection; estimating functionals of a signal; \"sparsity-oriented\" testing/estimation; applications to Poisson Imaging, Active Learning, and Quantum Statistics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Arkadi",
   "pi_last_name": "Nemirovski",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Arkadi S Nemirovski",
   "pi_email_addr": "nemirovs@isye.gatech.edu",
   "nsf_id": "000486169",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vladimir",
   "pi_last_name": "Koltchinskii",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vladimir Koltchinskii",
   "pi_email_addr": "vlad@math.gatech.edu",
   "nsf_id": "000118109",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue, NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7797",
   "pgm_ref_txt": "COMM & INFORMATION FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 460111.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The subject of our research is high-dimensional statistics and its interplay with optimization. Through theoretical analysis of fundamental problems of hypothesis testing and signal recovery it shows how the theory of convex optimization can be utilized to devise and analyze near-optimal statistical inferences. While the statistical problems we focus on are mainly quite traditional, the essential novelty is of our approach is its<em> operational nature</em>&nbsp; - our inferences and their performance characteristics are yielded by efficient computation rather than by traditional \"closed analytical form\" analysis. Thus, our emphasis is on <em>how to act</em> to achieve the (nearly) best possible under the circumstances statistical performance and on <em>how to compute performance characteristics</em> rather than on a priori analytical prediction of what this performance will be. The advantage of operational approach stems from its ability to provide <em>provably near-optimal</em> inferences in situations which are by far too complex to be amenable to the traditional analytical treatment. Another advantage of our inference routines is their<em> computational freindliness</em> -- their design and implementation stem from convex optimization, so that efficient computability is \"built in.\"<br /><br />In our research, we have developed, under rather general assumptions, novel computationally and statistically efficient inference routines for<br />&bull;&nbsp;plain and sequential testing multiple composite hypotheses in basic observation schemes (Gaussian, Poisson, and Discrete);<br />&bull; near-optimal recovery of linear and certain more general functionals of signals from noisy observations of linear images of these signals (<em>indirect observations</em> - the case which usually is far beyond the grasp of closed form analytical analysis of traditional high-dimensional statistics);<br />&bull; near-optimal signal recovery, under a wide spectrum of error quantifications and rather general a priori information on the signal, from indirect noisy observations;<br />&bull;&nbsp;estimating functionals of covariance and density matrices in quantum tomography.</p>\n<p><br />Taken together, our results advance significantly the theory of high dimensional statistics and cover a broad scope of its potential applications in Change Detection and Signal Processing (e.g., Positron Emission and Quantum Tomography, Poisson Biophotonics, etc.)</p>\n<p><br />The outcomes of the project form the subject of&nbsp; 21 journal papers and research monograph accepted for publication by Princeton University&nbsp; Press (2019).&nbsp; They were reflected in several invited lectures at prestigious international conferences, including International Congress of Mathematicians 2018, and&nbsp; underly, fully or partially, three completed&nbsp; Ph.D. Theses. Besides this, the project's outcomes underly advanced Ph.D. courses taught so far at Georgia Institute of Technology (V. Koltchinskii, 2015, 2017; A. Nemirovski, 2017), Columbia University (V. Koltchinskii), Graduate School on Computational Optimization, Vienna, Austria (A. Nemirovski, 2018), and &Eacute;cole Nationale de la Statistique et de l'Analyse de l'Information, Paris, France (A. Iouditski, 2018).<br /><br /><br /><br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/02/2019<br>\n\t\t\t\t\tModified by: Arkadi&nbsp;S&nbsp;Nemirovski</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1523768/1523768_10381761_1559397668944_movie--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1523768/1523768_10381761_1559397668944_movie--rgov-800width.jpg\" title=\"Change detection\"><img src=\"/por/images/Reports/POR/2019/1523768/1523768_10381761_1559397668944_movie--rgov-66x44.jpg\" alt=\"Change detection\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">When the image starts to change?</div>\n<div class=\"imageCredit\">Arkadi Nemirovski</div>\n<div class=\"imageSubmitted\">Arkadi&nbsp;S&nbsp;Nemirovski</div>\n<div class=\"imageTitle\">Change detection</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe subject of our research is high-dimensional statistics and its interplay with optimization. Through theoretical analysis of fundamental problems of hypothesis testing and signal recovery it shows how the theory of convex optimization can be utilized to devise and analyze near-optimal statistical inferences. While the statistical problems we focus on are mainly quite traditional, the essential novelty is of our approach is its operational nature  - our inferences and their performance characteristics are yielded by efficient computation rather than by traditional \"closed analytical form\" analysis. Thus, our emphasis is on how to act to achieve the (nearly) best possible under the circumstances statistical performance and on how to compute performance characteristics rather than on a priori analytical prediction of what this performance will be. The advantage of operational approach stems from its ability to provide provably near-optimal inferences in situations which are by far too complex to be amenable to the traditional analytical treatment. Another advantage of our inference routines is their computational freindliness -- their design and implementation stem from convex optimization, so that efficient computability is \"built in.\"\n\nIn our research, we have developed, under rather general assumptions, novel computationally and statistically efficient inference routines for\n&bull; plain and sequential testing multiple composite hypotheses in basic observation schemes (Gaussian, Poisson, and Discrete);\n&bull; near-optimal recovery of linear and certain more general functionals of signals from noisy observations of linear images of these signals (indirect observations - the case which usually is far beyond the grasp of closed form analytical analysis of traditional high-dimensional statistics);\n&bull; near-optimal signal recovery, under a wide spectrum of error quantifications and rather general a priori information on the signal, from indirect noisy observations;\n&bull; estimating functionals of covariance and density matrices in quantum tomography.\n\n\nTaken together, our results advance significantly the theory of high dimensional statistics and cover a broad scope of its potential applications in Change Detection and Signal Processing (e.g., Positron Emission and Quantum Tomography, Poisson Biophotonics, etc.)\n\n\nThe outcomes of the project form the subject of  21 journal papers and research monograph accepted for publication by Princeton University  Press (2019).  They were reflected in several invited lectures at prestigious international conferences, including International Congress of Mathematicians 2018, and  underly, fully or partially, three completed  Ph.D. Theses. Besides this, the project's outcomes underly advanced Ph.D. courses taught so far at Georgia Institute of Technology (V. Koltchinskii, 2015, 2017; A. Nemirovski, 2017), Columbia University (V. Koltchinskii), Graduate School on Computational Optimization, Vienna, Austria (A. Nemirovski, 2018), and &Eacute;cole Nationale de la Statistique et de l'Analyse de l'Information, Paris, France (A. Iouditski, 2018).\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 06/02/2019\n\n\t\t\t\t\tSubmitted by: Arkadi S Nemirovski"
 }
}