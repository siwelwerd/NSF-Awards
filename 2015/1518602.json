{
 "awd_id": "1518602",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Large: Collaborative Research: TextureShop: Tools for the Composition and Display of Virtual Texture",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 1174749.0,
 "awd_amount": 1190749.0,
 "awd_min_amd_letter_date": "2015-07-13",
 "awd_max_amd_letter_date": "2017-09-14",
 "awd_abstract_narration": "When we interact with the physical world touch is a vitally important sensory channel, but when we interact with the digital world that is not yet the case.  Historically, this situation may have been principally due to inadequate tactile displays, but that limitation is quickly disappearing.  Increasingly, the principal limitation is the lack of tactile content.  The goal of this collaborative research that involves scientists at three institutions is to empower the content creator, by enabling people to perform the same sorts of operations with tactile textures that they routinely perform with photographs.  Those operations include \"capturing\" a texture, building a mathematical representation of it, creating and displaying synthetic versions that feel very much like the original, enhancing it in various ways (e.g., making it rougher or more velvety), and ultimately \"composing\" novel textures that nonetheless feel realistic and credible.  As a tangible step in this direction, an open source, open hardware project begun under prior NSF support will be continued and expanded.  That project resulted in the distribution of surface haptic devices to about a dozen different labs, leading to a variety of research studies.  In this project, a low-cost surface haptic display and a variety of applications and software tools will be distributed to about 50 early adopters in the research community.  Those individuals will be engaged in this research (e.g., by helping to \"tag\" various textures), and will be empowered to carry out their own research.  In addition, workshops will be organized at major human-computer interaction conferences to support the growing surface haptics community.\r\n\r\nThis work is timely and compelling for a number of reasons.  One, scientific understanding of the physical and neuronal bases of texture perception has advanced considerably in recent years.  For instance, the relationships between vibrations on the skin (produced when a finger slides across a surface), spike timing in afferent neurons, and high-level percepts such as recognition of a specific texture, have recently been elucidated.  Two, \"surface haptic\" technologies for displaying texture to the bare fingertips have also advanced significantly and can now display complex stimuli across the full bandwidth of tactile acuity.  Three, the prevalence of touch screen interfaces has created a plethora of applications such as children's e-books, interfaces for the blind, games, and automobile control panels, which would be well-served by high quality tactile content.  The merit of this research is that it will provide a principled foundation for both the creation and manipulation of that content.  Contributions will include: the development of a \"tactile camera\" that is able to capture the relevant frictional and vibratory data from which realistic textures can be recreated; a novel mathematical representation of the salient aspects of texture as well as algorithms for synthesizing artificial textures on the basis of that representation; a suite of techniques for enhancing aspects of texture by direct operation on the mathematical representation, interpolation between multiple textures, and interaction with audio cues; and finally a set of tools for composing novel textures including search, texture combination and scale transformation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Colgate",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "James E Colgate",
   "pi_email_addr": "colgate@northwestern.edu",
   "nsf_id": "000267549",
   "pi_start_date": "2015-07-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Peshkin",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Michael A Peshkin",
   "pi_email_addr": "peshkin@northwestern.edu",
   "nsf_id": "000317165",
   "pi_start_date": "2015-07-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602080837",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "IL",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 309016.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 285365.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 596368.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to develop methods of measuring, representing, and displaying the tactile feel of surfaces via novel \"surface haptic\" technology.&nbsp; Our work drew inspiration from color displays.&nbsp; Today's advanced graphical displays rely on (1) a scientific understanding of human color perception, along with (2) mathematical representations of color (e.g., an amounts of red, blue, and green), and of course (3) devices that can display arrays of colored pixels.&nbsp; Prior to this project, we had developed surface haptic devices that could display tactile textures (3), but we had neither a sufficiently deep understanding of texture perception (1), nor a useful mathematical representation (2).&nbsp; Additionally, we did not understand the gamut of our surface haptic devices, where the term \"gamut\" refers to the range of textures that a device can display in the context of what a human can perceive.&nbsp;</p>\n<p>&nbsp;</p>\n<p>Over the course of this project, we developed more advanced tactile displays, mathematical representations of texture, tools for measuring and replaying textures, and finally an understanding of the gamut of our displays, along with techniques for expanding the gamut in the future.</p>\n<p>&nbsp;</p>\n<p>The surface haptic technology that we developed is based on electroadhesion.&nbsp; Electroadhesion is the use of electric fields to vary the strength with which fingertips adhere to a surface.&nbsp; By varying adhesion, we vary the friction forces acting on the finger as it slides across a surface.&nbsp; Variations in friction are perceived as texture.&nbsp; We gained a deep physical understanding of electroadhesion, which allowed us to develop new and better means of controlling it.&nbsp; These advances led to more predictable and reliable virtual textures, to new techniques for creating not only texture, but audio as well, and to new means of creating propulsive forces that could push a finger along a surface.&nbsp;</p>\n<p>&nbsp;</p>\n<p>We also continued an outreach project begun under prior NSF funding:&nbsp; the construction and sharing of the \"TPad Phone,\" an open-source hardware project that integrated a tactile display with an Android phone.&nbsp; Additionally, we licensed technology to the company Tanvas, Inc (founded by PI Colgate and co-PI Peshkin) which eventually began to sell and support a full development kit.&nbsp; At this point, we discontinued the TPaD Phone project since researchers around the world could easily access the technology.&nbsp; Tanvas has gone on to use the technology in the digital signage market, and is developing tactile displays for the automotive market.</p>\n<p>&nbsp;</p>\n<p>One of the important outcomes of our research was the development of a mathematical representation of fine texture (i.e., textures such as fabrics as opposed to coarse textures like tree bark).&nbsp; We demonstrated that, when displayed on a surface haptic device, three parameters - pitch, irregularity, and amplitude&nbsp; - were sufficient to cover the full gamut.&nbsp; Any combination of these three parameters could be used to construct a unique texture.&nbsp;&nbsp; Moreover, inexperienced users could employ a graphical interface with these parameters to build a texture that perceptually matched any given fine texture.&nbsp; Thus, we found that fine texture was similar to color insofar as it could be represented in a three-dimensional perceptual space.</p>\n<p>&nbsp;</p>\n<p>Despite this success, we also found that the tactile gamut of surface haptic devices is quite limited.&nbsp; We developed control techniques that enabled us to measure both friction forces and skin vibrations associated with sliding the finger across a physical texture, and then accurately replay these same forces and vibrations as the finger slid across an electroadhesion device.&nbsp; Although we were able to achieve an exquisite match, the physical and virtual (replay) textures did not feel at all similar.&nbsp; We were able to quantify the differences and isolate the issue:&nbsp; the lack of spatial variation across the fingertip.&nbsp; Variable friction textures, unlike natural textures, excite the entire fingertip in synchrony.&nbsp;</p>\n<p>&nbsp;</p>\n<p>To investigate the role of asynchrony, we developed a device with 14 individually controlled indenters.&nbsp; A fingertip placed on top of the indenters could experience either synchronized vibrations, or various degrees of asynchrony.&nbsp; We demonstrated that, when accompanied by a high degree of spatial variation, asynchronies as small as 1 millisecond could be perceived.&nbsp; This remarkable finding provides an entirely new perspective on fine texture perception:&nbsp; one that relies heavily on minute timing differences across the fingertip instead of the overall vibratory waveform.</p>\n<p>&nbsp;</p>\n<p>Informed by this result as well as our advances in electroadhesion, we have proposed a new type of tactile display consisting of an array of \"pucks\" worn on the fingertip.&nbsp; The friction between each individual puck and a touch surface can be controlled with electroadhesion.&nbsp; A new NSF grant has been received that will fund the exploration of this novel approach; however, under the current project we were able to build a simplified version using steel pucks and a magnet.&nbsp; In preliminary studies, we confirmed that small lateral motions of the pucks (induced by the magnet) were readily perceived.&nbsp; &nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/10/2021<br>\n\t\t\t\t\tModified by: J. Edward&nbsp;Colgate</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1518602/1518602_10376235_1631288515669_TPaDPhoneLandscape--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1518602/1518602_10376235_1631288515669_TPaDPhoneLandscape--rgov-800width.jpg\" title=\"TPaD Phone\"><img src=\"/por/images/Reports/POR/2021/1518602/1518602_10376235_1631288515669_TPaDPhoneLandscape--rgov-66x44.jpg\" alt=\"TPaD Phone\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The TPaD Phone integrates a variable friction haptic display with an Android phone.  It was developed as an open source project for the haptic research community.</div>\n<div class=\"imageCredit\">Joe Mullenbach and Craig Shultz</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">J. Edward&nbsp;Colgate</div>\n<div class=\"imageTitle\">TPaD Phone</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project aimed to develop methods of measuring, representing, and displaying the tactile feel of surfaces via novel \"surface haptic\" technology.  Our work drew inspiration from color displays.  Today's advanced graphical displays rely on (1) a scientific understanding of human color perception, along with (2) mathematical representations of color (e.g., an amounts of red, blue, and green), and of course (3) devices that can display arrays of colored pixels.  Prior to this project, we had developed surface haptic devices that could display tactile textures (3), but we had neither a sufficiently deep understanding of texture perception (1), nor a useful mathematical representation (2).  Additionally, we did not understand the gamut of our surface haptic devices, where the term \"gamut\" refers to the range of textures that a device can display in the context of what a human can perceive. \n\n \n\nOver the course of this project, we developed more advanced tactile displays, mathematical representations of texture, tools for measuring and replaying textures, and finally an understanding of the gamut of our displays, along with techniques for expanding the gamut in the future.\n\n \n\nThe surface haptic technology that we developed is based on electroadhesion.  Electroadhesion is the use of electric fields to vary the strength with which fingertips adhere to a surface.  By varying adhesion, we vary the friction forces acting on the finger as it slides across a surface.  Variations in friction are perceived as texture.  We gained a deep physical understanding of electroadhesion, which allowed us to develop new and better means of controlling it.  These advances led to more predictable and reliable virtual textures, to new techniques for creating not only texture, but audio as well, and to new means of creating propulsive forces that could push a finger along a surface. \n\n \n\nWe also continued an outreach project begun under prior NSF funding:  the construction and sharing of the \"TPad Phone,\" an open-source hardware project that integrated a tactile display with an Android phone.  Additionally, we licensed technology to the company Tanvas, Inc (founded by PI Colgate and co-PI Peshkin) which eventually began to sell and support a full development kit.  At this point, we discontinued the TPaD Phone project since researchers around the world could easily access the technology.  Tanvas has gone on to use the technology in the digital signage market, and is developing tactile displays for the automotive market.\n\n \n\nOne of the important outcomes of our research was the development of a mathematical representation of fine texture (i.e., textures such as fabrics as opposed to coarse textures like tree bark).  We demonstrated that, when displayed on a surface haptic device, three parameters - pitch, irregularity, and amplitude  - were sufficient to cover the full gamut.  Any combination of these three parameters could be used to construct a unique texture.   Moreover, inexperienced users could employ a graphical interface with these parameters to build a texture that perceptually matched any given fine texture.  Thus, we found that fine texture was similar to color insofar as it could be represented in a three-dimensional perceptual space.\n\n \n\nDespite this success, we also found that the tactile gamut of surface haptic devices is quite limited.  We developed control techniques that enabled us to measure both friction forces and skin vibrations associated with sliding the finger across a physical texture, and then accurately replay these same forces and vibrations as the finger slid across an electroadhesion device.  Although we were able to achieve an exquisite match, the physical and virtual (replay) textures did not feel at all similar.  We were able to quantify the differences and isolate the issue:  the lack of spatial variation across the fingertip.  Variable friction textures, unlike natural textures, excite the entire fingertip in synchrony. \n\n \n\nTo investigate the role of asynchrony, we developed a device with 14 individually controlled indenters.  A fingertip placed on top of the indenters could experience either synchronized vibrations, or various degrees of asynchrony.  We demonstrated that, when accompanied by a high degree of spatial variation, asynchronies as small as 1 millisecond could be perceived.  This remarkable finding provides an entirely new perspective on fine texture perception:  one that relies heavily on minute timing differences across the fingertip instead of the overall vibratory waveform.\n\n \n\nInformed by this result as well as our advances in electroadhesion, we have proposed a new type of tactile display consisting of an array of \"pucks\" worn on the fingertip.  The friction between each individual puck and a touch surface can be controlled with electroadhesion.  A new NSF grant has been received that will fund the exploration of this novel approach; however, under the current project we were able to build a simplified version using steel pucks and a magnet.  In preliminary studies, we confirmed that small lateral motions of the pucks (induced by the magnet) were readily perceived.   \n\n \n\n\t\t\t\t\tLast Modified: 09/10/2021\n\n\t\t\t\t\tSubmitted by: J. Edward Colgate"
 }
}