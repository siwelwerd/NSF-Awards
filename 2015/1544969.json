{
 "awd_id": "1544969",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: Synergy: Collaborative Research: Extracting Time-Critical Situational Awareness from Resource Constrained Networks",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "David Corman",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 576000.0,
 "awd_amount": 576000.0,
 "awd_min_amd_letter_date": "2015-09-16",
 "awd_max_amd_letter_date": "2020-08-14",
 "awd_abstract_narration": "The goal of this project is to facilitate timely retrieval of dynamic situational awareness information from field-deployed nodes by an operational center in resource-constrained uncertain environments, such as those encountered in disaster recovery or search and rescue missions.  This is an important cyber physical system problem with perspectives drawn at a system and platform level, as well as at the system of systems level.  Technology advances allow the deployment of field nodes capable of returning rich content (e.g., video/images) that can significantly aid rescue and recovery. However, development of techniques for acquisition, processing and extraction of the content that is relevant to the operation under resource constraints poses significant interdisciplinary challenges, which this project will address. The focus of the project will be on the fundamental science behind these tasks, facilitated by validation via both in house experimentation, and field tests orchestrated based on input from domain experts.\r\n\r\nIn order to realize the vision of this project, a set of algorithms and protocols will be developed to: (a) intelligently activate field sensors and acquire and process the data to extract semantically relevant information; (b) formulate expressive and effective queries that enable the near-real-time retrieval of relevant situational awareness information while adhering to resource constraints;  and, (c) impose a network structure that facilitates cost-effective query propagation and response retrieval. The research brings together multiple sub-disciplines in computing sciences including computer vision, data mining, databases and networking, and understanding the scientific principles behind information management with compromised computation/communication resources. The project will have a significant broader impact in the delivery of effective situational awareness in applications like disaster response. The recent :World Disaster Report\" states that there were more than 1 million deaths and $1.5 trillion in damage from disasters within the past decade; the research has the potential to drastically reduce these numbers.  Other possible applications are law enforcement and environmental monitoring.  The project will facilitate a strong inter-disciplinary education program and provide both undergraduate and graduate students experience with experimentation and prototype development.  There will be a strong emphasis on engaging the broader community and partnering with programs that target under-represented students and minorities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Amit",
   "pi_last_name": "Roy-Chowdhury",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Amit K Roy-Chowdhury",
   "pi_email_addr": "amitrc@ece.ucr.edu",
   "nsf_id": "000309390",
   "pi_start_date": "2015-09-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Srikanth",
   "pi_last_name": "Krishnamurthy",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Srikanth V Krishnamurthy",
   "pi_email_addr": "Krish@cs.ucr.edu",
   "nsf_id": "000183779",
   "pi_start_date": "2015-09-16",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Eamonn",
   "pi_last_name": "Keogh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eamonn Keogh",
   "pi_email_addr": "eamonn@farmsense.io",
   "nsf_id": "000486240",
   "pi_start_date": "2015-09-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Riverside",
  "inst_street_address": "200 UNIVERSTY OFC BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "RIVERSIDE",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "9518275535",
  "inst_zip_code": "925210001",
  "inst_country_name": "United States",
  "cong_dist_code": "39",
  "st_cong_dist_code": "CA39",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA AT RIVERSIDE",
  "org_prnt_uei_num": "",
  "org_uei_num": "MR5QC5FCAVH5"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Riverside",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "925210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "39",
  "perf_st_cong_dist": "CA39",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "8235",
   "pgm_ref_txt": "CPS-Synergy"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 576000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>CPS: Synergy: Collaborative Research: Extracting time-critical situational awareness from resource constrained networks</strong></p>\n<p>Lead PI and Institution: Amit Roy Chowdhury, University of California, Riverside (UCR)</p>\n<p>Collaborating Institution: University of California, Irvine (UCI)</p>\n<p>&nbsp;</p>\n<p>The goal of this project was to facilitate the timely retrieval of dynamic situational awareness information from field-deployed nodes by an operational center in disaster recovery or search and rescue missions, which are typically characterized by resource-constrained uncertain environments.&nbsp; Technology advances allow the deployment of field nodes capable of returning rich content (e.g., video/images) that can significantly aid rescue and recovery. However, development of techniques for acquisition, processing and extraction of the content that is relevant to the operation under resource constraints poses significant interdisciplinary challenges, which this project will address. The focus of the project was on some of the fundamental scientific issues behind these tasks. The research was facilitated by strong experimentation on testbeds available at UCR and UCI.</p>\n<p>&nbsp;</p>\n<p><strong><span style=\"text-decoration: underline;\">Intellectual Merit.</span></strong></p>\n<p>Towards realizing a networked system that facilitates the retrieval of time-critical, operation-relevant situational awareness this project addressed the following (non-exhaustive list) challenges:</p>\n<p>(a) How do we intelligently activate field sensors and acquire and process data to extract semantically relevant information that is easily interpreted?&nbsp;</p>\n<p>(b) How do we formulate expressive and effective queries that enable the near-time retrieval of the relevant situational awareness information while adhering to resource constraints?</p>\n<p>(c) How do we impose a network structure that facilitates cost-effective query propagation and response retrieval?</p>\n<p>This required bringing together multiple sub-disciplines in the computing sciences including computer vision, data mining, databases, and networking, and understanding the fundamental scientific principles behind information management with compromised computation/communication resources.</p>\n<p>&nbsp;</p>\n<p>The project encompassed the following three highly inter-related tasks:</p>\n<p>&nbsp;</p>\n<p><strong>Task A:&nbsp; Resource-Constrained Data Acquisition and Analysis.</strong> This task looked at how to reconfigure the network and adapt video analysis in real time to meet different (sometimes conflicting) application requirements, given resource constraints.</p>\n<p>&nbsp;</p>\n<p><strong>Task B: Information Fusion Under Resource Constraints.</strong> This task proposed methods to locally process and fuse the content generated, given the query needs and resource constraints. It also considered how to summarize the content received in response to the queries to facilitate further analysis at the operation center.</p>\n<p>&nbsp;</p>\n<p><strong>Task C: Cost-effective Query Formulation and Retrieval.</strong> This task addressed challenges in query formulation, refinement and retrieval, including (i) prioritizing queries as per importance criteria, (ii) effective query dissemination in the field, and (iii) effective retrieval of the sensed information.</p>\n<p>&nbsp;</p>\n<p>The main research results were the following.</p>\n<p>&nbsp;</p>\n<p><span style=\"text-decoration: underline;\">Video Acquisition with Limited Resources. </span>Since video is bandwidth-heavy, it is usually affected when there are limited computation and communication resources. We showed how to fill in missing frames in a multi-camera setup, how to extract the informative video segments for transmission and analysis, and how to steer a camera to the most interesting parts of a scene.</p>\n<p>&nbsp;</p>\n<p><span style=\"text-decoration: underline;\">Energy-Efficient Object Detection and Tracking on Mobile Platforms. </span>We developed a framework on mobile platforms that reduces the energy drain of Deep Neural Network (DNN)?based object detection while maintaining good tracking accuracy in videos. This would enable deployment of video computing applications in resource-constrained environments.</p>\n<p>&nbsp;</p>\n<p><span style=\"text-decoration: underline;\">Summarization of Key Events.</span> We have developed methods for summarizing data in different application domains. This includes summarizing videos from multi-camera networks, as well as summarizing data from a large crowd-sensed network that also constructs a concise visual summary.</p>\n<p>&nbsp;</p>\n<p><span style=\"text-decoration: underline;\">Multi-modal Information Fusion and Retrieval. </span>Data collected in most applications consists of multiple modalities including image/video, text, and other sensors. Our work has shown how to localize portions of a video that are relevant to the text and how to retrieve the most relevant videos given a query.</p>\n<p>&nbsp;</p>\n<p><span style=\"text-decoration: underline;\">Progressive Approach to Scalable Big Data Processing. </span>We have developed a query processing framework, where user/application queries are processed in an efficient and scalable manner in big data settings.</p>\n<p>&nbsp;</p>\n<p><span style=\"text-decoration: underline;\"><strong>Broader Impacts.</strong></span></p>\n<p>Efficient situational awareness information retrieval under severe resource limitations is critical in applications like disaster response. There is a need for technologies that can \"dramatically increase the situational awareness of emergency responders and enable optimized response through all phases of disaster events\" (CPS Vision Statement). Other possible applications of our work are in law enforcement or environmental monitoring. The PIs have also integrated some of the methods developed here into courses on video processing and sensor networks. They have also proposed senior capstone design projects that are aligned with some of the research tasks undertaken here. They have also engaged with the broader community and partnered with local school districts to create summer camps in robotics and electronics.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/20/2021<br>\n\t\t\t\t\tModified by: Amit&nbsp;K&nbsp;Roy Chowdhury</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1544969/1544969_10399869_1640042416718_Picture1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1544969/1544969_10399869_1640042416718_Picture1--rgov-800width.jpg\" title=\"Resource-Constrained Information Extraction\"><img src=\"/por/images/Reports/POR/2021/1544969/1544969_10399869_1640042416718_Picture1--rgov-66x44.jpg\" alt=\"Resource-Constrained Information Extraction\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Summary of main research tasks in a resource-constrained cyber-physical system.</div>\n<div class=\"imageCredit\">PI</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Amit&nbsp;K&nbsp;Roy Chowdhury</div>\n<div class=\"imageTitle\">Resource-Constrained Information Extraction</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nCPS: Synergy: Collaborative Research: Extracting time-critical situational awareness from resource constrained networks\n\nLead PI and Institution: Amit Roy Chowdhury, University of California, Riverside (UCR)\n\nCollaborating Institution: University of California, Irvine (UCI)\n\n \n\nThe goal of this project was to facilitate the timely retrieval of dynamic situational awareness information from field-deployed nodes by an operational center in disaster recovery or search and rescue missions, which are typically characterized by resource-constrained uncertain environments.  Technology advances allow the deployment of field nodes capable of returning rich content (e.g., video/images) that can significantly aid rescue and recovery. However, development of techniques for acquisition, processing and extraction of the content that is relevant to the operation under resource constraints poses significant interdisciplinary challenges, which this project will address. The focus of the project was on some of the fundamental scientific issues behind these tasks. The research was facilitated by strong experimentation on testbeds available at UCR and UCI.\n\n \n\nIntellectual Merit.\n\nTowards realizing a networked system that facilitates the retrieval of time-critical, operation-relevant situational awareness this project addressed the following (non-exhaustive list) challenges:\n\n(a) How do we intelligently activate field sensors and acquire and process data to extract semantically relevant information that is easily interpreted? \n\n(b) How do we formulate expressive and effective queries that enable the near-time retrieval of the relevant situational awareness information while adhering to resource constraints?\n\n(c) How do we impose a network structure that facilitates cost-effective query propagation and response retrieval?\n\nThis required bringing together multiple sub-disciplines in the computing sciences including computer vision, data mining, databases, and networking, and understanding the fundamental scientific principles behind information management with compromised computation/communication resources.\n\n \n\nThe project encompassed the following three highly inter-related tasks:\n\n \n\nTask A:  Resource-Constrained Data Acquisition and Analysis. This task looked at how to reconfigure the network and adapt video analysis in real time to meet different (sometimes conflicting) application requirements, given resource constraints.\n\n \n\nTask B: Information Fusion Under Resource Constraints. This task proposed methods to locally process and fuse the content generated, given the query needs and resource constraints. It also considered how to summarize the content received in response to the queries to facilitate further analysis at the operation center.\n\n \n\nTask C: Cost-effective Query Formulation and Retrieval. This task addressed challenges in query formulation, refinement and retrieval, including (i) prioritizing queries as per importance criteria, (ii) effective query dissemination in the field, and (iii) effective retrieval of the sensed information.\n\n \n\nThe main research results were the following.\n\n \n\nVideo Acquisition with Limited Resources. Since video is bandwidth-heavy, it is usually affected when there are limited computation and communication resources. We showed how to fill in missing frames in a multi-camera setup, how to extract the informative video segments for transmission and analysis, and how to steer a camera to the most interesting parts of a scene.\n\n \n\nEnergy-Efficient Object Detection and Tracking on Mobile Platforms. We developed a framework on mobile platforms that reduces the energy drain of Deep Neural Network (DNN)?based object detection while maintaining good tracking accuracy in videos. This would enable deployment of video computing applications in resource-constrained environments.\n\n \n\nSummarization of Key Events. We have developed methods for summarizing data in different application domains. This includes summarizing videos from multi-camera networks, as well as summarizing data from a large crowd-sensed network that also constructs a concise visual summary.\n\n \n\nMulti-modal Information Fusion and Retrieval. Data collected in most applications consists of multiple modalities including image/video, text, and other sensors. Our work has shown how to localize portions of a video that are relevant to the text and how to retrieve the most relevant videos given a query.\n\n \n\nProgressive Approach to Scalable Big Data Processing. We have developed a query processing framework, where user/application queries are processed in an efficient and scalable manner in big data settings.\n\n \n\nBroader Impacts.\n\nEfficient situational awareness information retrieval under severe resource limitations is critical in applications like disaster response. There is a need for technologies that can \"dramatically increase the situational awareness of emergency responders and enable optimized response through all phases of disaster events\" (CPS Vision Statement). Other possible applications of our work are in law enforcement or environmental monitoring. The PIs have also integrated some of the methods developed here into courses on video processing and sensor networks. They have also proposed senior capstone design projects that are aligned with some of the research tasks undertaken here. They have also engaged with the broader community and partnered with local school districts to create summer camps in robotics and electronics. \n\n \n\n\t\t\t\t\tLast Modified: 12/20/2021\n\n\t\t\t\t\tSubmitted by: Amit K Roy Chowdhury"
 }
}