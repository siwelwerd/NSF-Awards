{
 "awd_id": "1539007",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "VEC: Small: Collaborative Research: The Visual Computing Database: A Platform for Visual Data Processing and Analysis at Internet Scale",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2015-09-04",
 "awd_max_amd_letter_date": "2017-09-14",
 "awd_abstract_narration": "This project develops a new parallel computing platform, namely Visual Computing Database, that facilitates the development of applications that require visual data analysis at massive scale. The developed system combines ideas from traditional relational database management systems (to more easily and powerfully organize and manage visual data collections) with modern graphics programming abstractions for efficiently manipulating pixel data. This project implements a prototype of the visual computing database, release it as an open source project to the community, and deploys the system at scale as a service to scientists and researchers on the Google Cloud Platform. There is strong evidence that in domains ranging from personal digital assistants that interpret one's surroundings, to management of critical infrastructure in smart cities, and to scientific data analysis, a fundamental requirement of the next generation of visual and experiential computing (VEC) applications will be the efficient analysis and mining of large repositories of visual data (images, videos, RGBD, etc.). Scaling visual data analysis applications to operate on collections such as the photos and videos on Facebook and YouTube, the traffic cameras in a city, or petabytes of images in a digital sky survey, presents significant computer science challenges due to the size of visual data representations and the computational expense of algorithms understanding and manipulating large image datasets. The difficulty of developing efficient, supercomputing scale applications from scratch inhibits the field's ability to explore advanced data-driven VEC applications. \r\n\r\nA central aspect of the project is the design of a new visual data query language that integrates concepts from high performance, functional image processing languages with relational operators and spatial and temporal predicates, providing the ability to execute sequences of complex image/video analysis operations with high efficiency in the database (near the data store). Since visual analysis workloads involve tight integration of data retrieval operations and processing of the result sets (e.g., largescale machine learning, image registration/alignment, and 3D reconstruction), a key design challenge is making the results of database operations easily accessible to non-relational, supercomputing scale computations. All together the project addresses fundamental systems design questions such as: what is a good visual query language for future visual data analysis tasks? How can key operations be implemented efficiently on throughput hardware at scale? What are the appropriate benchmarks for evaluating visual data analysis systems at scale?\r\n\r\nURL: http://graphics.cs.cmu.edu/projects/visualdb",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Patrick",
   "pi_last_name": "Hanrahan",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Patrick M Hanrahan",
   "pi_email_addr": "hanrahan@cs.stanford.edu",
   "nsf_id": "000333801",
   "pi_start_date": "2015-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943055008",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "748400",
   "pgm_ele_name": "IIS Special Projects"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "002Z",
   "pgm_ref_txt": "Intel/NSF VEC Partnership"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 157772.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 77465.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 14763.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this systems project was to design and implement a system for analyzing large collections of images and videos. Image and videos comprise the largest percentage of data stored in data centers and transmitted on the internet. A major challenge was to efficiently operate in a heterogenous compute environment, for example a mix of CPUs and GPUs. Leveraging GPUs is particularly important since they are optimized for imaging.</p>\n<p>The main aritfact was an open source image and video analysis system called Scanner. This software runs in the cloud and can be used to process large collections of images and videos. The software and documentation is available at&nbsp;<a rel=\"nofollow\" href=\"https://github.com/scanner-research/\">https://github.com/scanner-research/</a></p>\n<p>The system has neen used to analyze several large video databases. One was a database of movies.&nbsp; The goal of this analysis was to understand changes in cinematographic techniques over the years. Another major project was the analysis of 200,000 hours (over a period of a decade) of cable tv news coverage. Here the analysts wanted to understand how information is presented in news broadcasts, as well as the demographics of anchors and guests. The news project was done in collaboration wirth the internet archive and Prof. Maneesh Agrawala and his students. Finally, the system has been used by multiple cloud computing vendors to experiment with different video processing workloads and requirements.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/20/2020<br>\n\t\t\t\t\tModified by: Patrick&nbsp;M&nbsp;Hanrahan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this systems project was to design and implement a system for analyzing large collections of images and videos. Image and videos comprise the largest percentage of data stored in data centers and transmitted on the internet. A major challenge was to efficiently operate in a heterogenous compute environment, for example a mix of CPUs and GPUs. Leveraging GPUs is particularly important since they are optimized for imaging.\n\nThe main aritfact was an open source image and video analysis system called Scanner. This software runs in the cloud and can be used to process large collections of images and videos. The software and documentation is available at https://github.com/scanner-research/\n\nThe system has neen used to analyze several large video databases. One was a database of movies.  The goal of this analysis was to understand changes in cinematographic techniques over the years. Another major project was the analysis of 200,000 hours (over a period of a decade) of cable tv news coverage. Here the analysts wanted to understand how information is presented in news broadcasts, as well as the demographics of anchors and guests. The news project was done in collaboration wirth the internet archive and Prof. Maneesh Agrawala and his students. Finally, the system has been used by multiple cloud computing vendors to experiment with different video processing workloads and requirements.\n\n \n\n\t\t\t\t\tLast Modified: 07/20/2020\n\n\t\t\t\t\tSubmitted by: Patrick M Hanrahan"
 }
}