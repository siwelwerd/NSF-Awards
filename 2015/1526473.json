{
 "awd_id": "1526473",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Human-Directed Optical Music Recognition",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 496197.0,
 "awd_amount": 504197.0,
 "awd_min_amd_letter_date": "2015-08-25",
 "awd_max_amd_letter_date": "2017-05-11",
 "awd_abstract_narration": "Vast quantities of character-encoded text form the foundation for the information retrieval revolution of recent decades.  In contrast, very little symbolically-represented music exists, preventing music from fully participating in the 21st century.  The International Music Score Library Project (IMSLP) is a large and rapidly growing open library of public domain machine-printed classical music scores, actively used by many musicians, scholars, and researchers around the world.  Optical music recognition (OMR) forms the natural bridge between the IMSLP and the missing symbolic music data.  While there has been active OMR research since the 1960s, the state of the art still is not sufficiently well-developed to create symbolic data from realistic documents, as represented on the IMSLP.  This is because music notation contains a thicket of special cases, exceptions to general rules, image pathologies, and interpretation challenges, whose recognition requires a deep level of content understanding.  With this in mind, the PI has developed prototype software named Ceres for supporting a hybrid human-computer team, in which both machine and person partner in a collaborative recognition effort.  The human guides the computer through the recognition task, identifying and providing crucial missing pieces of information, while allowing the computer to fill in the details, consistent with the human guidance.  The ultimate goal is to build a Wikipedia-like community centered around Ceres and the IMSLP with the mission of creating a definitive, open access, symbolic music library that distributes music scores electronically and globally, allowing for adaptive display and automatic transformation and registration of scores with audio and video.  The prevalence of symbolic music data would open up a world of possibilities to music-science researchers, including systems for music information retrieval, expressive performance, musical accompaniment, transcription and arranging, performance assistance, and many others.  Last but not least, the symbolic music library would enable innovative commercial applications; tablet computers will likely be the sheet music \"delivery system\" of the future, allowing automatic page turning, performance feedback, and various kinds of content-based annotation. \r\n\r\nThe challenge of integrating both human and algorithmic intelligence to create a tractable and efficient OMR solution constitutes the heart of this project.  The PI's approach is to adopt the interface paradigm of constrained optimization; the human uses domain understanding to supply crucial missing pieces of information when needed, and the computer uses this guidance to re-recognize and reinterpret subject to these user-supplied constraints.  A preliminary experiment conducted by the PI using a medium-difficulty test set showed a 17% error rate on the part of his prototype system, accounting for both false positives and false negatives at the primitive level.  The human-computer interface is where the recognition results become tangible and subject to manipulation, so its design is critical; this is an area where the PI expects to make contributions to HCI in general.  The PI argues that to be useful for OMR the interface should be almost completely open, providing a set of tools and options, and imposing only the minimal required structure (e.g., staff recognition must be verified before we identify page structure, while the latter must be verified before it is worth continuing to the symbol recognition phase).  The interface development strategy will be one of iterative refinement, the evaluation of each version to involve time- and effort-oriented metrics as well as open-ended user comments.  For example, the Ceres user interface (the null hypothesis for the current project) superimposes the recognized results on the original image, making discrepancies readily apparent (in contrast to other systems that present side-by-side original and recognized notation which is cognitively more difficult to compare), but maybe even better solutions are possible?  Other aspects of the work will include exploration of the roles of visualization (including directing the user's attention) and music playback (hearing the score).  OMR is just one of many computer vision problems that fall into the constrained optimization category, and the approach also applies to natural language processing, machine listening, and others; the essential process to be explored here would extend to these domains as well, providing a general template with far-reaching significance.  For OMR the constraints are individual pixel labels, but for other problem domains they could equally well refer to labelling of individual samples, words, or whatever fundamental units compose the data.  In this way, the approach uses a generic and flexible view for human input that doesn't require the human to understand the inner workings of the recognition processes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Raphael",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher S Raphael",
   "pi_email_addr": "craphael@indiana.edu",
   "nsf_id": "000453143",
   "pi_start_date": "2015-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Erik",
   "pi_last_name": "Stolterman",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Erik A Stolterman",
   "pi_email_addr": "estolter@indiana.edu",
   "nsf_id": "000292064",
   "pi_start_date": "2015-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "901 E 10th Street",
  "perf_city_name": "Bloomington",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474083619",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 496197.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><br /><br />This work endeavors to build a human-in-the-loop system for optical music recognition (OMR). &nbsp; The OMR task takes a machine printed music document and identifies the notes, rhythms, and other information necessary to understand the music. &nbsp; A successful solution to this OMR problem would be the basis for large-scale symbolic music libraries that could make &nbsp;all public domain written music freely available.Since the libraries would be composed of symbolically-representedmusic, rather than images or printed documents, one could hear the music or analyze it many interesting and useful ways. &nbsp;In short, this would allow music to browsed, searched, and organized in ways analogous to those common for text today. &nbsp;This result would be transformative for music. &nbsp;</p>\n<p><br />However, OMR is a difficult problem. &nbsp;While it contains many sub-parts that are solvable with a computer, there are many situations that cannot be properly resolved without the intervention of a human.There has been a great deal of interest in human-in-the-loop systems for such difficult recognition tasks. &nbsp;Human-in-the-loop systems promise to extend the realm of computer systems to cover problems not solvable by computational means alone. &nbsp;One of the principal challengeof these systems is finding a way to allow the human to communicate important knowledge in a language that is easily utilized by the computer. &nbsp;Our work develops a paradigm for this communication channelin which the human user is given a single flexible tool: &nbsp;the user is presented with fully automatic recognition of the current page, as produced by our OMR system. &nbsp;The user then identifies single pixel locations that are incorrectly labeled by the system, while providingthe correct label for the pixel such as beam, note head, treble class, staff line, etc. &nbsp;The system that re-recognizes subject to the constraint supplied by the user. &nbsp;Given the grammatical nature of music documents, it often happens that a single such human-labeled constraint can change the document interpretation locations other than the immediate realm of the labeled pixel. &nbsp;This user iterates this process until error-free results are obtained. &nbsp;</p>\n<p><br />Our system has been developed from scratch to the point where it is close to the leading commercial systems for OMR. &nbsp;While our core recognition results lag behind those of the best commercial systems,the addition of the human-in-the-loop component was able to nearly close the gap when measured in terms of the amount of human effort needed to produce error-free results. &nbsp;Thus the promise of human-in-the-loop recognition, as well as the specific paradigm we explore has been validated and deserves further effort. &nbsp;<br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/02/2020<br>\n\t\t\t\t\tModified by: Christopher&nbsp;S&nbsp;Raphael</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\nThis work endeavors to build a human-in-the-loop system for optical music recognition (OMR).   The OMR task takes a machine printed music document and identifies the notes, rhythms, and other information necessary to understand the music.   A successful solution to this OMR problem would be the basis for large-scale symbolic music libraries that could make  all public domain written music freely available.Since the libraries would be composed of symbolically-representedmusic, rather than images or printed documents, one could hear the music or analyze it many interesting and useful ways.  In short, this would allow music to browsed, searched, and organized in ways analogous to those common for text today.  This result would be transformative for music.  \n\n\nHowever, OMR is a difficult problem.  While it contains many sub-parts that are solvable with a computer, there are many situations that cannot be properly resolved without the intervention of a human.There has been a great deal of interest in human-in-the-loop systems for such difficult recognition tasks.  Human-in-the-loop systems promise to extend the realm of computer systems to cover problems not solvable by computational means alone.  One of the principal challengeof these systems is finding a way to allow the human to communicate important knowledge in a language that is easily utilized by the computer.  Our work develops a paradigm for this communication channelin which the human user is given a single flexible tool:  the user is presented with fully automatic recognition of the current page, as produced by our OMR system.  The user then identifies single pixel locations that are incorrectly labeled by the system, while providingthe correct label for the pixel such as beam, note head, treble class, staff line, etc.  The system that re-recognizes subject to the constraint supplied by the user.  Given the grammatical nature of music documents, it often happens that a single such human-labeled constraint can change the document interpretation locations other than the immediate realm of the labeled pixel.  This user iterates this process until error-free results are obtained.  \n\n\nOur system has been developed from scratch to the point where it is close to the leading commercial systems for OMR.  While our core recognition results lag behind those of the best commercial systems,the addition of the human-in-the-loop component was able to nearly close the gap when measured in terms of the amount of human effort needed to produce error-free results.  Thus the promise of human-in-the-loop recognition, as well as the specific paradigm we explore has been validated and deserves further effort.  \n\n\n\n\n\t\t\t\t\tLast Modified: 06/02/2020\n\n\t\t\t\t\tSubmitted by: Christopher S Raphael"
 }
}