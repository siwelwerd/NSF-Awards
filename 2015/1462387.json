{
 "awd_id": "1462387",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: EAGER-DynamicData: Probabilistic Analysis of Dynamic X-ray Diffraction Data: Toward Validated Computational Models for Polycrystalline Plasticity",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Lawrence Goldberg",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 90000.0,
 "awd_amount": 90000.0,
 "awd_min_amd_letter_date": "2015-09-04",
 "awd_max_amd_letter_date": "2018-08-10",
 "awd_abstract_narration": "The past two decades have witnessed the development of accurate and efficient computational methods for a wide range of physical processes and the transition of these models into regularly used tools for product design and development within all sectors of the US economy. One important exception to this trend is in the field of material science where progress in creating new classes of materials and advancing the use of existing systems is hampered by the lack of validated computational models. Of particular interest in this proposal are structural polycrystalline metals, of central importance in the automotive, aircraft, and energy industries, where the processes of fatigue and fracture pose significant modeling and computational challenges. To resolve these issues, dynamic high-energy X-ray diffraction (HEXD) experiments have recently come on line that are capable of probing the internal evolution of samples of these materials in real time as they are subject to processing or service conditions.  The resulting data sets are both large (up to 10Tb for a single experiment) and complex thereby complicating their analysis and integration within the material design process.  Even with extensive human interaction, state-of-the-art computational tools can extract only a tiny fraction of the full information contained in these data sets.   Realizing the potential offered by these data and models requires fundamentally new Big Data-type of computational methods.  The work in this project is aimed at developing such a tool set. \r\n \r\nOf specific concern in this project are the use and extension of sophisticated, probabilistic, video processing methods as the basis for addressing a pressing problem in the analysis of dynamic HEXD data. The physics of X-ray diffraction from polycrystalline samples gives rise to data sets comprised of temporally evolving collections of localized structures, referred to as \"spots,\" in a three-dimensional data space. Use of these data in conjunction with computational plasticity codes requires that these spots be associated with individual grains in the polycrystal and that these sets of evolving structures be tracked over time. To date, the only tools for addressing this indexing problem are static in nature and function best for cases where the material sample is in a pristine state. Similarities between this dynamic indexing problem and the problem of identifying and tracking objects moving in a video scene motivate the adaptation and further development of a multi-hypothesis tracking approach developed by the PI team to the analysis of HEXD data. The method is based on the construction of a conditional random field over a large set of hypotheses capturing ways in which spots can be associated with one. Estimation of the optimal tracks and association is carried out using efficient graph cut methods making the overall approach well suited to near real time implementation. The existing work in this field will be extended through the construction of dynamic models for the evolution of features associated with the spots (e.g., centroid location, low order moments) based on existing plasticity codes and incorporation of these models into the random field to achieve a multiple model, multi-hypothesis tracking approach for dynamic HEXD data.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Miller",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Eric L Miller",
   "pi_email_addr": "eric.miller@tufts.edu",
   "nsf_id": "000114959",
   "pi_start_date": "2015-09-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Tufts University",
  "inst_street_address": "80 GEORGE ST",
  "inst_street_address_2": "",
  "inst_city_name": "MEDFORD",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6176273696",
  "inst_zip_code": "021555519",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "TRUSTEES OF TUFTS COLLEGE",
  "org_prnt_uei_num": "WL9FLBRVPJJ7",
  "org_uei_num": "WL9FLBRVPJJ7"
 },
 "perf_inst": {
  "perf_inst_name": "Tufts University",
  "perf_str_addr": "20 Professors Row",
  "perf_city_name": "Medford",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021555807",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "153E",
   "pgm_ref_txt": "Wireless comm & sig processing"
  },
  {
   "pgm_ref_code": "5384",
   "pgm_ref_txt": "DATA AND DATA SYSTEMS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516RB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 90000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While the advent of \"Big Data\" has had tremendous impact in areas of daily interest to the general public in fields including social- as well as traditional-media, health and fitness, and travel and dining to name but a few, the reach and impact of this data explosion goes well beyond these domains.&nbsp; Of specific interest in this project has been the development of analytics methods that can lend insight into a class of massive data sets collected to better understand the properties of structural polycrystalline materials of which steel and titanium are two notable examples.&nbsp; With their widespread use in industries ranging from automotive and aerospace to medical and energy, this class of materials has a quiet but nonetheless significant impact on our daily lives.&nbsp; Thus, the development of structural materials that are better performing in terms of weight, strength, and other properties is an important, though challenging, technical problem.&nbsp;&nbsp;</p>\n<p>&nbsp;In much the same way that CAT scans have revolutionized the ability of medical doctors to ?see into? patients, X-ray methods provide material scientists and mechanical engineers with the ability to peer into new materials to assess their suitability for demanding applications.&nbsp; Unlike a CAT scanner which can fit into an ordinary room, large scale synchrotrons are required to generate X-rays capable of penetrating metallic samples.&nbsp; Moreover, rather than providing a clear ?picture? of the internal structure of the material, the physics of the synchrotron data acquisition process results in images that are comprised of solid rings, spots localized on rings, or some complex combination of the two. Interpreting what these patterns have to say about the internal structure of a material sample is subtle and time consuming.&nbsp;&nbsp; These problems have grown significantly worse in recent years as new experimental capabilities at these synchrotron sources have led to data sets comprised of thousands or even millions of images capable of capturing the dynamic response of a material sample as a function of space to e.g., changes in temperature or stress.</p>\n<p>This project has focused on the development of automated data processing methods capable of addressing this type of challenge.&nbsp; The approach begins by modeling the signal in the vicinity of a ring as a superposition of localized ?blobs;? specifically Gaussian basis functions.&nbsp;&nbsp; Convolutional sparse coding (CSC) methods are employed to obtain a parsimonious model of the data as a function of time and space.&nbsp;&nbsp; The parameters of this model are used to define a quantity (which we call the Amplitude Weighted Mean Variance or AWMV) which can be naturally related to the internal state of the sample.&nbsp; While one could apply this approach to each image in the data set individually, there is much to be gained by exploiting the fact that the state of the sample should vary smoothly as a function of both space and time.&nbsp; To encourage the resulting expected degree of smoothness in the CSC solutions, we have developed a method building on recent machine learning ideas in the area of optimal transport.&nbsp; The method has been evaluated and shown promise on real data sets collected by our colleagues at the Cornell High Energy Synchrotron Source (CHESS).&nbsp; The code instantiating these techniques has been provided to the researchers at CHESS who are currently using them as part of their workflow.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/19/2019<br>\n\t\t\t\t\tModified by: Eric&nbsp;L&nbsp;Miller</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhile the advent of \"Big Data\" has had tremendous impact in areas of daily interest to the general public in fields including social- as well as traditional-media, health and fitness, and travel and dining to name but a few, the reach and impact of this data explosion goes well beyond these domains.  Of specific interest in this project has been the development of analytics methods that can lend insight into a class of massive data sets collected to better understand the properties of structural polycrystalline materials of which steel and titanium are two notable examples.  With their widespread use in industries ranging from automotive and aerospace to medical and energy, this class of materials has a quiet but nonetheless significant impact on our daily lives.  Thus, the development of structural materials that are better performing in terms of weight, strength, and other properties is an important, though challenging, technical problem.  \n\n In much the same way that CAT scans have revolutionized the ability of medical doctors to ?see into? patients, X-ray methods provide material scientists and mechanical engineers with the ability to peer into new materials to assess their suitability for demanding applications.  Unlike a CAT scanner which can fit into an ordinary room, large scale synchrotrons are required to generate X-rays capable of penetrating metallic samples.  Moreover, rather than providing a clear ?picture? of the internal structure of the material, the physics of the synchrotron data acquisition process results in images that are comprised of solid rings, spots localized on rings, or some complex combination of the two. Interpreting what these patterns have to say about the internal structure of a material sample is subtle and time consuming.   These problems have grown significantly worse in recent years as new experimental capabilities at these synchrotron sources have led to data sets comprised of thousands or even millions of images capable of capturing the dynamic response of a material sample as a function of space to e.g., changes in temperature or stress.\n\nThis project has focused on the development of automated data processing methods capable of addressing this type of challenge.  The approach begins by modeling the signal in the vicinity of a ring as a superposition of localized ?blobs;? specifically Gaussian basis functions.   Convolutional sparse coding (CSC) methods are employed to obtain a parsimonious model of the data as a function of time and space.   The parameters of this model are used to define a quantity (which we call the Amplitude Weighted Mean Variance or AWMV) which can be naturally related to the internal state of the sample.  While one could apply this approach to each image in the data set individually, there is much to be gained by exploiting the fact that the state of the sample should vary smoothly as a function of both space and time.  To encourage the resulting expected degree of smoothness in the CSC solutions, we have developed a method building on recent machine learning ideas in the area of optimal transport.  The method has been evaluated and shown promise on real data sets collected by our colleagues at the Cornell High Energy Synchrotron Source (CHESS).  The code instantiating these techniques has been provided to the researchers at CHESS who are currently using them as part of their workflow. \n\n \n\n\t\t\t\t\tLast Modified: 12/19/2019\n\n\t\t\t\t\tSubmitted by: Eric L Miller"
 }
}