{
 "awd_id": "1511945",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Development of New Approaches for Analysis of Markov Chain Monte Carlo Algorithms to Facilitate Principled Use of MCMC in Practice",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2019-06-30",
 "tot_intn_awd_amt": 199977.0,
 "awd_amount": 199977.0,
 "awd_min_amd_letter_date": "2015-06-24",
 "awd_max_amd_letter_date": "2015-06-24",
 "awd_abstract_narration": "Markov Chain Monte Carlo (MCMC) is a probability-based simulation technique that is used to approximate high-dimensional intractable integrals. MCMC has revolutionized scientific computing in the last two decades by enabling the use of intricate statistical models in a vast array of disciplines as diverse as genetics, agricultural science, computer science, physics, and economics. Any new methodology that leads to more effective ways to employ MCMC algorithms has countless potential applications in myriad scientific fields. It is vital for users of MCMC to have principled methods for constructing error bounds for the resulting estimates, and to have theoretical guarantees of convergence for the underlying Markov chains. Unfortunately, such methods and guarantees are currently lacking. This research project aims to address this problem by developing new methodology that will allow for more principled application of MCMC. Because the use of MCMC has become so widespread, there is great potential for the methods developed in this project to contribute to the improvement of society from many different corners of science.\r\n\r\nIt is typically straightforward to construct an MCMC algorithm for sampling from a given intractable posterior probability distribution. However, a long-standing difficulty with MCMC is in determining how long an algorithm should be run to produce useful results. The principled approaches to making such a determination are all predicated on the asymptotic normality of the MCMC estimators. Unfortunately, establishing the existence of the requisite central limit theorems (CLTs) requires a detailed analysis of the underlying Markov chain. Worse yet, the methods that are currently available for analyzing Monte Carlo Markov chains are extremely difficult to apply in practice. In fact, for the vast majority of MCMC algorithms that are used in practice, it is unknown whether these CLTs exist. This project concerns the development of new techniques for analyzing complex Markov chains, like those that underlie MCMC algorithms, with an eye towards making it easier to establish the existence of CLTs. The are two main ideas that will be pursued: (1) The standard techniques for analyzing Monte Carlo Markov chains were developed using the total variation (TV) metric (between probability distributions), but it is now becoming clear that the Wasserstein metric is actually much more natural than TV for analyzing the types of Markov chains that arise in statistical applications of MCMC. This suggests that going \"back to the drawing board'' with Wasserstein distance in place of TV distance may lead to new methods that are far more useful in practice than those based on TV. (2) Markov chains with countable state spaces are routinely analyzed with great success via spectral techniques, but this approach is not often used for the Markov chains that underlie statistical applications of MCMC (which usually have uncountable state spaces). This is (at least) partly due to a general perception in the MCMC community that very few of the Markov operators associated with practically relevant Monte Carlo Markov chains are compact. However, recent work suggests that many Gibbs samplers and data augmentation (DA) algorithms do, in fact, have compact Markov operators. Furthermore, application of the spectral techniques to these operators is often much simpler than the standard analysis. This calls for the development of new, general, spectral techniques for the analysis of Markov operators associated with Gibbs samplers and DA algorithms.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Hobert",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "James P Hobert",
   "pi_email_addr": "jhobert@stat.ufl.edu",
   "nsf_id": "000170306",
   "pi_start_date": "2015-06-24",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kshitij",
   "pi_last_name": "Khare",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kshitij Khare",
   "pi_email_addr": "kdkhare@stat.ufl.edu",
   "nsf_id": "000545160",
   "pi_start_date": "2015-06-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Florida",
  "inst_street_address": "1523 UNION RD RM 207",
  "inst_street_address_2": "",
  "inst_city_name": "GAINESVILLE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "3523923516",
  "inst_zip_code": "326111941",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "FL03",
  "org_lgl_bus_name": "UNIVERSITY OF FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NNFQH1JAPEP3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Florida",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "326118545",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "FL03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 199977.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The use of Bayesian statistics has increased dramatically over the<br />last two decades, largely because of the availability of Markov chain<br />Monte Carlo (MCMC) methods.&nbsp; Indeed, MCMC methods have revolutionized<br />scientific computing in the last two decades by enabling the use of<br />intricate statistical models in a vast array of disciplines as diverse<br />as genetics, agricultural science, computer science, physics and<br />economics.&nbsp; Any new methodology that leads to more effective ways to<br />employ MCMC algorithms has countless potential applications in myriad<br />scientific fields.&nbsp; It is typically straightforward to construct an<br />MCMC algorithm for sampling from a given intractable (Bayesian)<br />posterior probability distribution.&nbsp; However, a long-standing<br />difficulty with MCMC is in determining how long an algorithm should be<br />run to produce useful results.&nbsp; This NSF grant has allowed the Co-PIs<br />to compare competing MCMC algorithms for specific problems, and these<br />comparisons have resulted in clear recommendations as to which<br />algorithm should be used in practice.&nbsp; The algorithms that the Co-PIs<br />studied include Gibbs samplers and data augmentation procedures for<br />linear and non-linear models in both classical (small $n$, small $p$)<br />and high-dimensional (big data) situations.&nbsp; Moreover, these<br />algorithms can be used by researchers in many different fields to<br />perform statistical analyses of the data that they have collected.<br />The theoretical results that the Co-PIs have developed as a result of<br />this project have important practical applications, such as allowing<br />for the calculation of valid asymptotic standard errors for MCMC-based<br />estimates.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/29/2019<br>\n\t\t\t\t\tModified by: James&nbsp;P&nbsp;Hobert</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe use of Bayesian statistics has increased dramatically over the\nlast two decades, largely because of the availability of Markov chain\nMonte Carlo (MCMC) methods.  Indeed, MCMC methods have revolutionized\nscientific computing in the last two decades by enabling the use of\nintricate statistical models in a vast array of disciplines as diverse\nas genetics, agricultural science, computer science, physics and\neconomics.  Any new methodology that leads to more effective ways to\nemploy MCMC algorithms has countless potential applications in myriad\nscientific fields.  It is typically straightforward to construct an\nMCMC algorithm for sampling from a given intractable (Bayesian)\nposterior probability distribution.  However, a long-standing\ndifficulty with MCMC is in determining how long an algorithm should be\nrun to produce useful results.  This NSF grant has allowed the Co-PIs\nto compare competing MCMC algorithms for specific problems, and these\ncomparisons have resulted in clear recommendations as to which\nalgorithm should be used in practice.  The algorithms that the Co-PIs\nstudied include Gibbs samplers and data augmentation procedures for\nlinear and non-linear models in both classical (small $n$, small $p$)\nand high-dimensional (big data) situations.  Moreover, these\nalgorithms can be used by researchers in many different fields to\nperform statistical analyses of the data that they have collected.\nThe theoretical results that the Co-PIs have developed as a result of\nthis project have important practical applications, such as allowing\nfor the calculation of valid asymptotic standard errors for MCMC-based\nestimates.\n\n\t\t\t\t\tLast Modified: 08/29/2019\n\n\t\t\t\t\tSubmitted by: James P Hobert"
 }
}