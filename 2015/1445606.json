{
 "awd_id": "1445606",
 "agcy_id": "NSF",
 "tran_type": "CoopAgrmnt",
 "awd_istr_txt": "Cooperative Agreement",
 "awd_titl_txt": "Bridges: From Communities and Data to Workflows and Insight",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032922247",
 "po_email": "rchadduc@nsf.gov",
 "po_sign_block_name": "Robert Chadduck",
 "awd_eff_date": "2014-12-01",
 "awd_exp_date": "2021-11-30",
 "tot_intn_awd_amt": 9650000.0,
 "awd_amount": 20895167.0,
 "awd_min_amd_letter_date": "2014-11-20",
 "awd_max_amd_letter_date": "2020-10-27",
 "awd_abstract_narration": "1.  Abstract: Nontechnical Description\r\n\r\nThe Pittsburgh Supercomputing Center (PSC) will provide an innovative and groundbreaking high-performance computing (HPC) and data-analytic system, Bridges, which will integrate advanced memory technologies to empower new communities, bring desktop convenience to HPC, connect to campuses, and intuitively express data-intensive workflows.\r\n\r\nTo meet the requirements of nontraditional HPC communities, Bridges will emphasize memory, usability, Title and effective data management, leveraging innovative new technologies to transparently benefit applications and lower the barrier to entry.\r\nThree tiers of processing nodes with shared memory ranging from 128GB to 12TB will address an extremely broad range of user needs including interactivity, workflows, long-running jobs, virtualization, and high capacity. Flexible node allocation will enable interactive use for debugging, analytics, and visualization. Bridges will also include a shared flash memory device to accelerate Hadoop and databases. \r\n\r\nBridges will host a variety of popular gateways and portals through which users will easily be able to access its resources. Its many nodes will allow long-running jobs, flexible access to interactive use (for example, for debugging, analytics, and visualization, and access to nodes with more memory. Bridges will host a broad spectrum of application software, and its familiar operating system and programming environment will support high-productivity programming languages and development tools.\r\n\r\nBridges will address data management at all levels. Its shared Project File System, connected to processing nodes by a very capable, appropriately scaled fabric, will provide high-bandwidth, low-latency access to large datasets. Storage on each node will provide local filesystem space that is frequently requested by users and will prevent congestion to the shared filesystem. A set of nodes will be optimized for and dedicated to running databases to support gateways, workflows, and applications. Dedicated web server nodes will enable distributed workflows.\r\n\r\nBridges will introduce powerful new CPUs and GPUs, and a new interconnection fabric to connect them. These new technologies will be supported by extremely broad set of applications, libraries, and easy-to-use programming languages and tools.\r\nBridges will interoperate with and complement other NSF Advanced Cyberinfrastructure resources and large scientific instruments such as telescopes and high-throughput genome sequencers, and it will provide convenient bridging to campuses.\r\n\r\nBridges will enable important advances for science and society. By supporting pioneers who set examples in fields not traditionally users of HPC, and by lowering the barrier of entry, this project will spur others to recognize the power of the technology and transform their fields, as has happened in traditional HPC fields such as physics and chemistry. The project will engage students in research and systems internships, develop and offer training to novices and experts, extend the impact of the new system to minority schools and EPSCoR states, impact the undergraduate and graduate curriculum at many universities, raise the level of computational awareness at four-year colleges, and support the introduction of computational thinking into high schools.\r\n\r\n2. Abstract: Technical Description\r\n\r\nThe Pittsburgh Supercomputing Center will substantially increase the scientific output of a large community of scientific and engineering researchers who have not traditionally used high-performance computing (HPC) resources. This will be accomplished by the acquisition, deployment, and management of Bridges, a HPC system designed for extreme flexibility, functionality, and usability. Bridges will be supported by operations, user service, and networking staff attuned to the needs of these new user communities, and it will offer a wide range of software appropriate for nontraditional HPC research communities. Users will be able to access Bridges through a variety of popular gateways and portals, and the system will provide development tools for gateway building.\r\n \r\nInnovative capabilities to be introduced by Bridges are:\r\n\r\n  1.  Three tiers of processing nodes will offer 128GB, 3TB, and 12TB of hardware-supported, coherent shared memory per node to address an extremely broad range of user needs including interactivity, workflows, long-running jobs, virtualization, and high capacity. The 12TB nodes, featuring a proprietary, high-bandwidth internal communication fabric, will be particularly valuable for genome sequence assembly, graph analytics, and machine learning. Bridges will also include a shared flash memory device to accelerate Hadoop and databases. Flexible node allocation will enable interactive use for debugging, analytics, and visualization.\r\n\r\n  2.  Bridges will provide integrated, full-time relational and NoSQL databases to support metadata, data management and efficient organization, gateways, and workflows. Database nodes will include SSDs for high IOPs and will be allocated through an extension to the XRAC process. Dedicated web server nodes with high-bandwidth connections to the national cyberinfrastructure will enable distributed workflows. The system topology will provide balanced bandwidth for nontraditional HPC workloads and data-intensive computing.\r\n\r\n  3.  Bridges will introduce powerful new CPUs (Intel Haswell and Broadwell), GPUs (NVIDIA GK210 and GP100), the innovative, high-performance Intel Omni Scale Fabric to support increasingly productive development of advanced applications, supported by an extremely broad set of applications, libraries, and easy-to-use programming languages and tools such as OpenACC, parallel MATLAB, Python, and R.\r\n\r\n  4.  A shared Project File System (PFS) will provide high-bandwidth, low-latency access to large datasets. Each node will also provide distributed, high-performance storage to support many emerging applications, intermediate and temporary storage, and reduce congestion on the shared PFS.\r\n\r\nBridges will enable important advances for science and society. By supporting pioneers who set examples in fields not traditionally users of HPC, and by lowering the barrier of entry, this project will spur others to recognize the power of the technology and transform their fields, as has happened in traditional HPC fields such as physics and chemistry. The project will engage students in research and systems internships, develop and offer training to novices and experts, extend the impact of the new system to minority schools and EPSCoR states, impact the undergraduate and graduate curriculum at many universities, raise the level of computational awareness at four-year colleges, and support the introduction of computational thinking into high schools.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Nicholas",
   "pi_last_name": "Nystrom",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nicholas Nystrom",
   "pi_email_addr": "nystrom@psc.edu",
   "nsf_id": "000216722",
   "pi_start_date": "2014-11-20",
   "pi_end_date": "2020-09-25"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shawn",
   "pi_last_name": "Brown",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Shawn T Brown",
   "pi_email_addr": "stbrown@psc.edu",
   "nsf_id": "000279617",
   "pi_start_date": "2020-09-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Levine",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Michael J Levine",
   "pi_email_addr": "levine@psc.edu",
   "nsf_id": "000311748",
   "pi_start_date": "2014-11-20",
   "pi_end_date": "2018-04-12"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Ralph",
   "pi_last_name": "Roskies",
   "pi_mid_init": "Z",
   "pi_sufx_name": "",
   "pi_full_name": "Ralph Z Roskies",
   "pi_email_addr": "roskies@psc.edu",
   "nsf_id": "000196046",
   "pi_start_date": "2014-11-20",
   "pi_end_date": "2018-03-06"
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Scott",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph R Scott",
   "pi_email_addr": "scott@psc.edu",
   "nsf_id": "000224442",
   "pi_start_date": "2014-11-20",
   "pi_end_date": "2018-05-09"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "John",
   "pi_last_name": "Urbanic",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "John M Urbanic",
   "pi_email_addr": "urbanic@psc.edu",
   "nsf_id": "000204073",
   "pi_start_date": "2018-03-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Paola",
   "pi_last_name": "Buitrago",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Paola A Buitrago",
   "pi_email_addr": "paola@psc.edu",
   "nsf_id": "000753808",
   "pi_start_date": "2018-08-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Sommerfield",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jason Sommerfield",
   "pi_email_addr": "jasons@psc.edu",
   "nsf_id": "000776420",
   "pi_start_date": "2018-05-09",
   "pi_end_date": "2020-03-18"
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "747600",
   "pgm_ele_name": "XD-Extreme Digital"
  },
  {
   "pgm_ele_code": "761900",
   "pgm_ele_name": "Innovative HPC"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 9650000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 7559167.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 3686000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Bridges research computing platform for novel and innovative research provided&nbsp;<span id=\"docs-internal-guid-55b7dd91-7fff-bfe6-3804-48ad844fa6b2\"><span>an innovative production computing resource that converges high-performance computing (HPC), artificial intelligence (AI), and Big Data to empower new research communities, bring desktop convenience to high-end computing, expand remote access, and help researchers to work more intuitively. Bridges provided heterogeneous computing capabilities to support complex workflows and disparate computing types under a common framework so researchers could perform highly-complex and challenging computing and data analytics. With Bridges' unique blend of capacity, high-memory, and gpu-based computing, it was capable of supporting virtually all levels of tradtional computing while bringing new user communities into the NSF research computing ecosystem. The impact of Bridges for the science and engineering community has been vast, having supported over 2700 projects and over 26,000 users and produced over 1500 peer-reviewed publications over its lifetime, with 40-50% of these projects serving novel communities and applications that were not traditionally users of high-performance computing. Over 265 grants and 10 million CPU-hours have been awarded for&nbsp;<span id=\"docs-internal-guid-465a1c18-7fff-b341-faf2-768e5ae654cd\"><span>use of the resource in university curriculum and workshop curriculum. Bridges has had broad impact, providing resources to several novel research computing compunities including genomics, epidemiology, neuroscience, and artificial intelligence. With the additiona of Bridges-AI, the platform brought state-of-the-art artificial intelligence capabilities to the academic community and paved the way for several future research architectures. Web-based science gateways and portals, such as those developed in the HuBMAP project (https://hubmapconsortium.org/). and the Bridges Community Data Set programs have helped propel the areas of datacentric and open-science research. Bridges has had significant impact across all areas of science and engineering throughout its lifetime and has led the charge in the deployment of heterogeneous research computing platforms.</span></span></span></span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/31/2022<br>\n\t\t\t\t\tModified by: Shawn&nbsp;T&nbsp;Brown</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Bridges research computing platform for novel and innovative research provided an innovative production computing resource that converges high-performance computing (HPC), artificial intelligence (AI), and Big Data to empower new research communities, bring desktop convenience to high-end computing, expand remote access, and help researchers to work more intuitively. Bridges provided heterogeneous computing capabilities to support complex workflows and disparate computing types under a common framework so researchers could perform highly-complex and challenging computing and data analytics. With Bridges' unique blend of capacity, high-memory, and gpu-based computing, it was capable of supporting virtually all levels of tradtional computing while bringing new user communities into the NSF research computing ecosystem. The impact of Bridges for the science and engineering community has been vast, having supported over 2700 projects and over 26,000 users and produced over 1500 peer-reviewed publications over its lifetime, with 40-50% of these projects serving novel communities and applications that were not traditionally users of high-performance computing. Over 265 grants and 10 million CPU-hours have been awarded for use of the resource in university curriculum and workshop curriculum. Bridges has had broad impact, providing resources to several novel research computing compunities including genomics, epidemiology, neuroscience, and artificial intelligence. With the additiona of Bridges-AI, the platform brought state-of-the-art artificial intelligence capabilities to the academic community and paved the way for several future research architectures. Web-based science gateways and portals, such as those developed in the HuBMAP project (https://hubmapconsortium.org/). and the Bridges Community Data Set programs have helped propel the areas of datacentric and open-science research. Bridges has had significant impact across all areas of science and engineering throughout its lifetime and has led the charge in the deployment of heterogeneous research computing platforms.\n\n\t\t\t\t\tLast Modified: 03/31/2022\n\n\t\t\t\t\tSubmitted by: Shawn T Brown"
 }
}