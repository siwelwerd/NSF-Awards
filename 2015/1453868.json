{
 "awd_id": "1453868",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Generalizable, Robust, and Closed-Loop Brain-Machine Interface Control Architectures",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2015-02-15",
 "awd_exp_date": "2024-01-31",
 "tot_intn_awd_amt": 503148.0,
 "awd_amount": 503148.0,
 "awd_min_amd_letter_date": "2015-02-03",
 "awd_max_amd_letter_date": "2022-11-17",
 "awd_abstract_narration": "Brain-machine interfaces (BMI) aim to restore movement in millions of disabled people. Despite successful laboratory demonstrations, the lack of generalizability and robustness, and the low performance remain key challenges hindering clinical viability. BMIs should be able to control a variety of prosthetic devices, and to exploit any neural signal modality as their control signal. This research develops generalizable, robust, and closed-loop BMI architectures for neuroprosthetic control, and applies these architectures both to build proficient neuroprosthetics and to investigate the brain mechanisms underlying such control. This research is fully integrated with outreach and education activities including interactions with disabled Veterans, and mentoring of women and underrepresented minorities.\r\n\r\nOne main reason for the lack of generalizability and robustness in existing BMIs is that they do not model the behavior of the single common component in all BMI settings, i.e., the brain, which controls the movement. Moreover, performance of current BMIs has been sacrificed because they have not been adapted to the statistical properties of the recorded neural signal modality and have used standard signal processing algorithms for any modality. This research develops a BMI that can control prosthetics with various dynamics and using different neural recording modalities. It builds a novel model of the brain in closed-loop control, constructs principled stochastic models for different recording modalities, and combines these two models to devise an adaptive supervised learning and decoding algorithm. It also uses the architecture to investigate the brain mechanisms underlying neuroprosthetic control. This research enables a universal and principled neuroprosthetic architecture, replacing ad-hoc approaches; it significantly improves neuroprosthetic performance; finally, it allows for a deeper understanding of the fundamental brain mechanisms underlying neurprosthetic and motor control.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maryam",
   "pi_last_name": "Shanechi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Maryam Shanechi",
   "pi_email_addr": "shanechi@usc.edu",
   "nsf_id": "000675013",
   "pi_start_date": "2015-02-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3740 McClintock Avenue, Ste 404",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900892564",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7797",
   "pgm_ref_txt": "COMM & INFORMATION FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  },
  {
   "pgm_ref_code": "7936",
   "pgm_ref_txt": "SIGNAL PROCESSING"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 191550.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 204361.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 107237.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we have developed novel methods for brain-computer interfaces (BCIs) that improve their performance and robustness. In particular, we developed methods that can model neuronal spiking activity at their fast millisecond timescale and as a discrete point process time-series. We showed that doing so significantly improves BCI performance. Further, to improve longevity and robustness in BCIs, we have developed a multimodal modeling framework for BCIs that allows them to use multiple modalities of neural activity consisting of spiking activity as well as local field potentials (LFP). Our framework includes&nbsp;multimodal decoders that fuse information in spiking and LFP about behavior,&nbsp;multimodal learning algorithm that can learn joint dynamical models of these modalities, and&nbsp;multimodal adaptive decoders to track non-stationarity in these multimodal neural data. Our work has developed both maximum-likelihood optimization techniques and faster analytical subspace identification techniques to learn models of these multimodal data. We have also developed methods to dissociate shared vs. distinct dynamics in these modalities. We have fully tested these algorithms in simulations and in neural datasets, showing that they improve both decoding performance and robustness toward enhanced BCIs. The novel approaches developed and demonstrated in this program can bring BCIs closer to clinical viability to restore motor function in patients with motor injury and disease.</p>\r\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 12/13/2024<br>\nModified by: Maryam&nbsp;Shanechi</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn this project, we have developed novel methods for brain-computer interfaces (BCIs) that improve their performance and robustness. In particular, we developed methods that can model neuronal spiking activity at their fast millisecond timescale and as a discrete point process time-series. We showed that doing so significantly improves BCI performance. Further, to improve longevity and robustness in BCIs, we have developed a multimodal modeling framework for BCIs that allows them to use multiple modalities of neural activity consisting of spiking activity as well as local field potentials (LFP). Our framework includesmultimodal decoders that fuse information in spiking and LFP about behavior,multimodal learning algorithm that can learn joint dynamical models of these modalities, andmultimodal adaptive decoders to track non-stationarity in these multimodal neural data. Our work has developed both maximum-likelihood optimization techniques and faster analytical subspace identification techniques to learn models of these multimodal data. We have also developed methods to dissociate shared vs. distinct dynamics in these modalities. We have fully tested these algorithms in simulations and in neural datasets, showing that they improve both decoding performance and robustness toward enhanced BCIs. The novel approaches developed and demonstrated in this program can bring BCIs closer to clinical viability to restore motor function in patients with motor injury and disease.\r\n\n\n\t\t\t\t\tLast Modified: 12/13/2024\n\n\t\t\t\t\tSubmitted by: MaryamShanechi\n"
 }
}