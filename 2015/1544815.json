{
 "awd_id": "1544815",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CPS: TTP Option: Synergy: Collaborative Research: Nested Control of Assistive Robots through Human Intent Inference",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2020-09-30",
 "tot_intn_awd_amt": 296998.0,
 "awd_amount": 296998.0,
 "awd_min_amd_letter_date": "2015-09-14",
 "awd_max_amd_letter_date": "2015-09-14",
 "awd_abstract_narration": "Part 1: Upper-limb motor impairments arise from a wide range of clinical conditions including amputations, spinal cord injury, or stroke. Addressing lost hand function, therefore, is a major focus of rehabilitation interventions; and research in robotic hands and hand exoskeletons aimed at restoring fine motor control functions gained significant speed recently. Integration of these robots with neural control mechanisms is also an ongoing research direction. We will develop prosthetic and wearable hands controlled via nested control that seamlessly blends neural control based on human brain activity and dynamic control based on sensors on robots. These Hand Augmentation using Nested Decision (HAND) systems  will also provide rudimentary tactile feedback to the user. The HAND design framework will contribute to the assistive and augmentative robotics field. The resulting technology will improve the quality of life for individuals with lost limb function. The project will help train engineers skilled in addressing multidisciplinary challenges. Through outreach activities, STEM careers will be promoted at the K-12 level, individuals from underrepresented groups in engineering will be recruited to engage in this research project, which will contribute to the diversity of the STEM workforce.\r\n\r\nPart 2: The team previously introduced the concept of human-in-the-loop cyber-physical systems (HILCPS). Using the HILCPS hardware-software co-design and automatic synthesis infrastructure, we will develop prosthetic and wearable HAND systems that are robust to uncertainty in human intent inference from physiological signals. One challenge arises from the fact that the human and the cyber system jointly operate on the same physical element. Synthesis of networked real-time applications from algorithm design environments poses a framework challenge. These will be addressed by a tightly coupled optimal nested control strategy that relies on EEG-EMG-context fusion for human intent inference. Custom distributed embedded computational and robotic platforms will be built and iteratively refined. This work will enhance the HILCPS design framework, while simultaneously making novel contributions to body/brain interface technology and assistive/augmentative robot technology. Specifically we will (1) develop a theoretical EEG-EMG-context fusion framework for agile HILCPS application domains; (2) develop theory for and design novel control theoretic solutions to handle uncertainty, blend motion/force planning with high-level human intent and ambient intelligence to robustly execute daily manipulation activities; (3) further develop and refine the HILCPS domain-specific design framework to enable rapid deployment of HILCPS algorithms onto distributed embedded systems, empowering a new class of real-time algorithms that achieve distributed embedded sensing, analysis, and decision making; (4) develop new paradigms to replace, retrain or augment hand function via the prosthetic/wearable HAND by optimizing performance on a subject-by-subject basis.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Paolo",
   "pi_last_name": "Bonato",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Paolo Bonato",
   "pi_email_addr": "pbonato@mgh.harvard.edu",
   "nsf_id": "000135729",
   "pi_start_date": "2015-09-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Spaulding Rehabilitation Hospital",
  "inst_street_address": "125 NASHUA STREET",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "8572821769",
  "inst_zip_code": "021141100",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "MA08",
  "org_lgl_bus_name": "SPAULDING REHABILITATION HOSPITAL (SRH) VOLUNTEER SERVICES, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "GX6ELAY5M4N9"
 },
 "perf_inst": {
  "perf_inst_name": "Spaulding Rehabilitation Hospital",
  "perf_str_addr": "300 First Avenue",
  "perf_city_name": "Charlestown",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021293109",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "791800",
   "pgm_ele_name": "CPS-Cyber-Physical Systems"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7918",
   "pgm_ref_txt": "CYBER-PHYSICAL SYSTEMS (CPS)"
  },
  {
   "pgm_ref_code": "8235",
   "pgm_ref_txt": "CPS-Synergy"
  },
  {
   "pgm_ref_code": "1640",
   "pgm_ref_txt": "INFORMATION TECHNOLOGY RESEARC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 296998.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was a collaboration between Northeastern University, the Worchester Polyethnic Institute, and the Department of Physical Medicine and Rehabilitation, Harvard Medical School at Spaulding Rehabilitation Hospital. The major goals of the project were to fuse multimodal sources of evidence for human intent inference regarding desired hand grasp type, developing semi-autonomous robotic hands that can perform multiple grasps required for activities of daily living, embedded real-time implementations of developed techniques in sensing, computing, and actuation platforms, and validating and iterating with human-in-the-loop experiments.</p>\n<p>During the project, electroencephalographic and electromyographic data was collected simultaneously to image data gathered using a camera positioned in the palm of study volunteers. A small-scale crowd-sourced labeling study was carried out based on video recordings gathered during the above-stated data collections. That led to the generation of labels later used to train a neural network classifier that generated a probability distribution over grasp types given the images collected using the camera positioned in the palm of study volunteers. These estimates were fused with estimates derived from electroencephalographic and electromyographic data.</p>\n<p>The electroencephalographic-based classification approach heavily relied on information dimension reduction techniques to help achieve good performance generalization. Techniques that we explored included the use of autoencoder and generative adversarial network training concepts to develop both reduced dimensionality feature extraction and generalizable electroencephalographic data synthesis that we anticipated could offer accurate simulation capabilities for brain interfaces.</p>\n<p>Electromyographic data was analyzed using a technique known as muscle synergy. This technique is based on neurophysiological studies suggesting that the co-activation of different muscle groups is encoded in spinal circuits. Hence, movement is generated via descending motor commands that activate spinal modules (i.e. the muscle synergies) and modulate their activity. This technique is of particular interest in rehabilitation medicine because it has the potential to allow one to infer the recruitment of a synergy including a distal muscle lost following an amputation. Such inference would in turn allow one to reconstruct the desired movement even if the subject is no-longer capable of generating it.</p>\n<p>The above-summarized techniques were all successfully implemented and utilized to control a robotic hand. The hand included tri-axial (normal and shear) soft force sensors on the fingertips, which was utilized as an additional input the above-described models.</p>\n<p>The project was interdisciplinary in nature. Researchers at Northeastern University and the Worchester Polyethnic Institute primarily contributed to the development of the technologies and models embedded in the system assembled during the project. Researchers as Spaulding Rehabilitation Hospital primarily provided consultations related to the experimental procedures and the analysis of the electromyographic data, based on previous experience with the analysis of muscle synergies.</p>\n<p>While all aspects of the project covered by researchers at Spaulding Rehabilitation Hospital have been completed, the teams at Northeastern University and the Worchester Polyethnic Institute continue to work on the development of new implementations of the image, electroencephalographic data, and electromyographic data based techniques. The team at Spaulding Rehabilitation Hospital is providing assistance in kind.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/16/2021<br>\n\t\t\t\t\tModified by: Paolo&nbsp;Bonato</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project was a collaboration between Northeastern University, the Worchester Polyethnic Institute, and the Department of Physical Medicine and Rehabilitation, Harvard Medical School at Spaulding Rehabilitation Hospital. The major goals of the project were to fuse multimodal sources of evidence for human intent inference regarding desired hand grasp type, developing semi-autonomous robotic hands that can perform multiple grasps required for activities of daily living, embedded real-time implementations of developed techniques in sensing, computing, and actuation platforms, and validating and iterating with human-in-the-loop experiments.\n\nDuring the project, electroencephalographic and electromyographic data was collected simultaneously to image data gathered using a camera positioned in the palm of study volunteers. A small-scale crowd-sourced labeling study was carried out based on video recordings gathered during the above-stated data collections. That led to the generation of labels later used to train a neural network classifier that generated a probability distribution over grasp types given the images collected using the camera positioned in the palm of study volunteers. These estimates were fused with estimates derived from electroencephalographic and electromyographic data.\n\nThe electroencephalographic-based classification approach heavily relied on information dimension reduction techniques to help achieve good performance generalization. Techniques that we explored included the use of autoencoder and generative adversarial network training concepts to develop both reduced dimensionality feature extraction and generalizable electroencephalographic data synthesis that we anticipated could offer accurate simulation capabilities for brain interfaces.\n\nElectromyographic data was analyzed using a technique known as muscle synergy. This technique is based on neurophysiological studies suggesting that the co-activation of different muscle groups is encoded in spinal circuits. Hence, movement is generated via descending motor commands that activate spinal modules (i.e. the muscle synergies) and modulate their activity. This technique is of particular interest in rehabilitation medicine because it has the potential to allow one to infer the recruitment of a synergy including a distal muscle lost following an amputation. Such inference would in turn allow one to reconstruct the desired movement even if the subject is no-longer capable of generating it.\n\nThe above-summarized techniques were all successfully implemented and utilized to control a robotic hand. The hand included tri-axial (normal and shear) soft force sensors on the fingertips, which was utilized as an additional input the above-described models.\n\nThe project was interdisciplinary in nature. Researchers at Northeastern University and the Worchester Polyethnic Institute primarily contributed to the development of the technologies and models embedded in the system assembled during the project. Researchers as Spaulding Rehabilitation Hospital primarily provided consultations related to the experimental procedures and the analysis of the electromyographic data, based on previous experience with the analysis of muscle synergies.\n\nWhile all aspects of the project covered by researchers at Spaulding Rehabilitation Hospital have been completed, the teams at Northeastern University and the Worchester Polyethnic Institute continue to work on the development of new implementations of the image, electroencephalographic data, and electromyographic data based techniques. The team at Spaulding Rehabilitation Hospital is providing assistance in kind.\n\n \n\n\t\t\t\t\tLast Modified: 02/16/2021\n\n\t\t\t\t\tSubmitted by: Paolo Bonato"
 }
}