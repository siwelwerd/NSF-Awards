{
 "awd_id": "1462408",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Gradient Methods for Solving Big Data (Tensor) Optimization Problems",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922443",
 "po_email": "gaklutke@nsf.gov",
 "po_sign_block_name": "Georgia-Ann Klutke",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 299999.0,
 "awd_amount": 299999.0,
 "awd_min_amd_letter_date": "2015-07-26",
 "awd_max_amd_letter_date": "2015-07-26",
 "awd_abstract_narration": "Rapid developments in modern technologies have made large-scale statistical data sets readily available in many industrial settings, but the task of effectively turning data into useful information still remains a major challenge in a wide range of applications. One important source of the 'big data' complication stems from the way in which the data points are collected and stored. In particular, the data format in question is known as the tensor, which is a useful format, because it reflects the interconnections between various factors. Tensor data sets can be found in statistical learning, bioinformatics, consumer behavior in marketing, climate change studies, and signal and image processing. However, computationally the tensor data formats are notoriously difficult.  This award supports fundamental research on the computational aspects of the above-mentioned information retrieval process. The project has a multidisciplinary research element and will positively impact engineering education.\r\n\r\nIn the context of tensor data processing, a desirable operation is to compute the projection of a given data tensor onto a simpler set with a certain low complexity structure, where the 'low complexity' tensors may refer to low-rank tensors, or sparse tensors, or it may also refer to the tensors with low co-cluster numbers. Formulating tensor projection and completion problems leads to large scale non-convex -- yet algebraic -- optimization models. This research will develop a framework for the iteration complexity analysis which will enable effective first-order computational methods for tensor projection, completion and optimization models.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Shuzhong",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Shuzhong Zhang",
   "pi_email_addr": "zhangs@umn.edu",
   "nsf_id": "000601028",
   "pi_start_date": "2015-07-26",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota",
  "perf_str_addr": "111 Church Street SE",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554550150",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "006Y00",
   "pgm_ele_name": "OE Operations Engineering"
  },
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "072E",
   "pgm_ref_txt": "NETWORKS & QUEUING SYSTEMS"
  },
  {
   "pgm_ref_code": "073E",
   "pgm_ref_txt": "OPTIMIZATION & DECISION MAKING"
  },
  {
   "pgm_ref_code": "077E",
   "pgm_ref_txt": "SIMULATION MODELS"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 299999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In machine learning and statistics, the success of the practice often depends on our capability to effectively handle large scale optimization models, which may have some potentially useful structures that one may wish to exploit. Developing solution methods for solving structured optimization models has been the general goal of this project. Specifically, we set out to study optimization models using block variables which are often related to each other. Moreover, the objective function in question may be non-convex, though some nice algebraic structures are in place. For example, the objective may take the form of a tensor. The applications of such models are pervasive in practice. One specific application of interest is image processing using the bioinformatics data. In this project, we developed a machine learning approach to read the CT-scan images, in the hope that it will lead to potentially successful early-stage lung cancer diagnosis with high accuracy. The challenges of those problems are typically twofold. First, these problems are typically &lsquo;big-data&rsquo; in nature, and so the scale of the optimization problems are exceedingly large and so any &lsquo;off-the-shelf&rsquo; optimization software will not be an option. Secondly, the problems are usually non-convex, and indeed they are often highly nonlinear. This introduces additional challenges. In this project, we proposed to study the low-order methods (e.g. the first-order methods, aka. the gradient methods) to meet these challenges.&nbsp;</p>\n<p>&nbsp;</p>\n<p>This project has succeeded in all its scope and aspects that were stipulated in the proposal. We completed our investigations on the block-variable optimization, the first-order methods, the tensor optimization problems, and the bioinformatics applications. In a period of four years, 20 journal papers and 1 book chapter (invited review on big data analytics published by the Cambridge University Press) have appeared (or accepted for publication) as direct outcomes of this NSF project; all these papers acknowledged the support of the NSF. There are still 2-3 manuscripts that were submitted and are still in the refereeing process. The venues of the publications are prestigious journals in our field, such as the SIAM journals, the IEEE journals, the MOS (Mathematical Optimization Society) flagship journal Mathematical Programming. Moreover, 3 Ph.D. students have been trained through this project; 2 of them have graduated already and the last student will graduate next year. In the course of the project, the PI disseminated the findings generated from the project to a wide public through conference presentations and invited talks for people in practice (industry). As educators, it is our duty to raise the level of awareness of this important research direction and to pass the knowledge on to the next generation. With this educational goal in mind, the PI developed a new course in his home department (University of Minnesota) on optimization methods using some of the materials generated in this project. Moreover, two short summer courses were designed and offered to the interested students, one in Minneapolis and one in Shanghai.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2019<br>\n\t\t\t\t\tModified by: Shuzhong&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn machine learning and statistics, the success of the practice often depends on our capability to effectively handle large scale optimization models, which may have some potentially useful structures that one may wish to exploit. Developing solution methods for solving structured optimization models has been the general goal of this project. Specifically, we set out to study optimization models using block variables which are often related to each other. Moreover, the objective function in question may be non-convex, though some nice algebraic structures are in place. For example, the objective may take the form of a tensor. The applications of such models are pervasive in practice. One specific application of interest is image processing using the bioinformatics data. In this project, we developed a machine learning approach to read the CT-scan images, in the hope that it will lead to potentially successful early-stage lung cancer diagnosis with high accuracy. The challenges of those problems are typically twofold. First, these problems are typically \u2018big-data\u2019 in nature, and so the scale of the optimization problems are exceedingly large and so any \u2018off-the-shelf\u2019 optimization software will not be an option. Secondly, the problems are usually non-convex, and indeed they are often highly nonlinear. This introduces additional challenges. In this project, we proposed to study the low-order methods (e.g. the first-order methods, aka. the gradient methods) to meet these challenges. \n\n \n\nThis project has succeeded in all its scope and aspects that were stipulated in the proposal. We completed our investigations on the block-variable optimization, the first-order methods, the tensor optimization problems, and the bioinformatics applications. In a period of four years, 20 journal papers and 1 book chapter (invited review on big data analytics published by the Cambridge University Press) have appeared (or accepted for publication) as direct outcomes of this NSF project; all these papers acknowledged the support of the NSF. There are still 2-3 manuscripts that were submitted and are still in the refereeing process. The venues of the publications are prestigious journals in our field, such as the SIAM journals, the IEEE journals, the MOS (Mathematical Optimization Society) flagship journal Mathematical Programming. Moreover, 3 Ph.D. students have been trained through this project; 2 of them have graduated already and the last student will graduate next year. In the course of the project, the PI disseminated the findings generated from the project to a wide public through conference presentations and invited talks for people in practice (industry). As educators, it is our duty to raise the level of awareness of this important research direction and to pass the knowledge on to the next generation. With this educational goal in mind, the PI developed a new course in his home department (University of Minnesota) on optimization methods using some of the materials generated in this project. Moreover, two short summer courses were designed and offered to the interested students, one in Minneapolis and one in Shanghai. \n\n\t\t\t\t\tLast Modified: 11/29/2019\n\n\t\t\t\t\tSubmitted by: Shuzhong Zhang"
 }
}