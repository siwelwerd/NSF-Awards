{
 "awd_id": "1528121",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Socially Aware, Expressive, and Personalized Mobile Remote Presence: Co-Robots as Gateways to Access to K-12 In-School Education",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032927078",
 "po_email": "idolinsk@nsf.gov",
 "po_sign_block_name": "Irina Dolinskaya",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 600000.0,
 "awd_amount": 608000.0,
 "awd_min_amd_letter_date": "2015-08-06",
 "awd_max_amd_letter_date": "2020-06-25",
 "awd_abstract_narration": "Participating in the school environment is essential to children's social, emotional, and cognitive development and learning. It has long been recognized that the quality of a student's school experience is important not only for the academic and achievement outcomes, but for fostering self-esteem, self-confidence, and general psychological well-being. Yet annually 26.6% of America's children have health or behavioral challenges that cause them to miss significant amounts of school, and 13% of all US K-12 public school students receive interventions due to learning disabilities or emotional disturbances.  This project focuses on the problem of using mobile remote presence co-robots as a means to provide numerous K-12 aged children who cannot be present in school access to the curricular and social learning experiences critical to their development and future outcomes. Using mobile remote presence for access to K-12 classrooms for homebound students may be a powerful gateway for minimizing the effects of physical separation from the school environment. This project develops methods that enable the creation of personalizable robots that allow shared autonomy, socially appropriate movement and socially expressive nonverbal communication in dynamic in-class K-12 environments, allowing children to be truly embodied in the classroom, even from a distance. The impact of this NRI project spans K-12 education at large, but also applies to general uses of mobile remote presence systems outside of the classroom setting, for both education and training. In addition, the project connects the research themes with outreach; it engages K-12 students and teachers in co-robot-themed activities and holds annual NRI-themed workshops at large-scale public venues. The broader outreach program is designed to train students in STEM, so they can become not only end users of robotics and other technologies but capable of developing such technologies themselves, thereby contributing to the US STEM workforce. \r\n\r\nThis proposal focuses on developing control algorithms for mobile remote presence (MRP) co-robot systems that will improve human access to a learning/training environment, focusing on homebound K-12 students, but with general implications to users of all ages and a variety of contexts. Work with MRP systems has identified key missing technical capabilities necessary for facilitating natural remote interaction and learning: 1) simple, socially-appropriate autonomous behavior and context awareness that reduces user cognitive load; 2) expressiveness for conveying the user's affect and communicative intent; and 3) the ability to personalize the way the user interacts through the MRP. This project addresses these challenges with participatory user-informed algorithm development, system integration, and evaluation. Specifically, it first develops an approach to automating and facilitating spatial and social context awareness for the operator and the MRP, and uses it to enable the two research thrusts, social appropriateness and expressiveness, with algorithmic methods for personalizing both. To ground the results in the selected real-world context, iterative design and evaluation is performed in the K-12 in-class setting, involving users across the age and education span, providing a test of the co-robot's relevance, effectiveness, and robustness. The project brings together a pair of interdisciplinary experts with a track record of successful past collaborations and three partners: industry, deployment, and outreach, committed to a project timeline with specific evaluable milestones.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Maja",
   "pi_last_name": "Matari\u0107",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Maja J Matari\u0107",
   "pi_email_addr": "mataric@usc.edu",
   "nsf_id": "000410606",
   "pi_start_date": "2015-08-06",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gisele",
   "pi_last_name": "Ragusa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gisele Ragusa",
   "pi_email_addr": "ragusa@usc.edu",
   "nsf_id": "000447315",
   "pi_start_date": "2015-08-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Southern California",
  "inst_street_address": "3720 S FLOWER ST FL 3",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2137407762",
  "inst_zip_code": "90033",
  "inst_country_name": "United States",
  "cong_dist_code": "34",
  "st_cong_dist_code": "CA34",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTHERN CALIFORNIA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G88KLJR3KYT5"
 },
 "perf_inst": {
  "perf_inst_name": "University of Southern California",
  "perf_str_addr": "3720 S. Flower St.",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900890001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "37",
  "perf_st_cong_dist": "CA37",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "010E",
   "pgm_ref_txt": "DISABILITY RES & HOMECARE TECH"
  },
  {
   "pgm_ref_code": "116E",
   "pgm_ref_txt": "RESEARCH EXP FOR UNDERGRADS"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 600000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>A large number of US K-12 students miss extended amounts of school for reasons that range from chronic illness to behavioral challenges. Missing significant amount of school time has negative impacts on student learning and their social development that are critical for lifelong work and health outcomes. The main goal of this project was to understand, implement, and study how mobile remote presence (MRP) / telepresence robots could provide access to the K-12 classroom to students who cannot be physically present in school.&nbsp; This research took place before the COVID-19 pandemic.&nbsp; Early results show that remote learning forced by the pandemic has had an impact on child social and cognitive development, highlighting the importance of physical in-school immersion for K-12.</p>\n<p>Telepresence robots have been used in corporate settings and lower-cost versions have been developed and piloted in classrooms.&nbsp; This work focused on how to make such systems effective in K-12 classrooms. The key barriers we explored included the few affordable telepresence robots, and the lack of features for effective integration in the dual contexts of the educational use case: the classroom and the student?s residence/home. &nbsp;Most telepresence robots are too expensive for this use case, and their software is proprietary, with companies having little interest in working on the educational context.&nbsp; After attempting to partner with larger companies, we identified OhmniLabs Inc. as a collaborative corporate partner, allowing us access to the robot?s software and hardware, leading to many novel insights and results from this grant.</p>\n<p>Scientific merit: We first teamed up with social scientists, designers, and usability experts, to explore the usability of telepresence robots for the classroom setting.&nbsp; We deployed robots in classrooms, collecting feedback from the students and teachers and produced a large set of insights and recommendations for telepresence robots in the K-12 setting.&nbsp; These included the limitations of telepresence robots for the user (the remote student) to communicate and be expressive.&nbsp; An action as common as turning one?s head is not possible on a telepresence robot; the entire robot must be turned to change its point of view.&nbsp; Additionally, students using a telepresence robot have no way to raise their hand or gesture, both common classroom activities.&nbsp;&nbsp; Furthermore, while telepresence robots have a screen, the face of the remote student operator on that screen is small and barely visible to those in the classroom, so facial expressions are not perceived by the peers or teachers.&nbsp; Finally, we explored a critical limitation of telepresence robots: the inability of the remote student operator to perceive how loudly they should speak and to control their voice so they are heard appropriately by the whole class (if asking or answering a question) or by only the student next to them (if making a small comment to a peer).&nbsp; In summary, we identified major issues with telepresence as a means of communication, expression, and user self-awareness and situational awareness, all barriers that need to be overcome for enabling effective remote learning, and we developed prototype solutions to multiple of those issues, including a user-friendly light-signaling system and button control system, low-cost expressive arm, and a sound-and-voice adjustment system.</p>\n<p>We studied acceptance of the telepresence robot as the embodiment of the remote student, and found that some remote students were bullied by their classmates when using the robot.&nbsp; Robot bullying has been documented in other settings, but is more serious in the telepresence context because it is not a machine being bullied, but a human student operating it. We explored personalizing the robot to make it more acceptable through clothing, accessories, and wigs.&nbsp; In studies with university students, clothing and typical accessories can be effective when used in groups of students familiar with one another, but were less effective and more distracting in groups of strangers.&nbsp;&nbsp; Additionally, we found that wigs on telepresence robots were not found to be acceptable by either friends or strangers.</p>\n<p>Broader impacts: The most important work on this grant resulted from long-term multi-week/month deployments of our telepresence systems in classrooms and homes of students with special needs, which ranged from severe physical impairment (mobility limited to a single finger due to an ALS-like condition) to severe psychological impairment (inability to be physically around peers due to severe social anxiety).&nbsp; We collected a rich dataset of student user logs and surveys, as well as classroom teacher and student interviews.&nbsp; We identified key, novel, and subtle usability issues for student operators with a variety of health-related needs, and classroom acceptance issues from peers and teachers. &nbsp;These major novel insights provide guidance and a roadmap for developing telepresence systems that can be accessible, accepted, and effective in supporting remote presence learning for a broadly inclusive student population with a wide variety of needs and abilities.</p>\n<p>All publications and software produced by this grant are freely available on the Web.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/24/2021<br>\n\t\t\t\t\tModified by: Maja&nbsp;J&nbsp;Mataric</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640373935330_Picture2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640373935330_Picture2--rgov-800width.jpg\" title=\"Telepresence robots in the classroom\"><img src=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640373935330_Picture2--rgov-66x44.jpg\" alt=\"Telepresence robots in the classroom\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Left: A homebound participant attending a new Spanish class via the Ohmni MRP system allowing them to attend school with peers for the first time in six years. Right: A remote student participating in a science class.</div>\n<div class=\"imageCredit\">Maja Matari&#263;</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Telepresence robots in the classroom</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640373857430_Picture1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640373857430_Picture1--rgov-800width.jpg\" title=\"Telepresence use in K-12 classrooms\"><img src=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640373857430_Picture1--rgov-66x44.jpg\" alt=\"Telepresence use in K-12 classrooms\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Telepresence robot use case in the K-12 classroom, improving accessibility to the classroom for homebound/hospital-bound students</div>\n<div class=\"imageCredit\">Maja Matari&#263;</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Telepresence use in K-12 classrooms</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374041511_Picture3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374041511_Picture3--rgov-800width.jpg\" title=\"Telepresence data collection game\"><img src=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374041511_Picture3--rgov-66x44.jpg\" alt=\"Telepresence data collection game\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A simulated classroom telepresence game, tested with 95 students from 3 middle school classrooms to evaluate usability of features of telepresence systems.</div>\n<div class=\"imageCredit\">Maja Matari&#263;</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Telepresence data collection game</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374230442_Picture4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374230442_Picture4--rgov-800width.jpg\" title=\"Personalized telepresence robots\"><img src=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374230442_Picture4--rgov-66x44.jpg\" alt=\"Personalized telepresence robots\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Telepresence robots personalized with user-selected clothing and wig.</div>\n<div class=\"imageCredit\">Maja Matari&#263;</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Personalized telepresence robots</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374307747_Picture5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374307747_Picture5--rgov-800width.jpg\" title=\"Telepresence robot with low-cost arm\"><img src=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374307747_Picture5--rgov-66x44.jpg\" alt=\"Telepresence robot with low-cost arm\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Telepresence robot with a low-cost arm for hand-raising and simple gestures</div>\n<div class=\"imageCredit\">Maja Matari&#263;</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Telepresence robot with low-cost arm</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374400277_Picture6--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374400277_Picture6--rgov-800width.jpg\" title=\"Light display interface\"><img src=\"/por/images/Reports/POR/2021/1528121/1528121_10384630_1640374400277_Picture6--rgov-66x44.jpg\" alt=\"Light display interface\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">User interface for selecting settings for the light signaling system designed to make the telepresence robot more expressive</div>\n<div class=\"imageCredit\">Maja Matari&#263;</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Maja&nbsp;J&nbsp;Mataric</div>\n<div class=\"imageTitle\">Light display interface</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nA large number of US K-12 students miss extended amounts of school for reasons that range from chronic illness to behavioral challenges. Missing significant amount of school time has negative impacts on student learning and their social development that are critical for lifelong work and health outcomes. The main goal of this project was to understand, implement, and study how mobile remote presence (MRP) / telepresence robots could provide access to the K-12 classroom to students who cannot be physically present in school.  This research took place before the COVID-19 pandemic.  Early results show that remote learning forced by the pandemic has had an impact on child social and cognitive development, highlighting the importance of physical in-school immersion for K-12.\n\nTelepresence robots have been used in corporate settings and lower-cost versions have been developed and piloted in classrooms.  This work focused on how to make such systems effective in K-12 classrooms. The key barriers we explored included the few affordable telepresence robots, and the lack of features for effective integration in the dual contexts of the educational use case: the classroom and the student?s residence/home.  Most telepresence robots are too expensive for this use case, and their software is proprietary, with companies having little interest in working on the educational context.  After attempting to partner with larger companies, we identified OhmniLabs Inc. as a collaborative corporate partner, allowing us access to the robot?s software and hardware, leading to many novel insights and results from this grant.\n\nScientific merit: We first teamed up with social scientists, designers, and usability experts, to explore the usability of telepresence robots for the classroom setting.  We deployed robots in classrooms, collecting feedback from the students and teachers and produced a large set of insights and recommendations for telepresence robots in the K-12 setting.  These included the limitations of telepresence robots for the user (the remote student) to communicate and be expressive.  An action as common as turning one?s head is not possible on a telepresence robot; the entire robot must be turned to change its point of view.  Additionally, students using a telepresence robot have no way to raise their hand or gesture, both common classroom activities.   Furthermore, while telepresence robots have a screen, the face of the remote student operator on that screen is small and barely visible to those in the classroom, so facial expressions are not perceived by the peers or teachers.  Finally, we explored a critical limitation of telepresence robots: the inability of the remote student operator to perceive how loudly they should speak and to control their voice so they are heard appropriately by the whole class (if asking or answering a question) or by only the student next to them (if making a small comment to a peer).  In summary, we identified major issues with telepresence as a means of communication, expression, and user self-awareness and situational awareness, all barriers that need to be overcome for enabling effective remote learning, and we developed prototype solutions to multiple of those issues, including a user-friendly light-signaling system and button control system, low-cost expressive arm, and a sound-and-voice adjustment system.\n\nWe studied acceptance of the telepresence robot as the embodiment of the remote student, and found that some remote students were bullied by their classmates when using the robot.  Robot bullying has been documented in other settings, but is more serious in the telepresence context because it is not a machine being bullied, but a human student operating it. We explored personalizing the robot to make it more acceptable through clothing, accessories, and wigs.  In studies with university students, clothing and typical accessories can be effective when used in groups of students familiar with one another, but were less effective and more distracting in groups of strangers.   Additionally, we found that wigs on telepresence robots were not found to be acceptable by either friends or strangers.\n\nBroader impacts: The most important work on this grant resulted from long-term multi-week/month deployments of our telepresence systems in classrooms and homes of students with special needs, which ranged from severe physical impairment (mobility limited to a single finger due to an ALS-like condition) to severe psychological impairment (inability to be physically around peers due to severe social anxiety).  We collected a rich dataset of student user logs and surveys, as well as classroom teacher and student interviews.  We identified key, novel, and subtle usability issues for student operators with a variety of health-related needs, and classroom acceptance issues from peers and teachers.  These major novel insights provide guidance and a roadmap for developing telepresence systems that can be accessible, accepted, and effective in supporting remote presence learning for a broadly inclusive student population with a wide variety of needs and abilities.\n\nAll publications and software produced by this grant are freely available on the Web.\n\n \n\n\t\t\t\t\tLast Modified: 12/24/2021\n\n\t\t\t\t\tSubmitted by: Maja J Mataric"
 }
}