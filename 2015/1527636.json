{
 "awd_id": "1527636",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Collaborative Research: Ordinal Data Compression",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2015-08-11",
 "awd_max_amd_letter_date": "2015-08-11",
 "awd_abstract_narration": "With the emergence of Big Data platforms in social and life sciences, it is becoming of paramount importance to develop efficient lossless and lossy data compression methods catering to the need of such information systems. Although many near-optimal compression methods exist for classical text, image and video data, they tend to perform poorly on data which naturally appears in fragmented or ordered form. This is especially the case for so called ordinal data, arising in crowd-voting, recommender systems, and genome rearrangement studies. There, information is represented with respect to a ?relative,? rather than ?absolute? scale, and the particular constraints of the ordering cannot be properly captured via simple dictionary constructions. This project seeks to improve the operational performance of a number of data management, cloud computing and communication systems by developing theoretical, algorithmic and software solutions for ordinal data compaction.\r\n\r\nThe main goal of the project is to develop the first general and comprehensive theoretical framework for ordinal compression. In particular, the investigators propose to investigate new distortion measures for ordinal data and rate-distortion functions for lossy ordinal compression; rank aggregation and learning methods for probabilistic ordinal models, used for ordinal clustering and quantization; and smooth compression and compressive computing in the ordinal domain. The proposed analytical framework will also allow for addressing algorithmic challenges arising in the context of compressing complete, partial and weak rankings. The accompanying software solutions are expected to find broad applications in areas as diverse as theoretical computer science (sorting, searching and selection), machine learning (clustering and learning to rank), and gene prioritization and phylogeny (reconstruction of lists of influential genes and ancestral genomes, respectively).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Olgica",
   "pi_last_name": "Milenkovic",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Olgica Milenkovic",
   "pi_email_addr": "milenkov@uiuc.edu",
   "nsf_id": "000322789",
   "pi_start_date": "2015-08-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Ordinal Data Compression project addressed a number of fundamental theoretical and algorithmic problems pertaining to learning on rankings, partial and weak rankings data and related data formats. Rankings - often referred to as ordinal data - describe preferences and priorities, and frequently arise in social sciences, genomics, marketing and recommender systems. The learning tasks of interest include ranking aggregation (fusion of ordinal data), ranking clustering and learning to rank. In all these settings, the goal is to come up with both probabilistic and combinatorial models for system/user preferences and their time dynamics and then develop fast parallel algorithms for performing the tasks at hand. We developed a number of new techniques combining coding, information theory and machine learning to describe ranking models, aggregate them and compress massive ranking datasets. A particularly important result is the development of new mapping techniques for ordinal data that allow one to study Gaussian distribution analogues in the ordinal domain in a simplified manner. The mapping technique relies on the use of so-called Lehmer codes that render a number of ranking data features independent.&nbsp;We applied the resulting algorithms on problems such as rank aggregation on trees, parallel rank aggregation for mixture Mallows models, rank aggregation of cancer patient data and gene prioritization. Our methods demonstrate significant performance improvement over other techniques used in practice. &nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/05/2019<br>\n\t\t\t\t\tModified by: Olgica&nbsp;Milenkovic</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Ordinal Data Compression project addressed a number of fundamental theoretical and algorithmic problems pertaining to learning on rankings, partial and weak rankings data and related data formats. Rankings - often referred to as ordinal data - describe preferences and priorities, and frequently arise in social sciences, genomics, marketing and recommender systems. The learning tasks of interest include ranking aggregation (fusion of ordinal data), ranking clustering and learning to rank. In all these settings, the goal is to come up with both probabilistic and combinatorial models for system/user preferences and their time dynamics and then develop fast parallel algorithms for performing the tasks at hand. We developed a number of new techniques combining coding, information theory and machine learning to describe ranking models, aggregate them and compress massive ranking datasets. A particularly important result is the development of new mapping techniques for ordinal data that allow one to study Gaussian distribution analogues in the ordinal domain in a simplified manner. The mapping technique relies on the use of so-called Lehmer codes that render a number of ranking data features independent. We applied the resulting algorithms on problems such as rank aggregation on trees, parallel rank aggregation for mixture Mallows models, rank aggregation of cancer patient data and gene prioritization. Our methods demonstrate significant performance improvement over other techniques used in practice.  \n\n\t\t\t\t\tLast Modified: 09/05/2019\n\n\t\t\t\t\tSubmitted by: Olgica Milenkovic"
 }
}