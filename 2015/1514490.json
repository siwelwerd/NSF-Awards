{
 "awd_id": "1514490",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Transforming Scientific Presentations with Co-Presenter Agents",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2021-06-30",
 "tot_intn_awd_amt": 1164306.0,
 "awd_amount": 1164306.0,
 "awd_min_amd_letter_date": "2015-07-13",
 "awd_max_amd_letter_date": "2020-04-17",
 "awd_abstract_narration": "Although journal and conference articles are recognized as the most formal and enduring forms of scientific communication, oral presentations are central to science because they are the means by which researchers, practitioners, the media, and the public hear about the latest findings thereby becoming engaged and inspired, and where scientific reputations are made.  Yet despite decades of technological advances in computing and communication media, the fundamentals of oral scientific presentations have not advanced since software such as Microsoft's PowerPoint was introduced in the 1980's.  The PI's goal in this project is to revolutionize media-assisted oral presentations in general, and STEM presentations in particular, through the use of an intelligent, autonomous, life-sized, animated co-presenter agent that collaborates with a human presenter in preparing and delivering his or her talk in front of a live audience.   The PI's pilot studies have demonstrated that audiences are receptive to this concept, and that the technology is especially effective for individuals who are non-native speakers of English (which may be up to 21% of the population of the United States).  Project outcomes will be initially deployed and evaluated in higher education, both as a teaching tool for delivering STEM lectures and as a training tool for students in the sciences to learn how to give more effective oral presentations (which may inspire future generations to engage in careers in the sciences).\r\n\r\nThis research will be based on a theory of human-agent collaboration, in which the human presenter is monitored using real-time speech and gesture recognition, audience feedback is also monitored, and the agent, presentation media, and human presenter (cued via an intelligent wearable teleprompter) are all dynamically choreographed to maximize audience engagement, communication, and persuasion.  The project will make fundamental, theoretical contributions to models of real-time human-agent collaboration and communication.  It will explore how humans and agents can work together to communicate effectively with a heterogeneous audience using speech, gesture, and a variety of presentation media, amplifying the abilities of scientist-orators who would otherwise be \"flying solo.\"  The work will advance both artificial intelligence and computational linguistics, by extending dialogue systems to encompass mixed-initiative, multi-party conversations among co-presenters and their audience.  It will impact the state of the art in virtual agents, by advancing the dynamic generation of hand gestures, prosody, and proxemics for effective public speaking and turn-taking.  And it will also contribute to the field of human-computer interaction, by developing new methods for human presenters to interact with autonomous co-presenter agents and their presentation media, including approaches to cueing human presenters effectively using wearable user interfaces.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Bickmore",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy W Bickmore",
   "pi_email_addr": "bickmore@ccs.neu.edu",
   "nsf_id": "000442154",
   "pi_start_date": "2015-07-13",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Harriet",
   "pi_last_name": "Fell",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Harriet J Fell",
   "pi_email_addr": "fell@ccs.neu.edu",
   "nsf_id": "000476523",
   "pi_start_date": "2015-07-13",
   "pi_end_date": "2020-04-17"
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 279047.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 286435.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 598824.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project is to develop technologies to help individuals deliver media-enhanced professional oral presentations, with a special emphasis on providing support for scientific presentations. A range of technologies were developed and evaluated, most involving the use of conversational agents or robots.<br /><br />The first effort resulted in a technology called \"DynamicDuo\" that uses a life-sized animated human character as a virtual co-presenter. This character shares the presentation stage with the human presenter and takes turns delivering parts of the presentation, or interacts with the human presenter in front of the audience. We used DynamicDuo to assist teachers in several undergraduate and graduate courses at Northeastern University, to help students in giving their presentations, and to help investigators give scientific presentations to their peers. In an evaluation study, we found that DynamicDuo resulted in significant reductions in public speaking anxiety and increases in speaker confidence compared to giving presentations without the technology. We also found that judges who viewed recorded presentations with DynamicDuo rated them significantly higher on speech quality and overall presentation quality compared to presentations without DynamicDuo.<br /><br />We developed a robotic version of this system, in which a mobile human-like robot takes turns giving a presentation with a human. We found that when individuals co-presented with the robot they exhibited significant reductions in public speaking anxiety and significantly higher public speaking confidence, compared to presentations in which they did not co-present with the robot. Audience members who watched presentations with the robot rated the presentations significantly higher than neutral on ratings of presentation quality. <br /><br />We also developed a robotic public speaking coach named \"RoboCOP\" that would listen to a speaker practice their presentation and provide feedback on speaking rate and quality, audience eye contact, and coverage of important points. In an evaluation study, participants who rehearsed with RoboCOP reported high levels of satisfaction with the robot and desire to use it again for future rehearsals. Judges who viewed recorded presentations made by presenters who rehearsed with RoboCOP rated the presentations as significantly more engaging, novel, and exciting, and significantly better on overall presentation quality and presenter speech quality compared to presentations given by individuals who did not rehearse with RoboCOP.<br /><br />We also developed an augmented reality system that provided presenters with information about their audience, displayed as annotations over their heads, including their names, feedback on the presentation, and questions they had. In an evaluation experiment we found that presenters were satisfied with the system, and were better able to call on audience members by name when provided with this assistance.<br /><br />Finally, we developed a range of additional technologies to help individuals overcome public speaking anxiety. In one effort, we developed a conversational agent that used techniques from cognitive behavioral therapy to help speakers work through the negative thoughts they had about public speaking, and demonstrated that this led to significant reductions in public speaking anxiety. In another series of projects we developed techniques for detecting high levels of public speaking anxiety while a speaker is giving a presentation, and additional techniques to help them calm down during their presentation.<br /><br />The results from these development efforts and experiments will inform the design of future technologies that can help people in all industries and organizations give better oral presentations.<br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/24/2021<br>\n\t\t\t\t\tModified by: Timothy&nbsp;W&nbsp;Bickmore</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635100950204_DynamicDuo--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635100950204_DynamicDuo--rgov-800width.jpg\" title=\"DynamicDuo\"><img src=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635100950204_DynamicDuo--rgov-66x44.jpg\" alt=\"DynamicDuo\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">DynamicDuo: Virtual Co-Presenter Agent</div>\n<div class=\"imageCredit\">Timothy Bickmore</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Timothy&nbsp;W&nbsp;Bickmore</div>\n<div class=\"imageTitle\">DynamicDuo</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635101020659_pepper--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635101020659_pepper--rgov-800width.jpg\" title=\"Co-Presenter Robot\"><img src=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635101020659_pepper--rgov-66x44.jpg\" alt=\"Co-Presenter Robot\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Co-Presenter Robot</div>\n<div class=\"imageCredit\">Timothy Bickmore</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Timothy&nbsp;W&nbsp;Bickmore</div>\n<div class=\"imageTitle\">Co-Presenter Robot</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635101097097_robocop--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635101097097_robocop--rgov-800width.jpg\" title=\"RoboCOP\"><img src=\"/por/images/Reports/POR/2021/1514490/1514490_10376251_1635101097097_robocop--rgov-66x44.jpg\" alt=\"RoboCOP\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">RoboCOP: Robotic Public Speaking Coach</div>\n<div class=\"imageCredit\">Timothy Bickmore</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Timothy&nbsp;W&nbsp;Bickmore</div>\n<div class=\"imageTitle\">RoboCOP</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project is to develop technologies to help individuals deliver media-enhanced professional oral presentations, with a special emphasis on providing support for scientific presentations. A range of technologies were developed and evaluated, most involving the use of conversational agents or robots.\n\nThe first effort resulted in a technology called \"DynamicDuo\" that uses a life-sized animated human character as a virtual co-presenter. This character shares the presentation stage with the human presenter and takes turns delivering parts of the presentation, or interacts with the human presenter in front of the audience. We used DynamicDuo to assist teachers in several undergraduate and graduate courses at Northeastern University, to help students in giving their presentations, and to help investigators give scientific presentations to their peers. In an evaluation study, we found that DynamicDuo resulted in significant reductions in public speaking anxiety and increases in speaker confidence compared to giving presentations without the technology. We also found that judges who viewed recorded presentations with DynamicDuo rated them significantly higher on speech quality and overall presentation quality compared to presentations without DynamicDuo.\n\nWe developed a robotic version of this system, in which a mobile human-like robot takes turns giving a presentation with a human. We found that when individuals co-presented with the robot they exhibited significant reductions in public speaking anxiety and significantly higher public speaking confidence, compared to presentations in which they did not co-present with the robot. Audience members who watched presentations with the robot rated the presentations significantly higher than neutral on ratings of presentation quality. \n\nWe also developed a robotic public speaking coach named \"RoboCOP\" that would listen to a speaker practice their presentation and provide feedback on speaking rate and quality, audience eye contact, and coverage of important points. In an evaluation study, participants who rehearsed with RoboCOP reported high levels of satisfaction with the robot and desire to use it again for future rehearsals. Judges who viewed recorded presentations made by presenters who rehearsed with RoboCOP rated the presentations as significantly more engaging, novel, and exciting, and significantly better on overall presentation quality and presenter speech quality compared to presentations given by individuals who did not rehearse with RoboCOP.\n\nWe also developed an augmented reality system that provided presenters with information about their audience, displayed as annotations over their heads, including their names, feedback on the presentation, and questions they had. In an evaluation experiment we found that presenters were satisfied with the system, and were better able to call on audience members by name when provided with this assistance.\n\nFinally, we developed a range of additional technologies to help individuals overcome public speaking anxiety. In one effort, we developed a conversational agent that used techniques from cognitive behavioral therapy to help speakers work through the negative thoughts they had about public speaking, and demonstrated that this led to significant reductions in public speaking anxiety. In another series of projects we developed techniques for detecting high levels of public speaking anxiety while a speaker is giving a presentation, and additional techniques to help them calm down during their presentation.\n\nThe results from these development efforts and experiments will inform the design of future technologies that can help people in all industries and organizations give better oral presentations.\n\n\n\n\t\t\t\t\tLast Modified: 10/24/2021\n\n\t\t\t\t\tSubmitted by: Timothy W Bickmore"
 }
}