{
 "awd_id": "1522707",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "A Posteriori Error Estimation through Duality and Some Other Topics",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 260000.0,
 "awd_amount": 260000.0,
 "awd_min_amd_letter_date": "2015-07-30",
 "awd_max_amd_letter_date": "2017-07-04",
 "awd_abstract_narration": "Self-adaptive numerical methods provide a powerful and automatic approach in scientific computing. In particular, Adaptive Mesh Refinement (AMR) algorithms have been widely used in computational science and engineering and have become a common tool in computer simulations of complex natural science and engineering problems. As identified by the US National Research Council, AMR is one of two necessary tools (AMR and Parallel Computing) for computationally tackling Grand Challenge problems. The key ingredient for success of AMR algorithms is a posteriori error estimates that are able to accurately locate sources of global and local error in the current approximation. Another challenge in computer simulations of complex systems is the reliability of computer predictions. These considerations (efficiency in AMR algorithms and error control) demonstrate the need for an error estimator that can a posteriori be extracted from the computed numerical solution and the given data of the underlying problem. Such an a posteriori error estimate ideally should provide an underlying rigorous mathematical theory for estimating and quantifying discretization error in terms of the error's magnitude and its spatial distribution. Success in this project will allow AMR algorithms to automatically locate physical interfaces, detect layers and discontinuities, and resolve oscillations of various scales. The dual estimators to be developed in this project will resolve the most natural but extremely difficult question of discretization error control on coarse meshes for a class of problems and hence partially guarantee reliability of computer simulations.\r\n\r\nThis research project focuses on the development, analysis, and test of a posteriori error estimators through the methodology of duality. The dual estimators to be developed in this project will have a guaranteed reliability bound with reliability constant being one. Hence, these estimators are perfect for discretization error control and may be used as an accurate stopping criterion for iterative solvers. The methodology of duality may be applied to a large class of problems arising from continuum mechanics including linear and nonlinear problems. Since these estimators will not use a priori knowledge on the locations and characteristics of interface singularities, discontinuities (in the form of shock-like fronts, and of interior and boundary layers), and/or oscillations of various scales (multi-scale phenomena), they may then be applied more readily to highly nonlinear problems and have the potential of being applied to complex systems arising in applications. The emphases and the difficulties of the proposed research are (1) explicit or local construction of an approximation to the dual variable such that the resulting indicator is efficient and robust, and (2) theoretical and numerical confirmation of the efficiency and robustness. Finally, a small portion of the proposed research addresses an open theoretical question on the robustness of estimators for interface problems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhiqiang",
   "pi_last_name": "Cai",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhiqiang Cai",
   "pi_email_addr": "zcai@math.purdue.edu",
   "nsf_id": "000418047",
   "pi_start_date": "2015-07-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "150 N University Street",
  "perf_city_name": "West Lafayette",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072067",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 95290.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 57485.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 107225.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Self-adaptive numerical methods provide a powerful and automatic approach in scientific computing. In particular, Adaptive Mesh Refinement (AMR) algorithms have been widely used in computational science and engineering, and they have become a necessary tool in computer simulations of complex natural and engineering problems. The key ingredient for success of AMR algorithms is a posteriori error estimates that are able to accurately locate sources of global and local error in the current approximation.</p>\n<p>&nbsp;<strong>Intellectual merit. </strong>A posteriori error estimator of the Zienkiewicz and Zhu (ZZ) type possesses a number of attractive features that have led to their widespread adoption, especially in the engineering practice. However, it is well known that these estimators are not efficient for non-smooth problems since they over-refining regions where having no errors. By exploring mathematical structure of the underlying partial differential equations (PDEs) and combining with characteristics of various finite element approximations, a new estimator of the ZZ type has been developed in this project. This improved ZZ estimator is efficient for non-smooth problems and has the same computational cost as the original ZZ estimator. Moreover, a distinct feature of the improved ZZ estimator is no need of a priori information on locations of physical interfaces and, hence, it is ready for its application to complex system.</p>\n<p>For the elliptic interface problem, various robust estimators have been constructed and analyzed by following the milestone work of Bernardi and Verfurth in 2000. The robustness of those estimators is established theoretically under the quasi-monotonicity assumption (QMA) on the distribution of the coefficients. However, numerical results by many researchers including ours strongly suggest that those estimators are robust even without the QMA. This observation has led to many efforts by numerical analysts on removing such an assumption theoretically. For discontinuous (including nonconforming) elements, we successfully remove the QMA and, hence, resolve this more than decade-long open question partially. Moreover, a new analytic tool has been introduced in the project for establishing the reliability bound for discontinuous elements instead of using the Helmholtz decomposition.</p>\n<p>The dual (equilibrated) estimator has attracted much interest recently due to the guaranteed reliability, i.e., the reliability constant is one. This property sheds light on how to address accuracy control of computer simulations of complex system, which is paramount but extremely difficult.This is because those simulations, even on super-computers, are still limited on pre-asymptotic meshes and we lack analytic tools for error analysis on coarse meshes. For the H(curl) problem, a novel dual estimator developed in this project overcomes drawbacks of all existing estimators. In particular, the dual estimator can handle irregular data that is not in H(div) unlike existing estimators. For the conforming finite element approximation to diffusion problems, reconstruction of an equilibrated flux has been reduced to local constraint minimization problems over vertex patches through a partition of unity. In order to reduce computational cost, a major challenge for the past decade had been on how to extend Braess-Sch&ouml;berl&rsquo;s simple approach of recovering an equilibrated flux from the lowest-order elements in two dimensions to higher order elements and to three dimensions. Attempts have been made by many researchers, and progress was minimum. In this project, we have fully resolved this issue by introducing a computationally efficient algorithm by first computing&nbsp;an equilibrated flux and then adding a divergence free correction. The algorithm is valid for higher order elements and for both two and three dimensions. Moreover, a new and simple analysis is developed for local efficiency bound.</p>\n<p>&nbsp;A discretization-accurate stopping criterion for iterative solvers on finite element approximation has developed in this project. This stopping criterion greatly reduces the number of iterations comparing to the one used in HYPER, a scalable linear solvers and multigrid methods code developed in Lawrence Livermore National Lab. Moreover, we prove a natural and important reliability bound for inexact finite element solution: the total error is bounded by the estimator computed by the inexact finite element solution plus the algebraic error; and we develop a sharp a posteriori error estimator for estimating the algebraic error.</p>\n<p><strong>Broader impacts.</strong> &nbsp;AMR algorithms based on recovery estimators have been widely used in engineering codes. Newly developed estimators in this project will improve efficiency of practical computations. In particular, it will greatly reduce computational cost of AMR algorithms for non-smooth problems. Moreover, the improved ZZ estimator and the discretization-accurate stopping criterion developed in this project have impacts in software industry as they have been adopted in the codes, BLAST (a high-order finite element hydrodynamics code) and HYPER, in the Lawrence Livermore National Lab.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/15/2020<br>\n\t\t\t\t\tModified by: Zhiqiang&nbsp;Cai</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nSelf-adaptive numerical methods provide a powerful and automatic approach in scientific computing. In particular, Adaptive Mesh Refinement (AMR) algorithms have been widely used in computational science and engineering, and they have become a necessary tool in computer simulations of complex natural and engineering problems. The key ingredient for success of AMR algorithms is a posteriori error estimates that are able to accurately locate sources of global and local error in the current approximation.\n\n Intellectual merit. A posteriori error estimator of the Zienkiewicz and Zhu (ZZ) type possesses a number of attractive features that have led to their widespread adoption, especially in the engineering practice. However, it is well known that these estimators are not efficient for non-smooth problems since they over-refining regions where having no errors. By exploring mathematical structure of the underlying partial differential equations (PDEs) and combining with characteristics of various finite element approximations, a new estimator of the ZZ type has been developed in this project. This improved ZZ estimator is efficient for non-smooth problems and has the same computational cost as the original ZZ estimator. Moreover, a distinct feature of the improved ZZ estimator is no need of a priori information on locations of physical interfaces and, hence, it is ready for its application to complex system.\n\nFor the elliptic interface problem, various robust estimators have been constructed and analyzed by following the milestone work of Bernardi and Verfurth in 2000. The robustness of those estimators is established theoretically under the quasi-monotonicity assumption (QMA) on the distribution of the coefficients. However, numerical results by many researchers including ours strongly suggest that those estimators are robust even without the QMA. This observation has led to many efforts by numerical analysts on removing such an assumption theoretically. For discontinuous (including nonconforming) elements, we successfully remove the QMA and, hence, resolve this more than decade-long open question partially. Moreover, a new analytic tool has been introduced in the project for establishing the reliability bound for discontinuous elements instead of using the Helmholtz decomposition.\n\nThe dual (equilibrated) estimator has attracted much interest recently due to the guaranteed reliability, i.e., the reliability constant is one. This property sheds light on how to address accuracy control of computer simulations of complex system, which is paramount but extremely difficult.This is because those simulations, even on super-computers, are still limited on pre-asymptotic meshes and we lack analytic tools for error analysis on coarse meshes. For the H(curl) problem, a novel dual estimator developed in this project overcomes drawbacks of all existing estimators. In particular, the dual estimator can handle irregular data that is not in H(div) unlike existing estimators. For the conforming finite element approximation to diffusion problems, reconstruction of an equilibrated flux has been reduced to local constraint minimization problems over vertex patches through a partition of unity. In order to reduce computational cost, a major challenge for the past decade had been on how to extend Braess-Sch&ouml;berl\u2019s simple approach of recovering an equilibrated flux from the lowest-order elements in two dimensions to higher order elements and to three dimensions. Attempts have been made by many researchers, and progress was minimum. In this project, we have fully resolved this issue by introducing a computationally efficient algorithm by first computing an equilibrated flux and then adding a divergence free correction. The algorithm is valid for higher order elements and for both two and three dimensions. Moreover, a new and simple analysis is developed for local efficiency bound.\n\n A discretization-accurate stopping criterion for iterative solvers on finite element approximation has developed in this project. This stopping criterion greatly reduces the number of iterations comparing to the one used in HYPER, a scalable linear solvers and multigrid methods code developed in Lawrence Livermore National Lab. Moreover, we prove a natural and important reliability bound for inexact finite element solution: the total error is bounded by the estimator computed by the inexact finite element solution plus the algebraic error; and we develop a sharp a posteriori error estimator for estimating the algebraic error.\n\nBroader impacts.  AMR algorithms based on recovery estimators have been widely used in engineering codes. Newly developed estimators in this project will improve efficiency of practical computations. In particular, it will greatly reduce computational cost of AMR algorithms for non-smooth problems. Moreover, the improved ZZ estimator and the discretization-accurate stopping criterion developed in this project have impacts in software industry as they have been adopted in the codes, BLAST (a high-order finite element hydrodynamics code) and HYPER, in the Lawrence Livermore National Lab.\n\n \n\n\t\t\t\t\tLast Modified: 03/15/2020\n\n\t\t\t\t\tSubmitted by: Zhiqiang Cai"
 }
}