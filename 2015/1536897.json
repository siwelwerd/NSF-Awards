{
 "awd_id": "1536897",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Collaborative: A Research Agenda to Explore Privacy in Small Data Applications",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 53984.0,
 "awd_amount": 53984.0,
 "awd_min_amd_letter_date": "2015-08-25",
 "awd_max_amd_letter_date": "2015-08-25",
 "awd_abstract_narration": "One of the crucial ideas behind Privacy by Design (PbD) is that privacy should be taken into consideration in the process of design, not merely after-the-fact, as so often happens. Yet, this ideal has failed to gain widespread practical traction, challenged, in part, by the lack of developed methodologies and also because of privacy's conceptual complexity, which hampers its operationalization. This project addresses both challenges simultaneously, seeking (i) to demonstrate how a robust operationalization of privacy can lead to meaningful PbD and (ii) to contribute methodological insight by engaging with ongoing research and development in the area of small data applications, namely, systems that advance wellness and personal productivity by utilizing digital traces from individuals' day-to-day activities, such as e-mail, grocery shopping, TV watching, transportation, mobile devices, and so forth. Adopting the definition of privacy as contextual integrity, the project will focus on selected small-data applications currently \"on the drawing board\" in PI Deborah Estrin's Small Data lab. With these design cases, the project rises to one of the PbD challenges, namely consideration of privacy early on in development and, as a research enterprise, its primary aim is to uncover more and less productive methodological approaches for doing so, resulting in system characteristics well correlated with privacy requirements. \r\n\r\nAt the same time, the project will provide invaluable insight into how to operationalize contextual integrity, which conceives of privacy as appropriate flow of personal information, modeling appropriate flow as conformance with context-specific informational norms, which, prescribe (and prohibit) information flows according to three parameters: actors (subject, sender, recipient), information types, and transmission principles (functional constraints on flow). Adopting contextual integrity as an operational definition means that researchers will assess privacy properties by carefully mapping data flows, and evaluating these flows in terms of the context of application and use. The project also extends past work on formal representations of informational norms by demonstrating how they may be integrated into design practices.  In addition to its substantive contributions this project embodies an innovative collaborative model -- a novel pairing of a computer scientist, Deborah Estrin (Cornell), with a philosopher, Helen Nissenbaum (NYU), in an equal partnership to forge technologies that embody meaningful privacy.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Deborah",
   "pi_last_name": "Estrin",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Deborah S Estrin",
   "pi_email_addr": "destrin@cs.cornell.edu",
   "nsf_id": "000460549",
   "pi_start_date": "2015-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "111 Eighth Avenue, Suite 302",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100115201",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "114Z",
   "pgm_ref_txt": "SaTC-CISE-SBE New Collabs"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8225",
   "pgm_ref_txt": "SaTC Special Projects"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 53984.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-cb7cfc10-2c7c-147b-2b87-a216b1a06840\"> </span></p>\n<p dir=\"ltr\"><span>This interdisciplinary project has developed a framework for taking privacy into consideration in system design by applying philosophical concepts to software engineering. Our efforts contribute to work in privacy-by-design, an important aspiration in engineering and policy, but difficult to put into practice. Our particular application area has been the burgeoning field of mobile health&nbsp;<span><span>apps</span></span>, focusing on&nbsp;apps&nbsp;under development in the Small Data Lab at Cornell Tech. Using&nbsp;<span><span>Limbr</span></span>, an&nbsp;<span><span>app</span></span>&nbsp;for long-term pain management, as a test bed for our ideas, we have derived a general framework for revealing privacy threats in small data applications.</span></p>\n<p>The researchers worked on a two-step heuristic to assess potential privacy violations in health research&nbsp;apps&nbsp;and found that one of the most surprising sources was exposure to privacy threats arising from common practice of integrating third-party services whose data practice are unknown and beyond the control of the&nbsp;<span><span><span>app</span></span></span>&nbsp;developers. The first step in this heuristic is to create a detailed data flow map. This map breaks down data by type, and then tracks each data type by method of collection from the user and tracks any third parties involved in the collection and aggregation of that data type. In essence this map seeks to categorize data types by sender/recipient and transmission principles as laid out in Dr.&nbsp;<span><span><span>Nissenbaum&rsquo;s</span></span></span>&nbsp;theory of contextual integrity. The second step is to use the flow map to identify points of third-party involvement in the flow and assess these points for vulnerabilities to user privacy.</p>\n<p>We include the data map constructed for the&nbsp;Limbr&nbsp;project as the motivating example for the creation of our heuristic.</p>\n<p>&nbsp;</p>\n<p dir=\"ltr\">Intellectual Merit</p>\n<p dir=\"ltr\">The exercise of mapping information flows allows developers to identify sources of potential threats to privacy in areas where these flows may be unexpected or obscured, particularly where third parties are involved. The heuristic will help developers to include privacy considerations in their analysis of how a design decision will affect their product; in particular as our heuristic acknowledges the realities of the current software development environment--namely, that it is necessary to rely on third-party services to provide application functionality--and offers a framework to reason about these decisions.</p>\n<p>&nbsp;</p>\n<p dir=\"ltr\">Broader Impact</p>\n<p dir=\"ltr\"><span>All of the PhD students, researchers, and software developers in the small data lab were exposed to the systematic processes for thinking through and designing these privacy concerns. The adoption of our heuristic will lead to more privacy-oriented design decisions by software developers. The hope is that this heuristic will provide guidance to&nbsp;<span><span><span>app</span></span></span>&nbsp;developers who are interested in privacy-by-design but lack expertise to design methods first-hand.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/06/2017<br>\n\t\t\t\t\tModified by: Deborah&nbsp;L&nbsp;Estrin</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1536897/1536897_10391966_1512582293667_ProjectOutcomesNSFEagerImage--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1536897/1536897_10391966_1512582293667_ProjectOutcomesNSFEagerImage--rgov-800width.jpg\" title=\"Data Flow Map\"><img src=\"/por/images/Reports/POR/2017/1536897/1536897_10391966_1512582293667_ProjectOutcomesNSFEagerImage--rgov-66x44.jpg\" alt=\"Data Flow Map\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This map categorizes data by type, according to Dr. Nissenbaum?s theory of contextual integrity, and follows each data type by method of collection from the user while tracking any third party involvement in the collection and aggregation of that data type.</div>\n<div class=\"imageCredit\">Deborah Estrin, Helen Nissenbaum, Liming Luo</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Deborah&nbsp;L&nbsp;Estrin</div>\n<div class=\"imageTitle\">Data Flow Map</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nThis interdisciplinary project has developed a framework for taking privacy into consideration in system design by applying philosophical concepts to software engineering. Our efforts contribute to work in privacy-by-design, an important aspiration in engineering and policy, but difficult to put into practice. Our particular application area has been the burgeoning field of mobile health apps, focusing on apps under development in the Small Data Lab at Cornell Tech. Using Limbr, an app for long-term pain management, as a test bed for our ideas, we have derived a general framework for revealing privacy threats in small data applications.\n\nThe researchers worked on a two-step heuristic to assess potential privacy violations in health research apps and found that one of the most surprising sources was exposure to privacy threats arising from common practice of integrating third-party services whose data practice are unknown and beyond the control of the app developers. The first step in this heuristic is to create a detailed data flow map. This map breaks down data by type, and then tracks each data type by method of collection from the user and tracks any third parties involved in the collection and aggregation of that data type. In essence this map seeks to categorize data types by sender/recipient and transmission principles as laid out in Dr. Nissenbaum?s theory of contextual integrity. The second step is to use the flow map to identify points of third-party involvement in the flow and assess these points for vulnerabilities to user privacy.\n\nWe include the data map constructed for the Limbr project as the motivating example for the creation of our heuristic.\n\n \nIntellectual Merit\nThe exercise of mapping information flows allows developers to identify sources of potential threats to privacy in areas where these flows may be unexpected or obscured, particularly where third parties are involved. The heuristic will help developers to include privacy considerations in their analysis of how a design decision will affect their product; in particular as our heuristic acknowledges the realities of the current software development environment--namely, that it is necessary to rely on third-party services to provide application functionality--and offers a framework to reason about these decisions.\n\n \nBroader Impact\nAll of the PhD students, researchers, and software developers in the small data lab were exposed to the systematic processes for thinking through and designing these privacy concerns. The adoption of our heuristic will lead to more privacy-oriented design decisions by software developers. The hope is that this heuristic will provide guidance to app developers who are interested in privacy-by-design but lack expertise to design methods first-hand.\n\n\t\t\t\t\tLast Modified: 12/06/2017\n\n\t\t\t\t\tSubmitted by: Deborah L Estrin"
 }
}