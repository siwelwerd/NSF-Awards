{
 "awd_id": "1530544",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "In Search of Dolphin Language",
 "cfda_num": "47.049",
 "org_code": "03010000",
 "po_phone": "7032924666",
 "po_email": "kblagoev@nsf.gov",
 "po_sign_block_name": "Krastan Blagoev",
 "awd_eff_date": "2015-06-01",
 "awd_exp_date": "2017-05-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2015-06-02",
 "awd_max_amd_letter_date": "2016-06-13",
 "awd_abstract_narration": "This project will address central questions in dolphin communication research by aggressively attacking the key technical issues such as the attribution problem with state-of-the-art computational neuroscience and statistical physics methods. The project will move quantitative high-throughput studies, currently tied to the bench, into field research of wild animals. This interdisciplinary study is collaboration between the labs of animal cognitive psychologist Diana Reiss and physicist and computational neuroscientist Marcelo Magnasco. One of the broader impacts of the project, the aquarium studies are particularly conducive to outreach efforts since the dolphin related activities take place in an open amphitheater environment and the exhibit has changed from dolphin shows to more educational demonstrations about animal care, behavior, and conservation. The research activities will take place concurrently with visits of the public and field trips of schoolchildren and therefore, the research endeavor is being communicated to the public in real time. Virtually all the activities proposed can, with modest effort and cost, be made into an open exhibit at the National Aquarium in Baltimore, instructing visiting schoolchildren on the research process and on collaborative research across scientific boundaries. The field trips to the research sites are organized jointly with undergraduate and graduate courses in field research for Hunter College students and are excellent opportunities to showcase and engage actual cutting edge research to these students.\r\n\r\nThe cognitive and communication capabilities of dolphins are legendary. Untangling the legends into a body of rigorous science has been a slow process fraught with many pitfalls; rigorous work in the last two decades has painted a rather more nuanced picture than the legends. While dolphins do indeed have amazing cognitive abilities, their natural conspecific communication in the wild remains enigmatic, with ongoing debates as to the nature of many elements of their vocal repertoire and the complexity of their communication overall. The key technical problems have been the laboriousness of the attribution problem, the assignment of which animal emitted which vocalization, the lack of automated behavior analysis methods, and finally the linking of attributed vocalizations to specific behaviors. Because we currently cannot automatically triangulate and track their voices underwater there are no extant corpora of dolphin vocalizations: what have been studied are mostly isolated calls, as opposed to \"conversations\". In the last decade, studies in songbirds and rodents have demonstrated the power of high-throughput setups in which a large number of animals are studied through automated means. The overarching aim of this project is to extend these high-throughput settings to dolphin communication studies, in captivity and in the wild, and develop, for this far more difficult case, the relevant automated audio and video analysis tools to handle the huge amount of data generated. There are two specific activities: first, the PIs will study learning and free use of a synthetic language and second record from multiple vantage points and then computationally analyze natural dolphin behavior in the wild, both during natural behavior in pods as well as during highly circumscribed, specific behaviors such as bowriding. The corpora of vocalizations generated will be analyzed computationally to establish whether wild dolphins do have a rich-enough \"language\", as opposed to a repertoire of calls.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "PHY",
 "org_div_long_name": "Division Of Physics",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Marcelo",
   "pi_last_name": "Magnasco",
   "pi_mid_init": "O",
   "pi_sufx_name": "",
   "pi_full_name": "Marcelo O Magnasco",
   "pi_email_addr": "magnasco@rockefeller.edu",
   "nsf_id": "000314276",
   "pi_start_date": "2015-06-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Diana",
   "pi_last_name": "Reiss",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Diana Reiss",
   "pi_email_addr": "diana.reiss@hunter.cuny.edu",
   "nsf_id": "000506077",
   "pi_start_date": "2015-06-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rockefeller University",
  "inst_street_address": "1230 YORK AVE",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2123278309",
  "inst_zip_code": "100656399",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NY12",
  "org_lgl_bus_name": "ROCKEFELLER UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "LHGDNJMZ64Y1"
 },
 "perf_inst": {
  "perf_inst_name": "Rockefeller University",
  "perf_str_addr": "1230 York Avenue",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100656399",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NY12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "724600",
   "pgm_ele_name": "PHYSICS OF LIVING SYSTEMS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 201054.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 98946.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The outcomes of this preliminary study have been the creation of two innovative technologies that will enable future studies, and making the public aware and excited about them.&nbsp;</p>\n<p>The first technology is a large underwater touchscreen, to be used in carrying out cognitive studies in dolphins at National Aquarium in Baltimore. The touchscreen was designed to be intrinsically safe to dolphins, by using optical technology, with no parts within the dolphins' pool which could endanger them. The system, essentially &nbsp;an underwater computer touchscreen&nbsp;through which dolphins are able to interact and make choices, will be used to investigate dolphin intelligence and communication by providing them choice and control over a number of activities.</p>\n<p>The eight-foot underwater touchscreen features specialized dolphin-friendly &ldquo;apps&rdquo; and a symbolic keyboard to provide the dolphins with opportunities to interact with the system. To make the system safe for the dolphins, the touchscreen has been installed outside an underwater viewing window, so that no parts of the device are in the pool:&nbsp;&nbsp;the animals&rsquo; touch&nbsp;is detected optically.&nbsp; While the research is still in its early stages, the team has embarked on studies aimed at understanding dolphin vocal learning and communication, their capacity for symbolic communication, and what patterns of behavior may emerge when the animals have the ability to request items, videos, interactions, and images.</p>\n<p>We&nbsp;<span>have begun to introduce the dolphins to some of the system&rsquo;s interactive apps, so the animals can explore on their own how touching the screen results in specific&nbsp;contingencies. Without any explicit training or encouragement, one of the younger dolphins spontaneously showed immediate interest and expertise in playing a dolphin&nbsp;version of&nbsp;Whack-a-Mole, in which he tracks and touches moving fish on the touchscreen.</span></p>\n<p>The second development created under the auspices of this grant is a marine robot to unbotrusively eavesdrop on dolphin communication in the willd. Based on ultraquiet electric motors on a 16-foot catamaran frame, our robot can quietly approach and follow dolphins without disturbing or distract them. Two radio links permit control of the robot and status-checking, as well as real-time audio and video transmission to base. During the period of the grant we have designed, constructed, validated and field-tested our first unit.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/20/2017<br>\n\t\t\t\t\tModified by: Marcelo&nbsp;O&nbsp;Magnasco</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2017/1530544/1530544_10366917_1497964361879_Foster-at-Touchscreen-600x338--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1530544/1530544_10366917_1497964361879_Foster-at-Touchscreen-600x338--rgov-800width.jpg\" title=\"Dolphin using touchscreen\"><img src=\"/por/images/Reports/POR/2017/1530544/1530544_10366917_1497964361879_Foster-at-Touchscreen-600x338--rgov-66x44.jpg\" alt=\"Dolphin using touchscreen\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A dolphin at National Aquarium encounters the underwater touchscreen for the first time.</div>\n<div class=\"imageCredit\">m2c2.net</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Marcelo&nbsp;O&nbsp;Magnasco</div>\n<div class=\"imageTitle\">Dolphin using touchscreen</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2017/1530544/1530544_10366917_1497964721860_vlcsnap-2017-06-20-09h14m29s155--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2017/1530544/1530544_10366917_1497964721860_vlcsnap-2017-06-20-09h14m29s155--rgov-800width.jpg\" title=\"Robot during maiden voyage\"><img src=\"/por/images/Reports/POR/2017/1530544/1530544_10366917_1497964721860_vlcsnap-2017-06-20-09h14m29s155--rgov-66x44.jpg\" alt=\"Robot during maiden voyage\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our marine robot about to conclude its 3 mile maiden voyage. Notice the lack of a wake behind it, despite moving at 4 knots at that moment. Instrument pods are retracted during high-speed navigation to avoid damage to the sensitive equipment and curtail drag.</div>\n<div class=\"imageCredit\">m2c2.net</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Marcelo&nbsp;O&nbsp;Magnasco</div>\n<div class=\"imageTitle\">Robot during maiden voyage</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe outcomes of this preliminary study have been the creation of two innovative technologies that will enable future studies, and making the public aware and excited about them. \n\nThe first technology is a large underwater touchscreen, to be used in carrying out cognitive studies in dolphins at National Aquarium in Baltimore. The touchscreen was designed to be intrinsically safe to dolphins, by using optical technology, with no parts within the dolphins' pool which could endanger them. The system, essentially  an underwater computer touchscreen through which dolphins are able to interact and make choices, will be used to investigate dolphin intelligence and communication by providing them choice and control over a number of activities.\n\nThe eight-foot underwater touchscreen features specialized dolphin-friendly \"apps\" and a symbolic keyboard to provide the dolphins with opportunities to interact with the system. To make the system safe for the dolphins, the touchscreen has been installed outside an underwater viewing window, so that no parts of the device are in the pool:  the animals? touch is detected optically.  While the research is still in its early stages, the team has embarked on studies aimed at understanding dolphin vocal learning and communication, their capacity for symbolic communication, and what patterns of behavior may emerge when the animals have the ability to request items, videos, interactions, and images.\n\nWe have begun to introduce the dolphins to some of the system?s interactive apps, so the animals can explore on their own how touching the screen results in specific contingencies. Without any explicit training or encouragement, one of the younger dolphins spontaneously showed immediate interest and expertise in playing a dolphin version of Whack-a-Mole, in which he tracks and touches moving fish on the touchscreen.\n\nThe second development created under the auspices of this grant is a marine robot to unbotrusively eavesdrop on dolphin communication in the willd. Based on ultraquiet electric motors on a 16-foot catamaran frame, our robot can quietly approach and follow dolphins without disturbing or distract them. Two radio links permit control of the robot and status-checking, as well as real-time audio and video transmission to base. During the period of the grant we have designed, constructed, validated and field-tested our first unit. \n\n\t\t\t\t\tLast Modified: 06/20/2017\n\n\t\t\t\t\tSubmitted by: Marcelo O Magnasco"
 }
}