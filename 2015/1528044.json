{
 "awd_id": "1528044",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Small: Transforming Participation in Online Courses through Social Live Media Composition",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 499827.0,
 "awd_amount": 563827.0,
 "awd_min_amd_letter_date": "2015-08-13",
 "awd_max_amd_letter_date": "2020-07-13",
 "awd_abstract_narration": "This project will develop and evaluate techniques for scaling participation in online education through social composition of live media learning experiences. Massive open online courses (MOOCs) have grown engagement in remote education. Yet, MOOCs have primarily been based on the one-way talking heads model, serving curricula using bite-sized chunks of pre-recorded video. The problem is that education has been shown to be based on legitimate peripheral participation in learning communities. This research has the potential to transform online courses beyond talking heads, making them more participatory. Expected significant outcomes are: (1) understanding how social live media composition (SLMC) supports engagement; (2) methods for fostering legitimate peripheral participation in online learning activities; (3) techniques for forming small collaborative groups in online communities; (4) computational techniques to support qualitative and quantitative analysis of live media experiences; (5) techniques for supporting rich expression in online remote computer-supported cooperative work.\r\n\r\nThis research will investigate a new medium of social live media composition that affords collaborative authoring of diagrams connecting live streaming, chat, screen sharing, and web content. As evidenced by recent popularity of live streaming, live media affords the sharing of rich participatory experiences within online communities. Composition is the freeform assembly of component media and annotations to form a connected whole that supports creative cognition of relationships. Composition has been shown, in laboratory and field studies, to support ideation, that is, the imagination, generation, and development of new ideas. The long term objective is to develop new roles for computing in supporting creativity, learning, and participation. The principal research question is how engagement in SLMC will constitute legitimate peripheral participation in online courses and so improve learning. This research will involve these specific aims: (1) Design and develop a social live media composition environment to engage learning communities. (2) Enable participation in learning communities from the crowds of online courses through social sharing and construction of live media compositions. (3) Conduct an iterative crowdsourced study to identify and investigate emergent phenomena in which SLMC supports legitimate peripheral participation in online courses.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Andruid",
   "pi_last_name": "Kerne",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andruid Kerne",
   "pi_email_addr": "andruid@cs.tamu.edu",
   "nsf_id": "000234889",
   "pi_start_date": "2015-08-13",
   "pi_end_date": "2019-05-21"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dilma",
   "pi_last_name": "Da Silva",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dilma Da Silva",
   "pi_email_addr": "dilma@tamu.edu",
   "nsf_id": "000695299",
   "pi_start_date": "2019-05-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M Engineering Experiment Station",
  "inst_street_address": "3124 TAMU",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778433124",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A&M ENGINEERING EXPERIMENT STATION",
  "org_prnt_uei_num": "QD1MX6N5YTN4",
  "org_uei_num": "QD1MX6N5YTN4"
 },
 "perf_inst": {
  "perf_inst_name": "Texas Engineering Experiment Station",
  "perf_str_addr": "Dept of Computer Science and Eng",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433112",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 499827.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-bdecc36d-7fff-cf28-6e13-01b9a0c6457f\"><br />\n<p dir=\"ltr\"><span>This research is based in giving people capabilities, in a collaborative space, for organizing information that they collect and want to think about, along with video streams of live activity, which correspond to meetings and presentations. We call this process curation. The LiveMache prototype was iteratively designed and developed, enabling interaction in the curation space with a 2 &frac12; D zoomable interface, inside a web browser. We call this multiscale curation. The actions people can perform in the space correspond to what we have identified as \"strategies of free-form web curation\": collecting information elements with drag and drop, organizing them by moving, resizing, and rotating, writing about elements, sketching in relationship to elements, shifting perspective with zoom and pan, and exhibiting by sharing with others.&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>An extended series of field studies has been performed with the LiveMache prototype, in 29 offerings of 17 courses, involving 13 faculty members in 11 departments, spanning 5 universities. A dataset of 3462 curations has been aggregated over the first 6 semesters of the studies, encompassing the participation of 1450 students. LiveMache was developed via robust software engineering practices, as a web app, in order to support use at this scale. This approach to structuring information for ideation and communication has been shown to be valuable in diverse educational contexts, and could, has the potential to be valuable for families, government, and businesses. With the right attention, it would be possible to further scale this prototype for use by more students, through programs such Midscale Research Infrastructure, as well as to commercialize via programs such as SBIR, STTR, and Convergence Accelerator.</span></p>\n<br />\n<p dir=\"ltr\"><span>Through the studies, we found that LiveMache's shared spatial context supports conversational grounding, in which participants express relationships by pointing and context-based deictic language. Sketching over is an important means of teaching and learning, in educational contexts, such as architecture and mechanical engineering courses. We found that multiscale curation supports students in&nbsp; activities of learner-centered project-based learning, such as accessing information, actively structuring, managing complexity, and working together. We built an initial multiscale curation recognition algorithm and an innovative dashboard interface for presenting multiscale analytics in the context of curation instances.We found that students collected, created, and assembled diverse forms of information, including Google Docs and videos, as well as images from web pages, and their own sketches and writings. Incorporating creative cognition theory, we conclude that these findings demonstrate overall support for creativity and collaboration.</span></p>\n<br /><br /><br /><br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2021<br>\n\t\t\t\t\tModified by: Dilma&nbsp;Da Silva</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\n\nThis research is based in giving people capabilities, in a collaborative space, for organizing information that they collect and want to think about, along with video streams of live activity, which correspond to meetings and presentations. We call this process curation. The LiveMache prototype was iteratively designed and developed, enabling interaction in the curation space with a 2 &frac12; D zoomable interface, inside a web browser. We call this multiscale curation. The actions people can perform in the space correspond to what we have identified as \"strategies of free-form web curation\": collecting information elements with drag and drop, organizing them by moving, resizing, and rotating, writing about elements, sketching in relationship to elements, shifting perspective with zoom and pan, and exhibiting by sharing with others. \n\n\nAn extended series of field studies has been performed with the LiveMache prototype, in 29 offerings of 17 courses, involving 13 faculty members in 11 departments, spanning 5 universities. A dataset of 3462 curations has been aggregated over the first 6 semesters of the studies, encompassing the participation of 1450 students. LiveMache was developed via robust software engineering practices, as a web app, in order to support use at this scale. This approach to structuring information for ideation and communication has been shown to be valuable in diverse educational contexts, and could, has the potential to be valuable for families, government, and businesses. With the right attention, it would be possible to further scale this prototype for use by more students, through programs such Midscale Research Infrastructure, as well as to commercialize via programs such as SBIR, STTR, and Convergence Accelerator.\n\n\nThrough the studies, we found that LiveMache's shared spatial context supports conversational grounding, in which participants express relationships by pointing and context-based deictic language. Sketching over is an important means of teaching and learning, in educational contexts, such as architecture and mechanical engineering courses. We found that multiscale curation supports students in  activities of learner-centered project-based learning, such as accessing information, actively structuring, managing complexity, and working together. We built an initial multiscale curation recognition algorithm and an innovative dashboard interface for presenting multiscale analytics in the context of curation instances.We found that students collected, created, and assembled diverse forms of information, including Google Docs and videos, as well as images from web pages, and their own sketches and writings. Incorporating creative cognition theory, we conclude that these findings demonstrate overall support for creativity and collaboration.\n\n\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 12/30/2021\n\n\t\t\t\t\tSubmitted by: Dilma Da Silva"
 }
}