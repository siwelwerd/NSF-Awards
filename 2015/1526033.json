{
 "awd_id": "1526033",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Inferring Non-Rigid Geometry from Object Categories",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 460000.0,
 "awd_amount": 460000.0,
 "awd_min_amd_letter_date": "2015-08-07",
 "awd_max_amd_letter_date": "2015-09-17",
 "awd_abstract_narration": "This project integrates new theoretical developments in group sparse coding and non-rigid structure from motion (NRSFM) within model-based methods for computer vision. Geometry is at the heart of visual perception. Humans invert the procedure of 3D to 2D projection effortlessly, blissfully ignorant of the mathematics required to make such inversion possible. Computer vision has been striving to unlock these mathematical secrets for the past few decades, with the view that to create any machine that truly \"sees\" it must be able to perform a similar inversion from 2D to 3D. Inferring the camera position and the 3D structure of a scene/object from an ensemble of 2D projected points is known within the field of computer vision as structure from motion (SFM).  By definition a static 3D structure is rigid, however, the set of 3D structures with the same object category label is inherently non-rigid; making large-scale NRSFM crucial for model-based category classification and detection. \r\n\r\nModel-based methods for object category classification and detection attempt to understand the interplay between an object's projected photometric appearance and its underlying geometry. These methods, however, have largely been abandoned in computer vision over the last two decades in favor of methods that rely solely on appearance (i.e. view-based approaches). As the space of computer vision and robotics continues to merge it is becoming increasingly important to not only recognize an object, but also understand how to grasp or interact with it - a task much more suited to a model-based methodology. Further, as the space of augmented reality becomes more sophisticated it is clear that 3D understanding of a scene/object is crucial - something that model-based approaches to perception naturally provide. Finally, vision machines are demanding an increasingly deeper understanding of how the visual world is allowed to vary during learning. A model-based framework can naturally accommodate this type of 3D geometric variation within a learning framework.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Simon",
   "pi_last_name": "Lucey",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Simon M Lucey",
   "pi_email_addr": "slucey@cs.cmu.edu",
   "nsf_id": "000217779",
   "pi_start_date": "2015-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 460000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><!-- p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; font: 11.0px 'Helvetica Neue'; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} -->\n<p class=\"p1\"><span class=\"s1\">An important component of this project was to develop a new theoretical framework for recovering the 3D structure of object categories solely from 2D projected landmarks taken from multiple images that could dramatically improve upon current state of the art. This problem is commonly referred to as Non-Rigid Structure from Motion (NRSfM). This project satisfied this goal in a number of ways. In our work on \"Compressible Structure from Motion\" (CVPR 2016) we pioneered a brand new way of solving this problem using insights from sparse dictionary learning. This paper was of high importance to the final goal of the project, as it laid the theoretical bedrock from which a practical solution to this problem was born. Then we extended this idea to the problem of object-centric NRSfM, or something we refer to as \"Structure from Category\" (3DV 2016). This setup our central result from this project ?Deep Non-Rigid Structure from Motion? which proposed an extension to our CVPR 2016 work, by incorporating hierarchical sparsity.<span>&nbsp; </span>This extension, can be reinterpreted in practice through a deep neural network (DNN). Our approach can outperform current state of the art methods by sometimes an order of magnitude, and opens up a number of new and exciting avenues for future research. Another output of our work, was its application to modeling the dense 3D geometry of objects. Most notably, our work on \"Using Locally Corresponding CAD Models for Dense 3D Reconstructions from a Single Image\" (CVPR 2017) and \"Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction\" (AAAI 2018). Results from our research was disseminated to the public through conferences, code and educational seminars.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/16/2019<br>\n\t\t\t\t\tModified by: Simon&nbsp;M&nbsp;Lucey</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAn important component of this project was to develop a new theoretical framework for recovering the 3D structure of object categories solely from 2D projected landmarks taken from multiple images that could dramatically improve upon current state of the art. This problem is commonly referred to as Non-Rigid Structure from Motion (NRSfM). This project satisfied this goal in a number of ways. In our work on \"Compressible Structure from Motion\" (CVPR 2016) we pioneered a brand new way of solving this problem using insights from sparse dictionary learning. This paper was of high importance to the final goal of the project, as it laid the theoretical bedrock from which a practical solution to this problem was born. Then we extended this idea to the problem of object-centric NRSfM, or something we refer to as \"Structure from Category\" (3DV 2016). This setup our central result from this project ?Deep Non-Rigid Structure from Motion? which proposed an extension to our CVPR 2016 work, by incorporating hierarchical sparsity.  This extension, can be reinterpreted in practice through a deep neural network (DNN). Our approach can outperform current state of the art methods by sometimes an order of magnitude, and opens up a number of new and exciting avenues for future research. Another output of our work, was its application to modeling the dense 3D geometry of objects. Most notably, our work on \"Using Locally Corresponding CAD Models for Dense 3D Reconstructions from a Single Image\" (CVPR 2017) and \"Learning Efficient Point Cloud Generation for Dense 3D Object Reconstruction\" (AAAI 2018). Results from our research was disseminated to the public through conferences, code and educational seminars.\n\n\t\t\t\t\tLast Modified: 12/16/2019\n\n\t\t\t\t\tSubmitted by: Simon M Lucey"
 }
}