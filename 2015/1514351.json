{
 "awd_id": "1514351",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER:  COLLABORATIVE RESEARCH:  Developmental mechanisms of perception and language in the infant brain",
 "cfda_num": "47.075",
 "org_code": "04040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "David Moore",
 "awd_eff_date": "2015-05-15",
 "awd_exp_date": "2017-04-30",
 "tot_intn_awd_amt": 215815.0,
 "awd_amount": 215815.0,
 "awd_min_amd_letter_date": "2015-05-12",
 "awd_max_amd_letter_date": "2015-05-12",
 "awd_abstract_narration": "Understanding what infants understand about objects and words that they encounter in the world has been an important goal in developmental science, but the field understands relatively little about how infants perform either of these two tasks.  Several neuroimaging methods have been used to determine how adult brains recognize familiar objects and words, but most of these methods are not suitable for use with infants.  The goal of this research project is to deploy two neuroimaging methods that are amenable for use with infants, as a novel way to gain insights into the fundamental brain mechanisms that enable object recognition and word understanding in 3- to 12-month-old infants. One technique, electroencephalography (EEG) involves measuring electrical activity generated by the brain from sensors on the scalp. The other, functional near-infrared spectroscopy (fNIRS), shines near-infrared light through the skull and measures how it is absorbed by the brain at each location as an index of how active that part of the brain is. Recording both these measures while infants watch and listen to stimuli will provide important insights into how the infant brain processes this information.\r\n\r\nEEG has been in use with infants for many years, whereas functional near-infrared spectroscopy (fNIRS) is a relatively newer non-invasive neuroimaging technique ideally suited for use with infants. fNIRS, like fMRI, provides a signature of metabolic activity in localized regions of the brain but is more suitable for infants because it delivers light to the scalp via a tight-fitting cap.  In this project, EEG and fNIRS will be used to measure electrical and metabolic activity in the brain as infants watch objects of various categories such as vehicles or furniture, or listen to words that they know or do not know (or nonsense words).  The key analysis tool is a suite of machine-learning algorithms from the field of computer science that take the EEG or fNIRS signals to determine which components of these signals best predict, on a trial by trial basis, what the infant was seeing or hearing.\r\n\r\nThe outcome of the proposed research will localize in the brain where encoding of visual objects and spoken words takes place and over what time period after stimulus onset that processing occurs. These are fundamental aspects of object and language processing have eluded study in the human infant because of methodological challenges.  Establishing protocols for analyzing data generated by these two methods will contribute to analytic techniques available for future infant brain research.  Identifying normative properties of these processing mechanisms in the infant brain will set the stage for future research investigating how the developing brain is affected by variations in early experience, by compensation after injury, and by a variety of genetic anomalies.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "BCS",
 "org_div_long_name": "Division of Behavioral and Cognitive Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Aslin",
   "pi_mid_init": "N",
   "pi_sufx_name": "",
   "pi_full_name": "Richard N Aslin",
   "pi_email_addr": "richard.aslin@yale.edu",
   "nsf_id": "000336579",
   "pi_start_date": "2015-05-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "Brain and Cognitive Sciences",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "142670268",
  "perf_ctry_code": "US",
  "perf_cong_dist": "26",
  "perf_st_cong_dist": "NY26",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "169800",
   "pgm_ele_name": "DS -Developmental Sciences"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1698",
   "pgm_ref_txt": "DS-Developmental Sciences"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 215815.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the key questions in human development is what brain mechanisms enable infants to learn about the world, including the recognition of visual objects and the understanding of spoken words that refer to those objects.&nbsp; The overall goal of our project was to use two methods for recording brain activity &ndash; EEG and fNIRS &ndash; to determine how patterns of brain activity are correlated with visual objects and spoken words in 6- to 15-month-old infants as well as adults.&nbsp; Electroencephalography (EEG) entails placing 32-128 sensors on the head of the infant and recording electrical signals coming from the brain.&nbsp; Functional near-infrared spectroscopy (fNIRS) entails placing up to 24 pairs of optical fibers on the head of the infant and introducing light into one fiber of each pair and recording the light that returns from the other fiber of the pair.&nbsp; The returning light is modulated by the absorption of oxygenated hemoglobin in localized regions of the surface of the brain, providing a correlate of neural activity.&nbsp; Thus, both EEG and fNIRS enable us to estimate how active the brain is, with EEG providing measurements every 1-msec but with low spatial accuracy and fNIRS providing measurements every 100-msec but with high spatial accuracy.</p>\n<p>A key feature of our project was to use machine-learning techniques of data analysis developed by computer scientists to ask what <span style=\"text-decoration: underline;\">patterns</span> of activity across the set of EEG or fNIRS channels &ndash; at each time point after the stimulus is presented &ndash; are uniquely correlated with each of several visual or auditory stimuli.&nbsp; The basic idea is that EEG provides a measure of <span style=\"text-decoration: underline;\">when</span> the brain can reliably decode which stimulus is presented and fNIRS provides a measure of <span style=\"text-decoration: underline;\">where</span> in the brain this decoding takes place.</p>\n<p>We first documented that EEG decoding is reliable using a large dataset from adults who were presented with images of faces (some familiar and some novel).&nbsp; We then documented that fNIRS decoding is reliable for a small set of images presented to 6-month-olds infants, and that fNIRS decoding can be scaled up to a much larger set of images in adults.&nbsp; Finally, we documented that EEG decoding is reliable in both adults and infants as they either watched or listened to images or words, respectively.&nbsp;</p>\n<p>These findings have important methodological implications that will enable the field of developmental cognitive neuroscience to address key theoretical questions.&nbsp; One implication is that we can leverage the temporal benefits of EEG and the spatial benefits of fNIRS to begin to understand both <span style=\"text-decoration: underline;\">when</span> and <span style=\"text-decoration: underline;\">where</span> in the brain neural signals are active in a network that underlies visual or language processing.&nbsp; A second implication is that we can apply machine-learning techniques to obtain neural decoding data at the group level to eventually make trial-by-trial estimates of which (of several) stimuli an infant is processing.&nbsp; &nbsp;&nbsp;These techniques set the stage for future studies of how infants recognize specific objects, link those objects to spoken words that refer to those objects, and how these abilities change across age.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/25/2017<br>\n\t\t\t\t\tModified by: Richard&nbsp;N&nbsp;Aslin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne of the key questions in human development is what brain mechanisms enable infants to learn about the world, including the recognition of visual objects and the understanding of spoken words that refer to those objects.  The overall goal of our project was to use two methods for recording brain activity &ndash; EEG and fNIRS &ndash; to determine how patterns of brain activity are correlated with visual objects and spoken words in 6- to 15-month-old infants as well as adults.  Electroencephalography (EEG) entails placing 32-128 sensors on the head of the infant and recording electrical signals coming from the brain.  Functional near-infrared spectroscopy (fNIRS) entails placing up to 24 pairs of optical fibers on the head of the infant and introducing light into one fiber of each pair and recording the light that returns from the other fiber of the pair.  The returning light is modulated by the absorption of oxygenated hemoglobin in localized regions of the surface of the brain, providing a correlate of neural activity.  Thus, both EEG and fNIRS enable us to estimate how active the brain is, with EEG providing measurements every 1-msec but with low spatial accuracy and fNIRS providing measurements every 100-msec but with high spatial accuracy.\n\nA key feature of our project was to use machine-learning techniques of data analysis developed by computer scientists to ask what patterns of activity across the set of EEG or fNIRS channels &ndash; at each time point after the stimulus is presented &ndash; are uniquely correlated with each of several visual or auditory stimuli.  The basic idea is that EEG provides a measure of when the brain can reliably decode which stimulus is presented and fNIRS provides a measure of where in the brain this decoding takes place.\n\nWe first documented that EEG decoding is reliable using a large dataset from adults who were presented with images of faces (some familiar and some novel).  We then documented that fNIRS decoding is reliable for a small set of images presented to 6-month-olds infants, and that fNIRS decoding can be scaled up to a much larger set of images in adults.  Finally, we documented that EEG decoding is reliable in both adults and infants as they either watched or listened to images or words, respectively. \n\nThese findings have important methodological implications that will enable the field of developmental cognitive neuroscience to address key theoretical questions.  One implication is that we can leverage the temporal benefits of EEG and the spatial benefits of fNIRS to begin to understand both when and where in the brain neural signals are active in a network that underlies visual or language processing.  A second implication is that we can apply machine-learning techniques to obtain neural decoding data at the group level to eventually make trial-by-trial estimates of which (of several) stimuli an infant is processing.    These techniques set the stage for future studies of how infants recognize specific objects, link those objects to spoken words that refer to those objects, and how these abilities change across age.\n\n\t\t\t\t\tLast Modified: 07/25/2017\n\n\t\t\t\t\tSubmitted by: Richard N Aslin"
 }
}