{
 "awd_id": "1518703",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "SHF: Large: General-Purpose Approximate Computing Across the System Stack",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2015-07-01",
 "awd_exp_date": "2024-06-30",
 "tot_intn_awd_amt": 2399764.0,
 "awd_amount": 2399764.0,
 "awd_min_amd_letter_date": "2015-06-12",
 "awd_max_amd_letter_date": "2023-08-01",
 "awd_abstract_narration": "Energy efficiency is a fundamental challenge facing the IT industry. Benefits go beyond reduced power demands in data centers and longer battery life in mobile devices. It is a fundamental enabler of future systems as we approach the limits of silicon device scaling. Therefore, providing a novel and holistic approach to energy efficiency in computer systems can have a transformative effect on IT and society. Many important applications---e.g., computer vision, novel user interfaces, signal processing, web search, augmented reality, and big-data analytics---can inherently tolerate some forms of inaccurate computation at various levels. With approximate computing, this fact can be exploited for fundamentally more efficient computing systems. This is a direct analog to Daniel Kahneman's model of how our brains work: they do cheap and quick reasoning (using System 1) in an approximate way, and when required, they do more expensive (and tiring) detailed thinking (using System 2). This research project will develop a analogous model for computer systems, from hardware to programming tools. \r\n\r\nTaking advantage of approximate computing requires significant innovation: programming models, tools for testing and debugging, and system support with quality guarantees. This project will develop a comprehensive solution across the system stack, from programming language to hardware. To demonstrate the potentials, prototypes of compelling applications amenable to approximate computing (e.g., computer vision) will be created. The project involves work on systems, programming languages, formal methods, and architecture, matching the inter-disciplinary expertise of the PI team. In addition to research papers, the project scope also includes releasing tools, benchmarks, and general infrastructure to the academic and industrial communities. The PIs have a history of inclusion of minorities and undergraduate students in their research efforts.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Luis",
   "pi_last_name": "Ceze",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Luis Ceze",
   "pi_email_addr": "luisceze@cs.washington.edu",
   "nsf_id": "000083036",
   "pi_start_date": "2015-06-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mark",
   "pi_last_name": "Oskin",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Mark H Oskin",
   "pi_email_addr": "oskin@cs.washington.edu",
   "nsf_id": "000461512",
   "pi_start_date": "2015-06-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Grossman",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel J Grossman",
   "pi_email_addr": "djg@cs.washington.edu",
   "nsf_id": "000400274",
   "pi_start_date": "2015-06-12",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Emina",
   "pi_last_name": "Torlak",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emina Torlak",
   "pi_email_addr": "emina@cs.washington.edu",
   "nsf_id": "000642956",
   "pi_start_date": "2015-06-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "185 Stevens Way",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 895183.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 473783.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 1030798.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-f2a3e941-7fff-f578-2653-70eed34f862e\">\n<p dir=\"ltr\"><span>This project paved the way for three important directions in computer systems and architecture research:&nbsp; end-to-end approximate computing; use of alternative computing substrates; and machine-learning compilers. Approximate computing refers to a set of techniques that trade-off accuracy for better energy efficiency or performance. For example, reduce media processing fidelity by choosing different data types, sampling the execution of loops, or using less reliable but lower energy-consuming memory and communication links. In this project we proposed programming models to allow programmers to express approximate data and computational units, and mapped them to the right hardware mechanisms. This resulted in papers in top venues as well as open source artifacts that were used by other researchers in the field, and in multiple PhD thesis, including from two under-represented minorities in the field. On the alternative computing front, this project supported the development of techniques for mapping computational kernels to DNA-based data storage and processing mechanisms, more specifically on making it more effective to read out the output of DNA circuits using approximate computing techniques.&nbsp;</span></p>\n<br />\n<p dir=\"ltr\"><span>On the machine learning compiler front, this project developed pioneering work on automatic optimization of machine learning models across a broad range of hardware. Some of the techniques proposed include automatic quantization of the resulting efficient code that implements quantized operations; support for sparse tensors and the associated optimizations; and automatic selection of the most appropriate libraries or compiler techniques depending on the model or hardware requirements. This work contributed directly to a major open source project called Apache TVM, which is now one of the major machine learning compilers in active deployment. Apache TVM underpinned the formation of a startup company called OctoML which at the peak employed over 100 people and was ultimately acquired by a major technology company.&nbsp;</span></p>\n</span></p><br>\n<p>\n Last Modified: 10/29/2024<br>\nModified by: Luis&nbsp;Ceze</p></div>\n<div class=\"porSideCol\"\n></div>\n</div>\n",
  "por_txt_cntn": "\n\n\n\n\nThis project paved the way for three important directions in computer systems and architecture research: end-to-end approximate computing; use of alternative computing substrates; and machine-learning compilers. Approximate computing refers to a set of techniques that trade-off accuracy for better energy efficiency or performance. For example, reduce media processing fidelity by choosing different data types, sampling the execution of loops, or using less reliable but lower energy-consuming memory and communication links. In this project we proposed programming models to allow programmers to express approximate data and computational units, and mapped them to the right hardware mechanisms. This resulted in papers in top venues as well as open source artifacts that were used by other researchers in the field, and in multiple PhD thesis, including from two under-represented minorities in the field. On the alternative computing front, this project supported the development of techniques for mapping computational kernels to DNA-based data storage and processing mechanisms, more specifically on making it more effective to read out the output of DNA circuits using approximate computing techniques.\n\n\n\n\nOn the machine learning compiler front, this project developed pioneering work on automatic optimization of machine learning models across a broad range of hardware. Some of the techniques proposed include automatic quantization of the resulting efficient code that implements quantized operations; support for sparse tensors and the associated optimizations; and automatic selection of the most appropriate libraries or compiler techniques depending on the model or hardware requirements. This work contributed directly to a major open source project called Apache TVM, which is now one of the major machine learning compilers in active deployment. Apache TVM underpinned the formation of a startup company called OctoML which at the peak employed over 100 people and was ultimately acquired by a major technology company.\n\t\t\t\t\tLast Modified: 10/29/2024\n\n\t\t\t\t\tSubmitted by: LuisCeze\n"
 }
}