{
 "awd_id": "1527510",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Concurrent Accelerated Data Integration",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2015-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 502175.0,
 "awd_amount": 519275.0,
 "awd_min_amd_letter_date": "2015-08-20",
 "awd_max_amd_letter_date": "2017-06-30",
 "awd_abstract_narration": "Not only is big data voluminous, it is varied. Individual data analysis tasks must first collect data sets that are often in unrelated locations and frequently in vastly disparate formats. These data sets almost always need multiple changes prior to the analysis task, such as format normalization, data cleansing, type checking, and outlier detection. These \"data integration\" activities typically consume an inordinate amount of time and effort both on the part of the data analyst and on the part of the computing systems.\r\n\r\nThis project is to design, prototype, and evaluate an Application-Specific Instruction Processor (ASIP) that will support the concurrent execution of data integration workloads for multiple streams of big data. The ASIP will not only execute an individual integration stream, but will be capable of concurrently executing a number of distinct data integration streams (each with its own processing requirements), enabling data from disparate sources to be utilized for analysis. Successful ASIP deployment will substantially increase the throughput (and therefore effectiveness) of big data analysis across a range of fields.\r\n\r\nWhat is unique about the ASIP design is not just that the instruction set will be customized, but the entire data path will be optimized for the data integration problem. Both very long instruction word (VLIW) and vector techniques will be used to expose and exploit parallelism. Complex transformations will be supported by a combination of customized engines as well as hardware virtualization. The optimization for data integration not only includes the computational data path, but explicit attention will be paid to the memory subsystem design as well.  The project will include super-optimization of memory subsystems from individual applications to the application class comprised of data integration workflows.\r\n\r\nThe result should lead to dramatic improvements in the overhead of preparing data for analysis.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Roger",
   "pi_last_name": "Chamberlain",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Roger D Chamberlain",
   "pi_email_addr": "roger@wustl.edu",
   "nsf_id": "000362967",
   "pi_start_date": "2015-08-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ron",
   "pi_last_name": "Cytron",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Ron K Cytron",
   "pi_email_addr": "cytron@cs.wustl.edu",
   "nsf_id": "000374266",
   "pi_start_date": "2015-08-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington University",
  "inst_street_address": "1 BROOKINGS DR",
  "inst_street_address_2": "",
  "inst_city_name": "SAINT LOUIS",
  "inst_state_code": "MO",
  "inst_state_name": "Missouri",
  "inst_phone_num": "3147474134",
  "inst_zip_code": "631304862",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "MO01",
  "org_lgl_bus_name": "WASHINGTON UNIVERSITY, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "L6NFUM28LQM5"
 },
 "perf_inst": {
  "perf_inst_name": "Washington University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MO",
  "perf_st_name": "Missouri",
  "perf_zip_code": "631304899",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "MO01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 502175.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 17100.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project is to decrease the time required to prepare data for analysis, particularly when the data are in multiple distinct formats (e.g., from multiple sources) and the multiple data transformation tasks are executing concurrently.&nbsp; To this end, we have several accomplishments:</p>\n<p>1. We have published a benchmark suite of data integration applications that is open source and available to the research community. This benchmark suite includes applications from five distinct discipines: computational biology, image processing, enterprise data, Internet of things, and graph processing.</p>\n<p>2. We have developed new approaches to characterizing applications in terms of their memory access patterns.&nbsp; Specifically, we have published approaches to discern spatial locality information from measurements that were intended initially to simply provide temporal locality.&nbsp; A new use of an existing measure, earth mover's distance, is used for compression of this meta-data.</p>\n<p>3. We have demonstrated several circumstances where deviating from manufacturers' guidance provides significant performance gains when deploying applications on FPGAs using high-level synthesis tool flows. In several specific instances, the highest performing instance is guided directly by the earth mover's distance measure described above.</p>\n<p>The result is that we now know quite a bit more about both what data transformation applications do and how to effectively implement them using custom hardware.&nbsp; This will benefit a multitude of big-data analysis tasks, by decreasing the overhead of preparing the data for processing.</p>\n<p>A total of 2 graduate students and 11 undergraduate students were supported over the period of the grant, with all of the students being exposed to not only the computer engineering aspects of custom hardware design but also to the scientific disciplines that these data transformation applications support.</p>\n<p>The results have been published in the scientific literature, and the benchmark suite is open source and readily available.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/28/2020<br>\n\t\t\t\t\tModified by: Roger&nbsp;D&nbsp;Chamberlain</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project is to decrease the time required to prepare data for analysis, particularly when the data are in multiple distinct formats (e.g., from multiple sources) and the multiple data transformation tasks are executing concurrently.  To this end, we have several accomplishments:\n\n1. We have published a benchmark suite of data integration applications that is open source and available to the research community. This benchmark suite includes applications from five distinct discipines: computational biology, image processing, enterprise data, Internet of things, and graph processing.\n\n2. We have developed new approaches to characterizing applications in terms of their memory access patterns.  Specifically, we have published approaches to discern spatial locality information from measurements that were intended initially to simply provide temporal locality.  A new use of an existing measure, earth mover's distance, is used for compression of this meta-data.\n\n3. We have demonstrated several circumstances where deviating from manufacturers' guidance provides significant performance gains when deploying applications on FPGAs using high-level synthesis tool flows. In several specific instances, the highest performing instance is guided directly by the earth mover's distance measure described above.\n\nThe result is that we now know quite a bit more about both what data transformation applications do and how to effectively implement them using custom hardware.  This will benefit a multitude of big-data analysis tasks, by decreasing the overhead of preparing the data for processing.\n\nA total of 2 graduate students and 11 undergraduate students were supported over the period of the grant, with all of the students being exposed to not only the computer engineering aspects of custom hardware design but also to the scientific disciplines that these data transformation applications support.\n\nThe results have been published in the scientific literature, and the benchmark suite is open source and readily available.\n\n\t\t\t\t\tLast Modified: 04/28/2020\n\n\t\t\t\t\tSubmitted by: Roger D Chamberlain"
 }
}