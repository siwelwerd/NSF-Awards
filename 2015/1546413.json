{
 "awd_id": "1546413",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Collaborative Research: F: Big Data, It's Not So Big: Exploiting Low-Dimensional Geometry for Learning and Inference",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Victor Roytburd",
 "awd_eff_date": "2015-12-01",
 "awd_exp_date": "2020-11-30",
 "tot_intn_awd_amt": 333333.0,
 "awd_amount": 333333.0,
 "awd_min_amd_letter_date": "2015-09-16",
 "awd_max_amd_letter_date": "2015-09-16",
 "awd_abstract_narration": "This research will leverage ideas from algebraic and differential geometry to address core problems in modern high-dimensional and massive data science.  The project will develop statistical methods and numerical tools, grounded in solid mathematical, statistical, and computational foundations, to extract low dimensional geometry from massive data with applications in clustering, data summarization, prediction, dimension reduction, and visualization.  The solutions developed as part of this project can result in fundamental advances in practical applications across fields as diverse as biology, medicine, social sciences, communication networks, and engineering.  In addition to internal validation via statistical and mathematical theory and simulation studies, the methods developed in the project will involve external validation via interdisciplinary applications.  These applications include: (1) inference of population structure from genomic data; (2) document analysis via topic models; and (3) inference of subsets of putative gene networks relevant to drug resistance in melanoma.\r\n\r\nThe research is motivated by the central premise that, even though the amount of data may be massive, a compact model can represent these data.  Specifically, high-dimensional and/or massive data can be reasonably approximated by a mixture of subspaces, for which sparse representations exist.  A mixture of subspaces of potentially different dimensions is a flexible, rich representation of data with nice mathematical properties that can scale to large data.  There are several fundamental challenges in modeling mixtures of subspaces that will be addressed in this research: 1) the subspaces will be of different dimensions, 2) both the subspace parameters and the mixing parameters need to be inferred, 3) efficient algorithms for inference are required for both high-dimensional and massive data.  The central foundational impediment in all of these challenges is that the model is a stratified space (a union of manifolds), and therefore has singularities.  The key insight in this research is that there exist embeddings and representations of the model space that mitigate these singularities.  These ideas are implemented as concrete Bayesian, frequentist, and numerical algorithms and models to address the real world examples listed above.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Lek-Heng",
   "pi_last_name": "Lim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Lek-Heng Lim",
   "pi_email_addr": "lekheng@galton.uchicago.edu",
   "nsf_id": "000150703",
   "pi_start_date": "2015-09-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5734 South University Ave",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606375418",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 333333.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project begins from the premise that whether a data set is large, high-dimensional, or highly correlated often depends on how one models it. A large collection of points sampled from two lines in <strong>R</strong><em><sup>n</sup></em>&nbsp;with large <em>n</em> is a massive high-dimensional data set when viewed as a point cloud data but is just two points when viewed as subspace-valued data in the Grassmannian Gr(1,<em>n</em>). The goal is then to develop tools for working with various manifolds of common data types --- fundamental notions like distances and probability distributions, basic algorithms for optimizing functions and integrating vector fields, etc, on such manifolds. We have accomplised these to various degrees for various manifolds. Take optimization algorithms for example, before our work in this project, there are exactly three Riemannian manifolds aside from the Euclidean space on which one knows how to do optimization: the Stiefel manifold, the Grassmannian, and the manifold of positive definite matrices. In the first three year of this project, we added two more to this list: the affine Grassmannian and the flag manifold. In the last two years, we extended this list to a dozen semi-Riemannian manifolds: pseudospheres, pseudohyperbolic spaces, de Sitter and anti de Sitter spaces, indefinite Stiefel and Grassmann manifolds, indefinite Lie groups, and other many more.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/10/2021<br>\n\t\t\t\t\tModified by: Lek-Heng&nbsp;Lim</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1546413/1546413_10400111_1628618691939_savas-lim--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1546413/1546413_10400111_1628618691939_savas-lim--rgov-800width.jpg\" title=\"manifold optimization\"><img src=\"/por/images/Reports/POR/2021/1546413/1546413_10400111_1628618691939_savas-lim--rgov-66x44.jpg\" alt=\"manifold optimization\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Optimization over a manifold</div>\n<div class=\"imageCredit\">B. Savas and L.-H. Lim</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Lek-Heng&nbsp;Lim</div>\n<div class=\"imageTitle\">manifold optimization</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe project begins from the premise that whether a data set is large, high-dimensional, or highly correlated often depends on how one models it. A large collection of points sampled from two lines in Rn with large n is a massive high-dimensional data set when viewed as a point cloud data but is just two points when viewed as subspace-valued data in the Grassmannian Gr(1,n). The goal is then to develop tools for working with various manifolds of common data types --- fundamental notions like distances and probability distributions, basic algorithms for optimizing functions and integrating vector fields, etc, on such manifolds. We have accomplised these to various degrees for various manifolds. Take optimization algorithms for example, before our work in this project, there are exactly three Riemannian manifolds aside from the Euclidean space on which one knows how to do optimization: the Stiefel manifold, the Grassmannian, and the manifold of positive definite matrices. In the first three year of this project, we added two more to this list: the affine Grassmannian and the flag manifold. In the last two years, we extended this list to a dozen semi-Riemannian manifolds: pseudospheres, pseudohyperbolic spaces, de Sitter and anti de Sitter spaces, indefinite Stiefel and Grassmann manifolds, indefinite Lie groups, and other many more.\n\n\t\t\t\t\tLast Modified: 08/10/2021\n\n\t\t\t\t\tSubmitted by: Lek-Heng Lim"
 }
}