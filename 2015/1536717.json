{
 "awd_id": "1536717",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Optimal Dose-Response Learning",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922443",
 "po_email": "gaklutke@nsf.gov",
 "po_sign_block_name": "Georgia-Ann Klutke",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 287878.0,
 "awd_amount": 287878.0,
 "awd_min_amd_letter_date": "2015-07-29",
 "awd_max_amd_letter_date": "2015-07-29",
 "awd_abstract_narration": "Medical treatment for diseases such as rheumatoid arthritis, hepatitis C, and cancer often requires the administration of doses in multiple sessions. Higher doses achieve better disease-control but have a higher risk of side effects. Lower doses have lesser side effects but may lead to inadequate disease-control. Since each patient's response to treatment is uncertain, the need to effectively balance this trade-off pervades all of medicine. Consequently, within the field of personalized medicine, there has been a recent surge of interest in the idea of response-guided dosing. The goal is to administer the right dose to the right patient at the right time, based on the observed evolution of each patient's disease condition. To attain this goal, it is crucial to better-learn patients' dose- response as treatment progresses. Expert panels and government regulatory bodies have therefore called for analytical tools to facilitate such learning-while-doing. The research objective of this award is to develop a mathematically rigorous, theoretical and computational framework for optimal dose-response learning while treating a cohort of patients in clinical trials for response-guided dosing. Millions of patients in the U.S. suffer from diseases that require multiple-session treatments. Thus, if successful, the mathematical framework in this award has the potential for a considerable societal impact.\r\n\r\nMore specifically, this project plans to use Bayesian stochastic dynamic programming formulations and approximate solution methods rooted in convex programming to facilitate response-learning and dosing decisions. The state in these models equals the cohort's disease conditions and decisions equal the doses administered. Disutility functions model the cohort's aversion to doses and to the disease conditions reached at the end of the trial. The decision-maker's prior belief is assumed to be conjugate to the dose-response parameter's distribution. The information state thus equals the prior's hyperparameters and updates via a simple formula. The decision-make's goal is to minimize the total expected disutility of the doses administered and of the disease conditions reached. Exact solution of this formulation is computationally intractable. Two approximate control schemes called semi-stochastic certainty equivalent control and certainty equivalent control are therefore planned. Structural properties such as monotonicity, stationarity, and separability of the resulting dosing policies will be analyzed and exploited for efficient solution. Variations such as optimal stopping problems, model selection problems, and problems with imperfect measurements will be studied. Clinical data on rheumatoid arthritis will be employed to calibrate the models, and to validate and compare the dosing policies derived via computer simulations.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Archis",
   "pi_last_name": "Ghate",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Archis Ghate",
   "pi_email_addr": "archis@umn.edu",
   "nsf_id": "000490902",
   "pi_start_date": "2015-07-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952650",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "006Y00",
   "pgm_ele_name": "OE Operations Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "076E",
   "pgm_ref_txt": "SERVICE ENTERPRISE SYSTEMS"
  },
  {
   "pgm_ref_code": "078E",
   "pgm_ref_txt": "ENTERPRISE DESIGN & LOGISTICS"
  },
  {
   "pgm_ref_code": "8023",
   "pgm_ref_txt": "Health Care Enterprise Systems"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 287878.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Medical treatment often involves the administration of doses in several sessions. The higher the doses, the better the disease-control and higher the risk of adverse effects and of logistical inconvenience. Lower doses have lesser side effects but worse disease-control. Since an individual patient's dose-response is uncertain, the need to effectively balance this trade-off pervades all of medicine. As a result, there has been a surge of interest in response-guided dosing (RGD), where doses are tuned based on observations of each patient's progression of disease condition. Single-parameter dose-response functions can be used to model this progression. However, the distribution of the parameter of any assumed dose-response function is not known; furthermore, dynamic decision-models that utilize such functions in RGD are not available. Consequently, dose levels in RGD are often ad hoc. Several expert panels and&nbsp;government regulatory bodies have called for&nbsp;analytical tools to facilitate RGD.&nbsp;</p>\n<p><br />The primary research objective of this project was to develop a rigorous mathematical modeling and computational framework to learn the distribution of a dose-response parameter while optimally dosing a cohort of patients in clinical trials for RGD.</p>\n<p><br /><strong>Intellectual merit</strong></p>\n<p>A Bayesian stochastic dynamic programming (DP) formulation of this optimal learning problem was developed.&nbsp;Exact solution of this formulation was computationally intractable. Efficient algorithms for&nbsp;approximate solution were therefore devised. This formulation and algorithms were extended to optimal stopping&nbsp;problems, where, at the beginning of each treatment session, the decision-maker determines whether or not it is&nbsp;optimal to discontinue treatment. If treatment is continued, the decision-maker must also choose optimal dose&nbsp;levels for that session. The formulation and computational methods were also generalized to incorporate imperfect&nbsp;disease condition measurements. Computer simulations using data for rheumatoid arthritis and cancer were performed&nbsp;to assess potential benefits of the proposed mathematical framework.&nbsp;&nbsp;</p>\n<p><br /><strong>Broader impact</strong></p>\n<p>RGD is applicable to many diseases including rheumatoid arthritis, hepatitis C, heart disease, cancer, and AIDS.&nbsp;This project has laid a mathematical foundation for optimally learning dose-response from a cohort of patients and for making RGD decisions for such diseases. The hope is that this foundation will ultimately help physicians administer the right dose to the right patient at the right time. The PI mentored five doctoral students on dissertations related to this project, and incorporated project&nbsp;findings into his graduate class on Markov decision processes. Results were disseminated through conference&nbsp;presentations and journal publications.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2018<br>\n\t\t\t\t\tModified by: Archis&nbsp;Ghate</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMedical treatment often involves the administration of doses in several sessions. The higher the doses, the better the disease-control and higher the risk of adverse effects and of logistical inconvenience. Lower doses have lesser side effects but worse disease-control. Since an individual patient's dose-response is uncertain, the need to effectively balance this trade-off pervades all of medicine. As a result, there has been a surge of interest in response-guided dosing (RGD), where doses are tuned based on observations of each patient's progression of disease condition. Single-parameter dose-response functions can be used to model this progression. However, the distribution of the parameter of any assumed dose-response function is not known; furthermore, dynamic decision-models that utilize such functions in RGD are not available. Consequently, dose levels in RGD are often ad hoc. Several expert panels and government regulatory bodies have called for analytical tools to facilitate RGD. \n\n\nThe primary research objective of this project was to develop a rigorous mathematical modeling and computational framework to learn the distribution of a dose-response parameter while optimally dosing a cohort of patients in clinical trials for RGD.\n\n\nIntellectual merit\n\nA Bayesian stochastic dynamic programming (DP) formulation of this optimal learning problem was developed. Exact solution of this formulation was computationally intractable. Efficient algorithms for approximate solution were therefore devised. This formulation and algorithms were extended to optimal stopping problems, where, at the beginning of each treatment session, the decision-maker determines whether or not it is optimal to discontinue treatment. If treatment is continued, the decision-maker must also choose optimal dose levels for that session. The formulation and computational methods were also generalized to incorporate imperfect disease condition measurements. Computer simulations using data for rheumatoid arthritis and cancer were performed to assess potential benefits of the proposed mathematical framework.  \n\n\nBroader impact\n\nRGD is applicable to many diseases including rheumatoid arthritis, hepatitis C, heart disease, cancer, and AIDS. This project has laid a mathematical foundation for optimally learning dose-response from a cohort of patients and for making RGD decisions for such diseases. The hope is that this foundation will ultimately help physicians administer the right dose to the right patient at the right time. The PI mentored five doctoral students on dissertations related to this project, and incorporated project findings into his graduate class on Markov decision processes. Results were disseminated through conference presentations and journal publications.\n\n\t\t\t\t\tLast Modified: 11/25/2018\n\n\t\t\t\t\tSubmitted by: Archis Ghate"
 }
}