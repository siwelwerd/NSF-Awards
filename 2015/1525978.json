{
 "awd_id": "1525978",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Homological Methods for Big Enough Data",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Joseph Maurice Rojas",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 340954.0,
 "awd_amount": 340954.0,
 "awd_min_amd_letter_date": "2015-07-21",
 "awd_max_amd_letter_date": "2015-07-21",
 "awd_abstract_narration": "How do we know if big data is big enough? As algorithms make more and more decisions from data, we also need these algorithms to assure us that the decisions were well-informed, i.e. that enough data went into them. The theory of homological sensor networks, a branch of topological data analysis, was originally created to test if a collection of sensors covers a domain of interest, but the same theory can test if a data set \"covers\" an underlying decision space. Homological methods can complement, extend, and even replace statistical methods to give confidence in the completeness of a data set. Because they are topological, they can give robust signatures or summaries of data that are invariant to a wide range of implicit or explicit transformations. This project aims to extend the theoretical and algorithmic foundations of the homological sensor networks to be applicable in data analysis. Broader impacts include strengthening connections between theoretical computer science (TCS) and applied algebraic topology, and widening the range of data analyses to which topological methods and tools apply.\r\n\r\nThe PI will train both undergraduate and graduate researchers by incorporating advanced concepts in combinatorial topology in undergraduate and graduate curricula. The PI will also educate the larger TCS and data analysis communities through expository videos and open source software.\r\n\r\nThe specific aim of the proposal is to extend guarantees on homological sensor networks to apply to non-smooth sets, k-coverage, and dynamic coverage.  A second specific aim is to push these algorithmic results back into the theoretical foundations of the sampling theories that underlie data analysis problems, by extending the so-called Persistent Nerve Theorem and defining new classes of near-homeomorphisms to capture the realities of unknown transformations in data while still providing theoretical guarantees.  The third specific aim is to develop algorithms that extract information from what was traditionally called \"topological noise\" as simple experiments reveal that although it doesn't carry topological information, it does carry useful geometric information that may be used for classification and inference.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Donald",
   "pi_last_name": "Sheehy",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Donald Sheehy",
   "pi_email_addr": "drsheehy@ncsu.edu",
   "nsf_id": "000670803",
   "pi_start_date": "2015-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Connecticut",
  "inst_street_address": "438 WHITNEY RD EXTENSION UNIT 1133",
  "inst_street_address_2": "",
  "inst_city_name": "STORRS",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "8604863622",
  "inst_zip_code": "062699018",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CT02",
  "org_lgl_bus_name": "UNIVERSITY OF CONNECTICUT",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNTPS995QBM7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Connecticut",
  "perf_str_addr": "371 Fairfield Way, Unit 4155",
  "perf_city_name": "Storrs",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "062694155",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CT02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7929",
   "pgm_ref_txt": "COMPUTATIONAL GEOMETRY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 340954.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project explored the use of homological methods in data analysis. The key idea in this field of topological data analysis (TDA) is to compute algebraic summaries from data sets. The questions addressed in this research started from the desire to answer qualitative questions about global properties of the data set, or more generally, the underlying space from which the data is sampled. The papers published as a result of this research span several areas within the algorithmic foundations of TDA including data structures, sampling, visualization, data summarizing, and metric approximations. Below, three of the more impactful results are highlighted.</p>\n<p>One powerful tool in TDA is the Topological Coverage Criterion (TCC) which uses a so-called persistent homology computation to test if a collection of sensors in a network cover the entire domain. One outcome of the research was to generalize the TCC to eliminate many of the geometric constraints on the underlying domain. This work allows one to also test for robust coverage in the presence of failures.</p>\n<p>A second outcome of the project involved the use of topological signatures for comparing continuous functions. The most obvious example of such shapes is trajectories, which can be viewed as a function from an interval (of time) to a space. Metrics to compare trajectories such as the Frechet distance adjust the speeds of the functions to align them. This is challenging and becomes computational hard for anything beyond trajectories such as surfaces. New results from this project showed how to use persistent homology to give interesting bounds on such distances in polynomial time even for surfaces and higher-dimensional inputs. This approach was novel in that it uses topological invariance to eliminate the difficult alignment step.</p>\n<p>A third outcome of the project was to generalize one of the most important and widely used tools in TDA, the Persistent Nerve Lemma (PNL). This result is used explicitly or implicitly throughout TDA as it provides the main connection between the discrete that we compute with and the continuous spaces they represent. In this project, the PNL was generalized so that it continues to give meaningful guarantees in the presence of noise. Moreover, the guarantees are quantitative: the topological signatures implied by the Persistent Nerve Lemma differ from the ideal by an amount proportional to a measure of the topological noise.<br />Three PhD students were partially supported by this project, two of which defended their dissertations and the third will finish soon. These students were trained in the theory and practice of TDA. Several undergraduates were also mentored as part of this project.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/30/2019<br>\n\t\t\t\t\tModified by: Donald&nbsp;Sheehy</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project explored the use of homological methods in data analysis. The key idea in this field of topological data analysis (TDA) is to compute algebraic summaries from data sets. The questions addressed in this research started from the desire to answer qualitative questions about global properties of the data set, or more generally, the underlying space from which the data is sampled. The papers published as a result of this research span several areas within the algorithmic foundations of TDA including data structures, sampling, visualization, data summarizing, and metric approximations. Below, three of the more impactful results are highlighted.\n\nOne powerful tool in TDA is the Topological Coverage Criterion (TCC) which uses a so-called persistent homology computation to test if a collection of sensors in a network cover the entire domain. One outcome of the research was to generalize the TCC to eliminate many of the geometric constraints on the underlying domain. This work allows one to also test for robust coverage in the presence of failures.\n\nA second outcome of the project involved the use of topological signatures for comparing continuous functions. The most obvious example of such shapes is trajectories, which can be viewed as a function from an interval (of time) to a space. Metrics to compare trajectories such as the Frechet distance adjust the speeds of the functions to align them. This is challenging and becomes computational hard for anything beyond trajectories such as surfaces. New results from this project showed how to use persistent homology to give interesting bounds on such distances in polynomial time even for surfaces and higher-dimensional inputs. This approach was novel in that it uses topological invariance to eliminate the difficult alignment step.\n\nA third outcome of the project was to generalize one of the most important and widely used tools in TDA, the Persistent Nerve Lemma (PNL). This result is used explicitly or implicitly throughout TDA as it provides the main connection between the discrete that we compute with and the continuous spaces they represent. In this project, the PNL was generalized so that it continues to give meaningful guarantees in the presence of noise. Moreover, the guarantees are quantitative: the topological signatures implied by the Persistent Nerve Lemma differ from the ideal by an amount proportional to a measure of the topological noise.\nThree PhD students were partially supported by this project, two of which defended their dissertations and the third will finish soon. These students were trained in the theory and practice of TDA. Several undergraduates were also mentored as part of this project.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/30/2019\n\n\t\t\t\t\tSubmitted by: Donald Sheehy"
 }
}