{
 "awd_id": "1528070",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NSFSaTC-BSF: TWC: Small: Using Individual Differences to Personalize Security Mitigations",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Shannon Beck",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 499732.0,
 "awd_amount": 515732.0,
 "awd_min_amd_letter_date": "2015-08-14",
 "awd_max_amd_letter_date": "2016-06-16",
 "awd_abstract_narration": "Over the past decade, people have realized that failure to account for human factors has resulted in many software security problems. Yet, when software does feature user-centric design, it takes into account average user behavior rather than catering to the individual. Thus, systems designers have gone from designing for security experts to now appealing to the least common denominator. The goal of this project is to examine the ways in which security mitigations can be tailored to individuals, and how this is likely to result in even greater security compliance than what has been previously achieved through user-centric design. Specifically, this research focuses on demonstrating how security mitigations can be tailored to individuals through indirect measurements and inferences of individual differences. This research could help security and privacy engineers develop more personalized and salient means to alert users to security and privacy risks, which could increase users' compliance with security messaging and therefore reduce threats to users and their organizations.\r\n\r\nThe challenge to personalizing security mitigations is to infer the individual differences between users that are predictive of whether they are likely to respond more favorably to one mitigation design over another. This approach relies on using well-studied individual differences in the psychology and decision-making literature that are predictive of compliance to computer security mitigations. Building on extensive work on choice architecture and \"nudges,\" this research aims to personalize security mitigations to specific user traits in order to be able to dynamically present each user with the security \"nudge\" that would be most effective for her. For example, if the target user measures high on decision-making \"dependence\" (i.e., looking to others for advice), the system might state the number of experts who selected the recommended option. Specifically, the researchers focus on framing the following types of security mitigations based on users' psychometric traits: smartphone/tablet lock screen enrollment, password creation instructions, web browser warnings, and software update notices. Their goal is to implement systems that infer the ways in which users are likely to respond to particular security mitigation designs and then tailor security environments accordingly.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Serge",
   "pi_last_name": "Egelman",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Serge M Egelman",
   "pi_email_addr": "egelman@icsi.berkeley.edu",
   "nsf_id": "000553035",
   "pi_start_date": "2015-08-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "International Computer Science Institute",
  "inst_street_address": "2150 SHATTUCK AVE",
  "inst_street_address_2": "SUITE 250",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106662900",
  "inst_zip_code": "947041345",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "INTERNATIONAL COMPUTER SCIENCE INSTITUTE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GSRMP1QCXU74"
 },
 "perf_inst": {
  "perf_inst_name": "International Computer Science Institute",
  "perf_str_addr": "1947 Center St STE 600",
  "perf_city_name": "BERKELEY",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947044115",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "014Z",
   "pgm_ref_txt": "NSF and US-Israel Binational Science Fou"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 499732.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Over the past two decades, people have realized that failure to account for human factors has resulted in many software security problems. Yet, now when software does feature user-centric design, it is only designed to account for&nbsp;average&nbsp;user behavior, rather than catering to an individual. Thus, we have gone from designing for security experts to the least common denominator. Our goal in this project is to examine the ways in which security mitigations can be tailored to individuals, and how this is likely to result in even greater security compliance than what has been previously achieved through user-centric design alone.</p>\n<p><span>The challenge to personalizing security mitigations is to infer the individual differences between users that are predictive of whether they are likely to respond more favorably to one mitigation design over another. Our approach relies on using well-studied individual differences in the psychology and decision-making literature that are predictive of compliance to computer security mitigations. We previously demonstrated that such correlations exist: users&rsquo; security intentions can be predicted by traits such as impulsivity and concern for future consequences. Building on extensive work on choice architecture and &ldquo;nudges,&rdquo; our goal is to personalize security mitigations to specific user traits in order to be able to dynamically present each user with the security &ldquo;nudge&rdquo; that would be most effective for her. For example, if the target user measures high on decision-making &ldquo;dependence&rdquo; (i.e., looking to others for advice), our system might use &ldquo;social pressure&rdquo; by stating that many peers selected the recommended option. We focus on framing the following types of security mitigations based on users&rsquo; psychometric traits: smartphone/tablet lock screen enrollment, password creation instructions, web browser warnings, and software update notices.</span></p>\n<p><span>Our vision is to implement systems that infer the ways in which users are likely to respond to particular security mitigation designs and then tailor security environments accordingly. Whereas the psychology literature documents ways in which certain individual differences predict different behaviors, and then marketers apply this knowledge to &ldquo;segment&rdquo; the population for advertisement targeting, our goal is to apply segmentation towards the targeting of security mitigations.</span></p>\n<!-- p.p1 {margin: 0.0px 0.0px 14.0px 0.0px; line-height: 17.0px; font: 14.0px Verdana; color: #000000; -webkit-text-stroke: #000000} span.s1 {font-kerning: none} span.s2 {font-kerning: none; background-color: #ffffff} -->\n<p class=\"p1\"><span class=\"s1\">Towards that goal, we studied how participants' security attitudes might be predicted by knowledge of their individual differences. In so doing, we constructed and validated an attitudinal scale.&nbsp;We performed a study to validate the Security Behavior Intentions Scale (SeBIS), which measures users' willingness to comply with various types of security mitigations. We have been using the scale to find predictors of security attitudes and behaviors. We observed that the scale does in fact predict users' security behaviors, and that it correlates with various other traits, such as risk tolerance, numeracy, and rationality.</span></p>\n<p class=\"p1\"><span class=\"s1\">We subsequently applied these findings by designing and validating a series of targeted nudges. These nudges leveraged participants psychometric traits in order to target personalized nudges to them. First, we performed an exploratory experiment to use the psychometrics that we previously identified as being relevant to security behaviors; we collected these psychometrics from several hundred participants. These participants were subsequently recruited to a study in which they were randomly shown one of several password nudges that have previously been shown by the literature to be effective. Our goal was to examine whether these effects were more or less predominant amongst individuals with certain traits. Upon completion of this experiment, we were able to show that certain traits <em>did</em> correlate with the effectiveness of certain nudges.</span></p>\n<p class=\"p1\"><span class=\"s1\">Based on these results, we performed a followup experiment to validate this result. The validation experiment used a narrower set of conditions (taken from the most effective nudges and psychometrics), which were specifically targeted to a new sample of participants. These new participants had already completed the psychometrics, and therefore we were able to specifically target nudges to individuals (as opposed to randomly assigning them and looking for correlations, as we did in the first experiment). </span><span class=\"s2\">We observed that passwords created under this condition were significantly stronger than those created either without a nudge or by randomly assigning one of the nudges being tested. Thus, targeting nudges based on psychometrics is effective, which was the entire thesis that we sought to prove with this project.</span></p>\n<p><span><br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/03/2020<br>\n\t\t\t\t\tModified by: Serge&nbsp;M&nbsp;Egelman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOver the past two decades, people have realized that failure to account for human factors has resulted in many software security problems. Yet, now when software does feature user-centric design, it is only designed to account for average user behavior, rather than catering to an individual. Thus, we have gone from designing for security experts to the least common denominator. Our goal in this project is to examine the ways in which security mitigations can be tailored to individuals, and how this is likely to result in even greater security compliance than what has been previously achieved through user-centric design alone.\n\nThe challenge to personalizing security mitigations is to infer the individual differences between users that are predictive of whether they are likely to respond more favorably to one mitigation design over another. Our approach relies on using well-studied individual differences in the psychology and decision-making literature that are predictive of compliance to computer security mitigations. We previously demonstrated that such correlations exist: users\u2019 security intentions can be predicted by traits such as impulsivity and concern for future consequences. Building on extensive work on choice architecture and \"nudges,\" our goal is to personalize security mitigations to specific user traits in order to be able to dynamically present each user with the security \"nudge\" that would be most effective for her. For example, if the target user measures high on decision-making \"dependence\" (i.e., looking to others for advice), our system might use \"social pressure\" by stating that many peers selected the recommended option. We focus on framing the following types of security mitigations based on users\u2019 psychometric traits: smartphone/tablet lock screen enrollment, password creation instructions, web browser warnings, and software update notices.\n\nOur vision is to implement systems that infer the ways in which users are likely to respond to particular security mitigation designs and then tailor security environments accordingly. Whereas the psychology literature documents ways in which certain individual differences predict different behaviors, and then marketers apply this knowledge to \"segment\" the population for advertisement targeting, our goal is to apply segmentation towards the targeting of security mitigations.\n\nTowards that goal, we studied how participants' security attitudes might be predicted by knowledge of their individual differences. In so doing, we constructed and validated an attitudinal scale. We performed a study to validate the Security Behavior Intentions Scale (SeBIS), which measures users' willingness to comply with various types of security mitigations. We have been using the scale to find predictors of security attitudes and behaviors. We observed that the scale does in fact predict users' security behaviors, and that it correlates with various other traits, such as risk tolerance, numeracy, and rationality.\nWe subsequently applied these findings by designing and validating a series of targeted nudges. These nudges leveraged participants psychometric traits in order to target personalized nudges to them. First, we performed an exploratory experiment to use the psychometrics that we previously identified as being relevant to security behaviors; we collected these psychometrics from several hundred participants. These participants were subsequently recruited to a study in which they were randomly shown one of several password nudges that have previously been shown by the literature to be effective. Our goal was to examine whether these effects were more or less predominant amongst individuals with certain traits. Upon completion of this experiment, we were able to show that certain traits did correlate with the effectiveness of certain nudges.\nBased on these results, we performed a followup experiment to validate this result. The validation experiment used a narrower set of conditions (taken from the most effective nudges and psychometrics), which were specifically targeted to a new sample of participants. These new participants had already completed the psychometrics, and therefore we were able to specifically target nudges to individuals (as opposed to randomly assigning them and looking for correlations, as we did in the first experiment). We observed that passwords created under this condition were significantly stronger than those created either without a nudge or by randomly assigning one of the nudges being tested. Thus, targeting nudges based on psychometrics is effective, which was the entire thesis that we sought to prove with this project.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 03/03/2020\n\n\t\t\t\t\tSubmitted by: Serge M Egelman"
 }
}