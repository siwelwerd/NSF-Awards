{
 "awd_id": "1544163",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Developing Methodological Foundations for Empirical Evaluations of Non-Experimental Methods in STEM Intervention Evaluations",
 "cfda_num": "47.076",
 "org_code": "11010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Finbarr Sloane",
 "awd_eff_date": "2015-09-15",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 234782.0,
 "awd_amount": 234782.0,
 "awd_min_amd_letter_date": "2015-09-16",
 "awd_max_amd_letter_date": "2015-09-16",
 "awd_abstract_narration": "The Promoting Research and Innovation in Methodologies for Evaluation (PRIME) program seeks to support research on evaluation with special emphasis on: (1) exploring innovative approaches for determining the impacts and usefulness of STEM education projects and programs; (2) building on and expanding the theoretical foundations for evaluating STEM education and workforce development initiatives, including translating and adapting approaches from other fields; and (3) growing the capacity and infrastructure of the evaluation field. Three types of proposals will be supported by the program: Exploratory Projects that include proof-of-concept and feasibility studies; more extensive Full-Scale Projects; and workshops and conferences. The proposed research attends carefully to item 1 above.  \r\n     \r\nThis research will establish a coherent framework for the design, implementation, and analysis of within-study comparisons for evaluating non-experimental methods. It will also establish an infrastructure for conducting an ongoing quantitative synthesis of results from within-study comparison designs.\r\n\r\nThis research study will develop the methodological foundations for using within-study comparison designs (WSCs) to evaluate non-experimental methods in STEM evaluation settings. In WSC designs, treatment effects from a non-experiment are compared to those produced by a randomized experiment that shares the same target population. The purpose of a WSC is to determine whether the non-experiment can replicate results from an experimental benchmark, and the contexts and conditions under which these methods perform well in field settings. The project has two overarching research aims.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DGE",
 "org_div_long_name": "Division Of Graduate Education",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Steiner",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Peter M Steiner",
   "pi_email_addr": "psteiner@umd.edu",
   "nsf_id": "000667595",
   "pi_start_date": "2015-09-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Madison",
  "inst_street_address": "21 N PARK ST STE 6301",
  "inst_street_address_2": "",
  "inst_city_name": "MADISON",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "6082623822",
  "inst_zip_code": "537151218",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "WI02",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "LCLSJAGTNZQ7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Madison",
  "perf_str_addr": "21 N. Park Street",
  "perf_city_name": "Madison",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "537151218",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "WI02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "726100",
   "pgm_ele_name": "Project & Program Evaluation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "009Z",
   "pgm_ref_txt": "PRIME - Promoting Research and Innovatio"
  }
 ],
 "app_fund": [
  {
   "app_code": "0415",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001516DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 234782.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Given the widespread use of non-experimental, observational studies  and methods for assessing the causal impact of interventions in program  evaluations, this project aimed at identifying which non-experimental  methods produce credible impact estimates in field settings. To this  end, the project pursued two over-arching goals. With respect to the  first goal, the project developed methodological foundations for the  design, implementation and analysis of within-study comparisons for  evaluating non-experimental methods in STEM research (a typical  within-study comparison assesses, within a single study, whether a  non-experimental study is able to replicate the causal impact estimate  of a comparable randomized experiment). The rigorous theoretical  foundations were laid out in potential outcomes notation and cover the  assumptions required for a meaningful interpretation of results. The  project also evaluated several correspondence measures for assessing  replication success. The theoretical foundations and correspondence  measures will allow researchers to implement within-study comparisons of  higher quality and to better assess the outcomes of such studies. The  methodological framework has also been successfully extended to  replication studies in general and will contributes to a better  understanding and designing of replication efforts.</p>\n<p>With respect to the second goal, the project established infrastructure  for conducting a quantitative synthesis of all published within-study  comparisons and to develop an empirically based theory of &ldquo;best  practice&rdquo; on quasi-experimental designs. The project coded all known  within-study comparison results and will make the database publicly  available. A meta-analysis of the coded studies assessed the contexts  and conditions under which non-experimental methods are likely (or not  likely) to produce causal impact estimates in evaluation settings. The  project paid particular attention to developing and improving WSC  methods for STEM evaluation contexts.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2019<br>\n\t\t\t\t\tModified by: Peter&nbsp;Steiner</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nGiven the widespread use of non-experimental, observational studies  and methods for assessing the causal impact of interventions in program  evaluations, this project aimed at identifying which non-experimental  methods produce credible impact estimates in field settings. To this  end, the project pursued two over-arching goals. With respect to the  first goal, the project developed methodological foundations for the  design, implementation and analysis of within-study comparisons for  evaluating non-experimental methods in STEM research (a typical  within-study comparison assesses, within a single study, whether a  non-experimental study is able to replicate the causal impact estimate  of a comparable randomized experiment). The rigorous theoretical  foundations were laid out in potential outcomes notation and cover the  assumptions required for a meaningful interpretation of results. The  project also evaluated several correspondence measures for assessing  replication success. The theoretical foundations and correspondence  measures will allow researchers to implement within-study comparisons of  higher quality and to better assess the outcomes of such studies. The  methodological framework has also been successfully extended to  replication studies in general and will contributes to a better  understanding and designing of replication efforts.\n\nWith respect to the second goal, the project established infrastructure  for conducting a quantitative synthesis of all published within-study  comparisons and to develop an empirically based theory of \"best  practice\" on quasi-experimental designs. The project coded all known  within-study comparison results and will make the database publicly  available. A meta-analysis of the coded studies assessed the contexts  and conditions under which non-experimental methods are likely (or not  likely) to produce causal impact estimates in evaluation settings. The  project paid particular attention to developing and improving WSC  methods for STEM evaluation contexts.\n\n\t\t\t\t\tLast Modified: 12/02/2019\n\n\t\t\t\t\tSubmitted by: Peter Steiner"
 }
}