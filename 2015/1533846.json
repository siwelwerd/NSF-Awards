{
 "awd_id": "1533846",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: Full: FP: Collaborative Research: Sphinx: Combining Data and Instruction Level Parallelism through Demand Driven Execution of Imperative Programs",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2015-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 315000.0,
 "awd_amount": 347000.0,
 "awd_min_amd_letter_date": "2015-07-20",
 "awd_max_amd_letter_date": "2017-11-24",
 "awd_abstract_narration": "Title: XPS: Full: FP: Collaborative Research: Sphinx: Combining Data and Instruction Level Parallelism through Demand Driven Execution of Imperative Programs\r\n\r\nIt has become increasingly difficult to improve the performance of processors so that they can meet the demands of existing and emerging workloads. Recent emphasis has been towards enhancing the performance through the use of multi-core processors and Graphics Processing Units. However, these processors remain difficult to program and inflexible to adapt to dynamic changes in the available parallelism in a given program. Although the computer architecture and programming language community continues to innovate and make important gains towards better programmability and better designs, it remains that parallel programming is inherently costly and error prone, and automatic parallelization of programs is not always feasible or effective. The intellectual merits of this project are the development of a new program execution paradigm and the establishment of critical compiler and micro-architecture mechanisms so that we can design processors that can be easily programmed using existing programming languages and at the same time surpass the performance of existing parallel computers. The project's broader significance and importance are wide-spread: the deployment of such processors will push the limits of computation in every field of science and commerce.\r\n\r\nThe execution paradigm under consideration is a previously unexplored execution model, the demand-driven execution of imperative programs (DDE). The DDE paradigm rests on a solid theoretical framework and promises to efficiently deliver very high-levels of fine-grain parallelism. This parallelism is extracted from a program written in an imperative language such as C, and it is realized by means of an effective compiler-architecture collaboration mechanism using a common, single-assignment form for the program representation. DDE processors can extract instruction-level parallelism much more efficiently than existing superscalar processors as the paradigm does not require dynamic dependency checking. Such processors can fetch, buffer, and execute many more instructions in parallel than current superscalar processors. Owing to its dependence-driven instruction fetching and execution, the paradigm leads to extremely scalable designs, as the communication is naturally localized and synchronization is inherent in the model. Conventional thread-level parallelism (TLP) is orthogonal to DDE, and thus DDE designs can exploit both ILP and TLP. DDE architectures thus represent promising building blocks for extreme-scale machines.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Whalley",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "David B Whalley",
   "pi_email_addr": "whalley@cs.fsu.edu",
   "nsf_id": "000346269",
   "pi_start_date": "2015-07-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Florida State University",
  "inst_street_address": "874 TRADITIONS WAY",
  "inst_street_address_2": "",
  "inst_city_name": "TALLAHASSEE",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "8506445260",
  "inst_zip_code": "323060001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "FL02",
  "org_lgl_bus_name": "FLORIDA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF2BLNN4PJC3"
 },
 "perf_inst": {
  "perf_inst_name": "Florida State University",
  "perf_str_addr": "1004 Academic Way",
  "perf_city_name": "Tallahassee",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "323064530",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "FL02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 315000.0
  },
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Traditional computing relies on sequential processing of machine instructions which forms the basis for computing in every aspect of our lives.&nbsp; Further speeding up the execution of programs requires the use of parallelism and parallel execution of programs under the sequential execution model requires an extensive effort to develop and tune parallel programs, which are more prone to bugs and failures.</p>\n<p>The goal of the project is to develop an alternative execution model called demand-driven execution of imperative programs. In this model, programs are automatically translated to an internal representation which permits executing them starting with their outputs progressing towards their inputs and computing only what is necessary and automatically in parallel. Our project has developed the model, and developed the compiler technology to convert imperative programs written in a conventional imperative programming language, such as C or C++. We have also developed the processor designs which can efficiently execute the transformed programs.</p>\n<p>Since such a drastic change in program execution model requires the entire software stack to be developed, we cannot claim immediate and wide-spread use of this technology at this point. However, our project has demonstrated that we can automatically transform programs into this new paradigm and develop processors which can efficiently execute these programs. Further work on this approach may potentially provide significant speed-ups compared to conventional computing.&nbsp; Attached graphs show the performance of our approach for a limited set of Livermore kernels which our compiler can compile.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2020<br>\n\t\t\t\t\tModified by: David&nbsp;B&nbsp;Whalley</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1533846/1533846_10377919_1606662214159_superscalar--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1533846/1533846_10377919_1606662214159_superscalar--rgov-800width.jpg\" title=\"DDE vs Superscalar Processor\"><img src=\"/por/images/Reports/POR/2020/1533846/1533846_10377919_1606662214159_superscalar--rgov-66x44.jpg\" alt=\"DDE vs Superscalar Processor\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Performance of a DDE processor compared to a similarly configured superscalar processor.  A one token DDE machine can process a single operand per cycle.</div>\n<div class=\"imageCredit\">Omkar Javeri PhD Dissertation</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">David&nbsp;B&nbsp;Whalley</div>\n<div class=\"imageTitle\">DDE vs Superscalar Processor</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1533846/1533846_10377919_1606662124161_mips-base--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1533846/1533846_10377919_1606662124161_mips-base--rgov-800width.jpg\" title=\"DDE vs MIPS Single Issue\"><img src=\"/por/images/Reports/POR/2020/1533846/1533846_10377919_1606662124161_mips-base--rgov-66x44.jpg\" alt=\"DDE vs MIPS Single Issue\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Scalability of DDE processor with respect to a single issue MIPS processor. A one-token DDE processor can process one operand per clock cycle.</div>\n<div class=\"imageCredit\">Omkar Javeri PhD Dissertation</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">David&nbsp;B&nbsp;Whalley</div>\n<div class=\"imageTitle\">DDE vs MIPS Single Issue</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nTraditional computing relies on sequential processing of machine instructions which forms the basis for computing in every aspect of our lives.  Further speeding up the execution of programs requires the use of parallelism and parallel execution of programs under the sequential execution model requires an extensive effort to develop and tune parallel programs, which are more prone to bugs and failures.\n\nThe goal of the project is to develop an alternative execution model called demand-driven execution of imperative programs. In this model, programs are automatically translated to an internal representation which permits executing them starting with their outputs progressing towards their inputs and computing only what is necessary and automatically in parallel. Our project has developed the model, and developed the compiler technology to convert imperative programs written in a conventional imperative programming language, such as C or C++. We have also developed the processor designs which can efficiently execute the transformed programs.\n\nSince such a drastic change in program execution model requires the entire software stack to be developed, we cannot claim immediate and wide-spread use of this technology at this point. However, our project has demonstrated that we can automatically transform programs into this new paradigm and develop processors which can efficiently execute these programs. Further work on this approach may potentially provide significant speed-ups compared to conventional computing.  Attached graphs show the performance of our approach for a limited set of Livermore kernels which our compiler can compile.\n\n \n\n\t\t\t\t\tLast Modified: 11/29/2020\n\n\t\t\t\t\tSubmitted by: David B Whalley"
 }
}