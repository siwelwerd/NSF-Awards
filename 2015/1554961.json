{
 "awd_id": "1554961",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Reflection and Diffraction Sound Signals for Non-Field-of-View Target Estimation",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2015-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 165252.0,
 "awd_amount": 165252.0,
 "awd_min_amd_letter_date": "2015-09-01",
 "awd_max_amd_letter_date": "2015-09-01",
 "awd_abstract_narration": "This project studies the diffraction and reflection signals in sound source localization. The study could enable the capability of tracking and localizing human partners outside of the robots' Field-Of-View (FOV) to the co-robots for human-robot interaction.  The project estimates an object outside of FOV using auditory sensors and enhances perception capabilities of robots. The project integrates research and education by training graduate and undergraduate students and outreach local K-12 students.\r\n\r\nThis research proves the early-stage concept of the project that estimates the location of a Non-FOV (NFOV) target by learning from humans and utilizing the physics of sound wave propagation associated with the NFOV target. The research is to introduce the capability of localizing human partners outside of the robots' FOV to the co-robots for Human-Robot Interaction. The research team approaches the problem by deterministically formulating first-arrival diffraction and reflection signals and identifying signal directions. The project develops an approach that auditorily estimates the location of an NFOV target by learning from humans and utilizing the physics of sound wave propagation associated with the NFOV target. The project further evaluates the approach in unknown indoor environments by using both visual and auditory sensors.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tomonari",
   "pi_last_name": "Furukawa",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tomonari Furukawa",
   "pi_email_addr": "tomonari@virginia.edu",
   "nsf_id": "000527283",
   "pi_start_date": "2015-09-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Virginia Polytechnic Institute and State University",
  "inst_street_address": "300 TURNER ST NW",
  "inst_street_address_2": "STE 4200",
  "inst_city_name": "BLACKSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "5402315281",
  "inst_zip_code": "240603359",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "VA09",
  "org_lgl_bus_name": "VIRGINIA POLYTECHNIC INSTITUTE & STATE UNIVERSITY",
  "org_prnt_uei_num": "X6KEFGLHSJX7",
  "org_uei_num": "QDE5UHE5XD16"
 },
 "perf_inst": {
  "perf_inst_name": "Virginia Polytechnic Institute and State University",
  "perf_str_addr": "",
  "perf_city_name": "Blacksburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "240610001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "VA09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 165252.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The ultimate goal of this project is to introduce the capability of tracking and localizing human partners outside of the robots&rsquo; Field of View (FOV) to the co-robots for Human-Robot Interaction (HRI), or estimating the partner&rsquo;s location outside of FOV in short.&nbsp; Within the scope, the aim of this EAGER project has been set to prove the early-stage concept of the project, which is to estimate the location of an NFOV target by learning from humans and utilizing the physics of sound wave propagation associated with the NFOV target.&nbsp; The outcomes of the project consist of three achievements: (1) theoretical development, (2) prototyping and (3) experimental validation.&nbsp;</p>\n<p>The theory the PI developed in the past used Inter-aural Level Difference (ILD), which uses two microphones bio-mimetically.&nbsp; A NFOV target was estimated by collecting data of the environment can be collected in advance.&nbsp; Two microphones are sufficient when the environment data can be collected in advance, but it is not the case of many scenarios.&nbsp; Since this project is concerned with unknown environments, the theory of this project was thus built by using a microphone array, which provides more information on the environment.&nbsp; Instead of data, physics of reflection and diffraction have been incorporated into the theory to enable NFLOV target localization in unknown environments.&nbsp;</p>\n<p>Following the theoretical development, a prototype system was developed.&nbsp; The microphone array consists of 8 microphones, and a beam former was implemented to identify the direction of reflection and diffraction signals.&nbsp; To first prove the concept, the system was designed and developed for two-dimensional (2D) localization.&nbsp;</p>\n<p>The experimental validation was conducted in two steps.&nbsp; In the first step, auditory tests of humans including blind people were conducted to verify that humans have the ability to localize the NFOV target.&nbsp; The results of the step were also used for theoretical developments.&nbsp; In the second step, the developed prototype system was tested in an anechoic chamber.&nbsp; Having the NFOV target and the microphone array at the same height, the environment with one diffraction wall and one reflection wall enabled the proof-of-concept in the 2D space.&nbsp; The experimental validation has resulted in proving the concept of the developed theory and prototype successfully.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/03/2018<br>\n\t\t\t\t\tModified by: Tomonari&nbsp;Furukawa</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe ultimate goal of this project is to introduce the capability of tracking and localizing human partners outside of the robots? Field of View (FOV) to the co-robots for Human-Robot Interaction (HRI), or estimating the partner?s location outside of FOV in short.  Within the scope, the aim of this EAGER project has been set to prove the early-stage concept of the project, which is to estimate the location of an NFOV target by learning from humans and utilizing the physics of sound wave propagation associated with the NFOV target.  The outcomes of the project consist of three achievements: (1) theoretical development, (2) prototyping and (3) experimental validation. \n\nThe theory the PI developed in the past used Inter-aural Level Difference (ILD), which uses two microphones bio-mimetically.  A NFOV target was estimated by collecting data of the environment can be collected in advance.  Two microphones are sufficient when the environment data can be collected in advance, but it is not the case of many scenarios.  Since this project is concerned with unknown environments, the theory of this project was thus built by using a microphone array, which provides more information on the environment.  Instead of data, physics of reflection and diffraction have been incorporated into the theory to enable NFLOV target localization in unknown environments. \n\nFollowing the theoretical development, a prototype system was developed.  The microphone array consists of 8 microphones, and a beam former was implemented to identify the direction of reflection and diffraction signals.  To first prove the concept, the system was designed and developed for two-dimensional (2D) localization. \n\nThe experimental validation was conducted in two steps.  In the first step, auditory tests of humans including blind people were conducted to verify that humans have the ability to localize the NFOV target.  The results of the step were also used for theoretical developments.  In the second step, the developed prototype system was tested in an anechoic chamber.  Having the NFOV target and the microphone array at the same height, the environment with one diffraction wall and one reflection wall enabled the proof-of-concept in the 2D space.  The experimental validation has resulted in proving the concept of the developed theory and prototype successfully. \n\n \n\n\t\t\t\t\tLast Modified: 01/03/2018\n\n\t\t\t\t\tSubmitted by: Tomonari Furukawa"
 }
}