{
 "awd_id": "1560698",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Collaborative Research: An Integrated Approach to Performance Modeling and Optimization of Big-data Scientific Workflows",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2015-08-28",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 125000.0,
 "awd_amount": 125000.0,
 "awd_min_amd_letter_date": "2015-09-14",
 "awd_max_amd_letter_date": "2015-09-14",
 "awd_abstract_narration": "Next-generation e-science is producing colossal amounts of data, commonly known as Big Data, on the order of terabyte at present and petabyte or even exabyte in the predictable future. These scientific applications typically feature data- and network-intensive workflows comprised of computing modules with intricate inter-module dependencies. Application users oftentimes need to manually configure their computing workflows in distributed environments in an ad-hoc manner, which significantly limits the productivity of scientists and constrains the utilization of resources.\r\n\r\nThe end-to-end performance of big data scientific workflows depends on both the mapping scheme that determines module assignment and the scheduling policy that determines resource allocation. These two aspects of a workflow-based research process are traditionally treated as two separate topics, and the interactions between them have not been fully explored. As the scale and complexity of scientific workflows and network environments rapidly increase, each individual aspect of performance optimization has limited success. This research is an in-depth investigation into workflow execution dynamics in resource sharing environments to explore the interactions between workflow mapping and node scheduling on a unified application-support platform. The idea is to build a three-layer workflow optimization architecture that seamlessly integrates three interrelated components based on rigorous algorithmic design, theoretical dynamics analysis, and real network implementation, deployment, and evaluation. The successful completion of this project will provide a solid mathematical foundation for the analysis and control of system dynamics of big data scientific workflows, produce a suite of cooperative mapping and scheduling optimization solutions to facilitate scientific collaborations, and add an additional level of intelligence to existing workflow engines widely adopted in the current grid and cloud computing middleware.  The resulting workflow optimization solutions will benefit a broad spectrum of workflow-based scientific applications",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chase",
   "pi_last_name": "Wu",
   "pi_mid_init": "Q",
   "pi_sufx_name": "",
   "pi_full_name": "Chase Q Wu",
   "pi_email_addr": "chase.wu@njit.edu",
   "nsf_id": "000484365",
   "pi_start_date": "2015-09-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New Jersey Institute of Technology",
  "inst_street_address": "323 DR MARTIN LUTHER KING JR BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "9735965275",
  "inst_zip_code": "071021824",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NJ10",
  "org_lgl_bus_name": "NEW JERSEY INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SGBMHQ7VXNH5"
 },
 "perf_inst": {
  "perf_inst_name": "New Jersey Institute of Technology",
  "perf_str_addr": "323 Martin Luther King Blvd.",
  "perf_city_name": "Newark",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "071021982",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NJ10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0115",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001516DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2015,
   "fund_oblg_amt": 125000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of this project is to analyze&nbsp;workflow execution dynamics and&nbsp;optimize the performance of big data scientific workflows in distributed computing environments. Specifically, in this project, we&nbsp;constructed a layered workflow optimization architecture, developed various performance modeling and prediction methods for module execution and data transfer, and designed a class of workflow mapping/scheduling algorithms that account for practical constraints and objectives.&nbsp;During the entire life of the award, this project has involved the participation of four Ph.D. students, three of whom are female students, and&nbsp;has resulted in 5 journal articles and over 30 conference papers.</p>\n<p>During the current project period, we focused our research on improving execution speed, energy efficiency, and cost effectiveness of big data workflows based on various computing frameworks such as MapReduce, Spark, or Storm.&nbsp;The workflow scheduling algorithms we proposed are able to minimize the makespan of big data workflows and significantly reduce dynamic energy consumption while meeting various performance requirements. These algorithms have been incorporated into the existing job scheduler or implemented as separate modules in big data processing systems and tested extensively in Hadoop systems deployed in public clouds. The research conducted during the current project period has resulted in one journal article and 10 conference papers.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/20/2018<br>\n\t\t\t\t\tModified by: Chase&nbsp;Q&nbsp;Wu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main goal of this project is to analyze workflow execution dynamics and optimize the performance of big data scientific workflows in distributed computing environments. Specifically, in this project, we constructed a layered workflow optimization architecture, developed various performance modeling and prediction methods for module execution and data transfer, and designed a class of workflow mapping/scheduling algorithms that account for practical constraints and objectives. During the entire life of the award, this project has involved the participation of four Ph.D. students, three of whom are female students, and has resulted in 5 journal articles and over 30 conference papers.\n\nDuring the current project period, we focused our research on improving execution speed, energy efficiency, and cost effectiveness of big data workflows based on various computing frameworks such as MapReduce, Spark, or Storm. The workflow scheduling algorithms we proposed are able to minimize the makespan of big data workflows and significantly reduce dynamic energy consumption while meeting various performance requirements. These algorithms have been incorporated into the existing job scheduler or implemented as separate modules in big data processing systems and tested extensively in Hadoop systems deployed in public clouds. The research conducted during the current project period has resulted in one journal article and 10 conference papers.\n\n\t\t\t\t\tLast Modified: 10/20/2018\n\n\t\t\t\t\tSubmitted by: Chase Q Wu"
 }
}