{
 "awd_id": "1649415",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "ETHICS OF DATA AGGREGATION: PRIVACY, TRUST, AND FAIRNESS",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032928643",
 "po_email": "skiesler@nsf.gov",
 "po_sign_block_name": "Sara Kiesler",
 "awd_eff_date": "2016-09-15",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 149029.0,
 "awd_amount": 149029.0,
 "awd_min_amd_letter_date": "2016-08-12",
 "awd_max_amd_letter_date": "2016-08-12",
 "awd_abstract_narration": "This project closely examines data aggregation to understand what types of aggregation are normatively and descriptively important to individuals and how do different types and degree of aggregation impact individual trust.  This proposed research would advance knowledge and understanding within the study of big data, trust, and business ethics.  Initial investigations into data aggregation have been technical to ensure accuracy and diminish unwanted bias. This research explores the conceptually important types of aggregation - information type, time, location, context, technology - which are normatively important for users. This project also extends the work around the ethical implications of big data by focusing on normative judgments of data aggregation. The studies will provide empirical evidence to support policy decisions around aggregating, storing, and deleting consumer data. The results will be disseminated broadly to enhance scientific and technological knowledge through conferences across disciplines in business, ethics, and privacy.    \r\n\r\nBig data relies upon aggregating data from heterogeneous sources to create new knowledge and identify novel trends: researchers look for patterns in social networking sites, marketers understand consumer demands by aggregating behavior over contexts online, a website can track consumer interests over devices.  Attention thus far has focused on technical capabilities of aggregating data over time and space through matching records, de(re)-identification, and the potential use of the data. This research will fill in a gap in the literature by collecting empirical data to understand individuals' behavioral responses towards different types and degrees of data aggregation practices by different data practitioners. This project aims to focus first on inductively exploring the important types of aggregation - across technology/devices, across time, across location, across contexts, across information types - through factorial vignette survey methodology.  This exploratory phase aims to identify the most important factors in judging data aggregation as reinforcing trust. The second phase will measure the impact of these important types of data aggregation on individual trust through experiments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kirsten",
   "pi_last_name": "Martin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kirsten Martin",
   "pi_email_addr": "martink@gwu.edu",
   "nsf_id": "000578467",
   "pi_start_date": "2016-08-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "George Washington University",
  "inst_street_address": "1918 F ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "WASHINGTON",
  "inst_state_code": "DC",
  "inst_state_name": "District of Columbia",
  "inst_phone_num": "2029940728",
  "inst_zip_code": "200520042",
  "inst_country_name": "United States",
  "cong_dist_code": "00",
  "st_cong_dist_code": "DC00",
  "org_lgl_bus_name": "GEORGE WASHINGTON UNIVERSITY (THE)",
  "org_prnt_uei_num": "",
  "org_uei_num": "ECR5E2LU5BL6"
 },
 "perf_inst": {
  "perf_inst_name": "George Washington University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200520037",
  "perf_ctry_code": "US",
  "perf_cong_dist": "00",
  "perf_st_cong_dist": "DC00",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 149029.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has examined the privacy expectations and ethics of data aggregation. &nbsp;The PI used empirical studies and normative arguments to identify the responsibility of business to better govern the aggregation of data.&nbsp;&nbsp;Throughout the work, the studies show that individuals have very nuanced privacy expectations of information normally deemed &lsquo;public.&rsquo;&nbsp;This work has implications for public policy and corporate responsibility about the regulation of accessing and using individual data observed in public.&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>The project specifically focused on the collection of location data in public spaces via different mechanisms, such as phones, fitbits, CCTV, apps, etc.&nbsp;&nbsp;The paper, &ldquo;What is it about location?&rdquo; in&nbsp;<strong><em>Berkeley Technology and Law Journal</em></strong>(Martin and Nissenbaum, 2019) reports on a set of empirical studies that reveal how people think about location data, how these conceptions relate to expectations of privacy, and, consequently, what this might mean for law, regulation, and technology design.&nbsp;&nbsp;The results show that drawing inferences about an individuals&rsquo; location and identifying the &lsquo;place&rsquo; where they are, significantly affect how appropriate people judge respective practices to be.&nbsp;&nbsp;This means that tracking an individuals&rsquo; place &ndash; home, work, shopping &ndash; is seen to violate privacy, even without directly collecting GPS data.<em>&nbsp;&nbsp;</em>In general, individuals have strong expectations of privacy &ndash; particular when data aggregators and data brokers are involved.&nbsp;&nbsp;<em>&nbsp;</em></p>\n<p>&nbsp;</p>\n<p>The supposed &lsquo;privacy paradox&rsquo; or perceived disconnect between individuals&rsquo; stated privacy expectations, as captured in surveys and consumer market behavior in going online: individuals purport to value privacy yet still disclose information to firms.&nbsp;&nbsp;However<em>,&nbsp;</em>contrary to the privacy paradox, I show consumers retain strong privacy expectations even after disclosing information in &ldquo;Breaking the Privacy Paradox: The Value of Privacy and Associated Duty of Firms,&rdquo;&nbsp;<strong><em>Business Ethics Quarterly</em></strong><em>&nbsp;</em>(Martin, 2020). Privacy violations are valued akin to security violations in creating distrust in firms and in consumer (un)willingness to engage with firms. This paper suggest firms may have a positive obligation to identify reasonable expectations of privacy of individuals. Importantly, research perpetuating the privacy paradox, through the mistaken framing of disclosure as proof of anti-privacy behavior, gives license to firms to act contrary to the interests of consumers.&nbsp;&nbsp;&nbsp;&nbsp;</p>\n<p>&nbsp;</p>\n<p>Finally, the project examined the impact of aggregating data on institutional trust online.&nbsp;&nbsp;When online, individuals must trust the hidden online data market in general rather than a specific firm. I explore how privacy governance should also be framed as protecting a larger market to ensure consumers trust being online in &ldquo;Privacy, Trust, and Governance: Or are privacy violations akin to insider trading?&rdquo;&nbsp;<strong><em>Washington University Law Review</em></strong><em></em>(Martin, 2019)<em>.&nbsp;</em>&nbsp;I found most uses of data decrease institutional trust online.&nbsp;&nbsp;Also, institutional trust online impacts a consumer&rsquo;s willingness to engage with a specific online partner in a trust game experiment.&nbsp;Interestingly, given the focus on privacy notices in the US, using privacy notices is the least effective governance mechanism whereas being subject to an audit was as effective as using anonymized data in improving consumer trust.&nbsp;&nbsp;The findings have implications for public policy and practice. Uses of information online need not only be justified in a simple quid-pro-quo exchange with the consumer but could also be justified as appropriate for the online context. Second, if privacy violations hurt not only consumer trust in a firm but also institutional trust online, then privacy would be governed similar to insider trading, fraud, or bribery&mdash;to protect the integrity of the market. Punishment for privacy violations would be set to ensure bad behavior is curtailed and institutional trust is maintained rather than to remediate a specific harm to an individual.<em></em></p>\n<p>&nbsp;</p>\n<p>In addition to the empirical studies, this project also produced two articles on the corporate responsibility around aggregated data and AI.&nbsp;&nbsp;In an article &ldquo;Ethical Implications And Accountability Of Algorithms&rdquo; published in the&nbsp;<strong><em>Journal of Business Ethics&nbsp;</em></strong>(Martin, 2018)<em>,</em>I conceptualize algorithms as value-laden, rather than neutral, and are an important actor in ethical decisions and influence the delegation of roles and responsibilities within these decisions. Firms developing algorithms are accountable for designing how large a role individuals will be permitted to take in the subsequent algorithmic decision. Counter to current arguments, I find that if an algorithm is designed to preclude individuals from taking responsibility within a decision, then the designer of the algorithm should be held accountable for the ethical implications of the algorithm in use.&nbsp;<strong></strong></p>\n<p><em>&nbsp;</em></p>\n<p>Second, in a paper targeting both practitioners and academics in &ldquo;Designing Ethical Algorithms&rdquo; in&nbsp;<strong><em>MIS Quarterly Executive</em></strong>(Martin, 2019), I focus on algorithms as active, opinionated participants in algorithmic decisions, which, like all decisions, make mistakes. In effect, all algorithmic decisions will produce mistakes; but ethical algorithms will offer a mechanism to identify, judge and correct mistakes.&nbsp;&nbsp;Importantly, by creating inscrutable, autonomous algorithms, firms may voluntarily take on accountability for the role of the algorithm in the decision including the ability to govern the inevitable mistakes</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/30/2019<br>\n\t\t\t\t\tModified by: Kirsten&nbsp;Martin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project has examined the privacy expectations and ethics of data aggregation.  The PI used empirical studies and normative arguments to identify the responsibility of business to better govern the aggregation of data.  Throughout the work, the studies show that individuals have very nuanced privacy expectations of information normally deemed ?public.? This work has implications for public policy and corporate responsibility about the regulation of accessing and using individual data observed in public.  \n\n \n\nThe project specifically focused on the collection of location data in public spaces via different mechanisms, such as phones, fitbits, CCTV, apps, etc.  The paper, \"What is it about location?\" in Berkeley Technology and Law Journal(Martin and Nissenbaum, 2019) reports on a set of empirical studies that reveal how people think about location data, how these conceptions relate to expectations of privacy, and, consequently, what this might mean for law, regulation, and technology design.  The results show that drawing inferences about an individuals? location and identifying the ?place? where they are, significantly affect how appropriate people judge respective practices to be.  This means that tracking an individuals? place &ndash; home, work, shopping &ndash; is seen to violate privacy, even without directly collecting GPS data.  In general, individuals have strong expectations of privacy &ndash; particular when data aggregators and data brokers are involved.   \n\n \n\nThe supposed ?privacy paradox? or perceived disconnect between individuals? stated privacy expectations, as captured in surveys and consumer market behavior in going online: individuals purport to value privacy yet still disclose information to firms.  However, contrary to the privacy paradox, I show consumers retain strong privacy expectations even after disclosing information in \"Breaking the Privacy Paradox: The Value of Privacy and Associated Duty of Firms,\" Business Ethics Quarterly (Martin, 2020). Privacy violations are valued akin to security violations in creating distrust in firms and in consumer (un)willingness to engage with firms. This paper suggest firms may have a positive obligation to identify reasonable expectations of privacy of individuals. Importantly, research perpetuating the privacy paradox, through the mistaken framing of disclosure as proof of anti-privacy behavior, gives license to firms to act contrary to the interests of consumers.    \n\n \n\nFinally, the project examined the impact of aggregating data on institutional trust online.  When online, individuals must trust the hidden online data market in general rather than a specific firm. I explore how privacy governance should also be framed as protecting a larger market to ensure consumers trust being online in \"Privacy, Trust, and Governance: Or are privacy violations akin to insider trading?\" Washington University Law Review(Martin, 2019).  I found most uses of data decrease institutional trust online.  Also, institutional trust online impacts a consumer?s willingness to engage with a specific online partner in a trust game experiment. Interestingly, given the focus on privacy notices in the US, using privacy notices is the least effective governance mechanism whereas being subject to an audit was as effective as using anonymized data in improving consumer trust.  The findings have implications for public policy and practice. Uses of information online need not only be justified in a simple quid-pro-quo exchange with the consumer but could also be justified as appropriate for the online context. Second, if privacy violations hurt not only consumer trust in a firm but also institutional trust online, then privacy would be governed similar to insider trading, fraud, or bribery&mdash;to protect the integrity of the market. Punishment for privacy violations would be set to ensure bad behavior is curtailed and institutional trust is maintained rather than to remediate a specific harm to an individual.\n\n \n\nIn addition to the empirical studies, this project also produced two articles on the corporate responsibility around aggregated data and AI.  In an article \"Ethical Implications And Accountability Of Algorithms\" published in the Journal of Business Ethics (Martin, 2018),I conceptualize algorithms as value-laden, rather than neutral, and are an important actor in ethical decisions and influence the delegation of roles and responsibilities within these decisions. Firms developing algorithms are accountable for designing how large a role individuals will be permitted to take in the subsequent algorithmic decision. Counter to current arguments, I find that if an algorithm is designed to preclude individuals from taking responsibility within a decision, then the designer of the algorithm should be held accountable for the ethical implications of the algorithm in use. \n\n \n\nSecond, in a paper targeting both practitioners and academics in \"Designing Ethical Algorithms\" in MIS Quarterly Executive(Martin, 2019), I focus on algorithms as active, opinionated participants in algorithmic decisions, which, like all decisions, make mistakes. In effect, all algorithmic decisions will produce mistakes; but ethical algorithms will offer a mechanism to identify, judge and correct mistakes.  Importantly, by creating inscrutable, autonomous algorithms, firms may voluntarily take on accountability for the role of the algorithm in the decision including the ability to govern the inevitable mistakes\n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/30/2019\n\n\t\t\t\t\tSubmitted by: Kirsten Martin"
 }
}