{
 "awd_id": "1550601",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: SI2-SSI: Adding Volunteer Computing to the Research Cyberinfrastructure",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rajiv Ramnath",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2017-07-31",
 "tot_intn_awd_amt": 259999.0,
 "awd_amount": 259999.0,
 "awd_min_amd_letter_date": "2016-08-02",
 "awd_max_amd_letter_date": "2016-08-02",
 "awd_abstract_narration": "The aggregate computing power of consumer devices - desktop and laptop computers, tablets, smartphones - far exceeds that of institutional computing resources.  \"Volunteer computing\" uses these consumer devices, volunteered by their owners, to do scientific computing. In addition to providing additional, much-needed computational resources to scientists, volunteer computing publicizes scientific research and engages citizens in science. BOINC is the primary software system for volunteer computing.  It was developed at UC Berkeley with NSF support starting in 2002. Until now, BOINC has been based on a model of independent competing projects.  Scientists set up their own BOINC servers, port their applications to run on BOINC, and publicize their projects to attract volunteers.  There are about 40 such projects, in many areas of science: examples include Einstein@home, CERN, and SETI@home (astrophysics), Rosetta@home and GPUGrid.net (biomedicine), Climateprediction.net (climate study), and IBM World Community Grid (multiple applications).  Together these projects have about 400,000 active volunteers and 12 PetaFLOPS of computing throughput. This model, while successful to an extent, has reached a limit.  The number of projects and volunteers has stagnated.  Volunteer computing is supplying lots of computing power, but only to a few research projects.  For other scientists, there are two major barriers.  First, creating a BOINC project has significant overhead: learning a new technology, creating a public web site, generating publicity, and so on.  Second, volunteer computing is risky and uncertain; there is no guarantee that a new project will attract volunteers. This project aims to break this barrier, and to make volunteer computing available to all scientists doing high-throughput computing, by replacing the competing-projects model with a new \"central broker\" model. The new model has two related parts: 1) the integration of BOINC with existing high-throughput computing facilities such as supercomputing centers and science portals. Jobs currently run on cluster nodes will be transparently offloaded to volunteer computers. Scientists using these facilities will see faster turnaround times; they'll benefit from volunteer computing without even knowing it's there. 2) The project will change the volunteer interface so that participants sign up for scientific areas and goals rather then for particular projects. For example, a participant might sign up to contribute to cancer research. A central broker, to be developed as part of this project, would dynamically assign their computing resources to projects doing that type of research. This project mobilizes public support for and interest in scientific research by encouraging \"volunteer computing\" and engaging citizens in the conduct of the research itself. It simultaneously advances NSF's mission to advance science while broadening citizen engagement.\r\n\r\nThe first year of this project will prototype each of these parts, and will integrate BOINC with TACC and nanoHub. Integrating BOINC with existing HTC systems involves several subtasks: 1) Job routing: modifying existing job processing systems used by TACC and nanoHub (Launcher and Rappture respectively) to decide when a group of jobs should be offloaded to BOINC. This decision might involve the estimated runtime of the jobs, input and output file sizes, data sensitivity, the deadline or priority of the jobs, and the identity of the job submitter. 2) Job format conversion: mapping job descriptions (input/output file specifications, resource and timing requirements) to their BOINC equivalents. 3) Application packaging: adapting existing applications (such as nanoHub's simulation tools and TACC's Autodock) to run under BOINC. We will use BOINC's virtual machine facility, which packages an application as a virtual machine image (VirtualBox or Docker) and a program to be run within the VM.  This allows existing Linux applications to run on consumer desktop platforms such as Windows and Mac, as well as providing a strong security sandbox and an efficient application-independent checkpoint/restart mechanism. 4) File handling: moving input and output files between existing storage systems (typically inaccessible from outside firewalls) to Internet-visible servers.  This will use existing BOINC components that manage files based on hashes to eliminate duplicate transfer and storage of files. 5) Job monitoring and control: adapting existing web- or command-line based tools for monitoring the progress of batches of jobs, and for aborting jobs, to work with BOINC. This will use existing Web RPCs provided by BOINC for these purposes. This project will carry out these tasks by designing and implementing new software as needed, testing for correctness, performance, and scalability, and deploying it in a production environment. The second part of the project - a brokering system for allocating computing power based on volunteer scientific preferences - will be designed and prototyped.  This involves several subtasks: 1) Designing a schema for volunteer preferences, including scientific areas and sub-areas, project nationality and institutions, specific projects and applications, inclusions/exclusions, and so on. 2) Designing a schema for assigning attributes to job streams (e.g. their area, sub-area, institution, etc.), and for assigning quotas or priorities to job streams. 3) Designing a relational database for storing the above information. 4) Designing and implementing policies for assigning volunteer resources to job streams in a way that respects volunteer preferences and optimizes quota, fairness, and throughput criteria.  This will be implemented as a BOINC \"account manager\" so that volunteers see a single interface rather than lots of separate projects and web sites.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Anderson",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "David P Anderson",
   "pi_email_addr": "davea@ssl.berkeley.edu",
   "nsf_id": "000467556",
   "pi_start_date": "2016-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "9 Gauss Way",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947207450",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "800400",
   "pgm_ele_name": "Software Institutes"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8004",
   "pgm_ref_txt": "Software Institutes"
  },
  {
   "pgm_ref_code": "8009",
   "pgm_ref_txt": "Scientifc Software Integration"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 259999.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>During the award period we completed the first phase of a project that seeks to 1) make the immense computing power of the consumer digital infrastructure available to thousands of U.S. scientists and research groups, and 2) expand the volunteer computing population (which is currently mostly male, technical, and over 50) by offering a simpler interface and a more coherent marketing message.</p>\n<p>This project has two connected parts.&nbsp; The first involves adding BOINC-based volunteer-computing back ends to two existing HPC providers: TACC and nanoHUB.&nbsp; In each case we developed &ldquo;adapter&rdquo; software for moving jobs between the native job queueing system (Launcher at TACC, Rappture at nanoHUB) and BOINC:</p>\n<ul>\n<li>We used a system, developed by the BOINC community, for packaging applications using VirtualBox and Docker.&nbsp; This allows Linux-based applications to run on Windows and Mac OS X computers with no changes or recompilation.&nbsp; The hundreds of applications currently being run using Launcher and Rappture can now be run on volunteer computers with no per-application porting or other work.</li>\n<li>We extended BOINC&rsquo;s remote job submission and remote file management to handle the needs to TACC and nanoHUB; for example, extending batch operations to allow per-job specification of application, input/output file signature, expected runtime, etc.</li>\n</ul>\n<p>We helped the collaborators learn about BOINC, set up BOINC servers, and debug the job-processing systems described above.&nbsp; Each of the collaborators now has a fully-functioning test project.&nbsp; Both are in the process of moving to production, and are on track to do this by end of year.</p>\n<p>This work achieves our Broader Impact goals of creating a blueprint by which any HTC provider can add a volunteer computing back end with a fairly small investment. &nbsp;TACC is a leading supercomputing center, and nanoHUB is a leading science gateway; by creating these examples we encourage and enable other HPC providers to follow suit.</p>\n<p>A second part of the project involved creating a new framework for volunteer computing, based on a central &ldquo;coordinator&rdquo; called Science United (SU).&nbsp; In the original BOINC model, volunteers had to survey all the (40 or so) projects and decide which ones to compute for.&nbsp; In the new model volunteers register with SU and specify what kinds of research they want to support.&nbsp; SU then dynamically attaches their computers to appropriate projects (or, in the case of heterogeneous projects like TACC, applications within projects).&nbsp; Resource allocation among projects will be determined by an external XSEDE-type mechanism.</p>\n<p>We designed and implemented SU, which consists of a web site and a meta-scheduler that assigns computers to projects.&nbsp; These use a system of hierarchical keywords for specifying science areas and research project locations.&nbsp; We made significant modifications to the BOINC client and server software to support SU, in terms of keywords and resource accounting information.</p>\n<p>SU also incorporates a number of UI/UX changes designed to attract a broader volunteer population:</p>\n<ul>\n<li>We designed and implemented a new system for volunteer registration and software installation that reduces the number of mouse clicks from 12 to 3, and that keeps all UI on the web (rather than the BOINC client).</li>\n<li>SU eliminates &ldquo;leader boards&rdquo; that rank volunteers and teams based on how much computing they&rsquo;re done.&nbsp; We found that many people are repelled by this competitive aspect.</li>\n<li>We simplified the feature set in several places.&nbsp; For example, BOINC offered an elaborate set of features for specifying &ldquo;computing preferences&rdquo;: when to compute, how many cores to use, etc.&nbsp; SU replaces this with three choices: &ldquo;green&rdquo;, &ldquo;standard&rdquo;, and &ldquo;maximum computing&rdquo;.</li>\n<li>The BOINC web interfaces provide a glut of information, mostly in textual form.&nbsp; We found that many people feel overwhelmed by this.&nbsp; The SU interface reduces the amount of information, and presents it graphically when possible.</li>\n</ul>\n<p>SU is currently being tested internally, and we hope to open it to public testing by the end of year, and launch it early 2018.</p>\n<p>SU will have several major broader impacts:</p>\n<ul>\n<li>It will eliminate uncertainty for new BOINC projects: a research group or HPC provider can get an SU allocation before investing in BOINC, and be assured of a certain level of computing power.&nbsp; It will also eliminate the need for these new projects to do publicity and outreach activities to attract volunteers.&nbsp; These are currently enormous barriers to entry and have greatly limited the number of BOINC projects.&nbsp; In this way we hope that SU will increase the number of scientists who benefit from volunteer computing from dozens to thousands.</li>\n<li>It will provide a single brand (SU) for marketing volunteer computing through traditional, web, and social media, and will provide a UI/UX that is appealing and accessible to a much larger range of potential volunteers.&nbsp; In this way we hope that the volunteer population will grow from 100Ks to millions.</li>\n</ul>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2017<br>\n\t\t\t\t\tModified by: David&nbsp;P&nbsp;Anderson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDuring the award period we completed the first phase of a project that seeks to 1) make the immense computing power of the consumer digital infrastructure available to thousands of U.S. scientists and research groups, and 2) expand the volunteer computing population (which is currently mostly male, technical, and over 50) by offering a simpler interface and a more coherent marketing message.\n\nThis project has two connected parts.  The first involves adding BOINC-based volunteer-computing back ends to two existing HPC providers: TACC and nanoHUB.  In each case we developed \"adapter\" software for moving jobs between the native job queueing system (Launcher at TACC, Rappture at nanoHUB) and BOINC:\n\nWe used a system, developed by the BOINC community, for packaging applications using VirtualBox and Docker.  This allows Linux-based applications to run on Windows and Mac OS X computers with no changes or recompilation.  The hundreds of applications currently being run using Launcher and Rappture can now be run on volunteer computers with no per-application porting or other work.\nWe extended BOINC?s remote job submission and remote file management to handle the needs to TACC and nanoHUB; for example, extending batch operations to allow per-job specification of application, input/output file signature, expected runtime, etc.\n\n\nWe helped the collaborators learn about BOINC, set up BOINC servers, and debug the job-processing systems described above.  Each of the collaborators now has a fully-functioning test project.  Both are in the process of moving to production, and are on track to do this by end of year.\n\nThis work achieves our Broader Impact goals of creating a blueprint by which any HTC provider can add a volunteer computing back end with a fairly small investment.  TACC is a leading supercomputing center, and nanoHUB is a leading science gateway; by creating these examples we encourage and enable other HPC providers to follow suit.\n\nA second part of the project involved creating a new framework for volunteer computing, based on a central \"coordinator\" called Science United (SU).  In the original BOINC model, volunteers had to survey all the (40 or so) projects and decide which ones to compute for.  In the new model volunteers register with SU and specify what kinds of research they want to support.  SU then dynamically attaches their computers to appropriate projects (or, in the case of heterogeneous projects like TACC, applications within projects).  Resource allocation among projects will be determined by an external XSEDE-type mechanism.\n\nWe designed and implemented SU, which consists of a web site and a meta-scheduler that assigns computers to projects.  These use a system of hierarchical keywords for specifying science areas and research project locations.  We made significant modifications to the BOINC client and server software to support SU, in terms of keywords and resource accounting information.\n\nSU also incorporates a number of UI/UX changes designed to attract a broader volunteer population:\n\nWe designed and implemented a new system for volunteer registration and software installation that reduces the number of mouse clicks from 12 to 3, and that keeps all UI on the web (rather than the BOINC client).\nSU eliminates \"leader boards\" that rank volunteers and teams based on how much computing they?re done.  We found that many people are repelled by this competitive aspect.\nWe simplified the feature set in several places.  For example, BOINC offered an elaborate set of features for specifying \"computing preferences\": when to compute, how many cores to use, etc.  SU replaces this with three choices: \"green\", \"standard\", and \"maximum computing\".\nThe BOINC web interfaces provide a glut of information, mostly in textual form.  We found that many people feel overwhelmed by this.  The SU interface reduces the amount of information, and presents it graphically when possible.\n\n\nSU is currently being tested internally, and we hope to open it to public testing by the end of year, and launch it early 2018.\n\nSU will have several major broader impacts:\n\nIt will eliminate uncertainty for new BOINC projects: a research group or HPC provider can get an SU allocation before investing in BOINC, and be assured of a certain level of computing power.  It will also eliminate the need for these new projects to do publicity and outreach activities to attract volunteers.  These are currently enormous barriers to entry and have greatly limited the number of BOINC projects.  In this way we hope that SU will increase the number of scientists who benefit from volunteer computing from dozens to thousands.\nIt will provide a single brand (SU) for marketing volunteer computing through traditional, web, and social media, and will provide a UI/UX that is appealing and accessible to a much larger range of potential volunteers.  In this way we hope that the volunteer population will grow from 100Ks to millions.\n\n\n \n\n\t\t\t\t\tLast Modified: 11/29/2017\n\n\t\t\t\t\tSubmitted by: David P Anderson"
 }
}