{
 "awd_id": "1607251",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "US-French Collaboration: Collaborative Research: Neuro-Computational Models of Natural Language",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Jonathan Fritz",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 292168.0,
 "awd_amount": 292168.0,
 "awd_min_amd_letter_date": "2016-08-18",
 "awd_max_amd_letter_date": "2021-07-20",
 "awd_abstract_narration": "Our society is built upon shared ideas, ideas that get from one person to another via language that is \"understood.\" But how do brains give us the ability to understand a stream of spoken words? This is a grand challenge question in computational neuroscience. This project addresses it using mathematical models of the language understanding process. These models reflect insights from computer science as well as linguistics. They allow investigators to ask: which process model best accounts for the signals from a particular brain region, at particular moment in time? The signals come from people listening to French and English versions of the same book.  By comparing across models and across languages, the project seeks to differentiate between aspects of the understanding process that are language-specific and aspects that might be common to all humans. Increasingly precise modeling of this sort paves the way for future work with individuals who have trouble using language, such as those with Autism Spectrum Disorder. It could also lead to better computer systems, ones that use language in a brain-inspired way. \r\n\r\nBringing together computational linguists and cognitive neuroscientists, this project pursues two specific questions: (1) what aspects of sentence structure determine our expectations for upcoming words? and (2) what is the detailed balance between memorization and composition in natural language? Using electroencephalography (EEG) and functional Magnetic Resonance Imaging (fMRI) the PIs examine participants' neural responses to the spoken recitation of a literary work. These neural signals are fitted by time series predictors, themselves derived from linguistically plausible grammars and other language models. The project explores a family of such models, varying the size of grammatical units as well as the propensity for such units to be simply memorized as opposed to built up, step by step. Via information-theoretical complexity metrics, these theories derive quantitative predictions about the moment-by-moment neural responses of a person hearing a story.  The approach as a whole leads to computationally explicit process models that are grounded in human brain responses to naturalistic text across two languages. \r\n\r\nA companion project is being funded by the French National Research Agency (ANR).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jonathan",
   "pi_last_name": "Brennan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jonathan Brennan",
   "pi_email_addr": "jobrenn@umich.edu",
   "nsf_id": "000631934",
   "pi_start_date": "2016-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "Lorch Hall, RM 414",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 188726.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 103442.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project delivered computational cognitive models of language processing, analyses of neural data that adjudicate between alternative theories of language understanding, and a novel multi-language open science data corpus of annotated linguistic and neural signals to facilitate future research. The work was conducted by combining nneural signals while participants perform a more-or-less every-day task like listening to an audiobook story; data analysis was facilitated by using computational models to quantify the word-by-word dynamics of language processing (Figure 1 from Li et al. 2022)</p>\n<p>Advances in modeling include the development of a parser for recurrent neural network grammars (RNNG) that handles the ambiguities that are common in natural language syntax. The internal states of this model align with both electrophysiological and hemodynamic neural signals above-and-beyond recurrent neural network language models that lack an explicit account of syntax. Such alignment is most evident in both anterior and posterior foci of the left superior temporal gyrus. A report from this arm of the project received the \"Best Long Paper\" award from the 2018 meeting of the Association for Computatioanl Linguistics. Examples of these results appear in Figure 2 (from Hale et al. 2018) and Figure 3 (from Brennan et al. 2020)</p>\n<div>\n<div><span>Parallel efforts tested the balance of neural resources in composing complex linguistic expressions with the possibility of storing \"pre-built\" expressions for efficiency. Modeling so-called \"multi-word expressions\" offered a novel benchmark to track the reduction in fonto-temporal \"language network\" processing load when even complex expressions are stored in memory, as shown in Figure 4.</span></div>\n<br />\n<div><span>The award supported the collection, curation, and release of several datasets to the research community. (1) \"The Alice Datasets\" contain hemodynamic and electrophysiological signals collected from 75 individuals who listend to an audiobook chapter along with linguistic annotations for the audiobook. (2) \"The Little Prince Datasets\" contain hemodynamic signals collected from 112 individuals who listened to an audiobook story in one of three language (English, Mandarin, French.). The latter dataset is the first multi-lingual neurophysiological dataset released to the public to our knowledge. These datasets are summarized in papers appearing in \"Scientific Data\" and the 12th international Language Resources and Evaluation conference. An illustration of this multi-lingual dataset is given in Figure 5.</span></div>\n<br />\n<div><span>Evidence for impact of the open data includes its incorporation into an evaluation of language-brain encoding methods (Beinborn et al. 2019 arXiv:1904.02547) and its application for developing state-of-theart speech-decoding methods from non-invasive recordings (D?fossez et al. 2022 arXiv:2208.12266)</span></div>\n<br />\n<div><span>Project activities led to seven journal publications (as well as two currently under review) and six peer-reviewed conference papers during the funding period. </span></div>\n<br />\n<div><span>Impacts of the project also include training at the University of Michigan of both graduate and undergraduate students, including those from backgrounds that are under-represented in cognitive neuroscience and computer science.</span></div>\n</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/15/2022<br>\n\t\t\t\t\tModified by: Jonathan&nbsp;Brennan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671136880520_fig1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671136880520_fig1--rgov-800width.jpg\" title=\"Figure 1: Overview of the approach\"><img src=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671136880520_fig1--rgov-66x44.jpg\" alt=\"Figure 1: Overview of the approach\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Schematic illustrating how word-by-word linguistic annotations are statistically fit against neural signals</div>\n<div class=\"imageCredit\">Li et al. 2022 Sci Data</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jonathan&nbsp;Brennan</div>\n<div class=\"imageTitle\">Figure 1: Overview of the approach</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671136997175_fig2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671136997175_fig2--rgov-800width.jpg\" title=\"Figure 2: EEG correlates of parsing\"><img src=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671136997175_fig2--rgov-66x44.jpg\" alt=\"Figure 2: EEG correlates of parsing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Regression results between EEG signals and model-derived metrics for syntactic structure (left) and next-word predictability (right).</div>\n<div class=\"imageCredit\">Hale et al. 2018 Proc ACL</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Jonathan&nbsp;Brennan</div>\n<div class=\"imageTitle\">Figure 2: EEG correlates of parsing</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137215488_fig3--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137215488_fig3--rgov-800width.jpg\" title=\"Figure 3: fMRI correlates of parsing\"><img src=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137215488_fig3--rgov-66x44.jpg\" alt=\"Figure 3: fMRI correlates of parsing\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Correlations between a family of model-derived features and fMRI signals from selected regions of interest; terms shown at the bottom reflect aspects of abstract syntactic structure that independently drive neural signals above-and-beyond \"control\" terms shown towards the top.</div>\n<div class=\"imageCredit\">Brennan et al. 2020 Neuropsychologia</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Jonathan&nbsp;Brennan</div>\n<div class=\"imageTitle\">Figure 3: fMRI correlates of parsing</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137320979_fig4--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137320979_fig4--rgov-800width.jpg\" title=\"Figure 4: Multi-word expressions\"><img src=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137320979_fig4--rgov-66x44.jpg\" alt=\"Figure 4: Multi-word expressions\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">fMRI signals that correlate with the cohesion of words into stored \"multi-word expressions\"</div>\n<div class=\"imageCredit\">Bhattasali et al. 2018 Lang Cogn Neuroscience</div>\n<div class=\"imagePermisssions\">Royalty-free (restricted use - cannot be shared)</div>\n<div class=\"imageSubmitted\">Jonathan&nbsp;Brennan</div>\n<div class=\"imageTitle\">Figure 4: Multi-word expressions</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137423531_fig5--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137423531_fig5--rgov-800width.jpg\" title=\"Figure 5: Multilingual fMRI datasets\"><img src=\"/por/images/Reports/POR/2022/1607251/1607251_10452060_1671137423531_fig5--rgov-66x44.jpg\" alt=\"Figure 5: Multilingual fMRI datasets\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Example results from over 100 multilingual datasets (English, French, Mandarin) showing shared and distinct patterns of neural activity for accessing words in sentences.</div>\n<div class=\"imageCredit\">Li et al. 2022 Sci Data</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Jonathan&nbsp;Brennan</div>\n<div class=\"imageTitle\">Figure 5: Multilingual fMRI datasets</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project delivered computational cognitive models of language processing, analyses of neural data that adjudicate between alternative theories of language understanding, and a novel multi-language open science data corpus of annotated linguistic and neural signals to facilitate future research. The work was conducted by combining nneural signals while participants perform a more-or-less every-day task like listening to an audiobook story; data analysis was facilitated by using computational models to quantify the word-by-word dynamics of language processing (Figure 1 from Li et al. 2022)\n\nAdvances in modeling include the development of a parser for recurrent neural network grammars (RNNG) that handles the ambiguities that are common in natural language syntax. The internal states of this model align with both electrophysiological and hemodynamic neural signals above-and-beyond recurrent neural network language models that lack an explicit account of syntax. Such alignment is most evident in both anterior and posterior foci of the left superior temporal gyrus. A report from this arm of the project received the \"Best Long Paper\" award from the 2018 meeting of the Association for Computatioanl Linguistics. Examples of these results appear in Figure 2 (from Hale et al. 2018) and Figure 3 (from Brennan et al. 2020)\n\nParallel efforts tested the balance of neural resources in composing complex linguistic expressions with the possibility of storing \"pre-built\" expressions for efficiency. Modeling so-called \"multi-word expressions\" offered a novel benchmark to track the reduction in fonto-temporal \"language network\" processing load when even complex expressions are stored in memory, as shown in Figure 4.\n\n\nThe award supported the collection, curation, and release of several datasets to the research community. (1) \"The Alice Datasets\" contain hemodynamic and electrophysiological signals collected from 75 individuals who listend to an audiobook chapter along with linguistic annotations for the audiobook. (2) \"The Little Prince Datasets\" contain hemodynamic signals collected from 112 individuals who listened to an audiobook story in one of three language (English, Mandarin, French.). The latter dataset is the first multi-lingual neurophysiological dataset released to the public to our knowledge. These datasets are summarized in papers appearing in \"Scientific Data\" and the 12th international Language Resources and Evaluation conference. An illustration of this multi-lingual dataset is given in Figure 5.\n\n\nEvidence for impact of the open data includes its incorporation into an evaluation of language-brain encoding methods (Beinborn et al. 2019 arXiv:1904.02547) and its application for developing state-of-theart speech-decoding methods from non-invasive recordings (D?fossez et al. 2022 arXiv:2208.12266)\n\n\nProject activities led to seven journal publications (as well as two currently under review) and six peer-reviewed conference papers during the funding period. \n\n\nImpacts of the project also include training at the University of Michigan of both graduate and undergraduate students, including those from backgrounds that are under-represented in cognitive neuroscience and computer science.\n\n\n\t\t\t\t\tLast Modified: 12/15/2022\n\n\t\t\t\t\tSubmitted by: Jonathan Brennan"
 }
}