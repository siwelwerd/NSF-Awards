{
 "awd_id": "1640909",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SL-CN: Learning to Move and Moving to Learn",
 "cfda_num": "47.075",
 "org_code": "04010000",
 "po_phone": "7032927878",
 "po_email": "slim@nsf.gov",
 "po_sign_block_name": "Soo-Siang Lim",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 750000.0,
 "awd_amount": 750000.0,
 "awd_min_amd_letter_date": "2016-08-15",
 "awd_max_amd_letter_date": "2016-09-02",
 "awd_abstract_narration": "This Science of Learning Collaborative Network brings together an interdisciplinary team of researchers from University of California-San Diego and Indiana University, to study how children's movements impact their learning and how learning impacts movement skill. Identifying individuals with learning difficulties and matching these individuals with appropriate opportunities for improvement is one of the greatest challenges faced in education today. Novel measurement tools and analyses from the study of movement can be productively brought to bear on these problems to realize the potential of personalized education. To achieve this goal, the Learning through Movement Network (LMN) of investigators will bring together expertise from neuroscience, engineering, computation and physics, to study movement signatures in children who experience learning difficulties in school. New tools for the study of movement outside of the lab, and that can be readily deployed in educational settings, will also be created and tested. It is expected that the new knowledge created from this research will be useful in classifying children's movement signatures as those signatures map onto each child's own educational and cognitive profile. \r\n\r\nMovement offers an important window into brain function as a remarkable amount of the brain is engaged in movement decisions, planning, execution and evaluation. This network brings together new technology and novel analytic methods to determine what can be learned from fine-grained measurement of movement of the body, the face, and the eyes. LMN investigators working in cross-functional teams will share methods and data to capture the subtleties of movement and create a signature for a learner at any point in time. The three core projects in the network bring together theories and analytical methods from different fields to identify movement-based commonalities across seemingly different learning problems and potentially also identify movement-based differences across seemingly similar learning problems. The LMN network will leverage the fact that the motor system is quite trainable, and aims to use this plasticity as a tool to improve cognitive functioning for better learning opportunities in the future. In addition, LMN investigator links to local public schools and sites for informal science learning will allow the group to engage in blended research and outreach events highlighting the importance of physical activity in the development of motor skill for cognitive fitness.\r\n\r\nThe award is from the Science of Learning-Collaborative Networks (SL-CN) Program, with funding from the SBE Division of Behavioral and Cognitive Sciences (BCS) and the SBE Office of Multidisciplinary Activities (SMA).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SMA",
 "org_div_long_name": "SBE Office of Multidisciplinary Activities",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Leanne",
   "pi_last_name": "Chukoskie",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Leanne Chukoskie",
   "pi_email_addr": "l.chukoskie@northeastern.edu",
   "nsf_id": "000630070",
   "pi_start_date": "2016-08-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jorge",
   "pi_last_name": "Jose",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Jorge V Jose",
   "pi_email_addr": "jjosev@iu.edu",
   "nsf_id": "000110904",
   "pi_start_date": "2016-09-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Joseph",
   "pi_last_name": "Snider",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Joseph Snider",
   "pi_email_addr": "j1snider@ucsd.edu",
   "nsf_id": "000692063",
   "pi_start_date": "2016-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "9500 Gilman Dr. mail code 0523",
  "perf_city_name": "La Jolla",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930523",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "004y00",
   "pgm_ele_name": "Science of Learning"
  },
  {
   "pgm_ele_code": "004Y00",
   "pgm_ele_name": "Science of Learning"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 750000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Transforming input from our senses into purposeful movement is perhaps the primary role of the central nervous system. For example, the simple act of reaching out to lift a glass of water involves interactions throughout the entire brain: action planning in frontal regions, visual processing in the back, execution of a motor plan in deep structures that route up through the central part of the brain and down the spinal column. All while verifying that the actual movement is what the brain thought it would be. Given the importance of movement to cognition, the overarching goal of the Learning to Move and Moving to Learn (LMN) project was to build tools to observe movement with the same precision, accuracy, and robustness cognitive neuroscience has built up to observe neural activity in the brain. These tools may then support a wide range of basic cognitive science to help us understand the bidirectional link between thought and movement, and how it can go wrong in disease.</p>\n<p>The technological focus of the project was on small space motion capture in which movements of the whole body could be recorded at high precision. With the development of inexpensive, precise inertial measurement units and a demand from the consumer virtual reality market, movement recordings with millisecond and millimeter accuracy are well within reach of labs. Motion capture technologies that cost in the hundreds of thousands just a decade ago are now in living rooms across the world in gaming equipment and embedded in our phones. While consumer movement measurement technologies are accessible, they are not always validated and accurate enough to give researchers an accurate picture of behavior. The validation techniques developed in LMN have bridged that gap. For example, head-mounted eye trackers are accessible enough that multiple eye trackers were used to observe behavior in multiple participants at the same time to understand how participants follow each other?s attentional shifts during a conversation: joint attention. These measurements allowed us to assess multiple participants? gaze behavior in real time in a natural social setting.&nbsp; Next steps include advancing these and related technologies to capture behavioral data readily in schools, medical settings, and when desired also at home.</p>\n<p>Movement is a pervasive aspect of our daily lives.&nbsp; We make up to 4 eye movements every second, from our engaging book to the distracting squirrel outside and back again.&nbsp; Some people rhythmic movements such as rocking behavior to be soothing as these stimulate multiple senses including our vestibular sense. &nbsp;The practice of driving is a complex set of movement behaviors that are challenging to simulate given the complex interplay between movement and resulting sensations. In all cases, movement and learning are intimately linked. Our bodies are in constant motion to gather information to learn about our environment and or brains are constantly learning about how our movements alter our environment. At the millisecond scale, movements were seen to be statistically related to autism diagnosis and this link may lead to a better understanding of the relationship between movement and autism. At the scale of several seconds, markerless, non-contact motion capture with series of cameras allows the observation of self-soothing, e.g. body rocking, motion in individuals whose sensitivity to touch would otherwise have precluded accurate measurement. At even longer scales, when we drive a car, we move in a way that not even the most advanced computers and artificial intelligences can match, and when drivers are distracted by a text, even just to ask if they ?like pickles,? they swerve for as long as 20-25 seconds.</p>\n<p>Beyond the basic and applied science of the LMN project, the PIs also leveraged project resources to start the Power of NeuroGaming (PoNG) Center at UC San Diego. &nbsp;Our intention to using our hard won knowledge of how to incorporate readily available, consumer-oriented hardware into lab quality experimental paradigms has great utility in a university community, offering a services on a recharge basis. The PoNG center is also a space for neurodiverse individuals to gain work experience, including how to manage their behavior in a workplace. This effort has lead to an NSF Future of Work grant that supports a neurodiverse internship program and technical tools that are designed to provide feedback to neurodivergent workers to improve their own readiness for workforce immersion, while we simultaneous work to prepare the workforce for the talents of neurodivergent workers. &nbsp;The PoNG center was supported by the Qualcomm Institute and the Legler Benbough Foundation, but would not have emerged had the seeds of future collaborations not been planted through this Science of Learning NSF grant. &nbsp;We look forward to continuing these lines of research to create new tools useful for measuring human movement and new knowledge about the ways that human movement and learning are interrelated.&nbsp;&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/27/2021<br>\n\t\t\t\t\tModified by: Leanne&nbsp;Chukoskie</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTransforming input from our senses into purposeful movement is perhaps the primary role of the central nervous system. For example, the simple act of reaching out to lift a glass of water involves interactions throughout the entire brain: action planning in frontal regions, visual processing in the back, execution of a motor plan in deep structures that route up through the central part of the brain and down the spinal column. All while verifying that the actual movement is what the brain thought it would be. Given the importance of movement to cognition, the overarching goal of the Learning to Move and Moving to Learn (LMN) project was to build tools to observe movement with the same precision, accuracy, and robustness cognitive neuroscience has built up to observe neural activity in the brain. These tools may then support a wide range of basic cognitive science to help us understand the bidirectional link between thought and movement, and how it can go wrong in disease.\n\nThe technological focus of the project was on small space motion capture in which movements of the whole body could be recorded at high precision. With the development of inexpensive, precise inertial measurement units and a demand from the consumer virtual reality market, movement recordings with millisecond and millimeter accuracy are well within reach of labs. Motion capture technologies that cost in the hundreds of thousands just a decade ago are now in living rooms across the world in gaming equipment and embedded in our phones. While consumer movement measurement technologies are accessible, they are not always validated and accurate enough to give researchers an accurate picture of behavior. The validation techniques developed in LMN have bridged that gap. For example, head-mounted eye trackers are accessible enough that multiple eye trackers were used to observe behavior in multiple participants at the same time to understand how participants follow each other?s attentional shifts during a conversation: joint attention. These measurements allowed us to assess multiple participants? gaze behavior in real time in a natural social setting.  Next steps include advancing these and related technologies to capture behavioral data readily in schools, medical settings, and when desired also at home.\n\nMovement is a pervasive aspect of our daily lives.  We make up to 4 eye movements every second, from our engaging book to the distracting squirrel outside and back again.  Some people rhythmic movements such as rocking behavior to be soothing as these stimulate multiple senses including our vestibular sense.  The practice of driving is a complex set of movement behaviors that are challenging to simulate given the complex interplay between movement and resulting sensations. In all cases, movement and learning are intimately linked. Our bodies are in constant motion to gather information to learn about our environment and or brains are constantly learning about how our movements alter our environment. At the millisecond scale, movements were seen to be statistically related to autism diagnosis and this link may lead to a better understanding of the relationship between movement and autism. At the scale of several seconds, markerless, non-contact motion capture with series of cameras allows the observation of self-soothing, e.g. body rocking, motion in individuals whose sensitivity to touch would otherwise have precluded accurate measurement. At even longer scales, when we drive a car, we move in a way that not even the most advanced computers and artificial intelligences can match, and when drivers are distracted by a text, even just to ask if they ?like pickles,? they swerve for as long as 20-25 seconds.\n\nBeyond the basic and applied science of the LMN project, the PIs also leveraged project resources to start the Power of NeuroGaming (PoNG) Center at UC San Diego.  Our intention to using our hard won knowledge of how to incorporate readily available, consumer-oriented hardware into lab quality experimental paradigms has great utility in a university community, offering a services on a recharge basis. The PoNG center is also a space for neurodiverse individuals to gain work experience, including how to manage their behavior in a workplace. This effort has lead to an NSF Future of Work grant that supports a neurodiverse internship program and technical tools that are designed to provide feedback to neurodivergent workers to improve their own readiness for workforce immersion, while we simultaneous work to prepare the workforce for the talents of neurodivergent workers.  The PoNG center was supported by the Qualcomm Institute and the Legler Benbough Foundation, but would not have emerged had the seeds of future collaborations not been planted through this Science of Learning NSF grant.  We look forward to continuing these lines of research to create new tools useful for measuring human movement and new knowledge about the ways that human movement and learning are interrelated.  \n\n \n\n\t\t\t\t\tLast Modified: 08/27/2021\n\n\t\t\t\t\tSubmitted by: Leanne Chukoskie"
 }
}