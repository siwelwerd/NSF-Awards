{
 "awd_id": "1555986",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "IDBR TYPE B: Development of a $100 high-throughput whole slide imaging kit",
 "cfda_num": "47.074",
 "org_code": "08080000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Robert Fleischmann",
 "awd_eff_date": "2016-03-01",
 "awd_exp_date": "2020-02-29",
 "tot_intn_awd_amt": 206826.0,
 "awd_amount": 218826.0,
 "awd_min_amd_letter_date": "2016-02-10",
 "awd_max_amd_letter_date": "2017-02-21",
 "awd_abstract_narration": "An award is made to University of Connecticut to develop a cost-effective whole slide imaging (WSI) add-on kit. High-throughput whole slide imaging (WSI) system is an important tool for various biological research applications. By using WSI systems, large-scale biological samples can be digitalized with high resolution in seconds or minutes, significantly increasing laboratory efficiency and promoting the progress of science. This project aims to develop a $100 WSI add-on kit for high-throughput multimodal microscopy imaging. By adapting this add-on kit to an existing regular microscope platform, one can convert it into a high-throughput, multimodal WSI platform. The result from the WSI add-on kit is a comprehensive digital rending of the entire sample, on the order of centimeter in size, visible at diffraction-limited resolution, in two or three dimensions, and with multiple imaging modalities. Experiments that were typically carried out manually in single cell level and addressed a limited field of view at a time can now be done for the entire sample in an automated and intelligent manner. As high-content images are desired in many fields of biological and biomedical research, the dissemination of the WSI add-on kit in ~$100 budget could lead to new types of experimental designs in small research labs and benefit various health-related applications.\r\n \t\r\nThis project aims to develop the WSI add-on kit by integrating three different modules: 1) an autofocusing module that instantly identifies the optimal focal position of the sample, 2) a scanning module that drives the stages of a regular microscope in high speed, and 3) an illumination module that integrates multiple imaging modalities into the platform. For the autofocusing module, two pinhole-modulated cameras will be attached to the eyepiece ports for instant focal plane detection. By analyzing the captured images from these two eyepiece ports, one can infer the optimal focal position for a 2D thin section and the tomography structure of a 3D sample without a z-scan. Different z-sampling strategies can then be used for better image acquisition. For the scanning module, stepper motors and the associated gears will be used to control the motion of the microscope stages. Different mechanical coupling schemes will be tested and the best scheme will be chosen in terms of the scanning speed and positional repeatability. For the illumination module, a liquid crystal display will be inserted at the back-focal plane of the condenser lens. By setting different binary patterns on the display, this illumination module is able to integrate multiple imaging modalities into the platform, including brightfield, darkfield, phase contrast, quantitative phase, polarization, 3D tomography, and super-resolution Fourier ptychographic imaging. The education/outreach program of this project will include course development for graduate and undergraduate students at UConn, summer internships to high-school students and high-school/middle-school teachers. The knowledge generated through this project will be disseminated through conference presentations and workshops, publications in scientific journals, and news-room articles that raise the scientific literacy of the public. The protocol of building the WSI kit will be posted on a dedicated website. Industrial partners will be identified to promote the commercialization of the WSI add-on kit.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "DBI",
 "org_div_long_name": "Division of Biological Infrastructure",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Guoan",
   "pi_last_name": "Zheng",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Guoan Zheng",
   "pi_email_addr": "guoan.zheng@uconn.edu",
   "nsf_id": "000656304",
   "pi_start_date": "2016-02-10",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Kazunori",
   "pi_last_name": "Hoshino",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kazunori Hoshino",
   "pi_email_addr": "hoshino@engr.uconn.edu",
   "nsf_id": "000671481",
   "pi_start_date": "2016-02-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Connecticut",
  "inst_street_address": "438 WHITNEY RD EXTENSION UNIT 1133",
  "inst_street_address_2": "",
  "inst_city_name": "STORRS",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "8604863622",
  "inst_zip_code": "062699018",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CT02",
  "org_lgl_bus_name": "UNIVERSITY OF CONNECTICUT",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNTPS995QBM7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Connecticut",
  "perf_str_addr": "A.B. Bronwell Building, Room 213",
  "perf_city_name": "Storrs",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "062693247",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CT02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "110800",
   "pgm_ele_name": "INSTRUMENTAT & INSTRUMENT DEVP"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 112728.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 106098.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Tissue-based diagnostic pathology is considered the golden standard for cancer diagnosis in clinical environments. In recent years, there has been an upsurge in worldwide attention on digital pathology, which converts glass slides into digital slides that can be viewed, managed, and analyzed on computer screens. Digital pathology via whole slide imaging promises better and faster diagnosis and prognosis of cancers and other diseases. A major milestone was accomplished in 2017 when the Philips whole slide imaging system was approved for the primary diagnostic use in the US. In a conventional whole slide imaging system, the tissue slide is mechanically scanned to different lateral x-y positions, and the digital images are acquired using a high numerical aperture objective lens. The small depth of field of the objective, however, poses a challenge for proper focusing during the scanning process.</p>\n<p>To address this problem, conventional platforms often perform axial scanning to determine the best focus position at each tile of the specimen. In this NSF project, rapid autofocusing techniques have been developed for enabling whole slide imaging without stringent requirements on mechanical repeatability. Different from the conventional platforms, the best focus position is inferred from a single captured image in the newly developed techniques. As such, the autofocusing process can be performed in real-time during the scanning process. The findings of this project can transform the high-end whole slide imaging equipment into cost-effective platforms that can be made broadly available and utilizable without loss of capacity. Experiments that were typically carried out manually in single cell level and that addressed a limited field of view at a time can now be done for the entire sample in an automated and intelligent manner. The dissemination of the findings could also lead to new types of experimental designs in small research labs, e.g., cytology analysis in cell culture experiments, genetic studies on multicellular organisms, pharmaceutical drug profiling, RNA interference studies, or investigation of microbial communities in environmental systems. The broader impacts of this project include curriculum development and training of students, including those from underrepresented groups.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/27/2020<br>\n\t\t\t\t\tModified by: Guoan&nbsp;Zheng</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTissue-based diagnostic pathology is considered the golden standard for cancer diagnosis in clinical environments. In recent years, there has been an upsurge in worldwide attention on digital pathology, which converts glass slides into digital slides that can be viewed, managed, and analyzed on computer screens. Digital pathology via whole slide imaging promises better and faster diagnosis and prognosis of cancers and other diseases. A major milestone was accomplished in 2017 when the Philips whole slide imaging system was approved for the primary diagnostic use in the US. In a conventional whole slide imaging system, the tissue slide is mechanically scanned to different lateral x-y positions, and the digital images are acquired using a high numerical aperture objective lens. The small depth of field of the objective, however, poses a challenge for proper focusing during the scanning process.\n\nTo address this problem, conventional platforms often perform axial scanning to determine the best focus position at each tile of the specimen. In this NSF project, rapid autofocusing techniques have been developed for enabling whole slide imaging without stringent requirements on mechanical repeatability. Different from the conventional platforms, the best focus position is inferred from a single captured image in the newly developed techniques. As such, the autofocusing process can be performed in real-time during the scanning process. The findings of this project can transform the high-end whole slide imaging equipment into cost-effective platforms that can be made broadly available and utilizable without loss of capacity. Experiments that were typically carried out manually in single cell level and that addressed a limited field of view at a time can now be done for the entire sample in an automated and intelligent manner. The dissemination of the findings could also lead to new types of experimental designs in small research labs, e.g., cytology analysis in cell culture experiments, genetic studies on multicellular organisms, pharmaceutical drug profiling, RNA interference studies, or investigation of microbial communities in environmental systems. The broader impacts of this project include curriculum development and training of students, including those from underrepresented groups.\n\n \n\n\t\t\t\t\tLast Modified: 07/27/2020\n\n\t\t\t\t\tSubmitted by: Guoan Zheng"
 }
}