{
 "awd_id": "1607486",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "US-German Research Proposal: Neurocomputation in the Visual Periphery: Experiments and Models",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2016-12-01",
 "awd_exp_date": "2021-11-30",
 "tot_intn_awd_amt": 681746.0,
 "awd_amount": 681746.0,
 "awd_min_amd_letter_date": "2016-09-12",
 "awd_max_amd_letter_date": "2017-09-19",
 "awd_abstract_narration": "Peripheral vision comprises over 99.99% of the visual field. Its strengths and limitations strongly constrain visual perception -- what humans can see at a glance, and the processes by which they move their eyes to piece together information about the world. Peripheral vision differs from foveal vision in complex and interesting ways, most importantly due to \"crowding,\" in which identifying a peripheral stimulus can be substantially impaired by the presence of other, nearby stimuli. This project will examine the nature of the encoding in visual cortex, through development and testing of a set of models of peripheral vision. These models will be targeted at answering key questions about the neurobiological mechanisms. The collaborating investigators, in the US and Germany, will develop models and create a benchmark dataset of behavioral results to be explained. The models and dataset will be made freely available, to aid other researchers and to inform the development of applications such as heads up displays and user interfaces. This work will provide insight into what features are encoded in visual cortex, as well as what tradeoffs may have led the visual system to develop that encoding. Understanding those tradeoffs may inform computer vision which, like human vision, faces constraints on processing capacity. \r\n\r\nThe development of new model variants will be based on insights from neurophysiology, natural image statistics, sparse coding, and the recent success of convolutional neural networks in artificial intelligence. The investigators will gather benchmark behavioral phenomena far richer than existing crowding datasets, through a combination of studying natural image tasks and model-driven experiments. They will then compare predictions of the new models, as well as of Dr. Rosenholtz's existing high-performing model of peripheral vision, on the benchmark dataset. Doing so will identify the best-performing model(s), and answer key questions about the nature of pooling computations and of non-linear operators, and about the complexity, nature, and purpose of the features encoded by peripheral vision.\r\n\r\nA companion project is being funded by the Federal Ministry of Education and Research, Germany (BMBF).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ruth",
   "pi_last_name": "Rosenholtz",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ruth Rosenholtz",
   "pi_email_addr": "rruth@mit.edu",
   "nsf_id": "000414614",
   "pi_start_date": "2016-09-12",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 MASSACHUSETTS AVE",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "732700",
   "pgm_ele_name": "CRCNS-Computation Neuroscience"
  },
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7327",
   "pgm_ref_txt": "CRCNS"
  },
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 640213.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 41533.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project builds on a successful model of human peripheral vision. Peripheral vision encompasses over 99% of the visual field, and its strengths and limitations to a large degree determine the difficulty of most visual tasks. Peripheral vision, according to this well tested model, encodes its inputs using a rich set of summary statistics, collected over sizeable regions of the visual input. The larger regions lead to less precise representation farther from the point of gaze. The project advances the field by developing new, faster versions of this model, to facilitate testing and tech transfer; developing model variants to test critical components of the model architecture; and develops a set of benchmark visual tasks and phenomena for testing models of peripheral vision. This summary addresses each of these in turn:</p>\n<p>The existing model, while highly predictive and well tested, required upwards of 6 hours of compute time to generate predictions. The PI and collaborators utilized recent work in machine vision to develop several faster versions. One approach used the <em>machinery</em>&nbsp;of neural networks, but not the learning aspect of such networks, to implement a fast version of the original model from the PI's lab. In the process, this implementation also allowed for far more flexibility in the model components, facilitating future model comparisons to best model peripheral vision. Another approach used neural networks known as GANs to learn the transformation from input to model predictions, leading to even faster model predictions. Faster models of peripheral vision facilitate tech transfer, as more rapid predictions enable use of the model of human vision for iterative design, e.g. of information visualizations or user interfaces, or ultimately of real-time systems such as understanding what the driver of a car perceives, based on where they look.</p>\n<p>With both the new, faster and more flexible model framework, and with simplified versions of the peripheral vision architecture, the PI and collaborators tested critical components of the model, such as the features and statistics measured, the overlap between the regions over which statistics are computed, and region size. In addition, these tests examine aspects of model convergence. As such, this project provides information both about models of human peripheral vision and of potential use to machine vision systems. Human vision remains the best model of general purpose vision, and understanding it provides insights into machine vision systems.</p>\n<p>Prior to the start of this project, most tests of peripheral vision models involved tasks identifying simple peripheral symbols. This project has tested and in some cases added new perceptual tasks to create a new benchmark set. The existing model performed well on holistic scene perception tasks, but the PI eliminated such tasks from the benchmark because they poorly descriminated between models. To replace these tasks, the PI has demonstrated the utility of these tasks: peripheral object recognition in real scenes; change detection; and maze perception. Change detection and maze perception have real-world significance for inspection and IED detection; and for map and other designs, respectively.&nbsp;</p>\n<p>The project has led to 2 published papers in established journals, 2 under review, and at least 2 more in preparation.&nbsp; Model code of new model variants will be released open-source upon publication. This will allow others to use and modify the model, accelrating research in this area.</p>\n<p>The PI trained 2 high school students (both female), 1 female undergrad, 1 female grad student, co-advised 5 graduate students (2 female), co-advised one postdoc and advised three others (all female). Students/postdocs were trained in a combination of computational modeling, image processing, and human vision. In addition, other students and postdocs in the lab received training in modern machine-learning based machine vision through regular interactions with the project participants. This project, due to its interdisciplinary nature, also provided some training to the PI in modern neural networks, as well as providing approximately 5 senior collaborators (e.g. from computer graphics or behavioral sciences) with training in human vision and the modeling thereof, as well as in such topics as image/video compression and image quality.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/28/2022<br>\n\t\t\t\t\tModified by: Ruth&nbsp;E&nbsp;Rosenholtz</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project builds on a successful model of human peripheral vision. Peripheral vision encompasses over 99% of the visual field, and its strengths and limitations to a large degree determine the difficulty of most visual tasks. Peripheral vision, according to this well tested model, encodes its inputs using a rich set of summary statistics, collected over sizeable regions of the visual input. The larger regions lead to less precise representation farther from the point of gaze. The project advances the field by developing new, faster versions of this model, to facilitate testing and tech transfer; developing model variants to test critical components of the model architecture; and develops a set of benchmark visual tasks and phenomena for testing models of peripheral vision. This summary addresses each of these in turn:\n\nThe existing model, while highly predictive and well tested, required upwards of 6 hours of compute time to generate predictions. The PI and collaborators utilized recent work in machine vision to develop several faster versions. One approach used the machinery of neural networks, but not the learning aspect of such networks, to implement a fast version of the original model from the PI's lab. In the process, this implementation also allowed for far more flexibility in the model components, facilitating future model comparisons to best model peripheral vision. Another approach used neural networks known as GANs to learn the transformation from input to model predictions, leading to even faster model predictions. Faster models of peripheral vision facilitate tech transfer, as more rapid predictions enable use of the model of human vision for iterative design, e.g. of information visualizations or user interfaces, or ultimately of real-time systems such as understanding what the driver of a car perceives, based on where they look.\n\nWith both the new, faster and more flexible model framework, and with simplified versions of the peripheral vision architecture, the PI and collaborators tested critical components of the model, such as the features and statistics measured, the overlap between the regions over which statistics are computed, and region size. In addition, these tests examine aspects of model convergence. As such, this project provides information both about models of human peripheral vision and of potential use to machine vision systems. Human vision remains the best model of general purpose vision, and understanding it provides insights into machine vision systems.\n\nPrior to the start of this project, most tests of peripheral vision models involved tasks identifying simple peripheral symbols. This project has tested and in some cases added new perceptual tasks to create a new benchmark set. The existing model performed well on holistic scene perception tasks, but the PI eliminated such tasks from the benchmark because they poorly descriminated between models. To replace these tasks, the PI has demonstrated the utility of these tasks: peripheral object recognition in real scenes; change detection; and maze perception. Change detection and maze perception have real-world significance for inspection and IED detection; and for map and other designs, respectively. \n\nThe project has led to 2 published papers in established journals, 2 under review, and at least 2 more in preparation.  Model code of new model variants will be released open-source upon publication. This will allow others to use and modify the model, accelrating research in this area.\n\nThe PI trained 2 high school students (both female), 1 female undergrad, 1 female grad student, co-advised 5 graduate students (2 female), co-advised one postdoc and advised three others (all female). Students/postdocs were trained in a combination of computational modeling, image processing, and human vision. In addition, other students and postdocs in the lab received training in modern machine-learning based machine vision through regular interactions with the project participants. This project, due to its interdisciplinary nature, also provided some training to the PI in modern neural networks, as well as providing approximately 5 senior collaborators (e.g. from computer graphics or behavioral sciences) with training in human vision and the modeling thereof, as well as in such topics as image/video compression and image quality. \n\n \n\n\t\t\t\t\tLast Modified: 03/28/2022\n\n\t\t\t\t\tSubmitted by: Ruth E Rosenholtz"
 }
}