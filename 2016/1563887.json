{
 "awd_id": "1563887",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: III: Medium: Scalable Machine Learning for Automating Scientific Discovery in Astrophysics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2016-06-15",
 "awd_exp_date": "2020-05-31",
 "tot_intn_awd_amt": 1099889.0,
 "awd_amount": 1099889.0,
 "awd_min_amd_letter_date": "2016-06-03",
 "awd_max_amd_letter_date": "2017-09-14",
 "awd_abstract_narration": "The purpose of this work is to i) develop and validate new, efficient machine learning methods for making inferences and predictions in a massively parallel and distributed way on large-scale complex data sets coming from upcoming sky surveys, and ii) help answer important fundamental questions in cosmology and astrophysics using those new methods.  Theoretical properties of these algorithms will also be investigated.  The proposed cosmology and astrophysics applications will include a) building a probabilistic model for light intensity signals from stars, b) evolving the matter density of the Universe at a speed much higher than the traditional method of N-body simulations, and c) creating \"mock catalogs\" with all commonly observable galaxy properties. The methods that are developed will have far broader applicability than the examples listed here, both for other problems in astrophysics and problems in completely different domains (e.g. bioinformatics, climatology, social sciences), where complex scientific simulations require large-scale learning methods. The software developed in this work (including documentation, examples, and case studies) will be made publicly available. The PIs will also include the results in their course materials for graduate and undergraduate students.\r\n\r\n\r\nThe aim of this proposal is to develop new machine learning methods that can work directly on large-scale, high-dimensional functions and continuous distributions as inputs or outputs in a regression problem, and can process large-scale scientific data in a massively parallel distributed way. Important theoretical properties, such as computational efficiency, sample complexity, generalization accuracy, consistency, lower and upper bounds on the convergence rates will also be investigated. Gaussian processes (GPs) are among the most popular nonparametric Bayesian function approximation methods. However, the standard GP methods are limited to at most a few thousands data points, and not applicable for large datasets. Kernel learning for GPs is an even more challenging problem. The question of how to scale up GP kernel learning methods for large datasets will be addressed as part of this project. Using the machine learning methods developed in this proposal, the following cosmology and astrophysics problems will be investigated: a) Scalable Gaussian processes with spectral mixture kernels will be used to build a probabilistic generative model for light intensity signals from stars to extract fundamental properties such as density profiles. b) New machine learning algorithms will be used to evolve the matter density of the Universe at a speed much higher than the traditional method of N-body simulations. This will enable a completely new way of generating a large number of cosmological simulations in order to compare the cosmological observations to our understanding of the Universe. c) Simulated galaxy catalogs are a powerful tool for testing cosmological analysis methods, since the cosmological parameters in the simulation are known and thus our ability to recover them can be tested perfectly. For a single cosmological simulation, the properties and alignments of galaxies are not fully determined, but rather must be added probabilistically to the dark matter distribution as an extra layer of modeling typically with many parameters.  The new machine learning tools developed in this proposal will be used to make \"mock catalogs\" with all commonly observable galaxy properties.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Barnabas",
   "pi_last_name": "Poczos",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Barnabas Poczos",
   "pi_email_addr": "bapoczos@andrew.cmu.edu",
   "nsf_id": "000610578",
   "pi_start_date": "2016-06-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Xing",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Eric P Xing",
   "pi_email_addr": "epxing@cs.cmu.edu",
   "nsf_id": "000195787",
   "pi_start_date": "2016-06-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Rachel",
   "pi_last_name": "Mandelbaum",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Rachel S Mandelbaum",
   "pi_email_addr": "rmandelb@andrew.cmu.edu",
   "nsf_id": "000576944",
   "pi_start_date": "2016-06-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrew",
   "pi_last_name": "Wilson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Andrew Wilson",
   "pi_email_addr": "andrewgw@cims.nyu.edu",
   "nsf_id": "000696522",
   "pi_start_date": "2016-06-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 372382.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 727507.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>We have created Bayesian optimization, deep learning, and other machine learning methods to advance scientific discovery in astrophysics and cosmology.<br /> <br /> These new tools include Dragonfly (https://github.com/dragonfly/dragonfly),&nbsp;an open source python library for scalable Bayesian optimization. Bayesian optimization is used for optimizing black-box functions whose evaluations are usually expensive. Beyond vanilla optimization techniques, Dragonfly provides an array of tools to scale up Bayesian optimization to expensive large-scale problems. These include features/functionality that are especially suited for high dimensional optimization, parallel evaluations in synchronous or asynchronous settings (conducting multiple evaluations in parallel), multi-fidelity optimization (using cheap approximations to speed up the optimization process), and multi-objective optimization (optimizing multiple functions simultaneously).</span></p>\n<p><span>We have applied these new machine learning methods to a range of problems in astrophysics, cosmology,&nbsp;and other sciences:</span></p>\n<p><span>1. We have developed publicly-available software (https://github.com/McWilliamsCenter/CMUDeepLens) for analyzing images of the sky to identify strong gravitational lenses, in particular, cases where one galaxy that is nearly directly behind another galaxy appears multiple times due to the gravitational field of the more nearby galaxy.&nbsp; Our method was among the top-performing methods in a challenge that compared multiple methods of identifying strong lens systems.</span></p>\n<p><span>2. We have demonstrated how to analyze the light curves of a family of variable stars (which emit an amount of light that varies as a function of time) to measure the distances to those stars, which provides a new and independent cross-check on other methods of measuring distances to stars.</span></p>\n<p><span>3. We have developed generative models of galaxy morphology -- that is, machine learning models for the appearances of galaxy images.&nbsp; Since some galaxies have a complex appearance that is not easily described by a similar parametric model, for example exhibiting spiral arms or other structures, these generative models are valuable for making simulated sky images (to test analysis algorithms), or for interpreting corrupted data (for example, missing pixels due to cosmic ray hits).</span></p>\n<p><span>4. We have developed and demonstrated methodology for accurately inferring the distribution of distances to galaxies (or, equivalently, their redshifts) using Bayesian hierarchical inference.&nbsp; Crucially, this involves modeling astrophysical nuisance parameters, and optimizing the method so that it can be applied in practice to real datasets.</span></p>\n<p><span>5. In addition to cosmology and astrophysics, we have demonstrated that the new machine learning tools developed in this project can be very valuable in other scientific applications as well. As a specific Bayesian optimization application in organic chemistry, we developed ChemBO, a Bayesian optimization method for generating and optimizing organic molecules for desired molecular properties. While most of the previous data-driven methods for molecular design do not account for sample efficiency or fail to enforce realistic constraints on synthesizability, our method explores the synthesis graph in a sample-efficient way and produces synthesizable candidates. In our experiments, we demonstrated the effectiveness of our proposed approach on several molecular optimization problems.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/16/2020<br>\n\t\t\t\t\tModified by: Barnabas&nbsp;Poczos</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWe have created Bayesian optimization, deep learning, and other machine learning methods to advance scientific discovery in astrophysics and cosmology.\n \n These new tools include Dragonfly (https://github.com/dragonfly/dragonfly), an open source python library for scalable Bayesian optimization. Bayesian optimization is used for optimizing black-box functions whose evaluations are usually expensive. Beyond vanilla optimization techniques, Dragonfly provides an array of tools to scale up Bayesian optimization to expensive large-scale problems. These include features/functionality that are especially suited for high dimensional optimization, parallel evaluations in synchronous or asynchronous settings (conducting multiple evaluations in parallel), multi-fidelity optimization (using cheap approximations to speed up the optimization process), and multi-objective optimization (optimizing multiple functions simultaneously).\n\nWe have applied these new machine learning methods to a range of problems in astrophysics, cosmology, and other sciences:\n\n1. We have developed publicly-available software (https://github.com/McWilliamsCenter/CMUDeepLens) for analyzing images of the sky to identify strong gravitational lenses, in particular, cases where one galaxy that is nearly directly behind another galaxy appears multiple times due to the gravitational field of the more nearby galaxy.  Our method was among the top-performing methods in a challenge that compared multiple methods of identifying strong lens systems.\n\n2. We have demonstrated how to analyze the light curves of a family of variable stars (which emit an amount of light that varies as a function of time) to measure the distances to those stars, which provides a new and independent cross-check on other methods of measuring distances to stars.\n\n3. We have developed generative models of galaxy morphology -- that is, machine learning models for the appearances of galaxy images.  Since some galaxies have a complex appearance that is not easily described by a similar parametric model, for example exhibiting spiral arms or other structures, these generative models are valuable for making simulated sky images (to test analysis algorithms), or for interpreting corrupted data (for example, missing pixels due to cosmic ray hits).\n\n4. We have developed and demonstrated methodology for accurately inferring the distribution of distances to galaxies (or, equivalently, their redshifts) using Bayesian hierarchical inference.  Crucially, this involves modeling astrophysical nuisance parameters, and optimizing the method so that it can be applied in practice to real datasets.\n\n5. In addition to cosmology and astrophysics, we have demonstrated that the new machine learning tools developed in this project can be very valuable in other scientific applications as well. As a specific Bayesian optimization application in organic chemistry, we developed ChemBO, a Bayesian optimization method for generating and optimizing organic molecules for desired molecular properties. While most of the previous data-driven methods for molecular design do not account for sample efficiency or fail to enforce realistic constraints on synthesizability, our method explores the synthesis graph in a sample-efficient way and produces synthesizable candidates. In our experiments, we demonstrated the effectiveness of our proposed approach on several molecular optimization problems.\n\n \n\n\t\t\t\t\tLast Modified: 11/16/2020\n\n\t\t\t\t\tSubmitted by: Barnabas Poczos"
 }
}