{
 "awd_id": "1564330",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Medium: CompCog: Automated Discovery of Macro-Variables from Raw Spatiotemporal Data",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2016-05-15",
 "awd_exp_date": "2021-04-30",
 "tot_intn_awd_amt": 1100000.0,
 "awd_amount": 1100000.0,
 "awd_min_amd_letter_date": "2016-05-19",
 "awd_max_amd_letter_date": "2017-09-15",
 "awd_abstract_narration": "Observation and careful experimentation provide the basis for scientific inquiry, which in turn guides our understanding of the world and policy decisions. Today, scientific data is collected from a vast array of sensors: satellite images and radar, neuro-imaging, microscopes, body monitoring, socio-economic indicators, to name just a few. While models and theories were traditionally derived via careful handcrafting by domain experts, the new data deluge makes direct human analysis impossible. We need intelligent machines that can process vast amounts of sensory data into interpretable quantities that provide actionable information. This project will develop machines that will be able to learn on their own, purely from experience, produce and test hypotheses on causes and effects in complex dynamic scenes, and better collaborate with human scientists and analysts. For generality, we will develop and test our theory in two different domains. Amongst the immediate benefits of our project are methods for discovering the causal relationship between genes, brains and behavior. \r\n\r\n\r\nOur objective is to develop theory and practical algorithms for automatically interpreting a dynamic scene containing interacting agents. This will involve automatically identifying the main spatial locations, the objects, the actors, their actions and goals, and their relations to one another. The output is a description of the events, and hypotheses on the actors? goals, cause-effect relationships and likely developments. The key technical questions that we will tackle are how to infer semantically meaningful \"macro\" variables (i.e. agents' role and goals, actions, objects, special locations) directly from raw sensory data (mostly video), how to infer the causal relationships among such variables, and how to adaptively plan new experiments, including collecting feedback from human experts, to resolve ambiguities in the model.  The intellectual merit of our project lies in developing an end-to-end, pixels-to-causes approach to the automatic analysis of dynamic scenes. To this end, we will integrate, build upon, and transcend the capabilities of extant \"low-level\" correlational machine learning and \"high-level\" causal inference approaches, combined with interactive learning approaches to sequential experimental design.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Pietro",
   "pi_last_name": "Perona",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Pietro Perona",
   "pi_email_addr": "perona@caltech.edu",
   "nsf_id": "000442093",
   "pi_start_date": "2016-05-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Frederick",
   "pi_last_name": "Eberhardt",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Frederick Eberhardt",
   "pi_email_addr": "fde@caltech.edu",
   "nsf_id": "000662614",
   "pi_start_date": "2016-05-19",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Yisong",
   "pi_last_name": "Yue",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yisong Yue",
   "pi_email_addr": "yyue@caltech.edu",
   "nsf_id": "000678698",
   "pi_start_date": "2016-05-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "California Institute of Technology",
  "inst_street_address": "1200 E CALIFORNIA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "PASADENA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6263956219",
  "inst_zip_code": "911250001",
  "inst_country_name": "United States",
  "cong_dist_code": "28",
  "st_cong_dist_code": "CA28",
  "org_lgl_bus_name": "CALIFORNIA INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "U2JMKHNS5TG4"
 },
 "perf_inst": {
  "perf_inst_name": "California Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "911250600",
  "perf_ctry_code": "US",
  "perf_cong_dist": "28",
  "perf_st_cong_dist": "CA28",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 274218.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 825782.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Our objective is enabling machines to understand events and behaviors from observations. This includes understanding actions, causes and effects.</p>\n<p>We accomplished two major objectives.</p>\n<p>First, we developed a method for a machine to automatically analyze millions of `micro-variables' such as the firing patterns of neurons in the brains, and such as the values of pressure, temperature and humidity in each location on the planet, and infer `macro variables', such as the brain making a decision, or the weather pattern called `el nino'&nbsp; so that such macro variables may be used in causal reasoning, such as `a given stimulus caused a decision' and `el nino causes destructive flooding in the southern US'. The Causal Feature Learning method that constructs causal macro variables from micro level measurement data in an unsupervised manner has been developed into a well-annotated modular open source code package (https://github.com/eberharf/cfl) with implemented examples that show how to use the code.&nbsp;</p>\n<p>A second objective we accomplished is making it easier and more efficient for human experts to train machines to recognize certain events.&nbsp; Traditional techniques require experts to annotate minutiously very large training sets. This makes it more attractive for experts to carry out a given task by hand, rather than spend the time to train a machine that would automate that task. We focussed on animal behavior as an application. We developed a technique called ``Task Programming'' which reduces by up to tenfold the amount of work that is required of an expert in order to train a machine. Using task programming experts capture their knowledge into small programs that may be used to train an automated system, alongside self-supervision and a small number of traditionally annotated training examples. Our work on Task Programming was awarded an ``Best Student Paper Award'' by the IEEE CVPR 2021 conference - the premier conference for Computer Vision.</p>\n<p>A number of graduate students, post-doctoral fellows and undergraduate students were involved in our work. Amongst them three females, one of which recently became a Professor with NorthWestern university.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/20/2021<br>\n\t\t\t\t\tModified by: Pietro&nbsp;Perona</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOur objective is enabling machines to understand events and behaviors from observations. This includes understanding actions, causes and effects.\n\nWe accomplished two major objectives.\n\nFirst, we developed a method for a machine to automatically analyze millions of `micro-variables' such as the firing patterns of neurons in the brains, and such as the values of pressure, temperature and humidity in each location on the planet, and infer `macro variables', such as the brain making a decision, or the weather pattern called `el nino'  so that such macro variables may be used in causal reasoning, such as `a given stimulus caused a decision' and `el nino causes destructive flooding in the southern US'. The Causal Feature Learning method that constructs causal macro variables from micro level measurement data in an unsupervised manner has been developed into a well-annotated modular open source code package (https://github.com/eberharf/cfl) with implemented examples that show how to use the code. \n\nA second objective we accomplished is making it easier and more efficient for human experts to train machines to recognize certain events.  Traditional techniques require experts to annotate minutiously very large training sets. This makes it more attractive for experts to carry out a given task by hand, rather than spend the time to train a machine that would automate that task. We focussed on animal behavior as an application. We developed a technique called ``Task Programming'' which reduces by up to tenfold the amount of work that is required of an expert in order to train a machine. Using task programming experts capture their knowledge into small programs that may be used to train an automated system, alongside self-supervision and a small number of traditionally annotated training examples. Our work on Task Programming was awarded an ``Best Student Paper Award'' by the IEEE CVPR 2021 conference - the premier conference for Computer Vision.\n\nA number of graduate students, post-doctoral fellows and undergraduate students were involved in our work. Amongst them three females, one of which recently became a Professor with NorthWestern university.\n\n\t\t\t\t\tLast Modified: 12/20/2021\n\n\t\t\t\t\tSubmitted by: Pietro Perona"
 }
}