{
 "awd_id": "1613218",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Resampling Methods for High-Dimensional and Large-Scale Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2020-06-30",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2016-05-20",
 "awd_max_amd_letter_date": "2016-05-20",
 "awd_abstract_narration": "Resampling methods are a broad class of tools that serve to measure the variability of statistical results, for example, allowing a researcher to determine whether or not the outcome of an experiment is significant.  Over the course of the last few decades, these methods have been extensively studied, and they have become fundamental to the practice of statistics - in large part because they can solve complex problems while relying on relatively few assumptions. Nevertheless, much remains to be understood about the performance of resampling methods in the context of modern data analysis, where observations tend to have large numbers of features (high-dimensional data), or where the quantity of data is so large that it outstrips computational resources (large-scale data). In both of these challenging settings, the proposed research will extend the applicability of resampling methods, and these efforts will be guided by two research themes discussed below.\r\n\r\nFirst, in the setting of high-dimensional data, the understanding of inference problems, including tests and confidence intervals, remains underdeveloped in comparison with estimation and prediction problems. Given that resampling methods are a general-purpose approach to inference, it is important to know how they are influenced by the effects of low-dimensional structure and regularization. In particular, the proposed research will study the performance of resampling methods in high-dimensional models involving structured covariance matrices. Second, in the setting of large-scale data, randomized algorithms have received growing attention for their ability to produce fast approximate solutions. Although the outputs of such algorithms are random, their fluctuations can often be reduced at the expense of greater computation. This general trait of randomized algorithms leads to the problem of optimizing a tradeoff between precision and computational cost. Towards a solution, the proposed research will investigate how resampling methods can be used to measure this tradeoff for a collection of popular randomized algorithms.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Miles",
   "pi_last_name": "Lopes",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Miles Lopes",
   "pi_email_addr": "melopes@ucdavis.edu",
   "nsf_id": "000703401",
   "pi_start_date": "2016-05-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Davis",
  "inst_street_address": "1850 RESEARCH PARK DR STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "DAVIS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5307547700",
  "inst_zip_code": "956186153",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "CA04",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, DAVIS",
  "org_prnt_uei_num": "",
  "org_uei_num": "TX2DAGQPENZ5"
 },
 "perf_inst": {
  "perf_inst_name": "UC Davis, Department of Statistics",
  "perf_str_addr": "1 Shields Avenue",
  "perf_city_name": "Davis",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "956165270",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "CA04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Resampling methods are a fundamental class of statistical procedures that are widely used to perform hypothesis tests and assess the accuracy of estimators, among numerous other tasks. &nbsp;In the context of modern data analysis, where both the quantity and dimension of data may be very large, there are many aspects of resampling methods that remain to be explored. &nbsp;To this end, the main goals of this project were (1) to develop a general resampling-based framework for measuring tradeoffs between computational cost and statistical performance and (2) to develop resampling methods for inference in high-dimensional models.</p>\n<p>Intellectual merit. Overall, 9 published papers and 2 submitted papers resulted from the project. With regard to goal (1), several papers were written on the topic of using resampling methods to estimate the errors of randomized algorithms for prediction, least-squares, singular value decomposition, and optimization. In turn, the estimated values of the errors can be used to determine whether extra computation should be spent to achieve smaller errors. With regard to goal (2) of the project, a number of other papers studied resampling methods for high-dimensional inference in the contexts of \"spectral statistics\" related to sample covariance matrices, as well as \"max statistics\" related to the problem of constructing confidence regions.&nbsp;</p>\n<p>Broader impacts. While completing the research described above, the PI trained 4 undergraduate students, 4 PhD students, and 3 postdocs. In addition, 4 of the papers produced during the project were accompanied by open-source software repositories. Lastly, the PI actively communicated research results by giving many research presentations within the statistics and computer science communities.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/28/2020<br>\n\t\t\t\t\tModified by: Miles&nbsp;Lopes</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nResampling methods are a fundamental class of statistical procedures that are widely used to perform hypothesis tests and assess the accuracy of estimators, among numerous other tasks.  In the context of modern data analysis, where both the quantity and dimension of data may be very large, there are many aspects of resampling methods that remain to be explored.  To this end, the main goals of this project were (1) to develop a general resampling-based framework for measuring tradeoffs between computational cost and statistical performance and (2) to develop resampling methods for inference in high-dimensional models.\n\nIntellectual merit. Overall, 9 published papers and 2 submitted papers resulted from the project. With regard to goal (1), several papers were written on the topic of using resampling methods to estimate the errors of randomized algorithms for prediction, least-squares, singular value decomposition, and optimization. In turn, the estimated values of the errors can be used to determine whether extra computation should be spent to achieve smaller errors. With regard to goal (2) of the project, a number of other papers studied resampling methods for high-dimensional inference in the contexts of \"spectral statistics\" related to sample covariance matrices, as well as \"max statistics\" related to the problem of constructing confidence regions. \n\nBroader impacts. While completing the research described above, the PI trained 4 undergraduate students, 4 PhD students, and 3 postdocs. In addition, 4 of the papers produced during the project were accompanied by open-source software repositories. Lastly, the PI actively communicated research results by giving many research presentations within the statistics and computer science communities.\n\n \n\n\t\t\t\t\tLast Modified: 10/28/2020\n\n\t\t\t\t\tSubmitted by: Miles Lopes"
 }
}