{
 "awd_id": "1612660",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Debugging Failure: Fostering Youth Academic Resilience in Computer Science",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032928624",
 "po_email": "jjohnson@nsf.gov",
 "po_sign_block_name": "Julie Johnson",
 "awd_eff_date": "2016-09-15",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 607022.0,
 "awd_amount": 607022.0,
 "awd_min_amd_letter_date": "2016-09-14",
 "awd_max_amd_letter_date": "2018-08-16",
 "awd_abstract_narration": "Situated within the Advancing Informal STEM Learning program, this project Research in Service to Practice award seeks to design, implement, and evaluate an intervention aimed at fostering a culture of productive failure practices. The project responds to a broad concern in educational research and practice: Experiences of failure are frequently so negative that students shut down, lose agency, and develop low self-efficacy and learned helplessness. Surrendering too quickly to obstacles is particularly unfortunate, given evidence that initially \"getting it wrong\" ultimately breeds deep and sustained learning. In order to learn how students can make the most of productive failure, the proposed project will study how a community of practice that includes middle school youth and their mentors attempts to change its handling of learning obstacles. Building on prior research documenting storytelling practices in an afterschool program, the team now aims to embolden young students' productive practices of failure storytelling in computer science, a field in which experts practice candid, pervasive, and collaborative discourse around errors (\"bugs\"). \r\n\r\nPulling together the domains of narrative analysis, meta-cognitive reflection, and control theories of motivation, within the context of authentic computer-science debugging activity, this study develops a theoretical framework that views productive responses to failure as a discipline-specific process of reflecting as a community on how to locate obstacles, how to construct causal theories about why those obstacles emerged, and how to plan productive responses. A design-based research approach will investigate three questions: (1) What is the impact of the interventions on students and instructors' actions and discourse when they are debugging errors in computer code? (2) What is the impact of the interventions on students and instructors' reflections back on their prior debugging experiences and on failure in general? and (3) What is the impact of the instructor-development efforts on the instructors' capacity to foster students' productive attitudes toward failure? The study focus will be 15 summer and weekend coding workshops with 5th-8th grade students from populations typically under-represented in STEM. The interventions are (a) setting new norms and practices for debugging, (b) instructor education, and (c) coding software that provides students with feedback on their productive struggle. Data sources include video and audio recordings of the learning environment, artifacts produced during the activities, and semi-structured interviews. Measures will capture variations in debugging activities, reflections on debugging, students' ideas about grit and growth mindset, and instructors' struggles and successes with the new curriculum. The empirical results will consist of mixed-methods, micro-longitudinal accounts of how a community of practice works to reform its orientation to failure.\r\n\r\nThe products of this work include empirical knowledge, theory, and curriculum about how learning communities help students develop robust and efficient responses to failure. These will be disseminated through journals, open-source software, and workshops/conferences for researcher and practitioners working with youth afterschool programs. The products may be useful for exploring practices in the classroom. This project is being conducted by the 9 Dots Community Learning Center, UCLA and UC Berkeley.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Melissa",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Melissa Chen",
   "pi_email_addr": "melissa.chen@9dots.org",
   "nsf_id": "000681889",
   "pi_start_date": "2016-09-14",
   "pi_end_date": "2018-08-07"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Josh",
   "pi_last_name": "Taylor",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Josh Taylor",
   "pi_email_addr": "joshrtay@gmail.com",
   "nsf_id": "000752791",
   "pi_start_date": "2018-08-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "9 Dots Community Learning Center",
  "inst_street_address": "931 N HIGHLAND AVE",
  "inst_street_address_2": "",
  "inst_city_name": "LOS ANGELES",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "3235248328",
  "inst_zip_code": "900382412",
  "inst_country_name": "United States",
  "cong_dist_code": "30",
  "st_cong_dist_code": "CA30",
  "org_lgl_bus_name": "9 DOTS COMMUNITY LEARNING CENTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "JJ7HDS7LLY49"
 },
 "perf_inst": {
  "perf_inst_name": "9 Dots Community Learning Center",
  "perf_str_addr": "931 N. Highland Ave.",
  "perf_city_name": "Los Angeles",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "900382412",
  "perf_ctry_code": "US",
  "perf_cong_dist": "30",
  "perf_st_cong_dist": "CA30",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "725900",
   "pgm_ele_name": "AISL"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8212",
   "pgm_ref_txt": "Broaden Particip STEM Resrch"
  },
  {
   "pgm_ref_code": "8244",
   "pgm_ref_txt": "EHR CL Opportunities (NSF 14-302)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0416",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001617DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0417",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001718DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 234629.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 201158.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 171235.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-a262ead5-7fff-dbb6-1020-451484555c6e\">\n<p dir=\"ltr\"><span>The primary goal of the Debugging Failure project was to design, implement, refine, and evaluate a series of weekend and summer computer science workshops aimed at fostering among 5th-8th grade students a culture of productive-failure practices. Our team of researchers and practitioners implemented cycles of design-based research focused on three research designs: setting new norms around encountering, interrogating, and practicing expert debugging practices; leading instructor-education workgroups focused on helping instructors notice the structure of teaching around failure; and building coding software that gives students authentic debugging experiences, resources, and metadata on their struggles.&nbsp;</span></p>\n<p dir=\"ltr\"><span><span> </span></span><span>Over the course of the project, our research-practice team refined a five-part framework for what constitutes &ldquo;productive&rdquo; responses to failure: (1) fixing the current problem; (2) avoiding (or at least being better prepared for) recurring problems; (3) preparing for novel problem; (4) engaging with active participation in the debugging process; and (5) judging efficacy to resolve the problem. With this multifaceted target in mind, and with a research focus primarily on the social process through which teachers and students work together when debugging (DeLiema et al., 2020), we made a number of discoveries. We noticed that teachers value all five facets of productivity and explicitly design their instruction with them in mind, and in turn, that students orient to all five facets of productivity in different rhythms throughout their work. Building on our analysis of how instructors make space for learners to engage in debugging practices during one-on-one support in ways that preserve their agency in problem solving (Flood, DeLiema, Harrer, &amp; Abrahamson, 2018), we looked in particular at moments of refactoring. These situations in which students&rsquo; code is working and yet positioned by members of the community as incomplete (for any one of a number of reasons), are power laden, may problematically undermine students&rsquo; approaches to problem solving, and deserve to be studied carefully by teachers and educational researchers (Fong, W-V. Aalst, Flood, &amp; DeLiema, 2020).</span></p>\n<p dir=\"ltr\"><span>Toward this end, we made substantive space in our computer science workshops for arts-based reflections on the experience of debugging, and found these spaces to generate rich, detailed accounts of the private experience of navigating failure (Dahn &amp; DeLiema, 2020; Dahn, DeLiema, &amp; Enyedy, 2020). We would recommend further exploration of designs that nurture and support students&rsquo; reflections on the emotional experience of navigating bugs in code, including inquiries into how the community around the student responds to these stories. With respect to this latter goal, we worked closely with instructors to reflect through explicit design conjectures on what they viewed as successful about their pedagogical approach, and what should be revised. Through this approach, we unearthed a number of recurring tensions in instruction that revolve around students&rsquo; autonomy, goal setting, and emotional experiences, and instructors&rsquo; approaches to norm setting and modeling around debugging (Ryan, DeLiema, &amp; Abrahamson, 2019).&nbsp;</span></p>\n<p dir=\"ltr\"><span><span> </span></span><span>Lastly, our research-practice team examined two features of instruction that shape debugging with students. First, even with breakdowns in relatively simple computer programs, instructors and students often frame only one facet of the code as problematic (e.g., &ldquo;the bug&rdquo;), without attending to other parts of the code that combine to cause the problem noticed by the student (DeLiema, Bye, Marupudi, 2021). This selection process is understudied and yet consequential because it determines the specific learning that emerges from the failure moment. Second, we have examined how instructors during actual debugging exchanges draw students&rsquo; attention to the syntactic form of the code, the line-by-line process through which the compiler reads code, and the output of the code, including interleaving these dimensions and presenting them with ambiguity (DeLiema, Sharma, Valerie, Cabrera, &amp; Smith, 2020).&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span><span> </span></span><span>Along the way, our team developed software for students new to programming. Named PixelBots (https://pixelbots.io/), the software allows for both block-based and JavaScript programming to control the movement and painting actions of an animal avatar around a grid, and provides tools useful for debugging, such as a stepper, debugging metadata, and line highlights. Beyond our publications in journals, we have shared findings at research conferences and in teacher professional development sessions, and the 9 Dots team has implemented a number of findings coming from the study in their work with schools. Our team is continuing forward with longitudinal analyses of students&rsquo; growth in debugging, and we look forward to sharing these results over the coming years.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/15/2020<br>\n\t\t\t\t\tModified by: Josh&nbsp;Taylor</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe primary goal of the Debugging Failure project was to design, implement, refine, and evaluate a series of weekend and summer computer science workshops aimed at fostering among 5th-8th grade students a culture of productive-failure practices. Our team of researchers and practitioners implemented cycles of design-based research focused on three research designs: setting new norms around encountering, interrogating, and practicing expert debugging practices; leading instructor-education workgroups focused on helping instructors notice the structure of teaching around failure; and building coding software that gives students authentic debugging experiences, resources, and metadata on their struggles. \n Over the course of the project, our research-practice team refined a five-part framework for what constitutes \"productive\" responses to failure: (1) fixing the current problem; (2) avoiding (or at least being better prepared for) recurring problems; (3) preparing for novel problem; (4) engaging with active participation in the debugging process; and (5) judging efficacy to resolve the problem. With this multifaceted target in mind, and with a research focus primarily on the social process through which teachers and students work together when debugging (DeLiema et al., 2020), we made a number of discoveries. We noticed that teachers value all five facets of productivity and explicitly design their instruction with them in mind, and in turn, that students orient to all five facets of productivity in different rhythms throughout their work. Building on our analysis of how instructors make space for learners to engage in debugging practices during one-on-one support in ways that preserve their agency in problem solving (Flood, DeLiema, Harrer, &amp; Abrahamson, 2018), we looked in particular at moments of refactoring. These situations in which students\u2019 code is working and yet positioned by members of the community as incomplete (for any one of a number of reasons), are power laden, may problematically undermine students\u2019 approaches to problem solving, and deserve to be studied carefully by teachers and educational researchers (Fong, W-V. Aalst, Flood, &amp; DeLiema, 2020).\nToward this end, we made substantive space in our computer science workshops for arts-based reflections on the experience of debugging, and found these spaces to generate rich, detailed accounts of the private experience of navigating failure (Dahn &amp; DeLiema, 2020; Dahn, DeLiema, &amp; Enyedy, 2020). We would recommend further exploration of designs that nurture and support students\u2019 reflections on the emotional experience of navigating bugs in code, including inquiries into how the community around the student responds to these stories. With respect to this latter goal, we worked closely with instructors to reflect through explicit design conjectures on what they viewed as successful about their pedagogical approach, and what should be revised. Through this approach, we unearthed a number of recurring tensions in instruction that revolve around students\u2019 autonomy, goal setting, and emotional experiences, and instructors\u2019 approaches to norm setting and modeling around debugging (Ryan, DeLiema, &amp; Abrahamson, 2019). \n Lastly, our research-practice team examined two features of instruction that shape debugging with students. First, even with breakdowns in relatively simple computer programs, instructors and students often frame only one facet of the code as problematic (e.g., \"the bug\"), without attending to other parts of the code that combine to cause the problem noticed by the student (DeLiema, Bye, Marupudi, 2021). This selection process is understudied and yet consequential because it determines the specific learning that emerges from the failure moment. Second, we have examined how instructors during actual debugging exchanges draw students\u2019 attention to the syntactic form of the code, the line-by-line process through which the compiler reads code, and the output of the code, including interleaving these dimensions and presenting them with ambiguity (DeLiema, Sharma, Valerie, Cabrera, &amp; Smith, 2020).  \n Along the way, our team developed software for students new to programming. Named PixelBots (https://pixelbots.io/), the software allows for both block-based and JavaScript programming to control the movement and painting actions of an animal avatar around a grid, and provides tools useful for debugging, such as a stepper, debugging metadata, and line highlights. Beyond our publications in journals, we have shared findings at research conferences and in teacher professional development sessions, and the 9 Dots team has implemented a number of findings coming from the study in their work with schools. Our team is continuing forward with longitudinal analyses of students\u2019 growth in debugging, and we look forward to sharing these results over the coming years.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 12/15/2020\n\n\t\t\t\t\tSubmitted by: Josh Taylor"
 }
}