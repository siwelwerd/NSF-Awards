{
 "awd_id": "1564212",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CHS: Medium: Nanophotonics Phased Array for Virtual and Augmented Reality Multifocal Displays",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2016-07-15",
 "awd_exp_date": "2020-06-30",
 "tot_intn_awd_amt": 1199743.0,
 "awd_amount": 1199743.0,
 "awd_min_amd_letter_date": "2016-07-21",
 "awd_max_amd_letter_date": "2017-08-31",
 "awd_abstract_narration": "The current explosion of virtual and augmented reality (VR and AR) technologies is the subject of much academic, industrial and popular enthusiasm.  Unfortunately, these technologies have also been shown to induce a host of serious user complaints, including headaches, nausea and blurred vision.  This is particularly problematic for 3D displays and content, and the National Academy of Engineering has identified \"enhancing virtual reality interfaces\" as a grand challenge for the 21st century.  Studies have suggested that the vergence-accommodation conflict (or the decoupling of the intended \"virtual focus\" from the actual focal plane of a display) is the cause of many of these psychophysical problems.  The PI's goal in this project is to address this mismatch by utilizing advances in silicon nanophotonics to develop a prototype natural-to-the-senses VR and AR multifocal display along with the requisite visual computing algorithms for multifocal and automultiscopic displays.  The PI will also design and carry out user studies to validate the new technology (display and algorithms).  Project outcomes will not only directly impact the fields of computer graphics and visualization, but an array of other fields as well.  Multifocal accommodative-accurate stereo visualization of large-scale fluid flow simulations would represent a breakthrough in science and engineering generally, in areas ranging from the design of artificial arterial valves to aerial vehicles, the rational drug design process through protein docking, and in surgical advances that could take advantage of real-time MRI technologies and other high-dimensional medical imaging data.  No less important are the potential educational benefits of the new technology, which would unleash the power of VR and AR to immerse young students in worlds to which they would normally not have access, providing excitement, engagement and a breadth and depth of context that is nearly impossible to achieve in a traditional classroom setting.\r\n\r\nThe heart of this project lies in the design and implementation of a novel nanophotonic phased-array chip that will enable the generation of arbitrary radiation patterns with large-scale phased arrays, which would extend the functionality of phased arrays beyond conventional beam focusing and steering, communication and radar, and would open up new opportunities in image processing, 3D interactive holography, and virtual reality.  This project brings together collaborators with significant expertise in 3D computer graphics and scientific visualization, in nanophotonics and plasmonics for the sub-wavelength confinement and steering of light, and in microelectronics, integrated circuits, and microstructure science and technology.  The research will involve three thrusts: (a) slow light to significantly reduce the size and power requirements for the nanophotonics chip; (b) separate electronic and optical components of the chip to better optimize each; and (c) develop efficient algorithms to render and validate, through user studies, multifocal 3D graphics in the Fourier domain.  The design of the multifocal display is the highest-risk and highest-gain component of the work; the team has contingency plans in place to proceed if necessary with developing multifocal and automultiscopic display algorithms, and for conducting user studies, employing existing multiple-focal-plane displays.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Amitabh",
   "pi_last_name": "Varshney",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Amitabh Varshney",
   "pi_email_addr": "varshney@cs.umd.edu",
   "nsf_id": "000253793",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mario",
   "pi_last_name": "Dagenais",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mario Dagenais",
   "pi_email_addr": "dage@umd.edu",
   "nsf_id": "000155195",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Martin",
   "pi_last_name": "Peckerar",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Martin C Peckerar",
   "pi_email_addr": "peckerar@umd.edu",
   "nsf_id": "000183448",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 413471.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 786272.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><strong>Outcomes: </strong>In this project, we designed and implemented a novel nanophotonic phased-array (NPA) chip, to generate arbitrary radiation patterns with large-scale phased arrays. This opens up new opportunities in both interactive holography and virtual and augmented reality (VR and AR).&nbsp;To achieve our goals, we made several advances outlined below.<strong>&nbsp;</strong></p>\n<p><strong>Intellectual Merit:</strong> We designed and developed an independent control of phase and amplitude for each radiating element of the NPA. In our approach, the optical power is distributed on-chip using optical waveguides and directional couplers and radiated by antenna elements based on gratings. To adjust the phase of each element of the array, we have used the thermo-optic coefficient of silicon nitride and an appropriate heater design to achieve the desired phase shift between 0 and 360 degrees for each element of the array.&nbsp; We use slow light to reduce the power required by each element of the array and facilitate scaling to large arrays. We have optimized complex waveguide Bragg gratings to maximize the slow-light effect and we have successfully demonstrated this experimentally. The optical chip is controlled by a separate electronic chip which provides the control and feedback to each element of the array. The electronic and optical chips are flip-chip bonded to each other. We have fabricated 1D optical phased arrays (OPAs) with passive phase shifts and demonstrated the beam steering in the far field. We have also been able to fabricate a 2D 64 x 64 OPA and are in the process of optimizing the light distribution to all the elements of the array.</p>\n<p>To create holographic images for VR with a NPA, we needed to precisely control the per-element phase. Thus, we developed a novel current driver circuit with feedback control for NPAs using thermo-optic phase-shifters. Yet, realizing high-resolution and wide field of view requires that: an individual array unit be less than 15&mu;m on a side; it must be capable of sourcing 2.6mA of current; and the individual array elements must be set and reset in times on the order of 10&mu;s. These system requirements together posed a major design challenge because the size of the array unit is at the cutting edge of modern chip-level integration technology. We are pleased to report that we have successfully developed a current driver circuit capable of controlling local temperature in an OPA with unprecedented speed and precision using a deeply-scaled submicron CMOS process. The control circuit operates in two phases: sensing temperature feedback signal and sourcing current. As such, only a single electrical contact is required between the optical part of the NPA and its driver chip for each pixel. Our design is the first fully-scalable NPA system architecture integrated with an independent phase control feedback circuit.</p>\n<p>We have successfully designed and implemented an integrated light source NPA in a small form factor (each array element side measures 15&mu;m), and with a very high refresh rate (100 kHz), well-suited for multi-focal planes with dynamic content. However, since our design is built on a thermo-optic effect with very small array elements, there is inter-element thermal crosstalk that leads to significant degradation of the output image. To address the thermal proximity effect, we have developed and validated several novel proximity effect correction methods for NPA holographic displays at both far-field distances (Fraunhofer holograms) as well as closer distances (Fresnel holograms). Our methods can correct the thermal proximity effect for Fresnel and Fraunhofer holograms on the NPAs when realistic levels of proximity effect are present.</p>\n<p><strong>Broader Impacts:</strong> We note that we have submitted three patents, detailed in our Final Report, on the basis of the above work. We have also made several other advances that are synergistic to this project. To maximize the visual effectiveness of holographic displays, it is useful to use foveated rendering to mimic the distribution of the photoreceptors in the human visual system. We have developed novel GPU-based foveated rendering techniques for point clouds, meshes, videos, and light fields that are informed by user studies. Our research on eye-dominance-guided foveated rendering enables rendering the scene at a lower foveation level (with higher detail) for the dominant eye than the non-dominant eye. We have also worked on characterizing the desired scaling of patterns at higher eccentricities, so that they can be perceived within a similar amount of time as in the central vision. We are also exploring applications of holographic display technology, such as AR-based procedures in medicine. Specifically, we have developed an AR system to assist physicians in the placement of an external ventricular drain, a common&mdash;yet sometimes risky&mdash;procedure used to relieve the build-up of cerebrospinal fluid in the brain. Wearing an AR headset, a surgeon is able to virtually &ldquo;see&rdquo; both the location of the catheter&rsquo;s tip and also see important patient data available from a CT scan.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/28/2020<br>\n\t\t\t\t\tModified by: Amitabh&nbsp;Varshney</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOutcomes: In this project, we designed and implemented a novel nanophotonic phased-array (NPA) chip, to generate arbitrary radiation patterns with large-scale phased arrays. This opens up new opportunities in both interactive holography and virtual and augmented reality (VR and AR). To achieve our goals, we made several advances outlined below. \n\nIntellectual Merit: We designed and developed an independent control of phase and amplitude for each radiating element of the NPA. In our approach, the optical power is distributed on-chip using optical waveguides and directional couplers and radiated by antenna elements based on gratings. To adjust the phase of each element of the array, we have used the thermo-optic coefficient of silicon nitride and an appropriate heater design to achieve the desired phase shift between 0 and 360 degrees for each element of the array.  We use slow light to reduce the power required by each element of the array and facilitate scaling to large arrays. We have optimized complex waveguide Bragg gratings to maximize the slow-light effect and we have successfully demonstrated this experimentally. The optical chip is controlled by a separate electronic chip which provides the control and feedback to each element of the array. The electronic and optical chips are flip-chip bonded to each other. We have fabricated 1D optical phased arrays (OPAs) with passive phase shifts and demonstrated the beam steering in the far field. We have also been able to fabricate a 2D 64 x 64 OPA and are in the process of optimizing the light distribution to all the elements of the array.\n\nTo create holographic images for VR with a NPA, we needed to precisely control the per-element phase. Thus, we developed a novel current driver circuit with feedback control for NPAs using thermo-optic phase-shifters. Yet, realizing high-resolution and wide field of view requires that: an individual array unit be less than 15&mu;m on a side; it must be capable of sourcing 2.6mA of current; and the individual array elements must be set and reset in times on the order of 10&mu;s. These system requirements together posed a major design challenge because the size of the array unit is at the cutting edge of modern chip-level integration technology. We are pleased to report that we have successfully developed a current driver circuit capable of controlling local temperature in an OPA with unprecedented speed and precision using a deeply-scaled submicron CMOS process. The control circuit operates in two phases: sensing temperature feedback signal and sourcing current. As such, only a single electrical contact is required between the optical part of the NPA and its driver chip for each pixel. Our design is the first fully-scalable NPA system architecture integrated with an independent phase control feedback circuit.\n\nWe have successfully designed and implemented an integrated light source NPA in a small form factor (each array element side measures 15&mu;m), and with a very high refresh rate (100 kHz), well-suited for multi-focal planes with dynamic content. However, since our design is built on a thermo-optic effect with very small array elements, there is inter-element thermal crosstalk that leads to significant degradation of the output image. To address the thermal proximity effect, we have developed and validated several novel proximity effect correction methods for NPA holographic displays at both far-field distances (Fraunhofer holograms) as well as closer distances (Fresnel holograms). Our methods can correct the thermal proximity effect for Fresnel and Fraunhofer holograms on the NPAs when realistic levels of proximity effect are present.\n\nBroader Impacts: We note that we have submitted three patents, detailed in our Final Report, on the basis of the above work. We have also made several other advances that are synergistic to this project. To maximize the visual effectiveness of holographic displays, it is useful to use foveated rendering to mimic the distribution of the photoreceptors in the human visual system. We have developed novel GPU-based foveated rendering techniques for point clouds, meshes, videos, and light fields that are informed by user studies. Our research on eye-dominance-guided foveated rendering enables rendering the scene at a lower foveation level (with higher detail) for the dominant eye than the non-dominant eye. We have also worked on characterizing the desired scaling of patterns at higher eccentricities, so that they can be perceived within a similar amount of time as in the central vision. We are also exploring applications of holographic display technology, such as AR-based procedures in medicine. Specifically, we have developed an AR system to assist physicians in the placement of an external ventricular drain, a common&mdash;yet sometimes risky&mdash;procedure used to relieve the build-up of cerebrospinal fluid in the brain. Wearing an AR headset, a surgeon is able to virtually \"see\" both the location of the catheter\u2019s tip and also see important patient data available from a CT scan.\n\n \n\n\t\t\t\t\tLast Modified: 09/28/2020\n\n\t\t\t\t\tSubmitted by: Amitabh Varshney"
 }
}