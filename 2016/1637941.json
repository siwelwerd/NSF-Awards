{
 "awd_id": "1637941",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Real-Time Semantic Computer Vision for Co-Robotics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 719116.0,
 "awd_amount": 727116.0,
 "awd_min_amd_letter_date": "2016-08-18",
 "awd_max_amd_letter_date": "2018-04-13",
 "awd_abstract_narration": "This project develops real-time object recognition algorithms that generate extensive semantic object descriptions as a side effect of recognition. This side-information includes perceived object costs, attributes (object properties), and affordances (actions afforded by objects). With these, the act of recognizing a \"door knob\" would automatically produce the information that this is a \"flexible\" object, \"made of metal,\" which \"can be grasped\" and \"can be twisted,\" but \"cannot be eaten.\" For robotics, this information is sometimes more important than the recognition of the object itself. The project enables robots to perform zero shot learning, e.g. learn to recognize door knobs by simply being told that these are objects that \"are flexible, made of metal, can be grasped and twisted but not eaten.\" The research has applicability in areas such as manufacturing, intelligent systems, assisted living, and homeland security. Educationally, the project provides an exciting opportunity for undergraduate research.\r\n\r\nThis research develops new methods for top-down (task-driven) regularization of deep learning algorithms, though a combination of structural and loss-based regularizers. Structural regularizers constrain object and scene recognition models to guarantee speed and automatic generation of rich mid-level semantic (MLS) descriptions as a side effect of recognition. Loss-based regularizers penalize errors in the multiple semantic outputs of these models, enabling simultaneously high performance in object recognition, MLS predictions, and zero-shot learning. The resulting learning algorithms will endow robots with human-like abilities to infer rich MLS descriptions of objects and scenes as a \"side effect\" of object recognition and scene classification, in real-time. These contributions will be developed in the context of a new co-robotics problem, person-following unmanned aerial vehicles, where computer vision plays a mission critical role for tasks such as control and semantic motion planning but whose requirements in terms of speed and MLS inference are far superior to what is feasible today.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nuno",
   "pi_last_name": "Vasconcelos",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Nuno M Vasconcelos",
   "pi_email_addr": "nuno@ece.ucsd.edu",
   "nsf_id": "000104017",
   "pi_start_date": "2016-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-San Diego",
  "inst_street_address": "9500 GILMAN DR",
  "inst_street_address_2": "",
  "inst_city_name": "LA JOLLA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8585344896",
  "inst_zip_code": "920930021",
  "inst_country_name": "United States",
  "cong_dist_code": "50",
  "st_cong_dist_code": "CA50",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SAN DIEGO",
  "org_prnt_uei_num": "",
  "org_uei_num": "UYTTZT6G9DT1"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-San Diego",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "920930934",
  "perf_ctry_code": "US",
  "perf_cong_dist": "50",
  "perf_st_cong_dist": "CA50",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 719116.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 8000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project addressed the design of deep learning systems for computer vision and robotics. Many contributions resulted from the prject, in the areas of object detection, universal and adaptive neural networks, low-complexity and low precision networks, multiview objet recognition, action recognition, adversarial attacks, and mitigation of dataset biases.</p>\n<p>Figure 1 illustrates one of the major contributions, the cascade R-CNN object detector. This is a state of the art system for object detection, a critical problem for computer vision and of interest for many applications, from the detection of pedestrains and road objects by self-driving cars to the detection of tumors in medical images. The figure shows the bounding boxes of the detections produced by the cascade R-CNN on a complex street scene, including people, backpacks, cars, bycicles, traffic lights, etc. The cascade R-CNN can detect all these objects with greater accuracy than was previously possible. It relies on a two stage detection architecture. The first-stage identifies object proposals. The second classifies these into the bounding boxes that locate the different objects in the scene. The main innovation is a new cascade architecture for the second stage, which substantially increases the accuracy of the detector.</p>\n<p>Figure 2 illustrates another contribution, the release of a new dataset for adversarial attacks on neural networks. Adversarial attacks test the robustness of these networks by introducing perturbations in images that induce the network in error. In the literature, these perturbations are usually artificial, i.e. created by mathematical manipulation. The figure illustrates a new procedure to produce attacks in the real world, i.e. better matched to those that the network will face in real world operation. The perturbations are created by collecting images from many view angles, using drones, and choosing the views that induce the network in error. A dataset of such attacks, plus ground truth for human performance to allow comparison between networks and humans, is available from&nbsp;http://svcl.ucsd.edu/projects/OOWL/</p>\n<p>Figure 3 illustrates a contribution of the project in the area of adaptive neural networks. A new domain adaptation algorithm has been proposed to enable the adapation of a network to an image domain on which it has not been trained. In the example of the figure, a network trained to segment street scene images in a computer game environment (where data is plentiful) is adapted to images of real street scenes (for which segmentation ground-truth is very difficult to produce).&nbsp;&nbsp;The new algorithm is based on a novel bidirectional learning framework, composed by an image translation model and a segmentation adaptation model that are learned alternatively, to promote each other. The new algorithm substantally improved on the performance of previous domain adaptation approaches.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/19/2020<br>\n\t\t\t\t\tModified by: Nuno&nbsp;M&nbsp;Vasconcelos</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603138022636_driving_demo_Moment2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603138022636_driving_demo_Moment2--rgov-800width.jpg\" title=\"Figure 1\"><img src=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603138022636_driving_demo_Moment2--rgov-66x44.jpg\" alt=\"Figure 1\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Object Detections by the Cascade R-CNN</div>\n<div class=\"imageCredit\">Nuno Vasconcelos</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Nuno&nbsp;M&nbsp;Vasconcelos</div>\n<div class=\"imageTitle\">Figure 1</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603138703114_setup--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603138703114_setup--rgov-800width.jpg\" title=\"Figure 2\"><img src=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603138703114_setup--rgov-66x44.jpg\" alt=\"Figure 2\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Drones are used to collect many object views and create a dataset of real-world adversarial attacks on neural networks</div>\n<div class=\"imageCredit\">Nuno Vasconcelos</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Nuno&nbsp;M&nbsp;Vasconcelos</div>\n<div class=\"imageTitle\">Figure 2</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603139543605_domain-adaptation--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603139543605_domain-adaptation--rgov-800width.jpg\" title=\"Figure 3\"><img src=\"/por/images/Reports/POR/2020/1637941/1637941_10451858_1603139543605_domain-adaptation--rgov-66x44.jpg\" alt=\"Figure 3\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Bidirectional  learning for domain adaptation allows the transfer of a segmentation network trained on a gaming environment to the segmentation of real scenes.</div>\n<div class=\"imageCredit\">Nuno Vasconcelos</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Nuno&nbsp;M&nbsp;Vasconcelos</div>\n<div class=\"imageTitle\">Figure 3</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project addressed the design of deep learning systems for computer vision and robotics. Many contributions resulted from the prject, in the areas of object detection, universal and adaptive neural networks, low-complexity and low precision networks, multiview objet recognition, action recognition, adversarial attacks, and mitigation of dataset biases.\n\nFigure 1 illustrates one of the major contributions, the cascade R-CNN object detector. This is a state of the art system for object detection, a critical problem for computer vision and of interest for many applications, from the detection of pedestrains and road objects by self-driving cars to the detection of tumors in medical images. The figure shows the bounding boxes of the detections produced by the cascade R-CNN on a complex street scene, including people, backpacks, cars, bycicles, traffic lights, etc. The cascade R-CNN can detect all these objects with greater accuracy than was previously possible. It relies on a two stage detection architecture. The first-stage identifies object proposals. The second classifies these into the bounding boxes that locate the different objects in the scene. The main innovation is a new cascade architecture for the second stage, which substantially increases the accuracy of the detector.\n\nFigure 2 illustrates another contribution, the release of a new dataset for adversarial attacks on neural networks. Adversarial attacks test the robustness of these networks by introducing perturbations in images that induce the network in error. In the literature, these perturbations are usually artificial, i.e. created by mathematical manipulation. The figure illustrates a new procedure to produce attacks in the real world, i.e. better matched to those that the network will face in real world operation. The perturbations are created by collecting images from many view angles, using drones, and choosing the views that induce the network in error. A dataset of such attacks, plus ground truth for human performance to allow comparison between networks and humans, is available from http://svcl.ucsd.edu/projects/OOWL/\n\nFigure 3 illustrates a contribution of the project in the area of adaptive neural networks. A new domain adaptation algorithm has been proposed to enable the adapation of a network to an image domain on which it has not been trained. In the example of the figure, a network trained to segment street scene images in a computer game environment (where data is plentiful) is adapted to images of real street scenes (for which segmentation ground-truth is very difficult to produce).  The new algorithm is based on a novel bidirectional learning framework, composed by an image translation model and a segmentation adaptation model that are learned alternatively, to promote each other. The new algorithm substantally improved on the performance of previous domain adaptation approaches.\n\n \n\n\t\t\t\t\tLast Modified: 10/19/2020\n\n\t\t\t\t\tSubmitted by: Nuno M Vasconcelos"
 }
}