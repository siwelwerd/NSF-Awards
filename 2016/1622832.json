{
 "awd_id": "1622832",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Elastic Multi-layer Memcached Tiers",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Matt Mutka",
 "awd_eff_date": "2016-06-01",
 "awd_exp_date": "2019-05-31",
 "tot_intn_awd_amt": 257166.0,
 "awd_amount": 257166.0,
 "awd_min_amd_letter_date": "2016-05-11",
 "awd_max_amd_letter_date": "2016-05-11",
 "awd_abstract_narration": "Facebook and YouTube have massive databases containing many objects.\r\nObjects (e.g., pictures, videos) are read from these databases and presented\r\nto users.  These databases use slower and cheaper I/O devices.  Repeated\r\ndatabase queries are also slow, so companies cache popular objects in\r\nvolatile memory (RAM).  As RAM is about 1000x faster than I/O, queries to\r\npopular objects are serviced faster.  A single computer cannot efficiently\r\nuse too much RAM, so a distributed memory caching system called \"Memcached\"\r\nis utilized.  Memcached creates a cluster of nodes, forming a key-value\r\ndatabase in faster memory.\r\n\r\nMemcached's simple architecture led to its popularity, but is also its\r\nAchilles' heel.  When loads increase, more caching nodes are needed, but it\r\nis difficult to add new nodes and redistribute the cached data to more\r\nnodes.  Similarly, when loads reduce, it is harder to shut down some nodes\r\nand migrate their cached data to fewer nodes; scaling down the cluster helps\r\nreduce the large energy costs they consume.  Any changes to the number of\r\nMemcached nodes result in throwing out most cached data, leading to lengthy\r\nperiods where the distributed caches have to be slowly re-warmed up from the\r\nbackend database.\r\n\r\nThis EArly-concept Grants for Exploratory Research (EAGER) project investigates techniques to scale Memcached clusters\r\nsmoothly, without any transient performance degradations.  The project also\r\nintroduces an intermediate Flash-based storage tier between the memory nodes\r\nand the backend database, to help reduce high latencies to the backend\r\ndatabase and help the smooth scaling of the Memcached cluster.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anshul",
   "pi_last_name": "Gandhi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anshul Gandhi",
   "pi_email_addr": "anshul@cs.stonybrook.edu",
   "nsf_id": "000651407",
   "pi_start_date": "2016-05-11",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Erez",
   "pi_last_name": "Zadok",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Erez Zadok",
   "pi_email_addr": "ezk@cs.stonybrook.edu",
   "nsf_id": "000182603",
   "pi_start_date": "2016-05-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "WEST 5510 FRK MEL LIB",
  "perf_city_name": "Stony Brook",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117943362",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 257166.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-cc7299c3-7fff-d12b-f56b-b1f987f26025\"> </span></p>\n<p dir=\"ltr\"><span>Memory caching tiers are widely employed by many online service providers, including Facebook and YouTube, to reduce latency and alleviate load at the database tier. Unfortunately, memory caching tiers are stateful and thus cannot easily be scaled dynamically in response to changes in demand due to resultant cache misses. As a result, current static Memcached deployments that face dynamic workload demand lead to significant waste in cost and power.</span><span><br /></span></p>\n<p dir=\"ltr\"><span>This project developed an elastic Memcached system, ElMem. The ElMem system, publicly available on the PI's lab website, is built on top of stock Memcached, and is thus easily deployable in practice. ElMem works by intelligently moving hot cached data between nodes prior to scaling, thus enabling seamless scale-up or scale-down of cache nodes without the associated cache miss penalty. The key enabler of this mechanism is our FuseCache algorithm, that efficiently identified the subset of hot cached data to be migrated between cache nodes. FuseCache leverages the median-of-medians algorithm to achieve running time which is within a logarithmic factor of the theoretical lower bound. Our experimental evaluation results illustrated the significant (up to 30%) savings in cost and energy enabled by ElMem in cloud deployments.</span></p>\n<p dir=\"ltr\"><span>We have published our system design and results in leading distributed systems and storage systems venues, and have further disseminated our results via invited talks at Universities and research labs. We integrated topics from this project into many of our graduate courses, including the energy-efficient systems graduate course. The systems component of the project provided valuable hands-on experience for the involved Ph.D. and M.S. students. Several of the students, including Masters students, presented components of the ElMem work via talks and poster presentations at conferences.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/08/2019<br>\n\t\t\t\t\tModified by: Anshul&nbsp;Gandhi</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nMemory caching tiers are widely employed by many online service providers, including Facebook and YouTube, to reduce latency and alleviate load at the database tier. Unfortunately, memory caching tiers are stateful and thus cannot easily be scaled dynamically in response to changes in demand due to resultant cache misses. As a result, current static Memcached deployments that face dynamic workload demand lead to significant waste in cost and power.\n\nThis project developed an elastic Memcached system, ElMem. The ElMem system, publicly available on the PI's lab website, is built on top of stock Memcached, and is thus easily deployable in practice. ElMem works by intelligently moving hot cached data between nodes prior to scaling, thus enabling seamless scale-up or scale-down of cache nodes without the associated cache miss penalty. The key enabler of this mechanism is our FuseCache algorithm, that efficiently identified the subset of hot cached data to be migrated between cache nodes. FuseCache leverages the median-of-medians algorithm to achieve running time which is within a logarithmic factor of the theoretical lower bound. Our experimental evaluation results illustrated the significant (up to 30%) savings in cost and energy enabled by ElMem in cloud deployments.\nWe have published our system design and results in leading distributed systems and storage systems venues, and have further disseminated our results via invited talks at Universities and research labs. We integrated topics from this project into many of our graduate courses, including the energy-efficient systems graduate course. The systems component of the project provided valuable hands-on experience for the involved Ph.D. and M.S. students. Several of the students, including Masters students, presented components of the ElMem work via talks and poster presentations at conferences.\n\n \n\n\t\t\t\t\tLast Modified: 06/08/2019\n\n\t\t\t\t\tSubmitted by: Anshul Gandhi"
 }
}