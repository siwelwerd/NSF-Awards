{
 "awd_id": "1521539",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Collaborative Research: Expeditions in Computing:  The Science of Deep Specification",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2015-12-15",
 "awd_exp_date": "2022-11-30",
 "tot_intn_awd_amt": 3351811.0,
 "awd_amount": 3375811.0,
 "awd_min_amd_letter_date": "2015-12-17",
 "awd_max_amd_letter_date": "2017-07-24",
 "awd_abstract_narration": "In our interconnected world, software bugs and security vulnerabilities pose enormous costs and risks.  The Deep Specification (\"DeepSpec\", deepspec.org) project addresses this problem by showing how to build software that does what it is supposed to do, no less and (just as important) no more: No unintended backdoors that allow hackers in, no bugs that crash your app, your computer, or your car.  \"What the software is supposed to do\" is called its specification.  The DeepSpec project will develop new science, technology, and tools--for specifying what programs should do, for building programs that conform to those specifications, and for verifying that programs do behave exactly as intended.  The key enabling technology for this effort is modern interactive proof assistants, which support rigorous mathematical proofs about complex software artifacts.  Project activities will focus on core software-systems infrastructure such as operating systems, programming-language compilers, and computer chips, with applications such as elections and voting systems, cars, and smartphones.\r\n\r\n\r\nBetter-specified and better-behaved software will benefit us all.  Many high-profile security breaches and low-profile intrusions use software bugs as their entry points.  Building on decades of previous work, DeepSpec will advance methods for specifying and verifying software so they can be used by the software industry.  The project will include workshops and summer schools to bring in industrial collaborators for technology transfer.  But the broader use of specifications in engineering also requires software engineers trained in specification and verification--so DeepSpec has a major component in education: the development of introductory and intermediate curriculum in how to think logically about specifications, how to use specifications in building systems-software components, or how to connect to such components.  The education component includes textbook and on-line course material to be developed at Princeton, Penn, MIT, and Yale, and to be available for use by students and instructors worldwide.  There will also be a summer school to train the teachers who can bring this science to colleges nationwide.\r\n\r\n\r\nAbstraction and modularity underlie all successful hardware and software systems: We build complex artifacts by decomposing them into parts that can be understood separately. Modular decomposition depends crucially on the artful choice of interfaces between pieces. As these interfaces become more expressive, we think of them as specifications of components or layers. Rich specifications based on formal logic are little used in industry today, but a practical platform for working with them will significantly reduce the costs of system implementation and evolution by identifying vulnerabilities, helping programmers understand the behavior of new components, facilitating rigorous change-impact analysis, and supporting maintainable machine-checked verifications that components are correct and fit together correctly.   This Expedition focuses on a particularly rich class of specifications, \"deep specifications.\" These impose strong functional correctness requirements on individual components such that they connect together with rigorous composition theorems. The Expedition's goal is to focus the efforts of the programming languages and formal methods communities on developing and using deep specifications in the large.  Working in a formal proof management system, the project will concentrate particularly on connecting infrastructure components together at specification interfaces: compilers, operating systems, program analysis tools, and processor architectures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stephanie",
   "pi_last_name": "Weirich",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Stephanie C Weirich",
   "pi_email_addr": "sweirich@cis.upenn.edu",
   "nsf_id": "000368211",
   "pi_start_date": "2015-12-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Benjamin",
   "pi_last_name": "Pierce",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Benjamin C Pierce",
   "pi_email_addr": "bcpierce@cis.upenn.edu",
   "nsf_id": "000452070",
   "pi_start_date": "2015-12-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Stephan",
   "pi_last_name": "Zdancewic",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Stephan A Zdancewic",
   "pi_email_addr": "stevez@cis.upenn.edu",
   "nsf_id": "000220116",
   "pi_start_date": "2015-12-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Pennsylvania",
  "inst_street_address": "3451 WALNUT ST STE 440A",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158987293",
  "inst_zip_code": "191046205",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE",
  "org_prnt_uei_num": "GM1XX56LEP58",
  "org_uei_num": "GM1XX56LEP58"
 },
 "perf_inst": {
  "perf_inst_name": "University of Pennsylvania",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191046205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "772300",
   "pgm_ele_name": "Expeditions in Computing"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7723",
   "pgm_ref_txt": "EXPERIMENTAL EXPEDITIONS"
  },
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 2179742.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 1196069.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-56bfa556-7fff-25c1-664f-300660642f84\">\n<p dir=\"ltr\"><span>Bugs in computer software and hardware are collectively extremely costly to society today.&nbsp; Mathematical techniques for proving the correctness of these systems are promising but have not been deployed widely so far.&nbsp; The NSF Expedition on the Science of Deep Specification studied foundations for more complete and convincing proof of realistic systems.&nbsp; The project name was based on coined terminology of \"deep specification\" to crystallize ideas from the research community -- specifications giving very detailed requirements, with associated evidence that can be checked automatically for complete software-hardware systems.</span></p>\n<br />\n<p dir=\"ltr\"><span>The team across four universities developed new methods for both proving individual parts of systems and connecting those proofs together into full-system results.&nbsp; The individual parts studied included (in order of lower-level pieces to higher-level pieces that build on them) computer processors and other hardware, the C, LLVM and Haskell programming language and its compilers, operating systems, code libraries for purposes like networking, and application software like network servers.&nbsp; Cross-cutting approaches for connecting these proofs included the development of interaction trees, a specification formalism for systems that engage in unpredictable input and output with the external world.&nbsp; Specific demonstration systems included a web server with a proof that it implements the associated protocol correctly, where reasoning had to be pushed through the levels of the application, the programming language, and the operating system.</span></p>\n<br />\n<p dir=\"ltr\"><span>The Expedition also helped prepare the next generations of engineers to apply these ideas, through (as of this writing) two summer schools, and several REU summer sessions, serving about 200 students total.&nbsp; The team also extended a number of popular online books presenting the foundational and practical material, which were in turn used in a number of revamped course offerings that introduced mechanized specifications to traditional subjects like compilers and operating systems.</span></p>\n<br />\n<p dir=\"ltr\"><span>Highlights from Penn's contribution include the VeLLVM project, the QuickChick project, the hs-to-coq project, and the DeepSpec web server.</span></p>\n<br />\n<p dir=\"ltr\"><span>The VeLLVM project has created a formal specification of the LLVM IR, entirely implemented in the Coq interactive theorem prover. In contrast to previous approaches, which use relationally-specified operational semantics, this new semantics is based on monadic interpretation of </span><span>interaction trees</span><span>, a data structure developed as part of the DeepSpec project, and used rather widely.&nbsp; VeLLVM provides a more compositional approach to defining language semantics while retaining the ability to extract an executable interpreter. Our semantics handles many of the LLVM IR&rsquo;s non-trivial language features and is constructed modularly in terms of event handlers, including those that deal with nondeterminism in the specification. We show how this semantics admits compositional reasoning principles derived from the interaction trees equational theory of weak bisimulation, which we extend here to better deal with nondeterminism, and we use them to prove that the extracted reference interpreter faithfully refines the semantic model. We validate the correctness of the semantics by evaluating it on unit tests and LLVM IR programs generated by HELIX, a non-trivial optimizing compiler targeting numerical computations.</span></p>\n<br />\n<p dir=\"ltr\"><span>Interaction trees also played an important role in other verification efforts.&nbsp; For instance, we built a networked key-value server, implemented in C and formally verified in Coq. The server interacts with clients using a subset of the HTTP/1.1 protocol and is specified and verified using interaction trees and the Verified Software Toolchain. The codebase includes a reusable and fully verified C string library that provides 17 standard POSIX string functions and 17 general purpose non-POSIX string functions. For the KVServer socket system calls, we establish a refinement relation between specifications at user-space level and at CertiKOS kernel-space level.</span></p>\n<br />\n<p dir=\"ltr\"><span>The QuickChick tool, developed during this project, is the first framework in Coq for property-based testing in the style of Haskell&rsquo;s famous QuickCheck library. QuickChick aims to bridge the gap between lightweight software testing techniques and full-on formal verification by offering developers the opportunity to write specifications in a common environment and rigorously testing software against these specs before attempting to prove the correspondence. QuickChick is now among the most popular tools based on Coq, and a new textbook, &ldquo;QuickChick: Property-Based Testing in Coq,&rdquo; is being used at institutions across the world.</span></p>\n<br />\n<p dir=\"ltr\"><span>The hs-to-coq tool, developed as part of this project, enabled the specification and verification of parts of the Glasgow Haskell Compiler and its libraries. In this work, the team developed deep specifications about this tool from a number of sources, including existing testing frameworks, mathematical models of the programming structure, and source code comments describing programming invariants. This project demonstrated that existing code and informal specifications could be adapted for the verification of industry-scale Haskell systems.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/07/2023<br>\n\t\t\t\t\tModified by: Stephanie&nbsp;C&nbsp;Weirich</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nBugs in computer software and hardware are collectively extremely costly to society today.  Mathematical techniques for proving the correctness of these systems are promising but have not been deployed widely so far.  The NSF Expedition on the Science of Deep Specification studied foundations for more complete and convincing proof of realistic systems.  The project name was based on coined terminology of \"deep specification\" to crystallize ideas from the research community -- specifications giving very detailed requirements, with associated evidence that can be checked automatically for complete software-hardware systems.\n\n\nThe team across four universities developed new methods for both proving individual parts of systems and connecting those proofs together into full-system results.  The individual parts studied included (in order of lower-level pieces to higher-level pieces that build on them) computer processors and other hardware, the C, LLVM and Haskell programming language and its compilers, operating systems, code libraries for purposes like networking, and application software like network servers.  Cross-cutting approaches for connecting these proofs included the development of interaction trees, a specification formalism for systems that engage in unpredictable input and output with the external world.  Specific demonstration systems included a web server with a proof that it implements the associated protocol correctly, where reasoning had to be pushed through the levels of the application, the programming language, and the operating system.\n\n\nThe Expedition also helped prepare the next generations of engineers to apply these ideas, through (as of this writing) two summer schools, and several REU summer sessions, serving about 200 students total.  The team also extended a number of popular online books presenting the foundational and practical material, which were in turn used in a number of revamped course offerings that introduced mechanized specifications to traditional subjects like compilers and operating systems.\n\n\nHighlights from Penn's contribution include the VeLLVM project, the QuickChick project, the hs-to-coq project, and the DeepSpec web server.\n\n\nThe VeLLVM project has created a formal specification of the LLVM IR, entirely implemented in the Coq interactive theorem prover. In contrast to previous approaches, which use relationally-specified operational semantics, this new semantics is based on monadic interpretation of interaction trees, a data structure developed as part of the DeepSpec project, and used rather widely.  VeLLVM provides a more compositional approach to defining language semantics while retaining the ability to extract an executable interpreter. Our semantics handles many of the LLVM IR\u2019s non-trivial language features and is constructed modularly in terms of event handlers, including those that deal with nondeterminism in the specification. We show how this semantics admits compositional reasoning principles derived from the interaction trees equational theory of weak bisimulation, which we extend here to better deal with nondeterminism, and we use them to prove that the extracted reference interpreter faithfully refines the semantic model. We validate the correctness of the semantics by evaluating it on unit tests and LLVM IR programs generated by HELIX, a non-trivial optimizing compiler targeting numerical computations.\n\n\nInteraction trees also played an important role in other verification efforts.  For instance, we built a networked key-value server, implemented in C and formally verified in Coq. The server interacts with clients using a subset of the HTTP/1.1 protocol and is specified and verified using interaction trees and the Verified Software Toolchain. The codebase includes a reusable and fully verified C string library that provides 17 standard POSIX string functions and 17 general purpose non-POSIX string functions. For the KVServer socket system calls, we establish a refinement relation between specifications at user-space level and at CertiKOS kernel-space level.\n\n\nThe QuickChick tool, developed during this project, is the first framework in Coq for property-based testing in the style of Haskell\u2019s famous QuickCheck library. QuickChick aims to bridge the gap between lightweight software testing techniques and full-on formal verification by offering developers the opportunity to write specifications in a common environment and rigorously testing software against these specs before attempting to prove the correspondence. QuickChick is now among the most popular tools based on Coq, and a new textbook, \"QuickChick: Property-Based Testing in Coq,\" is being used at institutions across the world.\n\n\nThe hs-to-coq tool, developed as part of this project, enabled the specification and verification of parts of the Glasgow Haskell Compiler and its libraries. In this work, the team developed deep specifications about this tool from a number of sources, including existing testing frameworks, mathematical models of the programming structure, and source code comments describing programming invariants. This project demonstrated that existing code and informal specifications could be adapted for the verification of industry-scale Haskell systems.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 02/07/2023\n\n\t\t\t\t\tSubmitted by: Stephanie C Weirich"
 }
}