{
 "awd_id": "1563078",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Medium: Collaborative Research: From Volume to Velocity: Big Data Analytics in Near-Realtime",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 666665.0,
 "awd_amount": 666665.0,
 "awd_min_amd_letter_date": "2016-07-21",
 "awd_max_amd_letter_date": "2016-07-21",
 "awd_abstract_narration": "Most existing techniques and systems for data analytics focus exclusively on the volume side of the common definition of Big Data as volume, velocity and variety. In contrast, there are clear indications that the velocity component will become the dominant requirement in the near future, most significantly, because of the proliferation of mobile devices across the planet. This is compounded by the fact that the freshest data often contains the most valuable information and that users have grown accustomed to data that is deeply analyzed and processed by sophisticated machine learning (ML) techniques, to enable their \"always on\" experience. In most mobile interactions, for example, the physical locations of one or potentially many users play a role, but the system needs to process the actual locations, not the ones from ten minutes ago. Many similar use cases exist in finance, intelligence and other domains. In all of them, the desires for fresh and for highly processed data are in a fundamental tension, as high quality analysis is computationally expensive and often done in large batches. The intellectual merits of this project are to investigate a combination of new ideas to address this challenge, spanning machine learning algorithms, specialized hardware accelerators, domain-specific languages, and compiler technology. The project's broader significance and importance are to pave the way for new kinds of high-velocity big-data analytics, which have the potential to revolutionize the way that people interact with the world.\r\n\r\nThe project investigates new incremental ML primitives and new algorithms that can trade off speed with precision, but retain provable guarantees. Novel DSLs (domain-specific languages) make such algorithms and techniques available to application developers, and new compilation techniques map DSL programs to specialized accelerators. In particular, the project shows how through these novel compilation techniques, machine learning algorithms can especially benefit from hardware acceleration with FPGAs. Finally, the project investigates new compilation techniques for end-to-end data path optimizations, including conversion of incoming data from external formats into DSL data structures, and transferring data between network interfaces and FPGA accelerators. Tying these new ideas and techniques together, this project will result in an integrated full-stack solution (spanning algorithms, languages, compilers, and architecture) to the problem of achieving high velocity in big data analytics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Oyekunle",
   "pi_last_name": "Olukotun",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Oyekunle A Olukotun",
   "pi_email_addr": "kunle@stanford.edu",
   "nsf_id": "000320046",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Re",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Re",
   "pi_email_addr": "chrismre@cs.stanford.edu",
   "nsf_id": "000555316",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall, Gates 302",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943059025",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 666665.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-a6de742f-7fff-96db-6b8c-a5bb1b70a2d7\">\n<p dir=\"ltr\"><span>The major goals of this project were to address the research challenges posed by high-velocity, i.e., near-real-time, big data processing. As the desire for fresh data and highly processed data are in fundamental tension, scale-out techniques usually employed for volume-oriented workloads are no longer sufficient. During the course of this project, these challenges were addressed using combinations of novel dataflow computer architectures, novel compiler technology, and novel system development methodologies.</span></p>\n<br />\n<p dir=\"ltr\"><span>The intellectual merits of the project include new compiler intermediate representations (IRs) based on novel, expressive type and effect systems (&ldquo;reachability types&rsquo;), new techniques to compile end-to-end data processing pipelines that combine SQL-style relational processing with machine-learning kernels build on tensor operations, new techniques for high-performance spatial queries on geo-located data, new techniques for incrementalization of expressive correlated queries on streaming workloads, as well as new techniques for efficient dynamic de-optimization and re-optimization of such pipelines to adapt to changes in the environment or the workload. In addition, new reconfigurable dataflow architectures (RDAs) that are both flexible and efficient for big data processing and new </span><span>compiler technology to translate the data processing IRs to explicit dataflow graph programming paradigms required for RDAs.</span></p>\n<br />\n<p dir=\"ltr\"><span>The broader impacts of the project include mentoring of students, including undergraduate students and underrepresented minorities.</span></p>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/11/2022<br>\n\t\t\t\t\tModified by: Oyekunle&nbsp;A&nbsp;Olukotun</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nThe major goals of this project were to address the research challenges posed by high-velocity, i.e., near-real-time, big data processing. As the desire for fresh data and highly processed data are in fundamental tension, scale-out techniques usually employed for volume-oriented workloads are no longer sufficient. During the course of this project, these challenges were addressed using combinations of novel dataflow computer architectures, novel compiler technology, and novel system development methodologies.\n\n\nThe intellectual merits of the project include new compiler intermediate representations (IRs) based on novel, expressive type and effect systems (\"reachability types\u2019), new techniques to compile end-to-end data processing pipelines that combine SQL-style relational processing with machine-learning kernels build on tensor operations, new techniques for high-performance spatial queries on geo-located data, new techniques for incrementalization of expressive correlated queries on streaming workloads, as well as new techniques for efficient dynamic de-optimization and re-optimization of such pipelines to adapt to changes in the environment or the workload. In addition, new reconfigurable dataflow architectures (RDAs) that are both flexible and efficient for big data processing and new compiler technology to translate the data processing IRs to explicit dataflow graph programming paradigms required for RDAs.\n\n\nThe broader impacts of the project include mentoring of students, including undergraduate students and underrepresented minorities.\n\n\n \n\n\t\t\t\t\tLast Modified: 04/11/2022\n\n\t\t\t\t\tSubmitted by: Oyekunle A Olukotun"
 }
}