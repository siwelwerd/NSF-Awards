{
 "awd_id": "1622589",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SCH: INT: Collaborative Research: Computer Guided Laparoscopy Training",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032922568",
 "po_email": "wnilsen@nsf.gov",
 "po_sign_block_name": "Wendy Nilsen",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2021-11-30",
 "tot_intn_awd_amt": 1118923.0,
 "awd_amount": 1118923.0,
 "awd_min_amd_letter_date": "2016-08-01",
 "awd_max_amd_letter_date": "2016-08-01",
 "awd_abstract_narration": "Laparoscopic surgery, when performed by a well-trained surgeon, is a remarkably effective procedure that minimizes complications associated with open incisions, blood loss and post-operative pain. It also reduces recovery time. However, the procedure is more challenging than conventional surgery due to restricted vision, hand-eye coordination problems, limited working space, and lack of tactile sensation. Therefore, effective training and guidance methods are needed to minimize the potential risks inherent in such procedures. The goal of this project is to develop and validate techniques for computer-guided laparoscopic surgical training in a simulated, non-patient based environment. A computer-aided surgical trainer (CAST) will physically guide trainees' instruments during surgical skills practice sessions by utilizing assistive force with augmented reality displays. Guided training will be validated through a pilot experimental study, in which the expertise of computer-guided trainees will be compared to that of instructor-guided trainees. Data such as the time it takes a trainee to execute a particular surgical task, how accurate he or she is, etc., will be collected to analyze task performance precisely and objectively. New scientific methods for motion trajectory planning and path following using assistive force and augmented reality techniques will result from this work. It is anticipated that computer-guided practice will speed up learning and reinforce appropriate techniques, ultimately, leading to better surgical outcomes and improved patient safety. The CAST system should serve as a sophisticated, yet still low-cost, training solution for fundamental medical skills training.  \r\n\r\nThe specific objectives are a) to refine and implement a memory- and time-efficient hybrid offline-online optimal path planner for computer-guided training of basic laparoscopic skills. In this task, collision-free trajectory planning methods (such as those used in robotics) will be generated by incorporating offline-online hybrid techniques with memory and computational time efficient path repository. Thus, basic laparoscopic tasks can be planned and guided automatically, using haptic force and augmented reality visualization; b) to design and implement an intelligent, adaptive guidance controller for surgical space navigation, where a fuzzy logic and machine learning-based methods will be developed that will take into account trainees' skill levels so that optimal amount of training assistance can be provided in mastering surgical tasks; c) to design and implement visual guidance techniques through augmented reality overlays that provide 'navigational' cues, supplementing force-based control of surgical instruments; and d) to validate guided training through a pilot study. In this task, trainees' performance using computer guidance methods will be compared, using statistical analysis, to that of unguided trainees. The principal investigators will aim to increase the participation of undergraduate students, and in particular of underrepresented groups, through collaboration with the well-established programs at both PIs'  institutions and through sponsorship of senior projects and independent study courses.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jerzy",
   "pi_last_name": "Rozenblit",
   "pi_mid_init": "W",
   "pi_sufx_name": "",
   "pi_full_name": "Jerzy W Rozenblit",
   "pi_email_addr": "jerzyr@arizona.edu",
   "nsf_id": "000318949",
   "pi_start_date": "2016-08-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Allan",
   "pi_last_name": "Hamilton",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Allan Hamilton",
   "pi_email_addr": "allan@surgery.arizona.edu",
   "nsf_id": "000680433",
   "pi_start_date": "2016-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Arizona",
  "inst_street_address": "845 N PARK AVE RM 538",
  "inst_street_address_2": "",
  "inst_city_name": "TUCSON",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "5206266000",
  "inst_zip_code": "85721",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "AZ07",
  "org_lgl_bus_name": "UNIVERSITY OF ARIZONA",
  "org_prnt_uei_num": "",
  "org_uei_num": "ED44Y3W6P7B9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Arizona",
  "perf_str_addr": "888 N Euclid Ave",
  "perf_city_name": "TUCSON",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "857210001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "AZ07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801800",
   "pgm_ele_name": "Smart and Connected Health"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8018",
   "pgm_ref_txt": "Smart and Connected Health"
  },
  {
   "pgm_ref_code": "8062",
   "pgm_ref_txt": "SCH Type II: INT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 1118923.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Laparoscopic surgery has been widely performed in the last three decades. Its advantages are minimizing blood loss and post-operative pain with reduced recovery time. However, this surgical technique is more challenging than conventional open surgery due to using special surgical instruments and viewing a 3D operating field on a 2D display. To minimize the potential risks caused by the restricted view, limited working space, hand-eye coordination problems, and the lack of depth perception, a simulation-based training system is required. Throughout this project, we developed a computer-assisted surgical trainer (CAST) which enhances surgical training procedures in non-patient based settings.&nbsp;&nbsp;&nbsp;</p>\n<p>The CAST system provides haptic force and visual guidance with objective assessments for laparoscopic surgery skills training given physical reality-based training environments. The CAST hardware consists of two mechanical fixtures with surgical instruments to mimic actual surgical instrument movements, electronics with motors to provide force guidance, a single camera to replicate a laparoscope, a physical box model to provide various training tasks, and a standard personal computer to manage the entire hardware and software. The CAST software consists of 1) the optMIS module to generate collision free and optimally recommended surgical movements given a training scenario, 2) the optViz system to provide visual guidance, 3) the optGuide module to provide haptic force guidance, and 4) optAssessment to quantify competency objectively in surgical skills acquisition.</p>\n<p>For the optimal path planner (optMIS), we used the open motion planning library (OMPL) to reduce computation time and to consider dynamic environments. The visual guidance (optViz) was realized based on augmented reality (AR) rendering. We overlaid various visual cues such as arrows, posts, and spheres with text guidance messages on a 2D monitor screen to provide intuitive guidance information. We also realized the haptic force guidance (optGuide) by adjusting force adaptively based on trainees? performance. The optGuide monitors movements of surgical instruments performed by trainees and assists them as needed. The optGuide provides (a) attractive force to minimize deviations from a recommended trajectory and (b) assistive force to help a trainee traverse the recommended trajectory. For the force guidance, we developed self-adjusting fuzzy sliding mode controllers to calibrate force for an individual learner who may have different force sensitivity. The optGuide minimizes interventions if trainees perform well so that much control authority rests with them. However, the optGuide provides stronger interventions to correct their actions by applying more force while they perform below expectations. Moreover, we developed an achievable goal-based scoring system (optAssessment) using a hierarchical fuzzy inference system design approach to quantify trainees? performance objectively. By comparing their outcomes with the suggested goals, the scoring system allows them to understand their training progress.</p>\n<p>The main contribution of the proposed system is to provide a hands-on interface for trainees to practice surgical motor skills effectively by utilizing various active guidance schemes. We observed a significant improvement in surgical skills acquisition when they received active guidance. For instance, the force guidance resulted in 64% improvement in deviations and 35% improvement in economy of movement in training outcomes when they performed the \"ring transfer\" task. Results of this project and other findings have been disseminated at international conferences and in peer-reviewed publications.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/27/2022<br>\n\t\t\t\t\tModified by: Jerzy&nbsp;W&nbsp;Rozenblit</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLaparoscopic surgery has been widely performed in the last three decades. Its advantages are minimizing blood loss and post-operative pain with reduced recovery time. However, this surgical technique is more challenging than conventional open surgery due to using special surgical instruments and viewing a 3D operating field on a 2D display. To minimize the potential risks caused by the restricted view, limited working space, hand-eye coordination problems, and the lack of depth perception, a simulation-based training system is required. Throughout this project, we developed a computer-assisted surgical trainer (CAST) which enhances surgical training procedures in non-patient based settings.   \n\nThe CAST system provides haptic force and visual guidance with objective assessments for laparoscopic surgery skills training given physical reality-based training environments. The CAST hardware consists of two mechanical fixtures with surgical instruments to mimic actual surgical instrument movements, electronics with motors to provide force guidance, a single camera to replicate a laparoscope, a physical box model to provide various training tasks, and a standard personal computer to manage the entire hardware and software. The CAST software consists of 1) the optMIS module to generate collision free and optimally recommended surgical movements given a training scenario, 2) the optViz system to provide visual guidance, 3) the optGuide module to provide haptic force guidance, and 4) optAssessment to quantify competency objectively in surgical skills acquisition.\n\nFor the optimal path planner (optMIS), we used the open motion planning library (OMPL) to reduce computation time and to consider dynamic environments. The visual guidance (optViz) was realized based on augmented reality (AR) rendering. We overlaid various visual cues such as arrows, posts, and spheres with text guidance messages on a 2D monitor screen to provide intuitive guidance information. We also realized the haptic force guidance (optGuide) by adjusting force adaptively based on trainees? performance. The optGuide monitors movements of surgical instruments performed by trainees and assists them as needed. The optGuide provides (a) attractive force to minimize deviations from a recommended trajectory and (b) assistive force to help a trainee traverse the recommended trajectory. For the force guidance, we developed self-adjusting fuzzy sliding mode controllers to calibrate force for an individual learner who may have different force sensitivity. The optGuide minimizes interventions if trainees perform well so that much control authority rests with them. However, the optGuide provides stronger interventions to correct their actions by applying more force while they perform below expectations. Moreover, we developed an achievable goal-based scoring system (optAssessment) using a hierarchical fuzzy inference system design approach to quantify trainees? performance objectively. By comparing their outcomes with the suggested goals, the scoring system allows them to understand their training progress.\n\nThe main contribution of the proposed system is to provide a hands-on interface for trainees to practice surgical motor skills effectively by utilizing various active guidance schemes. We observed a significant improvement in surgical skills acquisition when they received active guidance. For instance, the force guidance resulted in 64% improvement in deviations and 35% improvement in economy of movement in training outcomes when they performed the \"ring transfer\" task. Results of this project and other findings have been disseminated at international conferences and in peer-reviewed publications.\n\n \n\n\t\t\t\t\tLast Modified: 03/27/2022\n\n\t\t\t\t\tSubmitted by: Jerzy W Rozenblit"
 }
}