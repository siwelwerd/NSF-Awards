{
 "awd_id": "1615706",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Collaborative Research: Batch Learning from Logged Bandit Feedback",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2019-06-30",
 "tot_intn_awd_amt": 399818.0,
 "awd_amount": 399818.0,
 "awd_min_amd_letter_date": "2016-07-05",
 "awd_max_amd_letter_date": "2016-07-05",
 "awd_abstract_narration": "Log data is one of the most ubiquitous forms of data available, as it can be recorded from a variety of systems (e.g., search engines, recommender systems, ad placement platforms) at little cost. Making huge amounts of log data accessible to learning algorithms provides the potential to acquire knowledge at unprecedented scale. Furthermore, the ability to learn from log data can enable effective machine learning even in systems where manual labeling of training data is not economically viable. Log data, however, provides only partial information -- \"contextual-bandit feedback\" -- limited to the particular actions taken by the system. The feedback for all the other actions the system could have taken is typically not known. This makes learning from log data fundamentally different from traditional supervised learning, where \"correct\" predictions together with a loss function provide full-information feedback.\r\n\r\nThis project tackles the problem of Batch Learning from Bandit Feedback (BLBF) by developing principled learning methods and algorithms that can be trained with logs containing contextual-bandit feedback. First, the project develops the learning theory of BLBF, especially with respect to understanding the use and design of counterfactual risk estimators for BLBF. Second, the project derives new learning methods for BLBF. Past work has already demonstrated that Conditional Random Fields can be trained in the BLBF setting, and the project derives BLBF analogs of other learning methods as well. Third, the project derives scalable training algorithms for these BLBF methods to enable large-scale applications. And, finally, the project validates the methods with real-world data from operational systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Thorsten",
   "pi_last_name": "Joachims",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Thorsten Joachims",
   "pi_email_addr": "tj@cs.cornell.edu",
   "nsf_id": "000224646",
   "pi_start_date": "2016-07-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Cornell University",
  "inst_street_address": "341 PINE TREE RD",
  "inst_street_address_2": "",
  "inst_city_name": "ITHACA",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6072555014",
  "inst_zip_code": "148502820",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "CORNELL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "G56PUALJ3KT5"
 },
 "perf_inst": {
  "perf_inst_name": "Cornell University",
  "perf_str_addr": "Gates Hall",
  "perf_city_name": "Ithaca",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "148535169",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 399818.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Log data is one of the most ubiquitous forms of data available, as it can be recorded from a variety of systems (e.g., search engines, recommender systems, ad placement platforms) at little cost. The interaction logs of such systems (e.g., a news recommendation system) typically contain a record of the input to the system (e.g., features describing the user), the prediction made by the system (e.g., a recommended portfolio of news articles) and the feedback (e.g., time the user spent reading). The feedback, however, provides only partial information - contextual-bandit feedback\" - limited to the particular prediction shown by the system. The feedback for all the other predictions the system could have made is typically not known. This makes learning from log data fundamentally different from traditional supervised learning, where 'correct' predictions (e.g., manual ratings of that user for all news articles) together with a loss function provide full-information feedback.</p>\n<p>The abundant availability of log data motivates the problem of Batch Learning from Bandit Feedback (BLBF). Unlike in conventional supervised learning, where full-information feedback typically has to be explicitly elicited at substantial cost, log data is virtually free as a by-product of system operation. By making huge amounts of log data accessible to learning algorithms, BLBF learning methods have the potential to acquire knowledge at unprecedented scale. Furthermore, BLBF methods can enable effective machine learning even in systems where manually labeling full-information feedback is not economically viable. Unlike the well-explored problem of online learning with bandit feedback, batch learning with bandit feedback does not require interactive experimental control over the system and allows offline model design and selection.</p>\n<p>The project developed several new machine learning methods to address the BLBF learning problem. Specifically, it developed a new way of training deep networks using bandit feedback. The resulting method, which is called BanditNet, does not require manual labels like traditional supervised learning methods, but can be trained with data that is readily available from online systems. We have shown that a wide range of networks can be trained this way, from recommender systems to computer vision applications. In order to make this type of learning practical, the project developed a number of theoretical advances on counterfactual estimator, which are at the core of BLBF methods. These estimators address the counterfactual questions of how well an alternative rule (e.g. a different version of a recommender system) would have performed, if it had been used in the past. If an effective and efficient counterfactual estimator exists, the learning algorithm can use it to search for the rule that would have performed best and use that one in the future. We have developed new counterfactual estimators, theoretically characterized their properties, and extended their applicability to new settings.</p>\n<p>Beyond the development of methods for machine learning, the project also designed the Localify system as a showcase and testbed for the machine learning methods. Localify is an online streaming and recommendation system for promoting local music, which is now available to the general public at www.localify.org. The long-term goal for Localify is to foster vibrant local music communities across the country. The development of Localify was led by Ithaca College in collaboration with researchers and students from Cornell. A large part of the work was done by undergraduates at all levels, providing a wide range of research opportunities for students from multiple disciplines (e.g. computer science, information science, musicology, interaction design).</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/15/2020<br>\n\t\t\t\t\tModified by: Thorsten&nbsp;Joachims</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLog data is one of the most ubiquitous forms of data available, as it can be recorded from a variety of systems (e.g., search engines, recommender systems, ad placement platforms) at little cost. The interaction logs of such systems (e.g., a news recommendation system) typically contain a record of the input to the system (e.g., features describing the user), the prediction made by the system (e.g., a recommended portfolio of news articles) and the feedback (e.g., time the user spent reading). The feedback, however, provides only partial information - contextual-bandit feedback\" - limited to the particular prediction shown by the system. The feedback for all the other predictions the system could have made is typically not known. This makes learning from log data fundamentally different from traditional supervised learning, where 'correct' predictions (e.g., manual ratings of that user for all news articles) together with a loss function provide full-information feedback.\n\nThe abundant availability of log data motivates the problem of Batch Learning from Bandit Feedback (BLBF). Unlike in conventional supervised learning, where full-information feedback typically has to be explicitly elicited at substantial cost, log data is virtually free as a by-product of system operation. By making huge amounts of log data accessible to learning algorithms, BLBF learning methods have the potential to acquire knowledge at unprecedented scale. Furthermore, BLBF methods can enable effective machine learning even in systems where manually labeling full-information feedback is not economically viable. Unlike the well-explored problem of online learning with bandit feedback, batch learning with bandit feedback does not require interactive experimental control over the system and allows offline model design and selection.\n\nThe project developed several new machine learning methods to address the BLBF learning problem. Specifically, it developed a new way of training deep networks using bandit feedback. The resulting method, which is called BanditNet, does not require manual labels like traditional supervised learning methods, but can be trained with data that is readily available from online systems. We have shown that a wide range of networks can be trained this way, from recommender systems to computer vision applications. In order to make this type of learning practical, the project developed a number of theoretical advances on counterfactual estimator, which are at the core of BLBF methods. These estimators address the counterfactual questions of how well an alternative rule (e.g. a different version of a recommender system) would have performed, if it had been used in the past. If an effective and efficient counterfactual estimator exists, the learning algorithm can use it to search for the rule that would have performed best and use that one in the future. We have developed new counterfactual estimators, theoretically characterized their properties, and extended their applicability to new settings.\n\nBeyond the development of methods for machine learning, the project also designed the Localify system as a showcase and testbed for the machine learning methods. Localify is an online streaming and recommendation system for promoting local music, which is now available to the general public at www.localify.org. The long-term goal for Localify is to foster vibrant local music communities across the country. The development of Localify was led by Ithaca College in collaboration with researchers and students from Cornell. A large part of the work was done by undergraduates at all levels, providing a wide range of research opportunities for students from multiple disciplines (e.g. computer science, information science, musicology, interaction design).\n\n \n\n\t\t\t\t\tLast Modified: 01/15/2020\n\n\t\t\t\t\tSubmitted by: Thorsten Joachims"
 }
}