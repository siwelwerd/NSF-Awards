{
 "awd_id": "1639994",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Transparency Bridges: Exploring Transparency Requirements in Smartphone Ecosystems",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2016-08-16",
 "awd_max_amd_letter_date": "2016-08-16",
 "awd_abstract_narration": "Transparency Bridges undertakes a cross-cultural investigation of the differences in privacy attitudes between the US and the EU, as a means of exploring the design requirements for user control mechanisms. We (1) investigate the currently available mechanisms in smartphone ecosystems to inform people of collection and use of their personal data, (2) examine how these mechanisms comply with US and EU data privacy legal frameworks, and (3) analyze how different mechanisms respond to requirements in both jurisdictions.\r\n\r\nOur approach is grounded in a cross-cultural (US-EU) in-the-wild user study to analyze people's privacy behavior in the form of privacy expectations, preferences, and concerns of different pieces of personal data within and across these ecosystem according to which - EU or US - legal framework is applicable to them. The outcome of this study will (a) help clarify the role of ecosystem providers in shaping privacy governance; (b) the features and factors within US and EU regulations that are most preferred and trusted and are most effective in addressing people's needs when making use of services that depend on the collection and use of their personal data; and (c) outline legal and policy recommendations for a number of stakeholders in the smartphone ecosystem, including lawmakers, regulators, and companies which can be useful when considering interpretation and implementation of current rules, and the need for reformed ones.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Weitzner",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel J Weitzner",
   "pi_email_addr": "djweitzner@csail.mit.edu",
   "nsf_id": "000187064",
   "pi_start_date": "2016-08-16",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Massachusetts Institute of Technology",
  "inst_street_address": "77 MASSACHUSETTS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6172531000",
  "inst_zip_code": "021394301",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "MASSACHUSETTS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "E2NYLCDML6V1",
  "org_uei_num": "E2NYLCDML6V1"
 },
 "perf_inst": {
  "perf_inst_name": "Massachusetts Institute of Technology",
  "perf_str_addr": "77 Massachusetts Ave.",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021394301",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "022Z",
   "pgm_ref_txt": "International Partnerships"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8225",
   "pgm_ref_txt": "SaTC Special Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-62c0eaa3-7fff-944d-8131-ef92b43a61ab\"> </span></p>\n<p dir=\"ltr\"><span>Globally-connected individuals value privacy more and more, because everyone is aware of their great dependence on digital technologies, and the increasing risks they face from misuse of personal information. Transparency and consent are some of the key legal rights granted to individuals in order to protect privacy. These laws give individuals the right to know how their information is going to be collected and used, and to withhold consent for such actions in some or all cases. But how are these laws actually working? Do these rights make people feel more protected? Are companies following their legal obligations? Are they held accountable when they fail to comply with the law?&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>Our interdisciplinary, cross-border research teams, bringing together computer scientists and legal scholars, United States and European universities, learned that even with the new gold-standard privacy law in Europe -- the General Data Protection Regulation (GDPR) -- there are significant gaps in how companies comply with the law. We found so-called ?dark patterns? in the way commercial websites present privacy choices, resulting in users not being able to make the choices they want to make, and many companies getting away with collecting and users people?s personal data without those individuals having adequate choice in the matter.&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>On the positive side, we found that when we gave users better tools to evaluate the often complex privacy choices they had to face, they could make better decisions. We developed designs for what we call Data Controller Indicators that help users see how their personal information is actually flowing around apps and the Web, and what is being done with it.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The broader impact of our work comes in helping to answer increasingly urgent questions about how the European privacy law is being implemented and enforced. While the law was passed in Europe, it has a binding effect on companies all around the world, so it is of concern for most in the United States, too. Leading European privacy enforcement authorities have identified dark patterns as a priority to address as they investigate who is and is not complying with EU law. And,&nbsp; as the United States Congress and a number of States seek to enact laws to protect US citizen?s privacy, the question of dark patterns is increasingly part of the legislative debate. The work from this project should help US regulators understand how to target their efforts at consumer protection. And just as importantly, we hope the lessons our research have revealed about how to enable individuals to make better privacy choices will help inform the design and operation of new digital services in the future.</span></p>\n<p><span>The research teams in this project, together with a paired project at the University of Amsterdam, and colleagues at the University of Oxford all came together in an earlier project called EU-US Privacy Bridges (</span><a href=\"https://privacybridges.mit.edu/\"><span>https://privacybridges.mit.edu/</span></a><span>), a cross-border collaboration which developed a framework of practical options that advance strong, globally-accepted privacy values in a manner that respects the substantive and procedural differences between different countries? laws. By working with intentionally international research teams, we hope that the research we have done here charts a path for common global standards on how to respect core privacy values of transparency and consent.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/28/2020<br>\n\t\t\t\t\tModified by: Daniel&nbsp;J&nbsp;Weitzner</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nGlobally-connected individuals value privacy more and more, because everyone is aware of their great dependence on digital technologies, and the increasing risks they face from misuse of personal information. Transparency and consent are some of the key legal rights granted to individuals in order to protect privacy. These laws give individuals the right to know how their information is going to be collected and used, and to withhold consent for such actions in some or all cases. But how are these laws actually working? Do these rights make people feel more protected? Are companies following their legal obligations? Are they held accountable when they fail to comply with the law?  \nOur interdisciplinary, cross-border research teams, bringing together computer scientists and legal scholars, United States and European universities, learned that even with the new gold-standard privacy law in Europe -- the General Data Protection Regulation (GDPR) -- there are significant gaps in how companies comply with the law. We found so-called ?dark patterns? in the way commercial websites present privacy choices, resulting in users not being able to make the choices they want to make, and many companies getting away with collecting and users people?s personal data without those individuals having adequate choice in the matter.  \nOn the positive side, we found that when we gave users better tools to evaluate the often complex privacy choices they had to face, they could make better decisions. We developed designs for what we call Data Controller Indicators that help users see how their personal information is actually flowing around apps and the Web, and what is being done with it. \nThe broader impact of our work comes in helping to answer increasingly urgent questions about how the European privacy law is being implemented and enforced. While the law was passed in Europe, it has a binding effect on companies all around the world, so it is of concern for most in the United States, too. Leading European privacy enforcement authorities have identified dark patterns as a priority to address as they investigate who is and is not complying with EU law. And,  as the United States Congress and a number of States seek to enact laws to protect US citizen?s privacy, the question of dark patterns is increasingly part of the legislative debate. The work from this project should help US regulators understand how to target their efforts at consumer protection. And just as importantly, we hope the lessons our research have revealed about how to enable individuals to make better privacy choices will help inform the design and operation of new digital services in the future.\n\nThe research teams in this project, together with a paired project at the University of Amsterdam, and colleagues at the University of Oxford all came together in an earlier project called EU-US Privacy Bridges (https://privacybridges.mit.edu/), a cross-border collaboration which developed a framework of practical options that advance strong, globally-accepted privacy values in a manner that respects the substantive and procedural differences between different countries? laws. By working with intentionally international research teams, we hope that the research we have done here charts a path for common global standards on how to respect core privacy values of transparency and consent.\n\n \n\n\t\t\t\t\tLast Modified: 06/28/2020\n\n\t\t\t\t\tSubmitted by: Daniel J Weitzner"
 }
}