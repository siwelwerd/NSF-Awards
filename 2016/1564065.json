{
 "awd_id": "1564065",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CHS: Medium: Physical-Virtual Patient Bed for Healthcare Training and Assessment",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2022-07-31",
 "tot_intn_awd_amt": 894431.0,
 "awd_amount": 918931.0,
 "awd_min_amd_letter_date": "2016-06-30",
 "awd_max_amd_letter_date": "2021-05-26",
 "awd_abstract_narration": "Flight simulators offer pilots a chance to safely practice flying a wide range of aircraft in a variety of scenarios. Similarly, human patient simulators offer nurses and physicians safe opportunities to practice healthcare on a wide range of patients and scenarios. Virtual patient simulators use computer graphics to render humans with a range of visual characteristics including medical symptoms, personality, race, and gender. However, they are inherently virtual--practitioners cannot manipulate them with their hands. Manikin-based patient simulators on the other hand are inherently physical, comprising human-sized bodies with realistic skin and electro-mechanical simulation of physiological symptoms. They afford a \"hands on\" experience but are very limited in their ability to present visual characteristics. Furthermore, medical educators are increasingly focusing on interpersonal skills and cultural competency, as these impact provider-patient relationships, diagnoses, and treatments. Manikins do not afford the associated humanistic traits.\r\n\r\nThe researchers on this project are developing a Physical-Virtual Patient Bed (PVPB) that combines the flexibility of virtual patients with the physicality of manikins. The PVPB will employ dynamic computer graphics rear-projected onto a body-shaped shell mounted in a real hospital bed, along with various sensors and actuators, to create a patient simulator that talks; appears to sweat, breathe, and squirm; exhibits a pulse; feels warm/cold on various body parts; and responds to touch by humans or medical instruments. It will be able to change race, gender, and visually-apparent symptoms on the fly, and will exhibit real human emotional complexity via real human agency. The researchers will assess the effectiveness of the PVPB in simulating certain conditions, and use it to develop new knowledge about the relative importance of various patient cues, and provider biases arising from patient demographics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Gregory",
   "pi_last_name": "Welch",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Gregory F Welch",
   "pi_email_addr": "welch@ucf.edu",
   "nsf_id": "000293088",
   "pi_start_date": "2016-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Juan",
   "pi_last_name": "Cendan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Juan Cendan",
   "pi_email_addr": "juan.cendan@ucf.edu",
   "nsf_id": "000586280",
   "pi_start_date": "2016-06-30",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Laura",
   "pi_last_name": "Gonzalez",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Laura Gonzalez",
   "pi_email_addr": "lgonzal24@gmail.com",
   "nsf_id": "000663073",
   "pi_start_date": "2016-06-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "The University of Central Florida Board of Trustees",
  "inst_street_address": "4000 CENTRAL FLORIDA BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "ORLANDO",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "4078230387",
  "inst_zip_code": "328168005",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "FL10",
  "org_lgl_bus_name": "THE UNIVERSITY OF CENTRAL FLORIDA BOARD OF TRUSTEES",
  "org_prnt_uei_num": "",
  "org_uei_num": "RD7MXJV7DKT9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Central Florida",
  "perf_str_addr": "",
  "perf_city_name": "Orlando",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "328263281",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "FL10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 894431.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 24500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project was primarily focused on the development and assessment of a new type of a patient simulator that could some day be widely used for the training and assessment of nurses and physicians. Specifically the researchers developed what they call a Physical-Virtual Patient Bed (PVPB) that combines the flexibility of computer graphics \"virtual\" patients with the physicality of conventional medical training manikins. See the included images of their pediatric PVPB prototype system alone and in use. The researchers created multiple PVPB prototypes. The prototypes employed dynamic computer graphics imagery that was projected onto the inside (from underneath) of a human body-shaped shell that was mounted in a metal frame resembling a hospital bed. The resulting system would display a dynamic patient, such as a child, on the body-shaped surface, such that the practitioner could stand next to the \"bed\" and talk with the patient, while touching their body when and where needed for diagnosis or comfort. The prototypes also included various sensors and actuators. For example they used sound and projected imagery to simulate patient talking and breathing; electronic tactile transducers to create a pulse that the practitioners could feel with their own hands; and forced air heating and cooling from underneath to create a feeling of warmth on the forehead (indicating a fever) or cold on their hands (indicating shock). Some prototypes incorporated cameras, infrared lighting, and novel computer algorithms to detect when a practitioner touched the simulated patient, and to respond by changing the patient imagery, e.g., to allow the practitioner to pull down on the patient's eyelid to check their sclera. The prototypes were able to change race, gender, and various visually-apparent symptoms on the fly. The simulated behavior was created by a remote human who observed the scene and controlled the patient response via a special computer interface. The result was very realistic human emotional intelligence and complexity. The researchers also carried out human subject research designed to evaluate the value and effectiveness of the PVPB paradigm and specific prototypes. The studies employed nursing and medical students who used the PVPB under various circumstances, e.g., stroke diagnosis, cases of the measles, and certain pediatric (children) needs.</p>\n<p>During the COVID-19 pandemic the researchers were unable to access the specialized PVPB equipment, or to meet with nursing and medical students in person. Under these circumstances the researchers conceived of a new pandemic-related technology to provide an isolated patient and their remote visitors with a visual interaction augmented by touch --- a perception of being touched for the isolated patient, and a perception of touching for the remote visitors. For example, a loved one might be able to virtually stroke the patient?s arm or head, or even squeeze the patient's hand. The researchers called the approach Tactile Telepresence for Isolated Patients (TTIP). The researchers developed a complete functioning TTIP prototype system employing a \"smart tablet\" for the family member to hold and a tactile headband for the patient. See the included images of their TTIP \"headband\" electronics and the headband in use. Imagery of the patient was shown on the tablet, along with indications of areas where one could touch the patient image such that the sensations were transmitted to the patient's forehead via the TTIP headband, which included an array of small vibration devices. The researchers carried out some preliminary (pilot) experiments to evaluate how well the TTIP prototype functioned, and how user's perceived the remote touching. The experiments demonstrated a relatively high rate of recognition of tracing out geometric shapes on a remote person's forehead, and a feeling of not being alone when tested under conditions that simulated real isolation.</p>\n<p>Over the life of the project the researchers published and/or presented over 25 relevant articles and several conference posters. There were 12 faculty members involved at various times, and there were four graduate students (with four PhD Degrees) and nine undergraduate students (general undergraduates and NSF REU students) involved.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/23/2022<br>\n\t\t\t\t\tModified by: Gregory&nbsp;F&nbsp;Welch</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502677584_nsfpvp_inuse--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502677584_nsfpvp_inuse--rgov-800width.jpg\" title=\"The Physical-Virtual Patient Bed In Use\"><img src=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502677584_nsfpvp_inuse--rgov-66x44.jpg\" alt=\"The Physical-Virtual Patient Bed In Use\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This image shows the Physical-Virtual Patient Bed in use by Prof. Mind Anderson (left) and Prof. Desiree Diaz, both from the UCF College of Nursing.</div>\n<div class=\"imageCredit\">Greg Welch</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gregory&nbsp;F&nbsp;Welch</div>\n<div class=\"imageTitle\">The Physical-Virtual Patient Bed In Use</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502448455_nsfpvp_system--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502448455_nsfpvp_system--rgov-800width.jpg\" title=\"The Physical-Virtual Patient Bed System\"><img src=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502448455_nsfpvp_system--rgov-66x44.jpg\" alt=\"The Physical-Virtual Patient Bed System\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This image shows the Physical-Virtual Patient Bed System including the bed with labeled components, and a screenshot of the application used to control the patient.</div>\n<div class=\"imageCredit\">Greg Welch</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gregory&nbsp;F&nbsp;Welch</div>\n<div class=\"imageTitle\">The Physical-Virtual Patient Bed System</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502986551_nsfttip_patient-interface--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502986551_nsfttip_patient-interface--rgov-800width.jpg\" title=\"Tactile Telepresence for Isolated Patients, Headband Electronics\"><img src=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667502986551_nsfttip_patient-interface--rgov-66x44.jpg\" alt=\"Tactile Telepresence for Isolated Patients, Headband Electronics\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This image shows the main electronic components of the patient headband for the Tactile Telepresence for Isolated Patients system.</div>\n<div class=\"imageCredit\">Greg Welch</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Gregory&nbsp;F&nbsp;Welch</div>\n<div class=\"imageTitle\">Tactile Telepresence for Isolated Patients, Headband Electronics</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667503112364_nsfttip_eval-process--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667503112364_nsfttip_eval-process--rgov-800width.jpg\" title=\"Tactile Telepresence for Isolated Patients, Headband In Use\"><img src=\"/por/images/Reports/POR/2022/1564065/1564065_10437015_1667503112364_nsfttip_eval-process--rgov-66x44.jpg\" alt=\"Tactile Telepresence for Isolated Patients, Headband In Use\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This image shows the Tactile Telepresence for Isolated Patients system being used for an experiment.</div>\n<div class=\"imageCredit\">Greg Welch</div>\n<div class=\"imageSubmitted\">Gregory&nbsp;F&nbsp;Welch</div>\n<div class=\"imageTitle\">Tactile Telepresence for Isolated Patients, Headband In Use</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project was primarily focused on the development and assessment of a new type of a patient simulator that could some day be widely used for the training and assessment of nurses and physicians. Specifically the researchers developed what they call a Physical-Virtual Patient Bed (PVPB) that combines the flexibility of computer graphics \"virtual\" patients with the physicality of conventional medical training manikins. See the included images of their pediatric PVPB prototype system alone and in use. The researchers created multiple PVPB prototypes. The prototypes employed dynamic computer graphics imagery that was projected onto the inside (from underneath) of a human body-shaped shell that was mounted in a metal frame resembling a hospital bed. The resulting system would display a dynamic patient, such as a child, on the body-shaped surface, such that the practitioner could stand next to the \"bed\" and talk with the patient, while touching their body when and where needed for diagnosis or comfort. The prototypes also included various sensors and actuators. For example they used sound and projected imagery to simulate patient talking and breathing; electronic tactile transducers to create a pulse that the practitioners could feel with their own hands; and forced air heating and cooling from underneath to create a feeling of warmth on the forehead (indicating a fever) or cold on their hands (indicating shock). Some prototypes incorporated cameras, infrared lighting, and novel computer algorithms to detect when a practitioner touched the simulated patient, and to respond by changing the patient imagery, e.g., to allow the practitioner to pull down on the patient's eyelid to check their sclera. The prototypes were able to change race, gender, and various visually-apparent symptoms on the fly. The simulated behavior was created by a remote human who observed the scene and controlled the patient response via a special computer interface. The result was very realistic human emotional intelligence and complexity. The researchers also carried out human subject research designed to evaluate the value and effectiveness of the PVPB paradigm and specific prototypes. The studies employed nursing and medical students who used the PVPB under various circumstances, e.g., stroke diagnosis, cases of the measles, and certain pediatric (children) needs.\n\nDuring the COVID-19 pandemic the researchers were unable to access the specialized PVPB equipment, or to meet with nursing and medical students in person. Under these circumstances the researchers conceived of a new pandemic-related technology to provide an isolated patient and their remote visitors with a visual interaction augmented by touch --- a perception of being touched for the isolated patient, and a perception of touching for the remote visitors. For example, a loved one might be able to virtually stroke the patient?s arm or head, or even squeeze the patient's hand. The researchers called the approach Tactile Telepresence for Isolated Patients (TTIP). The researchers developed a complete functioning TTIP prototype system employing a \"smart tablet\" for the family member to hold and a tactile headband for the patient. See the included images of their TTIP \"headband\" electronics and the headband in use. Imagery of the patient was shown on the tablet, along with indications of areas where one could touch the patient image such that the sensations were transmitted to the patient's forehead via the TTIP headband, which included an array of small vibration devices. The researchers carried out some preliminary (pilot) experiments to evaluate how well the TTIP prototype functioned, and how user's perceived the remote touching. The experiments demonstrated a relatively high rate of recognition of tracing out geometric shapes on a remote person's forehead, and a feeling of not being alone when tested under conditions that simulated real isolation.\n\nOver the life of the project the researchers published and/or presented over 25 relevant articles and several conference posters. There were 12 faculty members involved at various times, and there were four graduate students (with four PhD Degrees) and nine undergraduate students (general undergraduates and NSF REU students) involved.\n\n \n\n\t\t\t\t\tLast Modified: 11/23/2022\n\n\t\t\t\t\tSubmitted by: Gregory F Welch"
 }
}