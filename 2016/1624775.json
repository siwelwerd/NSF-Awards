{
 "awd_id": "1624775",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "I-Corps:  Non-invasive real-time Brain-Computer Interface (BCI)",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Steven Konsek",
 "awd_eff_date": "2016-02-15",
 "awd_exp_date": "2016-07-31",
 "tot_intn_awd_amt": 50000.0,
 "awd_amount": 50000.0,
 "awd_min_amd_letter_date": "2016-02-08",
 "awd_max_amd_letter_date": "2016-02-08",
 "awd_abstract_narration": "One of the major human developments in the 21st century is the creation of new ways to allow people to interact and immerse with the world around them, such as touch technology and virtual reality. With every new development, there has been rapid technological advancement across fields. Brian-Computer Interface has the potential to bring human interaction to a new level. However, current non-invasive brain technology is extremely limited in capability. For example, on the consumer end, current technology has only allowed for meditation-based applications. On the other hand, more highly capable brain technology is expensive, requires surgery and can take many months to learn to use. The proposed project will develop the first low-cost non-invasive brain-computer interface that allows for never before seen real-time control of devices. This would create new methods of interaction for everyone and also transform the lives of millions of people with severe disabilities.\r\n\r\nThis I-Corps team will develop a consumer product including hardware and software. The hardware will be a headset that includes a two-electrode behind-the-head wireless electroencephalography (EEG), along with visual stimuli and a unique software that allows computer to detect and determine a person?s intent using only brain activity. The product will allow for real-time control with similar performance compared to invasive methods, all with a non-invasive, quick setup headset and our innovative brain signal processing algorithms. The product will function better (much higher accuracy) in people with severe impairments, does not require eye gaze, and can be set up and learned to be used in only five to ten minutes. The Brian-Computer Interface product can be used to interface between operators and equipment in a wide variety of industries such as transportation, aerospace, manufacturing, education, communication and medicine. The team intends to apply the technology in commercial and industrial electronic control, assistive technology developers (e.g. wheel chair control), Brain-Computer Interface enthusiast and researchers, gamers or game developers and toy makers (e.g. virtual reality).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaoya",
   "pi_last_name": "Ma",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaoya Ma",
   "pi_email_addr": "xiaoyama@umich.edu",
   "nsf_id": "000715033",
   "pi_start_date": "2016-02-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": null,
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481083364",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802300",
   "pgm_ele_name": "I-Corps"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 50000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>NSF I-corps is a seven-week concentrated learning program, where the team was required to participate in mandatory training sessions and conduct 100 interviews with experts all over the world.&nbsp;</p>\n<p>Our team, neurable, aimed to&nbsp;develop a consumer product composed of hardware and software. The hardware will be a headset that includes a two-electrode behind-the-head wireless electroencephalography (EEG), along with visual stimuli and unique software that allows computer to detect and determine a person&rsquo;s intent using only brain activity. Our product will allow for real-time control with similar performance compared to invasive methods, all with a non-invasive, quick setup headset and our innovative brain signal processing algorithms. The product will function better (much higher accuracy) in people with severe impairments, does not require eye gaze, and can be set up and learned to be used in only five to ten minutes. The Brian-Computer Interface product can be used to interface between operators and equipment in a wide variety of industries such as education, communication and medicine. This amazing new technology will be extremely useful to assistive technology developers (e.g. wheel chair control), Brain-Computer Interface enthusiast and researchers, gamers or game developers and toy makers (e.g. virtual reality).&nbsp;</p>\n<p>Through the seven-week NSF Icorps program, we have attended expos and conferences including Vision, Strategicon, DICE Summit, I3D Summit, Versions,&nbsp;<span>Experiential Technology and NeuroGaming Conference and Expo,&nbsp;<span>SXSW and&nbsp;<span>GDC-Game developers conference.&nbsp;To explore the product and market fit, we were taught to go outside of the building and talk to people.&nbsp;</span></span></span>This is drastically different from normal research settings, where we stay in the lab and do bench work but lack of communicating to other people. It was challenging but taught us a lot:1) Everyone thinks their product is the greatest, however, customers do not think so. 2) Customer discovery is the key to a successful product; 3)We should always listen; 4) pivate to a new direction as soon as possible. Our team traveled ~41,000 miles across the United States and talked in person to 134 people (including CEOs, engineers, professors, kids and parents, etc.). We found that there is a progressing pain point in virtual reality(VR) and augmented reality (AR) area. With experimenting, we have concluded to focus on AR/VR area and start a company. Since then, we have been actively building the business and raised a million dollars to create a product for VR/AR with our software.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/30/2016<br>\n\t\t\t\t\tModified by: Xiaoya&nbsp;Ma</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nNSF I-corps is a seven-week concentrated learning program, where the team was required to participate in mandatory training sessions and conduct 100 interviews with experts all over the world. \n\nOur team, neurable, aimed to develop a consumer product composed of hardware and software. The hardware will be a headset that includes a two-electrode behind-the-head wireless electroencephalography (EEG), along with visual stimuli and unique software that allows computer to detect and determine a person?s intent using only brain activity. Our product will allow for real-time control with similar performance compared to invasive methods, all with a non-invasive, quick setup headset and our innovative brain signal processing algorithms. The product will function better (much higher accuracy) in people with severe impairments, does not require eye gaze, and can be set up and learned to be used in only five to ten minutes. The Brian-Computer Interface product can be used to interface between operators and equipment in a wide variety of industries such as education, communication and medicine. This amazing new technology will be extremely useful to assistive technology developers (e.g. wheel chair control), Brain-Computer Interface enthusiast and researchers, gamers or game developers and toy makers (e.g. virtual reality). \n\nThrough the seven-week NSF Icorps program, we have attended expos and conferences including Vision, Strategicon, DICE Summit, I3D Summit, Versions, Experiential Technology and NeuroGaming Conference and Expo, SXSW and GDC-Game developers conference. To explore the product and market fit, we were taught to go outside of the building and talk to people. This is drastically different from normal research settings, where we stay in the lab and do bench work but lack of communicating to other people. It was challenging but taught us a lot:1) Everyone thinks their product is the greatest, however, customers do not think so. 2) Customer discovery is the key to a successful product; 3)We should always listen; 4) pivate to a new direction as soon as possible. Our team traveled ~41,000 miles across the United States and talked in person to 134 people (including CEOs, engineers, professors, kids and parents, etc.). We found that there is a progressing pain point in virtual reality(VR) and augmented reality (AR) area. With experimenting, we have concluded to focus on AR/VR area and start a company. Since then, we have been actively building the business and raised a million dollars to create a product for VR/AR with our software.\n\n\t\t\t\t\tLast Modified: 08/30/2016\n\n\t\t\t\t\tSubmitted by: Xiaoya Ma"
 }
}