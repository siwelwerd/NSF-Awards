{
 "awd_id": "1618620",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Collaborative Research: Efficient Exploitation of Heterogeneous Memory through OS/Compiler Support",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Matt Mutka",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 249548.0,
 "awd_amount": 249548.0,
 "awd_min_amd_letter_date": "2016-08-03",
 "awd_max_amd_letter_date": "2016-08-03",
 "awd_abstract_narration": "Memory is a key component of computers. Modern parallel architectures begin to employ heterogeneous memory to improve both latency and bandwidth of the memory subsystem. Typically, a heterogeneous memory system consists of a fast and a slow component and requires explicit software management. It puts unique burdens on programmers and compilers, especially in the domains of high-performance computing (HPC) and big data analytics. These challenges are crucial to the evolution of computer systems and therefore are key to future scientific discovery, economic prosperity, and national security. \r\n\r\nTo address these challenges in exploiting heterogeneous memory, this project targets co-designing the compiler and the operating system (OS): it explores i) a new compiler design that supports heterogeneity-aware data management and ii) new OS facilities for efficient data move and fair memory sharing. Overall, this project serves as a stepping stone towards a long-term vision -- taming emerging heterogeneous hardware by tightly integrating programming and OS support.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xu",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xu Liu",
   "pi_email_addr": "xliu88@ncsu.edu",
   "nsf_id": "000677724",
   "pi_start_date": "2016-08-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "College of William and Mary",
  "inst_street_address": "1314 S MOUNT VERNON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "WILLIAMSBURG",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "7572213965",
  "inst_zip_code": "23185",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "VA08",
  "org_lgl_bus_name": "COLLEGE OF WILLIAM AND MARY",
  "org_prnt_uei_num": "EVWJPCY6AD97",
  "org_uei_num": "EVWJPCY6AD97"
 },
 "perf_inst": {
  "perf_inst_name": "College of William and Mary",
  "perf_str_addr": "",
  "perf_city_name": "Williamsburg",
  "perf_st_code": "VA",
  "perf_st_name": "Virginia",
  "perf_zip_code": "231878795",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "VA01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 249548.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-e3e714f1-7fff-6e43-e3cd-7725ad6599f5\">\n<p dir=\"ltr\"><span>Memory is a key component of the computer system. Modern parallel architectures begin to employ heterogeneous memory to improve both latency and bandwidth of the memory subsystem. Typically, a heterogeneous memory system consists of a fast and a slow component and requires explicit software management. It puts unique burdens on programmers and compilers, especially in the domains of high-performance computing (HPC) and big data analytics. These challenges are crucial to the evolution of computer systems and therefore are key to future scientific discovery, economic prosperity, and national security.</span></p>\n<br />\n<p dir=\"ltr\"><span>This project focused on co-designing the compiler and the OS for emerging memories, e.g. 3D-stacked DRAM and non-volatile memory, taking HPC/analytics performance to the next level. It explores i) a new compiler design that supports heterogeneity-aware data management and ii) new OS facilities for efficient data move and fair memory sharing. Overall, through accelerating big data analytics, the resulting technologies have the potential to impact various societies and economies providing faster analytics and capacity of processing large data sets.</span></p>\n<br />\n<p dir=\"ltr\"><span>This project produced opensource codebases: Dr-BW, a bandwidth contention detector; ProfDP, a profiler for data placement; CCProf, a cache conflict analyzer; NUMA-Caffe, a deep learning framework for NUMA; RDX, a lightweight tool to collect reuse-distance for cache characterization; StreamBox, a stream processing engine; VStore, a data store for video analytics. This project resulted in publications at ASPLOS (3), HPCA, Eurosys (2), USENIX ATC (2), ICS (2), CGO (4), IPDPS, and TACO. Many software packages developed under the support of this award are open source, under either BSD or MIT licenses. One US patent resulted from this award has been filed</span></p>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/12/2020<br>\n\t\t\t\t\tModified by: Xu&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nMemory is a key component of the computer system. Modern parallel architectures begin to employ heterogeneous memory to improve both latency and bandwidth of the memory subsystem. Typically, a heterogeneous memory system consists of a fast and a slow component and requires explicit software management. It puts unique burdens on programmers and compilers, especially in the domains of high-performance computing (HPC) and big data analytics. These challenges are crucial to the evolution of computer systems and therefore are key to future scientific discovery, economic prosperity, and national security.\n\n\nThis project focused on co-designing the compiler and the OS for emerging memories, e.g. 3D-stacked DRAM and non-volatile memory, taking HPC/analytics performance to the next level. It explores i) a new compiler design that supports heterogeneity-aware data management and ii) new OS facilities for efficient data move and fair memory sharing. Overall, through accelerating big data analytics, the resulting technologies have the potential to impact various societies and economies providing faster analytics and capacity of processing large data sets.\n\n\nThis project produced opensource codebases: Dr-BW, a bandwidth contention detector; ProfDP, a profiler for data placement; CCProf, a cache conflict analyzer; NUMA-Caffe, a deep learning framework for NUMA; RDX, a lightweight tool to collect reuse-distance for cache characterization; StreamBox, a stream processing engine; VStore, a data store for video analytics. This project resulted in publications at ASPLOS (3), HPCA, Eurosys (2), USENIX ATC (2), ICS (2), CGO (4), IPDPS, and TACO. Many software packages developed under the support of this award are open source, under either BSD or MIT licenses. One US patent resulted from this award has been filed\n\n\n \n\n\t\t\t\t\tLast Modified: 02/12/2020\n\n\t\t\t\t\tSubmitted by: Xu Liu"
 }
}