{
 "awd_id": "1553610",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Scaling Forensic Algorithms for Big Data and Adversarial Environments",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032928832",
 "po_email": "dcosley@nsf.gov",
 "po_sign_block_name": "Dan Cosley",
 "awd_eff_date": "2016-05-01",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 583578.0,
 "awd_amount": 583578.0,
 "awd_min_amd_letter_date": "2016-04-22",
 "awd_max_amd_letter_date": "2020-07-24",
 "awd_abstract_narration": "Forged digital images or video can threaten reputations or impede criminal justice, due to falsified evidence.  Over the past decade, researchers have developed a new class of security techniques known as 'multimedia forensics' to determine the origin and authenticity of multimedia information, such as potentially falsified images or videos.  However, the proliferation of smartphones and the rise of social media have led to an overwhelming increase in the volume of multimedia information that must be forensically authenticated.  Forger's capabilities have also grown dramatically, as sophisticated editing software allows forgers to perform complex manipulations of digital images and videos. Researchers have recently demonstrated that an adversarial forger can design anti-forensic attacks capable of fooling forensic algorithms. By contrast, little multimedia forensics research has focused on improving the speed at which multimedia forensics techniques operate, particularly on large data sets. This research project is focused on scaling multimedia forensic algorithms to address these new challenges that have arisen due to the evolving technical and social landscape.  \r\n\r\nThe research project is focusing on three main aims: (1) Scaling forensic algorithms to meet big data challenges, (2) Scaling forensic algorithms to handle complex forgeries, and (3) Scaling forensics to meet increased adversarial capabilities.  To accomplish these aims, the research is drawing from a wide variety of fields such as signal processing, estimation theory, statistical hypothesis testing, machine learning, optimization theory, and game theory.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matthew",
   "pi_last_name": "Stamm",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Matthew Stamm",
   "pi_email_addr": "mstamm@drexel.edu",
   "nsf_id": "000662091",
   "pi_start_date": "2016-04-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Drexel University",
  "inst_street_address": "3141 CHESTNUT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158956342",
  "inst_zip_code": "191042875",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "DREXEL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "XF3XM9642N96"
 },
 "perf_inst": {
  "perf_inst_name": "Drexel University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191042875",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 110648.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 113593.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 116624.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 119748.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 122965.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Fake media, such as manipulated images or videos, is a major information security threat. It can be used for many malicious purposes, such as part of misinformation or disinformation campaigns, create falsified evidence to impede criminal investigations, commit fraud, or threaten an individual?s reputation.&nbsp; To combat these threats, researchers have developed a new class of security techniques known as 'multimedia forensics' to determine the origin and authenticity of multimedia information. However, the proliferation of smartphones and the rise of social media have led to an overwhelming increase in the volume of multimedia information that must be forensically authenticated. Forger's capabilities have also grown dramatically, as sophisticated editing software allows forgers to perform complex manipulations of digital images and videos. Researchers have recently demonstrated that an adversarial forger can design anti-forensic attacks capable of fooling forensic algorithms. Additionally, during the course of this project society witnessed the rise of generative artificial intelligence (AI) systems capable of creating sophisticated, highly realistic fake media, such synthetic images and deepfake videos.</p>\n<p>This research project focused on scaling multimedia forensic algorithms to address these new challenges that have arisen due to the evolving technical and social landscape. To accomplish this, several new technologies were developed. Multimedia forensic algorithms identify traces left by different processing operations, such as those used in editing software, as well as by AI-based software to create deepfakes and synthetic images. This project developed a powerful new AI-based approach to automatically learn these traces from data using specially designed forms of convolutional neural networks (CNNs).&nbsp; CNNs were designed to detect evidence of editing, determine an image or video?s source camera, and identify evidence that an image was AI generated.&nbsp; Building upon this, new algorithms were created to both detect if fake or manipulated content is present in an image, as well as localize where in the image this content lies.&nbsp; To accomplish this, advanced neural networks were built to compare abstract representations of the forensic traces in each part of the image and search for inconsistencies.&nbsp; The presence of inconsistent and anomalous forensic traces indicates that part of the image came from a different source or was locally manipulated. Additional algorithms were developed to determine the source of a digital image or video, detect AI-generated synthetic images, and detect deepfake videos and audio.&nbsp; Furthermore, this project investigated anti-forensic attacks that an adversary could use to fool media forensic algorithms.&nbsp; Several new anti-forensic vulnerabilities were discovered, as well as the discovery of limitations in anti-forensic attacks that can be used to help defend against these attacks.</p>\n<p>This project produced several broader impacts to society and the American public.&nbsp; Several new technologies were developed to detect media forgeries. These technologies can be used to authenticate images and videos used in news reporting, as evidence in criminal investigations, and help protect against the spread of misinformation and disinformation. Through synergistic projects, software implementations of the technologies developed under this project were provided to several agencies within the US government that have a need for authenticating digital media. The PI worked with both local, national, and international news media organizations to help inform the general public about the threats posed by fake and manipulated media, as well as about research results produced under this project that can help protect against these threats. This project partially supported the development of new educational material at both the graduate, undergraduate, and high-school levels on the topics of multimedia forensics and security, including the development of multiple courses on media forensics and a new MS program in Machine Learning Engineering at Drexel University. Furthermore, this project partially supported the doctoral studies of six PhD students and five undergraduate volunteers.&nbsp; Four of these doctoral successfully completed their PhDs during the course of this project, including two female students, and secured employment American technology companies or as research scientists at American institutions.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/14/2023<br>\n\t\t\t\t\tModified by: Matthew&nbsp;Stamm</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nFake media, such as manipulated images or videos, is a major information security threat. It can be used for many malicious purposes, such as part of misinformation or disinformation campaigns, create falsified evidence to impede criminal investigations, commit fraud, or threaten an individual?s reputation.  To combat these threats, researchers have developed a new class of security techniques known as 'multimedia forensics' to determine the origin and authenticity of multimedia information. However, the proliferation of smartphones and the rise of social media have led to an overwhelming increase in the volume of multimedia information that must be forensically authenticated. Forger's capabilities have also grown dramatically, as sophisticated editing software allows forgers to perform complex manipulations of digital images and videos. Researchers have recently demonstrated that an adversarial forger can design anti-forensic attacks capable of fooling forensic algorithms. Additionally, during the course of this project society witnessed the rise of generative artificial intelligence (AI) systems capable of creating sophisticated, highly realistic fake media, such synthetic images and deepfake videos.\n\nThis research project focused on scaling multimedia forensic algorithms to address these new challenges that have arisen due to the evolving technical and social landscape. To accomplish this, several new technologies were developed. Multimedia forensic algorithms identify traces left by different processing operations, such as those used in editing software, as well as by AI-based software to create deepfakes and synthetic images. This project developed a powerful new AI-based approach to automatically learn these traces from data using specially designed forms of convolutional neural networks (CNNs).  CNNs were designed to detect evidence of editing, determine an image or video?s source camera, and identify evidence that an image was AI generated.  Building upon this, new algorithms were created to both detect if fake or manipulated content is present in an image, as well as localize where in the image this content lies.  To accomplish this, advanced neural networks were built to compare abstract representations of the forensic traces in each part of the image and search for inconsistencies.  The presence of inconsistent and anomalous forensic traces indicates that part of the image came from a different source or was locally manipulated. Additional algorithms were developed to determine the source of a digital image or video, detect AI-generated synthetic images, and detect deepfake videos and audio.  Furthermore, this project investigated anti-forensic attacks that an adversary could use to fool media forensic algorithms.  Several new anti-forensic vulnerabilities were discovered, as well as the discovery of limitations in anti-forensic attacks that can be used to help defend against these attacks.\n\nThis project produced several broader impacts to society and the American public.  Several new technologies were developed to detect media forgeries. These technologies can be used to authenticate images and videos used in news reporting, as evidence in criminal investigations, and help protect against the spread of misinformation and disinformation. Through synergistic projects, software implementations of the technologies developed under this project were provided to several agencies within the US government that have a need for authenticating digital media. The PI worked with both local, national, and international news media organizations to help inform the general public about the threats posed by fake and manipulated media, as well as about research results produced under this project that can help protect against these threats. This project partially supported the development of new educational material at both the graduate, undergraduate, and high-school levels on the topics of multimedia forensics and security, including the development of multiple courses on media forensics and a new MS program in Machine Learning Engineering at Drexel University. Furthermore, this project partially supported the doctoral studies of six PhD students and five undergraduate volunteers.  Four of these doctoral successfully completed their PhDs during the course of this project, including two female students, and secured employment American technology companies or as research scientists at American institutions.\n\n \n\n\t\t\t\t\tLast Modified: 07/14/2023\n\n\t\t\t\t\tSubmitted by: Matthew Stamm"
 }
}