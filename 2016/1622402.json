{
 "awd_id": "1622402",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Reasoning under Uncertainty in Cybersecurity",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2015-08-07",
 "awd_exp_date": "2017-02-28",
 "tot_intn_awd_amt": 23249.0,
 "awd_amount": 23249.0,
 "awd_min_amd_letter_date": "2016-02-11",
 "awd_max_amd_letter_date": "2016-02-11",
 "awd_abstract_narration": "Cyber security, like security in the physical world, relies upon investigation methodologies that piece together dispersed evidence spread across multiple places, and come to a conclusion on what security breaches have happened and how they happened. While effective evidential reasoning based on manual analysis are used in the physical world by law-enforcement agencies, in the cyber world we need automated reasoning methodologies to handle the automated cyber attacks against our nation's information infrastructures every day. This research aims at discovering and developing such automated reasoning methodologies. The problem is  difficult due to the uncertain nature of such reasoning, which is compounded by the characteristics of cyber attacks.\r\n\r\nThe uncertainty in cyber security comes from two sources. The first is the uncertainty from not knowing the attacker's actions and choices. Since hackers are essentially invisible in the cyberworld, we have to rely upon various types of sensors that report symptoms of potential attacks. The second source of uncertainty comes from these sensors. Since in most cases the symptoms of cyber\r\nattacks significantly overlap with symptoms from benign network activities, it is not possible to rely on a single sensor to give an absolutely correct judgment on whether an attack has happened and succeeded. A key question is how to use these imperfect sensors to conduct reasoning so that one can come up with almost certain conclusions regarding a system's security status. \r\n\r\nThis challenge of reasoning under uncertainty is not new. In the past four decades computer science researchers have developed an array of reasoning models and methods for uncertainty, especially in the area of artificial intelligence. However, the emergence of cyber threats poses a new\r\nchallenge to this problem. The existing methodologies typically require a knowledge-engineering process to build a knowledge model for the problem domain. This has worked reasonably well with the more static and well-behaved problem domains such as disease diagnosis. A key difference between these problem domains and cyber security is that the latter has to deal with an active\r\nmalicious attacker who will try to break whatever assumptions made in the reasoning model. For this reason, the knowledge model for cyber security cannot be static because then they can be easily evaded. What will be an effective and practical knowledge engineering approach to handle the uncertainty in cyber security is the biggest open problem that needs to be answered from the\r\nresearch.\r\n\r\nThis research adopts an empirical, bottom-up approach to tackle the above challenges. Instead of starting from the existing theories, the PI will start from empirical study on how a human security analysts would reason about cyber events and try to capture the essence of the reasoning in the process. Then, the PI will carry out this empirical study by running intrusion detection sensors on production networks and work with system administrators to understand and reason about the alerts. The next step is to develop a reasoning model that simulates the human reasoning process, and apply the automated reasoning engine on fresh new data to see how it fares. In this spiral theory development process the PI can always make sure that the methodologies are applicable to real cyber-security analysis and constantly find gaps in the model that reveal what will be the most appropriate theories and how to apply them in this problem. The eventual goal is to find the right theoretical framework for reasoning under uncertainty in cyber-security, and validate such theories through repeatable experiments on data from production systems.\r\n\r\nThis research is tightly integrated into the PI?s education efforts both for students and targeted at the society at large. The empirical nature of the research provides a valuable venue for dialogue between security practitioners and researchers, which will result in a two-way education process: students working on the project can acquire the essential skills of applying advanced knowledge to a practical problem; and security practitioners like system administrators can learn the state-of-the art in cyber security technology through collaborative work with the research team. The empirical study carried out from the research will provide endless data and examples to refresh the materials of the cyber-security courses taught by the PI. New courses with a focus on uncertainty in cyber security defense will be developed. There will be a number of undergraduate students who take part in the research efforts, which will provide a unique education experience for them. Moreover, the test-bed infrastructure produced from the research will also be used as an education platform for the general public about cyber-security problems, with the help of the out-reach programs already established at Kansas State University.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xinming",
   "pi_last_name": "Ou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xinming Ou",
   "pi_email_addr": "xou@usf.edu",
   "nsf_id": "000189047",
   "pi_start_date": "2016-02-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of South Florida",
  "inst_street_address": "4202 E FOWLER AVE",
  "inst_street_address_2": "",
  "inst_city_name": "TAMPA",
  "inst_state_code": "FL",
  "inst_state_name": "Florida",
  "inst_phone_num": "8139742897",
  "inst_zip_code": "336205800",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "FL15",
  "org_lgl_bus_name": "UNIVERSITY OF SOUTH FLORIDA",
  "org_prnt_uei_num": "",
  "org_uei_num": "NKAZLXLL7Z91"
 },
 "perf_inst": {
  "perf_inst_name": "University of South Florida",
  "perf_str_addr": "",
  "perf_city_name": "Tampa",
  "perf_st_code": "FL",
  "perf_st_name": "Florida",
  "perf_zip_code": "336129446",
  "perf_ctry_code": "US",
  "perf_cong_dist": "15",
  "perf_st_cong_dist": "FL15",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  }
 ],
 "app_fund": [
  {
   "app_code": "0114",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001415DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2014,
   "fund_oblg_amt": 23249.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has produced a number of technologies and insights into how to deal with the uncertainty problem in reasoning about cybersecurity events. Due to the \"invisible\" nature of cyber attacks, to detect them one has to rely upon symptoms observed from the computing systems to infer whether there is malicious misuse. Due to the small amount of attack events compared to the huge volumes of cyber activities generated by legitimate users, mathematically it looks impossible to have reliable detection of attacks without creating too many false alarms that inundate analysts. This project investigated how to effectively deal with this challenge in security analysis, using novel mathematical models and machine learning techniques. The research has created a number of novel models and methods to handle the false positive problem in cybersecurity analysis. These models have been evaluated on large sets of real-world data from numerous operational environments. The evaluation results show that a key insight to addressing the uncertainty problem, is to view the result from any automated reasoning system as a triage guidance, as opposed to a final decision maker. The right way to determine whether any such model and tool is useful, is to evaluate whether the output can effectively reduce analysts' time in making the final decisions. The research results have been published in a large number of reputable peer-reviewed computer security conferences (the primary venue for publishing research results in this area), and attracted strong interest from industry to transition the research result into practical use. In particular, HP Labs collaborated with the PI on this research and successfully transitioned some results from the research into a number of tools used internally by HP security analysts, and a product that eventually got commercialized into the HP ArcSight SIEM (security information and event management) system.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/03/2017<br>\n\t\t\t\t\tModified by: Xinming&nbsp;Ou</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project has produced a number of technologies and insights into how to deal with the uncertainty problem in reasoning about cybersecurity events. Due to the \"invisible\" nature of cyber attacks, to detect them one has to rely upon symptoms observed from the computing systems to infer whether there is malicious misuse. Due to the small amount of attack events compared to the huge volumes of cyber activities generated by legitimate users, mathematically it looks impossible to have reliable detection of attacks without creating too many false alarms that inundate analysts. This project investigated how to effectively deal with this challenge in security analysis, using novel mathematical models and machine learning techniques. The research has created a number of novel models and methods to handle the false positive problem in cybersecurity analysis. These models have been evaluated on large sets of real-world data from numerous operational environments. The evaluation results show that a key insight to addressing the uncertainty problem, is to view the result from any automated reasoning system as a triage guidance, as opposed to a final decision maker. The right way to determine whether any such model and tool is useful, is to evaluate whether the output can effectively reduce analysts' time in making the final decisions. The research results have been published in a large number of reputable peer-reviewed computer security conferences (the primary venue for publishing research results in this area), and attracted strong interest from industry to transition the research result into practical use. In particular, HP Labs collaborated with the PI on this research and successfully transitioned some results from the research into a number of tools used internally by HP security analysts, and a product that eventually got commercialized into the HP ArcSight SIEM (security information and event management) system.\n\n\t\t\t\t\tLast Modified: 06/03/2017\n\n\t\t\t\t\tSubmitted by: Xinming Ou"
 }
}