{
 "awd_id": "1640131",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Research Supporting Multisensory Engagement by Blind, Visually Impaired, and Sighted Students to Advance Integrated Learning of Astronomy and Computer Science",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032925117",
 "po_email": "adestrul@nsf.gov",
 "po_sign_block_name": "Arlene de Strulle",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 2499186.0,
 "awd_amount": 2515186.0,
 "awd_min_amd_letter_date": "2016-09-01",
 "awd_max_amd_letter_date": "2018-08-23",
 "awd_abstract_narration": "Computing and computational thinking are an integral part of everyday practice within modern fields of science, technology, engineering, and math (STEM). As a result, the STEM+Computing Partnerships (STEM+C) program seeks to advance new multidisciplinary approaches to, and evidence-based understanding of, the integration of computing in STEM teaching and learning, and discipline-specific efforts in computing designed to build an evidence base for teaching and learning of computer science in K-12, including within diverse populations. In the case of astronomy, computing and computational thinking (CT) are used for nearly every aspect of collecting, processing, and analyzing data. Yet, few educational resources exist to support students in learning astronomy in the computationally-intensive way that it is practiced. Furthermore, the predominance of visual interfaces that support computing processes present unique challenges for blind and visually impaired (BVI) individuals. The dearth of vision-neutral tools in astronomy and computer science introduce additional barriers to learning and workforce entry for BVI individuals. To address these challenges, this project will develop, implement, and study an innovative educational program that provides BVI and sighted students with opportunities to learn how to apply computing and computational thinking to design fully-accessible astronomical tools and to use those tools for their own astronomy inquiry. Investigators hypothesize that students' participation in both the user-centered design/universal design process and in the use of the resulting tools for astronomy inquiry will foster learning and broaden interest and participation in the high-barrier disciplines of computer science and astronomy. Led by investigators at Associated Universities Inc., the project team includes astronomers, computer scientists, software engineers, education developers, and learning scientists from University of North Carolina at Chapel Hill, University of Chicago Yerkes Observatory, TERC, and the University of Nevada Las Vegas. Approximately 200 BVI and sighted students near Yerkes Observatory and across the nation, will be involved with and benefit from the project. The demographically diverse student population will help the project achieve significant broader impacts, by assuring that the research findings and developed tools and resources reflect the needs of a broad diversity of people and places in which they learn. By enabling multi-sensory engagement for data acquisition, processing, and analysis processes, the developed tools will improve access to astronomy and to other visually- and computationally-intensive domains such as satellite, geophysical, and medical imaging.\r\n\r\nThis project will address a daunting challenge to developing STEM literacy in students - integrating teaching and learning of key ideas and practices of science and computer science in authentic, innovative and effective ways - while instilling the societal value of computational tools that increase access for all. Key components of the education intervention include a) inquiry-based curricular modules and facilitated activities that teach computing in the context of astronomy; b) a scaffolded process of user-centered design/universal design that underscores computational thinking practices in the context of optimizing astronomy tools to be fully-accessible to all users; c) student-driven, authentic astronomy research; and d) BVI and sighted astronomers and computer scientists as mentors and role models to the community of learners.  The intervention will address relevant disciplinary content, practices, and computation as specified in Next Generation Science Standards, Common Core State Standards for mathematics, and K-12 Computer Science Standards. The project will engage 20 teachers and 200 students from mainstream and specialized schools for the blind over three years. Quantitative and qualitative analysis of student and teacher assessments, surveys, interviews, work products, and user' computer log files, and classroom observations will be used to determine the effectiveness and broad utility of the approach for integrating physics and computing The student-level research questions focus on how students' understanding and use of computational thinking develops in relation to astronomy and the specific astronomy tools they use; and how students' participation augments their interest, self-efficacy, and understandings of who can participate in astronomy and computing. The teacher-level research focuses on teachers' capacity to integrate astronomy and computing and to support BVI students' learning in their classrooms. The project will provide the first longitudinal study of student learning and behaviors in the context of integrating astronomy and computer science. It will deepen understanding of how multisensory computing inputs and outputs support learning for BVI and sighted students. The project will begin to inform the field about how BVI individuals can participate in the workforce at the intersection of high barrier-to-entry disciplines, astronomy and computer science. The project team and advisory board members will disseminate findings to their respective professional associations and networks, including the American Astronomical Society and the American Geophysical Union, and through traditional means, such as papers in peer-reviewed journals and conference presentations. The accessible tools and educational resources produced in this study will be freely available to K-12 teachers nationwide and could be widely adopted by BVI and sighted individuals in astronomy and other visually-intensive domains.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Timothy",
   "pi_last_name": "Spuck",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Timothy Spuck",
   "pi_email_addr": "tspuck@aui.edu",
   "nsf_id": "000668215",
   "pi_start_date": "2016-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Doyal",
   "pi_last_name": "Harper",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Doyal A Harper",
   "pi_email_addr": "al@oddjob.uchicago.edu",
   "nsf_id": "000258663",
   "pi_start_date": "2016-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Reichart",
   "pi_mid_init": "E",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel E Reichart",
   "pi_email_addr": "reichart@physics.unc.edu",
   "nsf_id": "000231642",
   "pi_start_date": "2016-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Hammerman",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "James K Hammerman",
   "pi_email_addr": "jim_hammerman@terc.edu",
   "nsf_id": "000311541",
   "pi_start_date": "2016-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andreas",
   "pi_last_name": "Stefik",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Andreas M Stefik",
   "pi_email_addr": "stefika@gmail.com",
   "nsf_id": "000530645",
   "pi_start_date": "2016-09-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Associated Universities, Inc.",
  "inst_street_address": "2650 PARK TOWER DR STE 700",
  "inst_street_address_2": "",
  "inst_city_name": "VIENNA",
  "inst_state_code": "VA",
  "inst_state_name": "Virginia",
  "inst_phone_num": "2024621676",
  "inst_zip_code": "221807300",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "VA11",
  "org_lgl_bus_name": "ASSOCIATED UNIVERSITIES INC",
  "org_prnt_uei_num": "",
  "org_uei_num": "NZBMKZMW68N3"
 },
 "perf_inst": {
  "perf_inst_name": "Associated Universities Inc/National Radio Astronomy Observatory",
  "perf_str_addr": "1400 16th Street NW #730",
  "perf_city_name": "Washington",
  "perf_st_code": "DC",
  "perf_st_name": "District of Columbia",
  "perf_zip_code": "200362252",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "DC",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "005Y00",
   "pgm_ele_name": "STEM + Computing (STEM+C) Part"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0416",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001617DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0418",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001819DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 2499186.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>Research Supporting <span>Multisensory</span> Engagement by Blind, Visually Impaired, and Sighted Students to Advance Integrated Learning of Astronomy and Computer Science, NSF-1640131 (aka - Innovators Developing Accessible Tools for Astronomy - <span>IDATA</span>) explored how blind and visually impaired (<span>BVI</span>) middle and high school students and their sighted peers could use computational tools to engage in astronomy data collection and analysis. Students and their teachers partnered with undergraduate students, software engineers, astronomers, educators, and education researchers to design and develop a new <span>BVI</span>-accessible image analysis software tool called Afterglow Access (<span>AgA</span>). Accessible computational thinking and astronomy hands-on activities and <span>online</span> learning modules were also developed to support student learning.</span></p>\n<p><span>The <span>AgA</span> software resulting from <span>IDATA</span> is a full astronomy image analysis package with the ability to manipulate image appearance, measure brightness and position of objects, measure angular distance between objects, align sets of images, and much more. <span>AgA</span> was designed as a web application so that it works within most web browsers, and the core software is server-based making it easy to update and expand as need increases. No local software installation is required for individual users, greatly increasing potential for use in a variety of education settings.</span></p>\n<p><span>A number of features in <span>AgA</span> are also accessible to <span>BVI</span> individuals: 1) <span>AgA</span> is screen reader compliant; 2) <span>AgA</span> incorporates a breadth of intuitive, keyboard shortcuts, allowing <span>BVI</span> users to navigate without having to use a mouse; and 3) <span>AgA</span> is <span>zoomable</span>, and its color theme, font weight, and font size are easily customizable. <span>AgA</span> also features an image-<span>sonification</span> tool. With minimal training, one can broadly classify different types of astronomical objects. For example, globular clusters sound very different from galaxies or nebulae, and stray satellites are particularly easy to identify, sounding like someone sweeping their finger across the length of the keyboard. Navigation tools have also been built into the interface, allowing the user to zoom in to low, middle, or high frequencies, and early, middle, or late times in the <span>sonogram</span>, and then re-<span>sonify</span> the zoomed-in region. Preliminary testing of the software with <span>BVI</span> persons has shown they can use sound to identify different sources in astronomical images.</span></p>\n<p><span><span>IDATA</span> also resulted in the development of a number of curricular resources for use by both sighted and <span>BVI</span> students. Eight hands-on, accessible activities, along with appropriate lessons for using them were created and integrated into an <span>online</span> accessible asteroid search learning module. The hands-on resources and learning module provide students the opportunity to explore computation in astronomy and the Quorum programming language as they come to understand the way telescopes work with <span>CCD</span> cameras to collect light and produce astronomical images (data arrays). Students then use images to explore a known asteroid and generate a light curve caused by its rotation. In addition, <span>IDATA</span> also produced the Astronomy Hour of Code which helps users understand how astronomers use robotic telescopes via the Quorum programming language. To date the Astronomy Hour of Code has recorded nearly 190,000 sessions.</span></p>\n<p><span><span>IDATA</span> conducted education research to determine how student engagement with the modules and software affected their understanding of astronomy and computational thinking, as well as how it affected their attitudes about people with visual impairments engaging in STEM. <span>IDATA</span> research developed <span>BVI</span>-accessible instruments to measure gains in computational thinking, astronomy content, and STEM attitudes. The learning materials were accessible to students ? <span>BVI</span> students engaged with the modules at rates equal to their sighted peers. All students had small but statistically significant gains in both astronomy and computational thinking knowledge (focusing on data practices and computational problem-solving practices), and these gains were no different for visually impaired and sighted students. The impact on beliefs about <span>BVI</span> individuals' ability to engage successfully in computing and astronomy were more complicated: Sighted students slightly increased these beliefs; students with visual impairments had comparable increases in these beliefs about computing, but reduced these beliefs about people with visual impairments engaging in astronomy.</span></p>\n<p>For more information and to access IDATA resources, please visit <a href=\"https://idataproject.org/\" target=\"_blank\"><span><span>https</span>://<span>idataproject</span>.<span>org</span>/</span></a>.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/03/2023<br>\n\t\t\t\t\tModified by: Timothy&nbsp;Spuck</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672787759147_IMG_1592--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672787759147_IMG_1592--rgov-800width.jpg\" title=\"Exploring Data Array\"><img src=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672787759147_IMG_1592--rgov-66x44.jpg\" alt=\"Exploring Data Array\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Blind and visually impaired (BVI) and sighted IDATA Participants use a Connect Four: Vertical Checker Game to explore how data array (images) are constructed using a CCD camera.</div>\n<div class=\"imageCredit\">Spuck, T.</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Timothy&nbsp;Spuck</div>\n<div class=\"imageTitle\">Exploring Data Array</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672788342703_IMG_1589--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672788342703_IMG_1589--rgov-800width.jpg\" title=\"Exploring Accessible Software Features via Board Games\"><img src=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672788342703_IMG_1589--rgov-66x44.jpg\" alt=\"Exploring Accessible Software Features via Board Games\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">IDATA participants use board games to explore the concept of accessibility. Navigating a board game can be analogous to navigating software. This activity helped participants make software design recommendations.</div>\n<div class=\"imageCredit\">Spuck, T.</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Timothy&nbsp;Spuck</div>\n<div class=\"imageTitle\">Exploring Accessible Software Features via Board Games</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672788830912_AgAImage--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672788830912_AgAImage--rgov-800width.jpg\" title=\"Afterglow Access Software\"><img src=\"/por/images/Reports/POR/2023/1640131/1640131_10457983_1672788830912_AgAImage--rgov-66x44.jpg\" alt=\"Afterglow Access Software\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Screen shots from Afterglow Access (AgA) show the Display Settings screen (upper) and the Sonification screen (lower). Images can be explored either visually or through sound.</div>\n<div class=\"imageCredit\">Spuck, T.</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Timothy&nbsp;Spuck</div>\n<div class=\"imageTitle\">Afterglow Access Software</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nResearch Supporting Multisensory Engagement by Blind, Visually Impaired, and Sighted Students to Advance Integrated Learning of Astronomy and Computer Science, NSF-1640131 (aka - Innovators Developing Accessible Tools for Astronomy - IDATA) explored how blind and visually impaired (BVI) middle and high school students and their sighted peers could use computational tools to engage in astronomy data collection and analysis. Students and their teachers partnered with undergraduate students, software engineers, astronomers, educators, and education researchers to design and develop a new BVI-accessible image analysis software tool called Afterglow Access (AgA). Accessible computational thinking and astronomy hands-on activities and online learning modules were also developed to support student learning.\n\nThe AgA software resulting from IDATA is a full astronomy image analysis package with the ability to manipulate image appearance, measure brightness and position of objects, measure angular distance between objects, align sets of images, and much more. AgA was designed as a web application so that it works within most web browsers, and the core software is server-based making it easy to update and expand as need increases. No local software installation is required for individual users, greatly increasing potential for use in a variety of education settings.\n\nA number of features in AgA are also accessible to BVI individuals: 1) AgA is screen reader compliant; 2) AgA incorporates a breadth of intuitive, keyboard shortcuts, allowing BVI users to navigate without having to use a mouse; and 3) AgA is zoomable, and its color theme, font weight, and font size are easily customizable. AgA also features an image-sonification tool. With minimal training, one can broadly classify different types of astronomical objects. For example, globular clusters sound very different from galaxies or nebulae, and stray satellites are particularly easy to identify, sounding like someone sweeping their finger across the length of the keyboard. Navigation tools have also been built into the interface, allowing the user to zoom in to low, middle, or high frequencies, and early, middle, or late times in the sonogram, and then re-sonify the zoomed-in region. Preliminary testing of the software with BVI persons has shown they can use sound to identify different sources in astronomical images.\n\nIDATA also resulted in the development of a number of curricular resources for use by both sighted and BVI students. Eight hands-on, accessible activities, along with appropriate lessons for using them were created and integrated into an online accessible asteroid search learning module. The hands-on resources and learning module provide students the opportunity to explore computation in astronomy and the Quorum programming language as they come to understand the way telescopes work with CCD cameras to collect light and produce astronomical images (data arrays). Students then use images to explore a known asteroid and generate a light curve caused by its rotation. In addition, IDATA also produced the Astronomy Hour of Code which helps users understand how astronomers use robotic telescopes via the Quorum programming language. To date the Astronomy Hour of Code has recorded nearly 190,000 sessions.\n\nIDATA conducted education research to determine how student engagement with the modules and software affected their understanding of astronomy and computational thinking, as well as how it affected their attitudes about people with visual impairments engaging in STEM. IDATA research developed BVI-accessible instruments to measure gains in computational thinking, astronomy content, and STEM attitudes. The learning materials were accessible to students ? BVI students engaged with the modules at rates equal to their sighted peers. All students had small but statistically significant gains in both astronomy and computational thinking knowledge (focusing on data practices and computational problem-solving practices), and these gains were no different for visually impaired and sighted students. The impact on beliefs about BVI individuals' ability to engage successfully in computing and astronomy were more complicated: Sighted students slightly increased these beliefs; students with visual impairments had comparable increases in these beliefs about computing, but reduced these beliefs about people with visual impairments engaging in astronomy.\n\nFor more information and to access IDATA resources, please visit https://idataproject.org/.\n\n\t\t\t\t\tLast Modified: 01/03/2023\n\n\t\t\t\t\tSubmitted by: Timothy Spuck"
 }
}