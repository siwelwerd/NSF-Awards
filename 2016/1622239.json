{
 "awd_id": "1622239",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase I:  Virtual Interview Trait Estimation Combining Speech and Touch",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032928772",
 "po_email": "patherto@nsf.gov",
 "po_sign_block_name": "Peter Atherton",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2017-12-31",
 "tot_intn_awd_amt": 225000.0,
 "awd_amount": 225000.0,
 "awd_min_amd_letter_date": "2016-06-22",
 "awd_max_amd_letter_date": "2016-06-22",
 "awd_abstract_narration": "The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is in improved efficiency in labor markets by enabling faster, more accurate assessments of the interpersonal traits (\"soft skills\") of job candidates, employees, and students.  The project develops methods for accurate automated screening interviews that can save time, effort, and money for both employers and job seekers - delivering a more efficient candidate selection process for U.S. companies and public agencies that conduct hundreds of millions of screening interviews with job candidates each year. This project is focused on performance assessments of attitude, energy and social communication, specifically as these qualities are needed for selection of people for cooperative roles in employment settings. The project's applied research will refine (and may reconceive) the behavioral definitions of traits that are valued in employee selection because they are held to be predictive of success in work settings and in occupational training. Resultant refined measurement tools may enable advances in applied fields like industrial psychology and provide more precise variables for use in basic studies of the neurological correlates of emotion, social perception, personality, and mental disorders. \r\n\r\nThis Small Business Innovation Research (SBIR) Phase I project designs, develops and fields a prototype app that conducts an automated Virtual Screening Interview (VSI). The VSI app is an experimental instrument that probes job-relevant traits in speech and touch responses.  In recent decades, algorithms have estimated people's affect, sentiment, and emotions as observed in facial expression, text content, tone of voice, speech rate, gestures, posture and other body language. Among these, speech prosody, linguistic content, and facial expression have proven to be strong indicators of emotional valence (attitude) and psychomotor activation (energy level). VSI system research will identify measurable traits that support rapid learning and successful performance in activities and occupations that require teamwork or social skill.  The VSI app collects performance data (voice and screen-touch tracks) on mobile devices to investigate novel combinations of features from speech and motion that accelerate and improve trait measurement. The project will generate new knowledge about how the relationships between speech and movement can match expert evaluations of people in work groups and in social settings. Measurement technologies developed in the project may also be applied in education and industry to improve the efficiency and effectiveness of instruction and training.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jared",
   "pi_last_name": "Bernstein",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Jared C Bernstein",
   "pi_email_addr": "jared@analyticmeasures.com",
   "nsf_id": "000712359",
   "pi_start_date": "2016-06-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Analytic Measures Incorporated",
  "inst_street_address": "42 BOTANY CT",
  "inst_street_address_2": "",
  "inst_city_name": "EMERALD HILLS",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6503272929",
  "inst_zip_code": "940623101",
  "inst_country_name": "United States",
  "cong_dist_code": "15",
  "st_cong_dist_code": "CA15",
  "org_lgl_bus_name": "ANALYTIC MEASURES INCORPORATED",
  "org_prnt_uei_num": "",
  "org_uei_num": "EEMZNW9F5JM1"
 },
 "perf_inst": {
  "perf_inst_name": "Analytic Measures Inc.",
  "perf_str_addr": "1330 Tasso St.",
  "perf_city_name": "Palo Alto",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943013635",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537100",
   "pgm_ele_name": "SBIR Phase I"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5371",
   "pgm_ref_txt": "SMALL BUSINESS PHASE I"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Analytic Measures Inc. (AMI) designed, built and evaluated a virtual screening interview app, called PACES (Profile of Attitude, Communication, Energy, Skills). The PACES app is an automated voice-interactive assessment of a job candidate&rsquo;s intrapersonal and interpersonal qualities. The PACES app was designed to improve recruiting efficiency by identifying promising candidates for interviews early in the recruiting process. The initial design aimed to assess a candidate&rsquo;s social and personal qualities &ndash; the qualities that normally only emerge in an interview: mind-set, energy, and spontaneous communication skills.</p>\n<p>Before development, AMI conceived of PACES as a tool to ensure that more costly, human interviewing resources would be applied to candidates that PACES estimated had good social communication skills, positive attitudes and apparent energy. The PACES app also served as an experimental platform for data capture and machine learning research.</p>\n<p>The PACES app runs on iPhones and presents a series of spoken queries and other tasks designed to elicit spoken answers from a job candidate.&nbsp; These spoken answers, along with some screen touches, are automatically analyzed to measure a user&rsquo;s attitude, energy and social communication skills. Virtual interviews on the PACES app lasted 15 minutes on average and record about nine minutes of speech from each candidate.</p>\n<p>AMI tested the PACES app with paid participants and with hundreds of real job applicants.&nbsp; The machine learning process involved first establishing that candidates&rsquo; intrapersonal and interpersonal qualities can be found in the recordings of the spoken answers. Then one can train a machine extract that information from the recordings. AMI conducted an experiment in which applicant spoken responses were presented to human listeners for judgments of five qualities: attitude, energy, communication, politeness, and memory (for narratives and faces). Analysis of the listener judgments indicated that these candidate qualities can be extracted with substantial consistency by listener judges. Item Response Theoretic (IRT) analysis of the human judgments returned score reliabilities between 0.87 and 0.94 for the five qualities.&nbsp; Machine scores of spoken responses for these five qualities aligns well with the human judgments, as indicated by machine-human correlations. These results support the hypothesis that &ldquo;soft skills&rdquo; can be measured automatically from spontaneous spoken responses to an automated interview app and that accurate machine scoring is clearly feasible for three of them and within reach for all of them.</p>\n<p>Products of this project include the software framework behind the PACES app and four forms of the app that present sequences of questions and tasks that are proven effective in eliciting spontaneous spoken material that contains reliable indicators of a person&rsquo;s characteristics.&nbsp; Over 17,000 speech recordings and screen-touch responses from these virtual interviews were uploaded to a research database where they have been processed in a first wave of analysis that has established the feasibility of the project&rsquo;s original goals.&nbsp; The data itself and the first generation of machine scoring algorithms remain available for AMI&rsquo;s continued developments, protected by a pending patent application that covers AMI&rsquo;s approach to scoring these qualities in an app like PACES.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/23/2018<br>\n\t\t\t\t\tModified by: Jared&nbsp;C&nbsp;Bernstein</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nAnalytic Measures Inc. (AMI) designed, built and evaluated a virtual screening interview app, called PACES (Profile of Attitude, Communication, Energy, Skills). The PACES app is an automated voice-interactive assessment of a job candidate?s intrapersonal and interpersonal qualities. The PACES app was designed to improve recruiting efficiency by identifying promising candidates for interviews early in the recruiting process. The initial design aimed to assess a candidate?s social and personal qualities &ndash; the qualities that normally only emerge in an interview: mind-set, energy, and spontaneous communication skills.\n\nBefore development, AMI conceived of PACES as a tool to ensure that more costly, human interviewing resources would be applied to candidates that PACES estimated had good social communication skills, positive attitudes and apparent energy. The PACES app also served as an experimental platform for data capture and machine learning research.\n\nThe PACES app runs on iPhones and presents a series of spoken queries and other tasks designed to elicit spoken answers from a job candidate.  These spoken answers, along with some screen touches, are automatically analyzed to measure a user?s attitude, energy and social communication skills. Virtual interviews on the PACES app lasted 15 minutes on average and record about nine minutes of speech from each candidate.\n\nAMI tested the PACES app with paid participants and with hundreds of real job applicants.  The machine learning process involved first establishing that candidates? intrapersonal and interpersonal qualities can be found in the recordings of the spoken answers. Then one can train a machine extract that information from the recordings. AMI conducted an experiment in which applicant spoken responses were presented to human listeners for judgments of five qualities: attitude, energy, communication, politeness, and memory (for narratives and faces). Analysis of the listener judgments indicated that these candidate qualities can be extracted with substantial consistency by listener judges. Item Response Theoretic (IRT) analysis of the human judgments returned score reliabilities between 0.87 and 0.94 for the five qualities.  Machine scores of spoken responses for these five qualities aligns well with the human judgments, as indicated by machine-human correlations. These results support the hypothesis that \"soft skills\" can be measured automatically from spontaneous spoken responses to an automated interview app and that accurate machine scoring is clearly feasible for three of them and within reach for all of them.\n\nProducts of this project include the software framework behind the PACES app and four forms of the app that present sequences of questions and tasks that are proven effective in eliciting spontaneous spoken material that contains reliable indicators of a person?s characteristics.  Over 17,000 speech recordings and screen-touch responses from these virtual interviews were uploaded to a research database where they have been processed in a first wave of analysis that has established the feasibility of the project?s original goals.  The data itself and the first generation of machine scoring algorithms remain available for AMI?s continued developments, protected by a pending patent application that covers AMI?s approach to scoring these qualities in an app like PACES. \n\n \n\n\t\t\t\t\tLast Modified: 01/23/2018\n\n\t\t\t\t\tSubmitted by: Jared C Bernstein"
 }
}