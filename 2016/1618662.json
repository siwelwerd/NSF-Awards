{
 "awd_id": "1618662",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Collaborative Research: On-Line Learning Algorithms for Path Experts with Non-Additive Losses",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rebecca Hwa",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 275000.0,
 "awd_amount": 275000.0,
 "awd_min_amd_letter_date": "2016-09-07",
 "awd_max_amd_letter_date": "2016-09-07",
 "awd_abstract_narration": "On-line learning algorithms are increasingly adopted as the key solution to modern learning applications with very large data sets of several hundred million or billion points.  These algorithms process one sample at a time with an update per iteration that is typically computationally cheap and easy to implement. Additionally, these algorithms benefit from a rich theoretical foundation.  The objective of this research is to advance on-line learning by broadening its applicability to a variety of applications including machine translation, speech recognition, other natural language processing applications, handwriting recognition, computer vision, bioinformatics, and many other areas which can benefit the society. Expert skills and student talent will be combined to create effective theoretical and algorithmic solutions and open-source software tools tested experimentally that can benefit a wide community.\r\n\r\nMost learning problems admit some structure. In such problems, experts can be viewed as paths in a directed graph with each edge corresponding to a sub-structure corresponding to a word, phoneme, character, or image patch.  Current on-line algorithms with path experts are limited to additive losses and therefore are not applicable in many important applications where the loss is non-additive. We will create the theoretical foundation for designing efficient on-line algorithms for learning with path experts with non-additive losses.  Such non-additive losses are the relevant loss functions in most important applications such as machine translation, speech recognition, pronunciation modeling, parsing, image processing and other areas.  Carefully designed weighted automata and semiring tools will be used to devise on-line algorithms for path experts with non-additive losses.  The theoretical analysis of the algorithms will be complemented by a thorough experimental evaluation in a variety of applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mehryar",
   "pi_last_name": "Mohri",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mehryar Mohri",
   "pi_email_addr": "mohri@cims.nyu.edu",
   "nsf_id": "000201880",
   "pi_start_date": "2016-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "251 Mercer Street",
  "perf_city_name": "New York",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100121110",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 275000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main objectives of this project were the design of online learning algorithms with favorable regret guarantees both in the fullinformation and the bandit setting for graph path experts withnon-additive losses, and their applications to problems such asstructured prediction, including their evaluation. Our objectives alsoincluded the design of online learning algorithms generally relevant tothese applications.</p>\n<p>The outcomes of the project include a broad series of results showingthe success of the project. They include the recent algorithms forcorralling stochastic bandit algorithms, that is combining multiplebandit algorithms designed for a stochastic environment, with the goalof devising a corralling algorithm that performs almost as well as thebest base algorithm. Our solutions can be useful in a variety ofcontexts for combining existing bandit algorithms, includingalgorithms for graph path experts. We gave two general corrallingalgorithms for this setting, which we show benefit from favorableregret guarantees. We showed that the regret of the corrallingalgorithms is no worse than that of the best algorithm containing thearm with the highest reward, and that it depends on the gap betweenthe highest reward and other rewards.</p>\n<p>Altogether, we devised a series of algorithmic solutions fora broad set of online learning and bandit problems, includingsolutions for problems with non-additive losses. The theoreticalconcepts introduced, including our proof techniques, can berelevant in a variety of other similar contexts.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/30/2021<br>\n\t\t\t\t\tModified by: Mehryar&nbsp;Mohri</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main objectives of this project were the design of online learning algorithms with favorable regret guarantees both in the fullinformation and the bandit setting for graph path experts withnon-additive losses, and their applications to problems such asstructured prediction, including their evaluation. Our objectives alsoincluded the design of online learning algorithms generally relevant tothese applications.\n\nThe outcomes of the project include a broad series of results showingthe success of the project. They include the recent algorithms forcorralling stochastic bandit algorithms, that is combining multiplebandit algorithms designed for a stochastic environment, with the goalof devising a corralling algorithm that performs almost as well as thebest base algorithm. Our solutions can be useful in a variety ofcontexts for combining existing bandit algorithms, includingalgorithms for graph path experts. We gave two general corrallingalgorithms for this setting, which we show benefit from favorableregret guarantees. We showed that the regret of the corrallingalgorithms is no worse than that of the best algorithm containing thearm with the highest reward, and that it depends on the gap betweenthe highest reward and other rewards.\n\nAltogether, we devised a series of algorithmic solutions fora broad set of online learning and bandit problems, includingsolutions for problems with non-additive losses. The theoreticalconcepts introduced, including our proof techniques, can berelevant in a variety of other similar contexts.\n\n\t\t\t\t\tLast Modified: 11/30/2021\n\n\t\t\t\t\tSubmitted by: Mehryar Mohri"
 }
}