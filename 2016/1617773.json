{
 "awd_id": "1617773",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NeTS: Small: Collaborative Research: Enabling Application-Level Performance Predictability in Public Clouds",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Darleen Fisher",
 "awd_eff_date": "2016-10-01",
 "awd_exp_date": "2019-09-30",
 "tot_intn_awd_amt": 238500.0,
 "awd_amount": 238500.0,
 "awd_min_amd_letter_date": "2016-08-29",
 "awd_max_amd_letter_date": "2016-08-29",
 "awd_abstract_narration": "State-of-the-art resource sharing mechanisms in today's datacenters and compute clouds are agnostic to application-level performance requirements, resulting in unpredictable performance. This is especially true for the network. Unlike, CPU, memory, or disk, cloud operators do not provide any guarantees for the network. Many tenants rely on over-provisioning and static allocation for performance isolation, which results in low utilization and increased cost and environmental impacts. This project aims to build a set of solutions to achieve short- and long-term performance predictability with high resource utilization. The goal is to enable coexisting applications from different tenants to meet a variety of performance objectives including obtaining timely responses and minimizing variance of successive responses, while adhering to organizational hierarchies of individual tenants. The key technical challenges in this project include developing short- and long-term resource allocation algorithms, accurate demand estimation, as well as fast and efficient enforcement, all of which are compounded by the multi-resource and shared nature of the network. Two key techniques guide the proposed work: (i) temporal scheduling ensures predictable performance through short- and long-term performance isolation, and (ii) spatial placement ensures higher utilization through initial placement and periodic migration of tenants' virtual machines.\r\n\r\nPredictable, efficient data analytics will have significant socio-economic ramifications. It will also enable mission-critical applications, e.g., anomaly detection, fraud protection, autonomous vehicles, and robotics-- that require a highly consistent and reliable level of performance to coexist with the less sensitive ones. Algorithms and software from the project will be incorporated into existing open-source big data stacks for public reuse.  By leveraging ongoing relationships with the industry, artifacts from this project will be converted from research into practice in a fast manner. The project has significant educational and outreach components, which include introducing new courses at both graduate and undergraduate levels based on the outcomes of this project as well as arranging cloud computing boot camps aimed at students from high schools and involving women and under-represented minorities.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mosharaf",
   "pi_last_name": "Chowdhury",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mosharaf Chowdhury",
   "pi_email_addr": "mosharaf@umich.edu",
   "nsf_id": "000702601",
   "pi_start_date": "2016-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 238500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>State-of-the-art resource sharing mechanisms in today's cloud datacenters are agnostic to application-level performance requirements, resulting in unpredictable performance. This is as true for the network as it is for CPU, memory, or disk. Many tenants rely on over-provisioning and static allocation for performance isolation, which results in low utilization and increased cost and environmental impacts.</p>\n<p>The overarching goal of this project was to build a set of solutions to achieve short&shy; and long&shy;-term performance predictability with high resource utilization and improved application-level performance. As part of this project, we built a suite of solutions -- that span the entire cloud stack -- to enable coexisting applications from different tenants to meet a variety of performance objectives including obtaining timely responses and minimizing variance of successive responses, while adhering to organizational hierarchies of individual tenants.</p>\n<p>In terms of networking, we have designed and developed a datacenter load balancing solution (Hermes) as well as an end-host latency optimization mechanism (Leap). Hermes is a transport layer-aware load balancing solution that&nbsp;detects path conditions via comprehensive sensing using transport-level signals such as ECN and RTT.&nbsp;To further improve visibility, Hermes employs active probing &ndash; guided by the power of two choices technique &ndash; that can effectively increase the scope of sensing at minimal probing cost. Overall, it outperforms the state-of-the-art by more than 30%. Leap, in contrast, focuses on improving the data path inside the Linux kernel by removing unnecessary queueing and by proposing a new data prefetching algorithm. It improves the performance of low-latency, memory-intensive applications by up to 10X.</p>\n<p>In terms of resource management, we have designed two solutions: one that handles heterogeneous requests with throughput and latency constraints (BoPF) and one that handles heterogeneous compute resources such as CPU and GPU (AlloX). BoPF&nbsp;relies on the observation that throughput-sensitive tenants do not care about allocated resources in the short term, as long as the long-term averaged resource share remains the same. This temporal flexibility allows us to accommodate bursts of latency-sensitive tenants without hurting throughput-sensitive ones. It outperforms existing solutions by more than 5X in terms of performance while providing the same level of fairness. AlloX focuses on carefully&nbsp;picking CPU and GPU combinations for deep learning training jobs. The key idea is leveraging the interchangeability of computation resources. By judiciously combining both, AlloX can improve average training time by as much as 95% in comparison to existing solutions that ignore resource interchangeability.&nbsp;</p>\n<p>Finally, in the application level, we explored cloud applications are designed to interact with their data: is it via a key-value (KV) store or via remote procedure call (RPC).&nbsp;We observed that the root cause behind this choice -- and subsequent dichotomy between the two views -- is the shifting balance between CPU and network bottlenecks of a workload. One can improve throughput while satisfying service-level objectives (SLOs) by judiciously employing both at the same.&nbsp;We have proposed a fully decentralized algorithm (Kayak) that runs only on the client side and dynamically chooses the best option based on the shifting balance. Overall, Kayak can improve throughput by 35% by combining the best of both worlds.</p>\n<p>All software developed as part of this project are based on established open-source systems such as Kubernetes, and we have and continue to open-source our works at&nbsp;<a href=\"https://github.com/symbioticlab\">https://github.com/symbioticlab</a>. Research papers summarizing our works have been published or are under submission in top venues in networking and systems including SIGCOMM and NSDI. Some of the works have been incorporated into course contents in graduate- and undergraduate-level systems and networking courses at the University of Michigan. Last but not the least, three PhD students at the University of Michigan have worked on different pieces of our contributions, and this grant has helped in partly supporting their education and training.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/06/2020<br>\n\t\t\t\t\tModified by: Mosharaf&nbsp;Chowdhury</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nState-of-the-art resource sharing mechanisms in today's cloud datacenters are agnostic to application-level performance requirements, resulting in unpredictable performance. This is as true for the network as it is for CPU, memory, or disk. Many tenants rely on over-provisioning and static allocation for performance isolation, which results in low utilization and increased cost and environmental impacts.\n\nThe overarching goal of this project was to build a set of solutions to achieve short&shy; and long&shy;-term performance predictability with high resource utilization and improved application-level performance. As part of this project, we built a suite of solutions -- that span the entire cloud stack -- to enable coexisting applications from different tenants to meet a variety of performance objectives including obtaining timely responses and minimizing variance of successive responses, while adhering to organizational hierarchies of individual tenants.\n\nIn terms of networking, we have designed and developed a datacenter load balancing solution (Hermes) as well as an end-host latency optimization mechanism (Leap). Hermes is a transport layer-aware load balancing solution that detects path conditions via comprehensive sensing using transport-level signals such as ECN and RTT. To further improve visibility, Hermes employs active probing &ndash; guided by the power of two choices technique &ndash; that can effectively increase the scope of sensing at minimal probing cost. Overall, it outperforms the state-of-the-art by more than 30%. Leap, in contrast, focuses on improving the data path inside the Linux kernel by removing unnecessary queueing and by proposing a new data prefetching algorithm. It improves the performance of low-latency, memory-intensive applications by up to 10X.\n\nIn terms of resource management, we have designed two solutions: one that handles heterogeneous requests with throughput and latency constraints (BoPF) and one that handles heterogeneous compute resources such as CPU and GPU (AlloX). BoPF relies on the observation that throughput-sensitive tenants do not care about allocated resources in the short term, as long as the long-term averaged resource share remains the same. This temporal flexibility allows us to accommodate bursts of latency-sensitive tenants without hurting throughput-sensitive ones. It outperforms existing solutions by more than 5X in terms of performance while providing the same level of fairness. AlloX focuses on carefully picking CPU and GPU combinations for deep learning training jobs. The key idea is leveraging the interchangeability of computation resources. By judiciously combining both, AlloX can improve average training time by as much as 95% in comparison to existing solutions that ignore resource interchangeability. \n\nFinally, in the application level, we explored cloud applications are designed to interact with their data: is it via a key-value (KV) store or via remote procedure call (RPC). We observed that the root cause behind this choice -- and subsequent dichotomy between the two views -- is the shifting balance between CPU and network bottlenecks of a workload. One can improve throughput while satisfying service-level objectives (SLOs) by judiciously employing both at the same. We have proposed a fully decentralized algorithm (Kayak) that runs only on the client side and dynamically chooses the best option based on the shifting balance. Overall, Kayak can improve throughput by 35% by combining the best of both worlds.\n\nAll software developed as part of this project are based on established open-source systems such as Kubernetes, and we have and continue to open-source our works at https://github.com/symbioticlab. Research papers summarizing our works have been published or are under submission in top venues in networking and systems including SIGCOMM and NSDI. Some of the works have been incorporated into course contents in graduate- and undergraduate-level systems and networking courses at the University of Michigan. Last but not the least, three PhD students at the University of Michigan have worked on different pieces of our contributions, and this grant has helped in partly supporting their education and training. \n\n\t\t\t\t\tLast Modified: 02/06/2020\n\n\t\t\t\t\tSubmitted by: Mosharaf Chowdhury"
 }
}