{
 "awd_id": "1638107",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NRI: Collaborative Research: Scalable Robot Autonomy through Remote Operator Assistance and Lifelong Learning",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 486276.0,
 "awd_amount": 486276.0,
 "awd_min_amd_letter_date": "2016-07-27",
 "awd_max_amd_letter_date": "2016-07-27",
 "awd_abstract_narration": "One of the most significant barriers to the wider adoption of autonomous robotic systems in commercial applications is the challenge of achieving 100% reliable autonomy in unconstrained human environments. One path toward more robust autonomy is to spend more time in research labs improving robot capabilities, delaying deployment until autonomy is entirely robust.  Instead, it may be valuable to deploy robots out in the wild and adapt their behavior based on the rare examples, corner cases, and contingencies encountered after deployment in order to achieve near-term, fully reliable autonomy. This approach is specifically motivated by the call center model, in which robots are deployed at end-user sites and contact a remote human operator for assistance whenever an error is encountered.  This project develops a system that enables robots to perform lifelong, incremental improvement from remote human assistance with the long-term goal of achieving full autonomy. This research program has significant broader impacts, making personal robots more accessible to everyday people, while also providing opportunities for human-robot interaction that are ideal for educational K-12 programs, as well as undergraduate and graduate education. \r\n\r\n\r\nTowards these goals, novel algorithms, interfaces, and user studies are being developed to advance the state of the art in three key areas related to the call center model: (1) Robust, Multi-Sensory Task Outcome Detection: multimodal techniques for identifying conditions under which to seek assistance or deploy recovery behaviors; (2) Transparency Devices for Situated Awareness: visual and language interface modalities for increasing the situational awareness of the remote operator and allowing for intuitive interaction, leading to more efficient and correct recovery procedures; (3) Low-Level and High-Level Task Model Refinement: lifelong learning techniques for incorporating corrections and recovery procedures into existing task models, as well as active learning methods to collect more targeted data.  The proposed approach is being evaluated on a variety of mobile manipulation tasks that a hotel concierge robot might perform, such as delivery tasks or preparing for and cleaning up after a conference banquet.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Scott",
   "pi_last_name": "Niekum",
   "pi_mid_init": "D",
   "pi_sufx_name": "",
   "pi_full_name": "Scott D Niekum",
   "pi_email_addr": "sniekum@cs.umass.edu",
   "nsf_id": "000663218",
   "pi_start_date": "2016-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Andrea",
   "pi_last_name": "Thomaz",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Andrea L Thomaz",
   "pi_email_addr": "athomaz@ece.utexas.edu",
   "nsf_id": "000082310",
   "pi_start_date": "2016-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "101 East 27th Street, Suite 5.30",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121757",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 486276.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Rather than wait to deploy robotic systems in homes and workplaces until they are able to operate 100% reliably, we introduced a series of research objectives to enable a \"call center model\", in which robots identify errors, contact a remote operator, and receive (and learn from) assistance.&nbsp; Specifically, we designed algorithms to (1) specify and adjust robot goals and behaviors via human preferences and feedback; (2) efficiently learn from many different human data modalities such as gaze and natural language; and (3) provide strong performance guarantees to build trust with users and to let call-center operators know when to stop providing assistance.<br /><br />Towards these goals, we first developed a new approach to infer the goals of human users from preference rankings over task demonstrations, leading to an approach that was far more efficient than prior methods. This work was extended to a setting that allowed a robot to reason about its uncertainty about the goals or intentions of a human user or operator. This allowed the robot to behave safely and robustly, even when the intent of the human was ambiguous.<br /><br />While demonstrations and preferences are excellent ways to provide a robot with information about a human's desires, it ignores many rich channels of information that humans use when learning from each other. To capitalize on such sources of information, we developed algorithms that could learn from signals such as where a user was looking when providing a demonstration, or natural language descriptions of task goals or feedback, or people's facial expressions as they react to robot behavior. Taken together, this allowed for not just safe learning, but efficient learning as well.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/15/2021<br>\n\t\t\t\t\tModified by: Scott&nbsp;D&nbsp;Niekum</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nRather than wait to deploy robotic systems in homes and workplaces until they are able to operate 100% reliably, we introduced a series of research objectives to enable a \"call center model\", in which robots identify errors, contact a remote operator, and receive (and learn from) assistance.  Specifically, we designed algorithms to (1) specify and adjust robot goals and behaviors via human preferences and feedback; (2) efficiently learn from many different human data modalities such as gaze and natural language; and (3) provide strong performance guarantees to build trust with users and to let call-center operators know when to stop providing assistance.\n\nTowards these goals, we first developed a new approach to infer the goals of human users from preference rankings over task demonstrations, leading to an approach that was far more efficient than prior methods. This work was extended to a setting that allowed a robot to reason about its uncertainty about the goals or intentions of a human user or operator. This allowed the robot to behave safely and robustly, even when the intent of the human was ambiguous.\n\nWhile demonstrations and preferences are excellent ways to provide a robot with information about a human's desires, it ignores many rich channels of information that humans use when learning from each other. To capitalize on such sources of information, we developed algorithms that could learn from signals such as where a user was looking when providing a demonstration, or natural language descriptions of task goals or feedback, or people's facial expressions as they react to robot behavior. Taken together, this allowed for not just safe learning, but efficient learning as well.\n\n\t\t\t\t\tLast Modified: 11/15/2021\n\n\t\t\t\t\tSubmitted by: Scott D Niekum"
 }
}