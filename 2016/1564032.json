{
 "awd_id": "1564032",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "III: Medium: Collaborative Research: Deep Learning in Spectroscopic Domains",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2016-05-01",
 "awd_exp_date": "2022-04-30",
 "tot_intn_awd_amt": 804249.0,
 "awd_amount": 804249.0,
 "awd_min_amd_letter_date": "2016-04-22",
 "awd_max_amd_letter_date": "2017-08-31",
 "awd_abstract_narration": "Many problems in science today require the analysis of massive datasets. \r\nThis project investigates the fundamental problem of extracting latent hidden regularities from high-dimensional scientific data sets, specifically from two different types of spectroscopic measurements -- three-dimensional hyperspectral imaging used in remote sensing of the Earth and other planets, and one-dimensional spectral signals arising from chemical analyses from laser-induced breakdown spectroscopy (LIBS), such as used currently by the Curiosity rover on Mars. The project is applying recent advances in deep learning, optimization, and machine learning to practical real-world scientific applications involving the analysis of materials from Earth and outer space, such as Mars, as well as the mapping of Martian and terrestrial surfaces through hyperspectral imagery.\r\n\r\nDeep learning uses multi-layer neural networks to construct a hierarchy of latent representations of high-dimensional datasets.  This project designs novel architectures and algorithms for deep learning, and applies them to spectroscopic domains, such as LIBS and hyperspectral imaging. Three challenges from spectroscopic domains guide the research. First, in many applications such as the Curiosity rover on Mars, the number of available LIBS spectra are limited as it requires an active sensing operation followed by transmission of data by a robot situated millions of miles from Earth. A further challenge is that data from Mars is inherently unlabeled, and instrumental variations and terrain variations between Earth and Mars require solving a key transfer learning problem. For hyperspectral imaging, the project is extending work on deep learning applied to two-dimensional images to data that involves two spatial dimensions as well as the third spectral dimension, where images are recorded at multiple wavelengths. This project explores a variety of ways of designing new convolutional neural networks and other approaches that can effectively exploit the third spectral dimension.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Sridhar",
   "pi_last_name": "Mahadevan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sridhar Mahadevan",
   "pi_email_addr": "mahadeva@cs.umass.edu",
   "nsf_id": "000203723",
   "pi_start_date": "2016-04-22",
   "pi_end_date": "2017-05-24"
  },
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Mario",
   "pi_last_name": "Parente",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mario Parente",
   "pi_email_addr": "mparente@ecs.umass.edu",
   "nsf_id": "000636246",
   "pi_start_date": "2017-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sridhar",
   "pi_last_name": "Mahadevan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sridhar Mahadevan",
   "pi_email_addr": "mahadeva@cs.umass.edu",
   "nsf_id": "000203723",
   "pi_start_date": "2017-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Mario",
   "pi_last_name": "Parente",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mario Parente",
   "pi_email_addr": "mparente@ecs.umass.edu",
   "nsf_id": "000636246",
   "pi_start_date": "2016-04-22",
   "pi_end_date": "2017-05-24"
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "70 Butterfield Terrace",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039242",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 405430.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 398819.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The project addressed the fundamental problem of extracting deep semantic structures from high-dimensional spectroscopic data sets in three different types of domains: three-dimensional hyperspectral imaging used in remote sensing of our planet and other planets, one-dimensional spectral signals arising from Raman and laser-induced breakdown spectroscopy (LIBS) on two different missions (the SHERLOC Raman instrument and on the Mars 2020 rover and the ChemCam LIBS instrument onboard the Mars Science Laboratory), and three dimensional multispectral images (from the MastCam instrument onboard the Mars Science Laboratory.&nbsp;</p>\n<p>Raman and LIBS acquisitions from Martian rovers are scarce and&nbsp;a challenging problem was to ensure that deep learning feature extraction worked on relatively small spectral datasets. A further challenge was the inherent lack of true labels. Instrumental variations and terrain variations between Earth and Mars introduced a transfer learning problem. For hyperspectral imaging, the key challenge was extending work on deep learning applied to 2D images to data 3D data involving a spectral dimension. For MastCam images the challenge was to adapt notions of image textures learned by deep networks designed for computer vision tasks to extract scientifically significant morphological and geological attributes from Martian terrains.&nbsp;&nbsp;</p>\n<p>This research produced several outcomes:</p>\n<p><strong>Untapped Variational Autoencoders.&nbsp;</strong>We developed a novel architecture based on&nbsp;variational autoencoders (VAE). The Untapped VAE (UVAE)&nbsp;model exploits the (known) structure of the space of labels or targets and essentially&nbsp;&ldquo;inverts&rdquo; the deep generative model and trains it in reverse. This model was able to disentangle&nbsp;latent variable semantics as well as improved discriminative prediction on Martian&nbsp;hyperspectral images and elemental abundance prediction for LIBS data. In particular, UVAE significantly reduced endmember extraction error in hyperspectral data unmixing over previous state-of-the-art models and isolated artifacts in the spectral signal (atmospheric effects, observation geometry) into nuisance variables.&nbsp;&nbsp;The model was also successfully used to inferring endmember abundances in remotely sensed from&nbsp;Raman spectra of mineral assemblages in soils and rocks,&nbsp;in support of scientific investigation on Mars by the Mars 2020 SuperCam and SHERLOC teams.</p>\n<p><strong>Transfer Learning with Adversarial domain adaptation.&nbsp;&nbsp;</strong>Differences in laser power, energy distribution, detectors, stand-off distance and environmental conditions may cause spectra from terrestrial instruments to be distinct from data acquired on Mars. As a result, models that must be trained on spectra from one lab instruments are often not reliable for making predictions based on spectra from Mars.&nbsp;We developed a method based on Domain Adversarial Neural Networks (DANN)&nbsp;to extract features from the spectra that are useful in the prediction task but agnostic to the instrument used and resolve this domain adaptation problem. This model significantly advanced LIBS abundance regression for Mars rocks.&nbsp;<strong>&nbsp;</strong></p>\n<p><strong>Unsupervised adversarial deep learning of CRISM spectra.&nbsp;&nbsp;&nbsp;</strong>We developed a novel method based on&nbsp;Generative Adversarial Networks (GAN) to learn to generate spectra from the CRISM imaging spectrometer on Mars as a pretext task for discrimination of the spectral shapes of known minerals on the Martian surface. The model was able to accurately map&nbsp;various major and minor known mineral phases.&nbsp;&nbsp;The work had a significant impact on the planetary science community, and we were tasked by the NASA perseverance rover science team to provide detailed maps of the dominant mineralogy of the rover landing area. We also designed a technique to discover previously unknown spectral signatures, which provided a significant contribution to our understanding of the Martian surface.</p>\n<p><strong>Joint clustering and representation learning of MASTCAM images</strong>. We devised an approach that combined deep clustering with deep metric learning to train a deep network that learns a more semantically significant representation of image patches of Martian terrains at landscape scale. Deep clustering using metric learning (DCML) combines clustering and triplet loss learning to encourage a representation of the morphological features of Martian terrains that would effectively polarize different textures, thus producing clusters that are more semantically homogeneous. The model was able to autonomously discover categories that correspond to recognized geological attributes such as apparent lamination strength, nodule and fracture pervasiveness in Martian rocks. This allowed the creation of the first large, publicly accessible database of scientifically relevant morphological terrain categories from rover images. The work has been featured in a CVPR workshop.</p>\n<p><strong>Optimizing preprocessing pipelines of spectroscopic datasets</strong>. Both Raman and LIBS spectra require several preprocessing steps to make the data available for scientific analysis, including radiometric and spectral calibration, background subtraction and power normalization. We developed strategies to use reinforcement learning (RL) as an optimization approach to select spectral pre-processing steps to maximize classification accuracy (for Raman) and prediction accuracy (for LIBS). RL was reliably able to find near-optimal pre-processing sequences using considerably less resources than any other approach. Thus, RL makes the previously intractable problem of finding the right combination and ordering of pre-processing steps feasible.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/01/2023<br>\n\t\t\t\t\tModified by: Mario&nbsp;Parente</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe project addressed the fundamental problem of extracting deep semantic structures from high-dimensional spectroscopic data sets in three different types of domains: three-dimensional hyperspectral imaging used in remote sensing of our planet and other planets, one-dimensional spectral signals arising from Raman and laser-induced breakdown spectroscopy (LIBS) on two different missions (the SHERLOC Raman instrument and on the Mars 2020 rover and the ChemCam LIBS instrument onboard the Mars Science Laboratory), and three dimensional multispectral images (from the MastCam instrument onboard the Mars Science Laboratory. \n\nRaman and LIBS acquisitions from Martian rovers are scarce and a challenging problem was to ensure that deep learning feature extraction worked on relatively small spectral datasets. A further challenge was the inherent lack of true labels. Instrumental variations and terrain variations between Earth and Mars introduced a transfer learning problem. For hyperspectral imaging, the key challenge was extending work on deep learning applied to 2D images to data 3D data involving a spectral dimension. For MastCam images the challenge was to adapt notions of image textures learned by deep networks designed for computer vision tasks to extract scientifically significant morphological and geological attributes from Martian terrains.  \n\nThis research produced several outcomes:\n\nUntapped Variational Autoencoders. We developed a novel architecture based on variational autoencoders (VAE). The Untapped VAE (UVAE) model exploits the (known) structure of the space of labels or targets and essentially \"inverts\" the deep generative model and trains it in reverse. This model was able to disentangle latent variable semantics as well as improved discriminative prediction on Martian hyperspectral images and elemental abundance prediction for LIBS data. In particular, UVAE significantly reduced endmember extraction error in hyperspectral data unmixing over previous state-of-the-art models and isolated artifacts in the spectral signal (atmospheric effects, observation geometry) into nuisance variables.  The model was also successfully used to inferring endmember abundances in remotely sensed from Raman spectra of mineral assemblages in soils and rocks, in support of scientific investigation on Mars by the Mars 2020 SuperCam and SHERLOC teams.\n\nTransfer Learning with Adversarial domain adaptation.  Differences in laser power, energy distribution, detectors, stand-off distance and environmental conditions may cause spectra from terrestrial instruments to be distinct from data acquired on Mars. As a result, models that must be trained on spectra from one lab instruments are often not reliable for making predictions based on spectra from Mars. We developed a method based on Domain Adversarial Neural Networks (DANN) to extract features from the spectra that are useful in the prediction task but agnostic to the instrument used and resolve this domain adaptation problem. This model significantly advanced LIBS abundance regression for Mars rocks.  \n\nUnsupervised adversarial deep learning of CRISM spectra.   We developed a novel method based on Generative Adversarial Networks (GAN) to learn to generate spectra from the CRISM imaging spectrometer on Mars as a pretext task for discrimination of the spectral shapes of known minerals on the Martian surface. The model was able to accurately map various major and minor known mineral phases.  The work had a significant impact on the planetary science community, and we were tasked by the NASA perseverance rover science team to provide detailed maps of the dominant mineralogy of the rover landing area. We also designed a technique to discover previously unknown spectral signatures, which provided a significant contribution to our understanding of the Martian surface.\n\nJoint clustering and representation learning of MASTCAM images. We devised an approach that combined deep clustering with deep metric learning to train a deep network that learns a more semantically significant representation of image patches of Martian terrains at landscape scale. Deep clustering using metric learning (DCML) combines clustering and triplet loss learning to encourage a representation of the morphological features of Martian terrains that would effectively polarize different textures, thus producing clusters that are more semantically homogeneous. The model was able to autonomously discover categories that correspond to recognized geological attributes such as apparent lamination strength, nodule and fracture pervasiveness in Martian rocks. This allowed the creation of the first large, publicly accessible database of scientifically relevant morphological terrain categories from rover images. The work has been featured in a CVPR workshop.\n\nOptimizing preprocessing pipelines of spectroscopic datasets. Both Raman and LIBS spectra require several preprocessing steps to make the data available for scientific analysis, including radiometric and spectral calibration, background subtraction and power normalization. We developed strategies to use reinforcement learning (RL) as an optimization approach to select spectral pre-processing steps to maximize classification accuracy (for Raman) and prediction accuracy (for LIBS). RL was reliably able to find near-optimal pre-processing sequences using considerably less resources than any other approach. Thus, RL makes the previously intractable problem of finding the right combination and ordering of pre-processing steps feasible. \n\n \n\n\t\t\t\t\tLast Modified: 02/01/2023\n\n\t\t\t\t\tSubmitted by: Mario Parente"
 }
}