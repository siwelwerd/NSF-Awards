{
 "awd_id": "1613193",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Scalable Bayesian Methods for Complex Data with Optimality Guarantees",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2020-06-30",
 "tot_intn_awd_amt": 134138.0,
 "awd_amount": 134138.0,
 "awd_min_amd_letter_date": "2016-05-24",
 "awd_max_amd_letter_date": "2016-05-24",
 "awd_abstract_narration": "Spectacular advances in data acquisition, processing, and storage present the opportunity to analyze datasets of ever-increasing size and complexity in various applications, such as social and biological networks, epidemiology, genomics, and Internet recommender systems. Underlying the massive size and dimension of these data, there is often a parsimonious structure. The Bayesian approach to statistical inference is attractive in this context in terms of incorporating structural assumptions through prior distributions, enabling probabilistic modeling of complex phenomenon, and providing an automatic characterization of uncertainty. This research project aims to advance eliciting and translating prior knowledge regarding the low-dimensional skeleton of big data to provide realistic uncertainty characterizations while maintaining computational efficiency. Bayesian computation poses substantial challenge in high-dimensional and big data problems. The research aims to develop cutting-edge computational strategies and software packages for implementation to be made available publicly. The project involves graduate students in the research.\r\n\r\nThe research project focuses on theoretical foundations and computational strategies for Bayesian methods in high-dimensional and big data problems motivated by applications in social networks and epidemiology. Techniques for systematically developing and evaluating prior distributions in high-dimensional problems will be investigated with a special emphasis on the trade-off between statistical efficiency and computational scalability. Specific directions include efficient algorithms for posterior sampling with shrinkage priors, a theoretical framework for divide and conquer strategies in big data problems, fast algorithms for clustering nodes in large networks with unknown number of communities, and methods for discovering structure in sparse contingency tables. The algorithms will be motivated by rigorous theoretical understanding of the behavior of the posterior distribution with a particular emphasis on proper quantification of uncertainty in a distributed computing framework. Software will be developed for each application.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Anirban",
   "pi_last_name": "Bhattacharya",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Anirban Bhattacharya",
   "pi_email_addr": "anirbanb@stat.tamu.edu",
   "nsf_id": "000655820",
   "pi_start_date": "2016-05-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University Main Campus",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433143",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 134138.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Bayesian inference is a statistical framework for combining prior knowledge about a system with observed data in a principled probabilistic way and provide an automatic characterization of statistical uncertainties. With modern datasets getting increasingly bigger in size, there is a growing need for scalable algorithms for Bayesian inference of big data. Moreover, modern inferential problems often involve a large number of parameters, and certifying the quality of an estimation procedure poses fresh theoretical challenges. In this project, we have explored a variety of aspects of modern Bayesian inference and have succeeded in addressing some long-standing questions. &nbsp;Some specific contributions include development of scalable algorithms for Bayesian shrinkage priors that are popularly used in selecting important variables from a large collection of variables and thereby vastly increasing their applicability, building a theoretical framework to study the statistical accuracy of mean-field variational inference (a class of optimization procedures for approximate Bayesian inference) in models with hidden variables, and studying model selection in statistical network models.</p>\n<p>&nbsp;</p>\n<p>Publications resulting from this project have appeared in premier statistics journals and conference proceedings such as the Annals of Statistics, The Journal of the American Statistical Association, Biometrika, and AISTATS. A collaborative project with nuclear physicists has been published in Physical Review C. Multiple graduate students have been partially supported by this project, who have successfully defended their dissertation and continued their academic endeavors at reputed institutions. Their work has been additionally recognized by Student paper awards, poster presentation awards, and travel support awards. The PIs have developed advanced graduate-level courses, closely aligned with the research conducted in this project, at Texas A&amp;M University to disseminate most recent developments in this exciting area. The courses have been well-attended and received highly positive feedback. The work conducted in this project has been disseminated through multiple departmental seminars and conference presentations, and code to implement the methodologies developed in this project have been made publicly available through GitHub and R packages. PI Bhattacharya was awarded the Noether Young Scholar award by the American Statistical Association in 2018.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/28/2020<br>\n\t\t\t\t\tModified by: Anirban&nbsp;Bhattacharya</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nBayesian inference is a statistical framework for combining prior knowledge about a system with observed data in a principled probabilistic way and provide an automatic characterization of statistical uncertainties. With modern datasets getting increasingly bigger in size, there is a growing need for scalable algorithms for Bayesian inference of big data. Moreover, modern inferential problems often involve a large number of parameters, and certifying the quality of an estimation procedure poses fresh theoretical challenges. In this project, we have explored a variety of aspects of modern Bayesian inference and have succeeded in addressing some long-standing questions.  Some specific contributions include development of scalable algorithms for Bayesian shrinkage priors that are popularly used in selecting important variables from a large collection of variables and thereby vastly increasing their applicability, building a theoretical framework to study the statistical accuracy of mean-field variational inference (a class of optimization procedures for approximate Bayesian inference) in models with hidden variables, and studying model selection in statistical network models.\n\n \n\nPublications resulting from this project have appeared in premier statistics journals and conference proceedings such as the Annals of Statistics, The Journal of the American Statistical Association, Biometrika, and AISTATS. A collaborative project with nuclear physicists has been published in Physical Review C. Multiple graduate students have been partially supported by this project, who have successfully defended their dissertation and continued their academic endeavors at reputed institutions. Their work has been additionally recognized by Student paper awards, poster presentation awards, and travel support awards. The PIs have developed advanced graduate-level courses, closely aligned with the research conducted in this project, at Texas A&amp;M University to disseminate most recent developments in this exciting area. The courses have been well-attended and received highly positive feedback. The work conducted in this project has been disseminated through multiple departmental seminars and conference presentations, and code to implement the methodologies developed in this project have been made publicly available through GitHub and R packages. PI Bhattacharya was awarded the Noether Young Scholar award by the American Statistical Association in 2018.\n\n \n\n\t\t\t\t\tLast Modified: 10/28/2020\n\n\t\t\t\t\tSubmitted by: Anirban Bhattacharya"
 }
}