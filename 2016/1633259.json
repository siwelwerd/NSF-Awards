{
 "awd_id": "1633259",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Collaborative Research: IA: BirdVox: Automating Acoustic Monitoring of Migrating Bird Species",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2016-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 612383.0,
 "awd_amount": 612383.0,
 "awd_min_amd_letter_date": "2016-09-13",
 "awd_max_amd_letter_date": "2016-09-13",
 "awd_abstract_narration": "Current bioacoustic monitoring of natural environments requires processing by humans to extract information content from recordings. Thus human processing creates a fundamental bottleneck in which data collection far outpaces capabilities to extract relevant and desired information. Bioacoustic research on automatic species classification in natural environments can be broadly divided into two groups: distinguishing a predefined set of known species from audio clips and extracting species as events that occur in a continuous audio stream. Both classification techniques have their specific problems--many of the data used distinguishing predefined species are recorded under \"studio\" conditions and not extensible to natural conditions, while processing of continuous audio streams generate many false positives. \r\n\r\nTo overcome these challenges we will take a multi-tiered approach:  Analyzing a data set consisting of full-night recordings from 10 recording units over 100 nights. Building a web-enabled software to engage citizen scientists to identify the flight calls, providing us with a large and extensive model training dataset.  Developing novel convolutional deep-learning networks, which are well suited for analysis of complex auditory scenes.  Visualizing patterns detected and classified flight calls in space and time to produce novel information about the bird migration.  Comparing model-generated acoustic data with radar, video, and direct visual citizen science datasets to produce the most comprehensive accounts of nocturnal bird migration possible.  The combination of domain knowledge in bird vocalizations, engaging citizen scientists to allow development of large well annotated training datasets, and taking a novel deep-learning approach, will finally resolve the machine classification of acoustic signals in natural environments.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Juan",
   "pi_last_name": "Bello",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Juan P Bello",
   "pi_email_addr": "jpbello@nyu.edu",
   "nsf_id": "000496889",
   "pi_start_date": "2016-09-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New York University",
  "inst_street_address": "70 WASHINGTON SQ S",
  "inst_street_address_2": "",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2129982121",
  "inst_zip_code": "100121019",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NY10",
  "org_lgl_bus_name": "NEW YORK UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NX9PXMKW5KW8"
 },
 "perf_inst": {
  "perf_inst_name": "New York University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100122331",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NY10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 612383.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-351a29f3-7fff-0ba1-c0dc-5d308304ec49\"> </span></p>\n<p dir=\"ltr\"><span>The BirdVox project aims to develop computational approaches to automate the collection and annotation of large datasets of vocalizations from migrating birds occurring in diverse acoustic environments. To this end, the project curated and released 10 bioacoustic datasets including more than 6,600 hours of field acoustic recordings during migratory season, more than 350 hours of annotated data with flightcall timing and species information, and an assortment of flightcall datasets containing calls from dozens of free-flying bird species. Together, these datasets represent one of the largest collections of data ever made available for bioacoustics research, have been downloaded over 18,000 times and have the potential to enable machine learning research well beyond the scope of this project.</span></p>\n<p dir=\"ltr\"><span>The project has made significant contributions in computational methods at the intersection of signal processing, machine learning and bioacoustics. This includes early pioneering work on flight call detection and classification using dictionary methods and convolutional networks, and work on expanding the scattering transform family of methods across a wide range of sound event detection problems. Most notably, the project advanced groundbreaking work on deep learning methods for flight call detection in dynamic, real-world conditions with significant location bias. This work used combinations of PCEN front-end processing, deep convolutional networks, auxiliary and multi-task objectives, and is, to date, the state of the art in this task, with performance that significantly improves both traditional methods in widespread use by the bioacoustics community, and modern deep learning approaches proposed by the machine listening community. Beyond new methods and experimental validation, this work is the backbone of the BirdVox Detect (BVD) line of tools, which are now available to the research community and a growing and enthusiastic community of practitioners. The project also proposed novel methods for hierarchical bird species classification. Such methods address taxonomic uncertainties in field studies and annotation, out-of-vocabulary labels, and open-set deployment settings.&nbsp;</span></p>\n<p dir=\"ltr\"><span>The project integrated the above methods into an end-to-end pipeline for the acoustic monitoring of bird migration, which is able to provide robust estimates of vocal activity per species despite the unavoidable failures of acoustic sensor networks, the variability of acoustic conditions, and the uncertainty in automatic detection and classification of flight calls present in real-world applications. This pipeline has been deployed for the dynamic estimation of bird biomass and its species composition, both on its own and in combination with weather data. Experimental results show that information from a few, relatively close, acoustic sensors can recover most of the biomass information captured by a network of weather-surveillance radar stations across thousands of square kilometers, while also deriving information about specific species that is beyond radar and can only be obtained from human observation. This is the project?s most significant contribution to ecology research, opening new opportunities for bird migration monitoring in sparsely populated regions with poor radar coverage.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Finally, the project has contributed to the educational and professional development of a diverse cohort of postdoctoral, graduate, undergraduate and high-school students, contributing to both the US STEM workforce and a more inclusive community of STEM scholars.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/18/2021<br>\n\t\t\t\t\tModified by: Juan&nbsp;P&nbsp;Bello</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThe BirdVox project aims to develop computational approaches to automate the collection and annotation of large datasets of vocalizations from migrating birds occurring in diverse acoustic environments. To this end, the project curated and released 10 bioacoustic datasets including more than 6,600 hours of field acoustic recordings during migratory season, more than 350 hours of annotated data with flightcall timing and species information, and an assortment of flightcall datasets containing calls from dozens of free-flying bird species. Together, these datasets represent one of the largest collections of data ever made available for bioacoustics research, have been downloaded over 18,000 times and have the potential to enable machine learning research well beyond the scope of this project.\nThe project has made significant contributions in computational methods at the intersection of signal processing, machine learning and bioacoustics. This includes early pioneering work on flight call detection and classification using dictionary methods and convolutional networks, and work on expanding the scattering transform family of methods across a wide range of sound event detection problems. Most notably, the project advanced groundbreaking work on deep learning methods for flight call detection in dynamic, real-world conditions with significant location bias. This work used combinations of PCEN front-end processing, deep convolutional networks, auxiliary and multi-task objectives, and is, to date, the state of the art in this task, with performance that significantly improves both traditional methods in widespread use by the bioacoustics community, and modern deep learning approaches proposed by the machine listening community. Beyond new methods and experimental validation, this work is the backbone of the BirdVox Detect (BVD) line of tools, which are now available to the research community and a growing and enthusiastic community of practitioners. The project also proposed novel methods for hierarchical bird species classification. Such methods address taxonomic uncertainties in field studies and annotation, out-of-vocabulary labels, and open-set deployment settings. \nThe project integrated the above methods into an end-to-end pipeline for the acoustic monitoring of bird migration, which is able to provide robust estimates of vocal activity per species despite the unavoidable failures of acoustic sensor networks, the variability of acoustic conditions, and the uncertainty in automatic detection and classification of flight calls present in real-world applications. This pipeline has been deployed for the dynamic estimation of bird biomass and its species composition, both on its own and in combination with weather data. Experimental results show that information from a few, relatively close, acoustic sensors can recover most of the biomass information captured by a network of weather-surveillance radar stations across thousands of square kilometers, while also deriving information about specific species that is beyond radar and can only be obtained from human observation. This is the project?s most significant contribution to ecology research, opening new opportunities for bird migration monitoring in sparsely populated regions with poor radar coverage. \nFinally, the project has contributed to the educational and professional development of a diverse cohort of postdoctoral, graduate, undergraduate and high-school students, contributing to both the US STEM workforce and a more inclusive community of STEM scholars.\n\n \n\n\t\t\t\t\tLast Modified: 12/18/2021\n\n\t\t\t\t\tSubmitted by: Juan P Bello"
 }
}