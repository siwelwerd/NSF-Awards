{
 "awd_id": "1646955",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Studying Decentralized Searches in Large-scale Agent Networks",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Aidong Zhang",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 99940.0,
 "awd_amount": 99940.0,
 "awd_min_amd_letter_date": "2016-08-15",
 "awd_max_amd_letter_date": "2016-08-15",
 "awd_abstract_narration": "Many digital information networks such as the Web and the Internet operate in a rather decentralized manner with little global control. Searching in these networks is a great challenge because data are increasingly large and distributed. The proposed research envisions a fully decentralized architecture in which individual systems (agents) can communicate and work together to assist people in finding relevant information from growing distributed sources. The proposed search model will utilize collective intelligence of software agents in large networks in order to help individuals find access to information of an unmatched magnitude. The outcome of the research will revolutionize the way in which large-scale search engines operate and significantly improve the coverage of the world's information that can be discovered by ordinary people.\r\n\r\nDecentralization is the nature of many naturally, socially, and technologically grown structures that scale. The research aims to address the problem of finding relevant information in large-scale agent networks with distributed contents. The project will study decentralized search methods in growing agent networks and focus on their capacity to scale up (out). The primary goal is to understand how a very large number of search agents (many of which have limited computing capacity) can interconnect and collaborate to enable efficient query routing and information discovery. The research team will experiment with very large agent networks (of at least a million agents) and study how information indexing and searching can function efficiently in a fully decentralized manner. The plan is to examine the influences of important factors such as semantic network overlay (inter-connectivity) and distributed neighbor sampling (learning) on search efficiency and adaptation. The project will also investigate the capacity of the distributed agent architecture for greater search coverage as well as better freshness and timeliness in the search results.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Weimao",
   "pi_last_name": "Ke",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Weimao Ke",
   "pi_email_addr": "wk@drexel.edu",
   "nsf_id": "000596818",
   "pi_start_date": "2016-08-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Drexel University",
  "inst_street_address": "3141 CHESTNUT ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2158956342",
  "inst_zip_code": "191042875",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "PA03",
  "org_lgl_bus_name": "DREXEL UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "XF3XM9642N96"
 },
 "perf_inst": {
  "perf_inst_name": "Drexel University",
  "perf_str_addr": "",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191021119",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "PA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 99940.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In this project, we studied a new information retrieval model in which a number of search engines work with one another to search and retrieve information. Using simulations, we conducted computer experiments on a growing network of thousands to a hundred thousand software agents and examined its efficiency in search tasks.</p>\n<p><br />This represents a new search engine framework different from today's dominant search engine technologies such as Google and Bing. Whereas the giant search engines try to organize the world's information within their organizations for the world to search, the new technology envisions many more smaller search engines serving where data are originally situated and/or distributed.</p>\n<p><br />In short, this search engine technology we envision is decentralized. There is little central control, similar to the way the Internet works. There are several advantages associated with this technology and the research allowed us to look at these closely. First, the model has the potential to penetrate the deep web where it has been very challenging for classic search engines to do so. It circumvents the problems of collecting data from the deep web by building search engines where data are and enabling them to collaborate and form a larger network of \"findable\" information.</p>\n<p><br />Second, because of the decentralization, there is no a single point of failure. The network of search engines can continue to work robustly in the face of adversity. Just as data can be transmitted via different chains of routers on the Internet, the model can help find a different path to the same relevant information when certain nodes on a previous path become unavailable (e.g. due to attacks).</p>\n<p><br />Finally, our experiments also showed the decentralized model to be efficient and scalable. Even when the network grows exponentially in size, the path to find relevant information will remain very short. With potentially millions and even billions of search engines working together, the model will remain manageable in terms of search time and the computational cost to find information.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/12/2018<br>\n\t\t\t\t\tModified by: Weimao&nbsp;Ke</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn this project, we studied a new information retrieval model in which a number of search engines work with one another to search and retrieve information. Using simulations, we conducted computer experiments on a growing network of thousands to a hundred thousand software agents and examined its efficiency in search tasks.\n\n\nThis represents a new search engine framework different from today's dominant search engine technologies such as Google and Bing. Whereas the giant search engines try to organize the world's information within their organizations for the world to search, the new technology envisions many more smaller search engines serving where data are originally situated and/or distributed.\n\n\nIn short, this search engine technology we envision is decentralized. There is little central control, similar to the way the Internet works. There are several advantages associated with this technology and the research allowed us to look at these closely. First, the model has the potential to penetrate the deep web where it has been very challenging for classic search engines to do so. It circumvents the problems of collecting data from the deep web by building search engines where data are and enabling them to collaborate and form a larger network of \"findable\" information.\n\n\nSecond, because of the decentralization, there is no a single point of failure. The network of search engines can continue to work robustly in the face of adversity. Just as data can be transmitted via different chains of routers on the Internet, the model can help find a different path to the same relevant information when certain nodes on a previous path become unavailable (e.g. due to attacks).\n\n\nFinally, our experiments also showed the decentralized model to be efficient and scalable. Even when the network grows exponentially in size, the path to find relevant information will remain very short. With potentially millions and even billions of search engines working together, the model will remain manageable in terms of search time and the computational cost to find information. \n\n\t\t\t\t\tLast Modified: 09/12/2018\n\n\t\t\t\t\tSubmitted by: Weimao Ke"
 }
}