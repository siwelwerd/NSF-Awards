{
 "awd_id": "1642090",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: CICI: Secure and Resilient Architecture: Scientific Workflow Integrity with Pegasus.",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Rob Beverly",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 230000.0,
 "awd_amount": 230000.0,
 "awd_min_amd_letter_date": "2016-08-22",
 "awd_max_amd_letter_date": "2016-08-22",
 "awd_abstract_narration": "Scientists use computer systems to analyze and store their scientific data, sometimes in a complex process across multiple machines. This process can be tedious and error-prone, which has led to the development of software known as a \"workflow management system\". Workflow management systems allow scientists to describe their process in a human-friendly way and then the software handles the details of the processing for the scientists, dealing with tedious and repetitive steps and handling errors. One popular workflow management system is Pegasus, which, over the past three years, was used to run over 700,000 workflows by scientists in a number of domains including astronomy, bioinformatics, earthquake science, gravitational wave physics, ocean science, and neuroscience. The \"Scientific Workflow Integrity with Pegasus\" project enhances Pegasus with additional security features. The scientist's description of their desired work is protected from tampering and the data processed by Pegasus is checked to ensure it hasn't been accidentally or maliciously modified. Such tamper protection is attained by cryptographic techniques that ensure data integrity. These changes allow scientists, and our society, to be more confident of scientific findings based on collected data.\r\n\r\nThe Scientific Workflow Integrity with Pegasus project strengthens cybersecurity controls in the Pegasus Workflow Management System in order to provide assurances with respect to the integrity of computational scientific methods. These strengthened controls enhance both Pegasus' handling of science data and its orchestration of software-defined networks and infrastructure. The result is increased trust in computational science and increased assurance in our ability to reproduce the science by allowing scientists to validate that data has not been changed since a workflow completed and that the results from multiple workflows are consistent. The focus on Pegasus is due to its popularity in the scientific community as a method of computation and data management automation. For example, LIGO, the NSF-funded gravitational-wave physics project, recently used the Pegasus Workflow Management System to structure and execute the analyses that confirmed and quantified its historic detection of a gravitational wave, confirming the prediction made by Einstein 100 years ago. The proposed project has established collaborations with LIGO and additional key NSF infrastructure providers and science projects to ensure broadly applied results.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ilya",
   "pi_last_name": "Baldin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ilya Baldin",
   "pi_email_addr": "ibaldin@renci.org",
   "nsf_id": "000320133",
   "pi_start_date": "2016-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275991350",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802700",
   "pgm_ele_name": "Cybersecurity Innovation"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 230000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-622b41c8-7fff-7348-f624-7861bdd3fca2\" style=\"line-height: 1.38; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Scientists use computer systems to analyze and store their scientific data, sometimes in a complex process across multiple machines in different geographical locations. It has been observed that sometimes during this complex process, scientific data is unintentionally modified or accidentally tampered with, with errors going undetected and corrupt data becoming part of the scientific record. When such errors occur, scientific computations can fail and result in increased computational cost due to reruns, and worse, results can be corrupted in a manner not apparent to the scientist and produce invalid science results. Computer systems technologies such as TCP checksums, encrypted transfers, checksum validation, RAID and erasure coding provide data correctness assurances at different levels, but they may not work for large data sizes and may not cover a workflow process from end-to-end, leaving gaps in which data corruption can occur undetected.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">The SWIP project tackled the problem of detecting these data errors that could occur during the scientific processing workflow, and provided methods to report these errors to the scientists. The solutions were integrated into Pegasus, a popular workflow management system used to describe complex scientific processes in a user-friendly way and that handles the details of processing for the scientists. Pegasus is used to manage scientific computations in the whole range from small research teams to large scientific collaborations, such as the Laser Interferometer Gravitational- wave Observatory (LIGO). To validate our approach, we developed a software called ?Chaos Jungle? that can be used to intentionally inject errors into computer systems, either in the network or storage systems. This software allowed us to test our solutions by simulating corrupt computer systems and by determining whether we are able to detect data integrity errors under those conditions.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; text-align: justify; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Our research methods and solutions were also deployed and validated on national computing resources, e.g. the Open Science Grid (OSG), with exemplar scientific applications from gravitational-wave physics, earthquake science, and bioinformatics. A subset of active Pegasus users have opted in to share detailed workflow provenance data with the Pegasus development team. From that data, it was determined that Pegasus detected and protected users from integrity errors in 299 data transfer instances so far. The solutions developed in the SWIP project allowed scientists, and our society, to be more confident of scientific findings based on collected data.</span></p>\n<p><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/24/2020<br>\n\t\t\t\t\tModified by: Ilya&nbsp;Baldin</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Scientists use computer systems to analyze and store their scientific data, sometimes in a complex process across multiple machines in different geographical locations. It has been observed that sometimes during this complex process, scientific data is unintentionally modified or accidentally tampered with, with errors going undetected and corrupt data becoming part of the scientific record. When such errors occur, scientific computations can fail and result in increased computational cost due to reruns, and worse, results can be corrupted in a manner not apparent to the scientist and produce invalid science results. Computer systems technologies such as TCP checksums, encrypted transfers, checksum validation, RAID and erasure coding provide data correctness assurances at different levels, but they may not work for large data sizes and may not cover a workflow process from end-to-end, leaving gaps in which data corruption can occur undetected. \n\n \nThe SWIP project tackled the problem of detecting these data errors that could occur during the scientific processing workflow, and provided methods to report these errors to the scientists. The solutions were integrated into Pegasus, a popular workflow management system used to describe complex scientific processes in a user-friendly way and that handles the details of processing for the scientists. Pegasus is used to manage scientific computations in the whole range from small research teams to large scientific collaborations, such as the Laser Interferometer Gravitational- wave Observatory (LIGO). To validate our approach, we developed a software called ?Chaos Jungle? that can be used to intentionally inject errors into computer systems, either in the network or storage systems. This software allowed us to test our solutions by simulating corrupt computer systems and by determining whether we are able to detect data integrity errors under those conditions.\n\n \nOur research methods and solutions were also deployed and validated on national computing resources, e.g. the Open Science Grid (OSG), with exemplar scientific applications from gravitational-wave physics, earthquake science, and bioinformatics. A subset of active Pegasus users have opted in to share detailed workflow provenance data with the Pegasus development team. From that data, it was determined that Pegasus detected and protected users from integrity errors in 299 data transfer instances so far. The solutions developed in the SWIP project allowed scientists, and our society, to be more confident of scientific findings based on collected data.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 01/24/2020\n\n\t\t\t\t\tSubmitted by: Ilya Baldin"
 }
}