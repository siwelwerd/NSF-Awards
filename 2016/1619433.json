{
 "awd_id": "1619433",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Speedup Learning for Online Planning Under Uncertainty",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032924768",
 "po_email": "jyang@nsf.gov",
 "po_sign_block_name": "Jie Yang",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 450000.0,
 "awd_amount": 450000.0,
 "awd_min_amd_letter_date": "2016-06-20",
 "awd_max_amd_letter_date": "2016-06-20",
 "awd_abstract_narration": "Many complex stochastic planning domains such as logistics,\r\nemergency response, resilient power grids, and robotics require the\r\nability to make high-quality decisions under tight time\r\nconstraints. This project addresses the need for high-quality, but\r\ncomputationally efficient, decision making via new theory and\r\nalgorithms for speedup learning, which will enable planners to\r\nlearn to speedup their performance based on prior planning\r\nexperience. This speedup-learning approach is loosely inspired by\r\nthe fact that humans routinely learn to speedup their reasoning\r\nprocesses with experience, without sacrificing decision quality.\r\nSimilarly, through speedup learning, an inefficient planner that\r\nproduces high-quality decisions will be transformed into a much\r\nfaster planner with little loss in decision quality.\r\n\r\nThe project involves advancing speedup learning for online planning\r\nunder uncertainty on four fronts. First, the speedup-learning\r\nproblem is formalized by introducing the canonical problem of\r\nPrimitive Speedup Learning (PSL) and studying how PSL can be used\r\nto solve various speedup objectives. Second, a novel online\r\nplanning framework, which subsumes many existing frameworks and\r\nenables many potential speedup opportunities, is being designed and\r\ndeveloped. Third, the project is producing new speedup learning\r\nalgorithms for the new framework, which learn various types of\r\nknowledge and that can exploit deep neural network (DNN)\r\ntechniques. Finally, the research is producing extensive empirical\r\nevaluations including applications to the important problems of\r\npower grid control, municipal emergency response, and benchmark\r\nplanning domains. The project has the potential for significant broader impact on\r\napplications where time-sensitive decisions must be made within\r\nstochastic environments. It will directly contribute to advances in\r\ntwo applications in particular: remedial action control in\r\nelectrical grids to minimize cascading power outages, and planning\r\nfor municipal emergencies such as fire and rescue operations in\r\ncities. The project will also serve to advance graduate education\r\nthrough research assistantships and undergraduate education through\r\nsummer and academic term research experiences for undergraduates. A\r\nspecial topics graduate course will be taught on the area of\r\nplanning and learning at Oregon State University and all course\r\nmaterials will be open access.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alan",
   "pi_last_name": "Fern",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alan Fern",
   "pi_email_addr": "afern@eecs.oregonstate.edu",
   "nsf_id": "000088242",
   "pi_start_date": "2016-06-20",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Prasad",
   "pi_last_name": "Tadepalli",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Prasad H Tadepalli",
   "pi_email_addr": "tadepall@eecs.orst.edu",
   "nsf_id": "000101828",
   "pi_start_date": "2016-06-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Oregon State University",
  "inst_street_address": "1500 SW JEFFERSON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CORVALLIS",
  "inst_state_code": "OR",
  "inst_state_name": "Oregon",
  "inst_phone_num": "5417374933",
  "inst_zip_code": "973318655",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "OR04",
  "org_lgl_bus_name": "OREGON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "MZ4DYXE1SL98"
 },
 "perf_inst": {
  "perf_inst_name": "Oregon State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "OR",
  "perf_st_name": "Oregon",
  "perf_zip_code": "973305501",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "OR04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 450000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Many complex planning domains such as logistics, emergency response, resilient power grids, and robotics require the ability to make high-quality decisions under tight time constraints and significant uncertainty. This project studied and developed the framework of speedup learning for enabling AI planners to learn to speedup their decision-making performance without sacrificing decision quality. This approach was loosely inspired by the observation that humans routinely learn to speedup their reasoning processes with experience, often with minimal impact on decision quality. Similarly, through speedup learning, our work allows for an inefficient AI planner that produces high-quality decisions to be transformed into a much faster planner of similar quality.</p>\n<p>The intellectual merit of the work was to significantly advance the theory and practice of speedup learning. One approach was to develop learning algorithms for deep neural networks to quickly produce the same output as planners based on expensive combinatorial search. This allowed for effectively replacing the slow planner with the fast neural network at deployment time. Another approach was to design learning algorithms for acquiring knowledge for quickly guiding search-based planners toward the most promising solutions. This line of work developed a number of new theoretical advances for dealing with the complexities arising in applications with large action spaces and significant uncertainty about the effect of actions. Throughout the project new benchmarks were created for the research community along with corresponding baseline algorithms to support further work by other researchers.</p>\n<p>The broader impact of the project was to investigate the application of speedup learning to a number of application domains. This included work on fire-and-emergency response dispatching, where a planner must quickly decide how to allocate resources to incoming 911 calls. Another application domain was mitigating power system failures,&nbsp; where a planner must quickly decide on a strategy to minimize the impact of power system failure events in order to prevent massive cascading power outages (e.g. load shedding a particular geographic area). A third application domain was bipedal robot locomotion, where a fast planner is required for maintaining balance while robustly locomoting over complex terrain. Our work demonstrated that speedup learning can be an effective design and engineering approach to solving these and other planning problems. This experience has set the stage for similar processes to be used for designing future control and planning systems where rapid, high-quality decisions are required.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/31/2021<br>\n\t\t\t\t\tModified by: Alan&nbsp;Fern</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMany complex planning domains such as logistics, emergency response, resilient power grids, and robotics require the ability to make high-quality decisions under tight time constraints and significant uncertainty. This project studied and developed the framework of speedup learning for enabling AI planners to learn to speedup their decision-making performance without sacrificing decision quality. This approach was loosely inspired by the observation that humans routinely learn to speedup their reasoning processes with experience, often with minimal impact on decision quality. Similarly, through speedup learning, our work allows for an inefficient AI planner that produces high-quality decisions to be transformed into a much faster planner of similar quality.\n\nThe intellectual merit of the work was to significantly advance the theory and practice of speedup learning. One approach was to develop learning algorithms for deep neural networks to quickly produce the same output as planners based on expensive combinatorial search. This allowed for effectively replacing the slow planner with the fast neural network at deployment time. Another approach was to design learning algorithms for acquiring knowledge for quickly guiding search-based planners toward the most promising solutions. This line of work developed a number of new theoretical advances for dealing with the complexities arising in applications with large action spaces and significant uncertainty about the effect of actions. Throughout the project new benchmarks were created for the research community along with corresponding baseline algorithms to support further work by other researchers.\n\nThe broader impact of the project was to investigate the application of speedup learning to a number of application domains. This included work on fire-and-emergency response dispatching, where a planner must quickly decide how to allocate resources to incoming 911 calls. Another application domain was mitigating power system failures,  where a planner must quickly decide on a strategy to minimize the impact of power system failure events in order to prevent massive cascading power outages (e.g. load shedding a particular geographic area). A third application domain was bipedal robot locomotion, where a fast planner is required for maintaining balance while robustly locomoting over complex terrain. Our work demonstrated that speedup learning can be an effective design and engineering approach to solving these and other planning problems. This experience has set the stage for similar processes to be used for designing future control and planning systems where rapid, high-quality decisions are required. \n\n \n\n\t\t\t\t\tLast Modified: 12/31/2021\n\n\t\t\t\t\tSubmitted by: Alan Fern"
 }
}