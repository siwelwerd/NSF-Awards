{
 "awd_id": "1617583",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: A New Approach to Latent Space Learning with Diversity-Inducing Regularization and Applications to Healthcare Data Analytics",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 499361.0,
 "awd_amount": 499361.0,
 "awd_min_amd_letter_date": "2016-08-24",
 "awd_max_amd_letter_date": "2016-08-24",
 "awd_abstract_narration": "Latent variable models (LVMs), which extract hidden information, such as topics, themes, or disease patterns, from raw data, play an important role in electronic health record (EHR) management and applications. With the dramatic increase of the volume and complexity of EHR data, current LVMs face several new challenges, including inadequacy in capturing rare patterns existing in only small number of patients in a population (also known as long tail patterns), redundancy amongst patterns being discovered, and low computational efficiency, which all seriously impair the value of EHR data in driving high-quality personalized medicine. There is a critical need in developing new methods to transform conventional LVMs to ones that can circumvent such limitations so that the EHR data can be more effectively and reliably used for healthcare applications. This project addresses this need and develops a new technique known as \"diversity-inducing machine learning models\", which promote rare patterns and condense redundant patterns, at high computational efficiency, to enable more effective pattern discovery and knowledge extraction from complex and heterogeneous (e.g., textual, image, and time series) EHR data. \r\n\r\nSpecifically, this project contains the following research components: 1. Develop a new regularized LVM learning framework that allows the basis of the latent space to favor a more diversity-inducing geometry and less redundancy, thereby accomplish long-tail pattern coverage and better interpretability for both Euclidean and Hilbert space settings. 2. Develop a diversity-promoting Bayesian LVM learning framework that enables efficient inference of posteriors probability distributions to facilitate quantization of uncertainty and alleviate over fitting. 3. Theoretically analyze the diversity-inducing techniques proposed in 1 and 2 to understand how these techniques affect the generalization errors in supervised LVMs, posterior contraction rate in unsupervised LVMs, and the information geometry of the distributions induced by LVMs. 4. Apply the diversified LVMs to healthcare applications. This project also provides rich opportunities for multi-disciplinary education and research training, at both undergraduate, graduate, and professional levels.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Xing",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Eric P Xing",
   "pi_email_addr": "epxing@cs.cmu.edu",
   "nsf_id": "000195787",
   "pi_start_date": "2016-08-24",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 499361.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Project outcome report:</p>\n<p>Small: A New Approach to Latent Space Learning with Diversity-Inducing Regularization and Applications to Healthcare Data Analytics&nbsp;</p>\n<p>We aim to develop generic, mathematically sound and computationally efficient diversity-promoting techniques for LVMs to address these challenges, and thereby facilitate long-tail and more interpretable pattern and knowledge discovery from healthcare and generic big data with high statistical and computational efficiency. Our plan consists of the following thrusts:</p>\n<p>1: <span style=\"text-decoration: underline;\">Developing a diversity-promoting regularized latent space estimation framework</span></p>\n<p>2: <span style=\"text-decoration: underline;\">Developing a diversity-promoting Bayesian LVM learning framework</span></p>\n<p>3: <span style=\"text-decoration: underline;\">Theoretical analysis of the diversity-inducing techniques proposed in 1 and 2</span></p>\n<p>4. <span style=\"text-decoration: underline;\">Applying the diversified LVMs to healthcare applications</span></p>\n<p>Over the past 4 years, we have been following the above outlined plan and achieved a rich body of scientific and software development outcomes. Bellow is a brief summary of these results:</p>\n<p>For the core methodological development for Latent Space Learning with Diversity-Inducing Regularization, we have make the following innovations:</p>\n<ul>\n<li>Learning latent space models with angular constraints</li>\n<li>A new diversity-promoting regularizer based on uncorrelation and evenness</li>\n<li>Orthogonality-promoting distance metric learning: convex relaxation and theoretical analysis</li>\n<li>Near-orthogonality regularization in kernel methods</li>\n<li>Diversity-promoting Bayesian learning of latent variable models </li>\n<li>Tradeoffs of Linear Mixed Models in Genome-wide Association Studies</li>\n<li>A Network-structured High-dimension Variable Selection Method with P-values, for Gene Set Prioritization with Transcriptome Association Study Guided by Regulatory Network</li>\n</ul>\n<p>On applications to healthcare problems, here are the major outcomes:</p>\n<ul>\n<li>Developed A Generalized Zero-Shot Text Classification Framework for ICD Coding</li>\n<li>Developing A Multimodal Machine Learning Framework for Automated ICD Coding</li>\n<li>Developing A Neural Architecture for Automated ICD Coding</li>\n<li>Automatic Generation of Medical Imaging Reports</li>\n<li>Effective Use of Bidirectional Language Model for Medical Named Entity Recognition </li>\n<li>Nonoverlap-promoting variable selection</li>\n<li>Unsupervised Pseudo-Labeling for Extractive Summarization on Electronic Health Records</li>\n</ul>\n<p>Overall, our work led to 14 publications in top machine learning and healthcare conferences, and at least 4 graduate students haven been supported partly from this grant, including Dr. Pengtao Xie, who graduated in 2019 and is now assistant professor at UCSD.</p>\n<p>Regarding broader impact, for the first time that diversity-promoting learning is systematically studied. The study is conducted in both frequentist statistics and Bayesian statistics, covering various regularizers, Bayesian priors, optimization algorithms, Bayesian inference algorithms, theoretical analysis, and extensive empirical evaluations. This study lays a solid foundation for a potentially prominent new paradigm of learning: diversity-promoting learning, which enables us to address several fundamental issues in machine learning, including 1) how to better capture infrequent patterns; 2) how to reduce model size without sacrificing modeling power; 3) how to improve generalization error; 4) how to improve interpretability. The techniques developed in our work are widely adopted in CV, NLP, and Healthcare applications, and we believe we have filled our goal outlined in the original proposal.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/31/2022<br>\n\t\t\t\t\tModified by: Eric&nbsp;P&nbsp;Xing</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nProject outcome report:\n\nSmall: A New Approach to Latent Space Learning with Diversity-Inducing Regularization and Applications to Healthcare Data Analytics \n\nWe aim to develop generic, mathematically sound and computationally efficient diversity-promoting techniques for LVMs to address these challenges, and thereby facilitate long-tail and more interpretable pattern and knowledge discovery from healthcare and generic big data with high statistical and computational efficiency. Our plan consists of the following thrusts:\n\n1: Developing a diversity-promoting regularized latent space estimation framework\n\n2: Developing a diversity-promoting Bayesian LVM learning framework\n\n3: Theoretical analysis of the diversity-inducing techniques proposed in 1 and 2\n\n4. Applying the diversified LVMs to healthcare applications\n\nOver the past 4 years, we have been following the above outlined plan and achieved a rich body of scientific and software development outcomes. Bellow is a brief summary of these results:\n\nFor the core methodological development for Latent Space Learning with Diversity-Inducing Regularization, we have make the following innovations:\n\nLearning latent space models with angular constraints\nA new diversity-promoting regularizer based on uncorrelation and evenness\nOrthogonality-promoting distance metric learning: convex relaxation and theoretical analysis\nNear-orthogonality regularization in kernel methods\nDiversity-promoting Bayesian learning of latent variable models \nTradeoffs of Linear Mixed Models in Genome-wide Association Studies\nA Network-structured High-dimension Variable Selection Method with P-values, for Gene Set Prioritization with Transcriptome Association Study Guided by Regulatory Network\n\n\nOn applications to healthcare problems, here are the major outcomes:\n\nDeveloped A Generalized Zero-Shot Text Classification Framework for ICD Coding\nDeveloping A Multimodal Machine Learning Framework for Automated ICD Coding\nDeveloping A Neural Architecture for Automated ICD Coding\nAutomatic Generation of Medical Imaging Reports\nEffective Use of Bidirectional Language Model for Medical Named Entity Recognition \nNonoverlap-promoting variable selection\nUnsupervised Pseudo-Labeling for Extractive Summarization on Electronic Health Records\n\n\nOverall, our work led to 14 publications in top machine learning and healthcare conferences, and at least 4 graduate students haven been supported partly from this grant, including Dr. Pengtao Xie, who graduated in 2019 and is now assistant professor at UCSD.\n\nRegarding broader impact, for the first time that diversity-promoting learning is systematically studied. The study is conducted in both frequentist statistics and Bayesian statistics, covering various regularizers, Bayesian priors, optimization algorithms, Bayesian inference algorithms, theoretical analysis, and extensive empirical evaluations. This study lays a solid foundation for a potentially prominent new paradigm of learning: diversity-promoting learning, which enables us to address several fundamental issues in machine learning, including 1) how to better capture infrequent patterns; 2) how to reduce model size without sacrificing modeling power; 3) how to improve generalization error; 4) how to improve interpretability. The techniques developed in our work are widely adopted in CV, NLP, and Healthcare applications, and we believe we have filled our goal outlined in the original proposal.\n\n\t\t\t\t\tLast Modified: 01/31/2022\n\n\t\t\t\t\tSubmitted by: Eric P Xing"
 }
}