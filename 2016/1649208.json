{
 "awd_id": "1649208",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: IIS: Empowering Probabilistic Reasoning with Random Projections",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032925149",
 "po_email": "kwhang@nsf.gov",
 "po_sign_block_name": "Kenneth Whang",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2017-08-31",
 "tot_intn_awd_amt": 90000.0,
 "awd_amount": 90000.0,
 "awd_min_amd_letter_date": "2016-08-09",
 "awd_max_amd_letter_date": "2016-08-09",
 "awd_abstract_narration": "Autonomous agents such as self-driving cars are required to act intelligently and adaptively in increasingly complex and uncertain real-world environments. To cope with the uncertainty and ambiguity of real world domains, AI systems rely heavily on statistical approaches. To make sensible decisions under uncertainty, agents need to reason probabilistically about their environments. Probabilistic reasoning, however, is known to be computationally very difficult in the worst case. While significant progress has been made over the past decades, many complex problems remain out of reach. This project aims to develop a new family of algorithms for reasoning under uncertainty. These novel techniques have the potential to provide more efficient algorithms for decision-making, learning and inference with improved theoretical guarantees on the accuracy. These techniques will be applicable in a wide range of domains, including medical diagnosis, information extraction, computer vision, and robotics.\r\n\r\nThis research project will develop a new family of algorithms for reasoning under uncertainty based on random projections. Random projections have played a key role in scaling up data mining and database systems. While drastically reducing computational cost, they also provide principled approximations. This research will explore the use of random projections based on universal hashing schemes in the context of probabilistic reasoning. The project will develop new techniques for learning and decision making under uncertainty problems. Specifically, new frameworks and algorithms with improved theoretical guarantees and practical performance will be developed. In order to provide efficient reasoning algorithms, the use of random projections will be considered in combination with a range of existing techniques, including modern optimization, variational, and sampling methods. A key focus will be to develop practical techniques and scale-up to real-world domains.  The techniques developed will be made available to both academia and industry through open-source software. Educational and outreach efforts will include the involvement of undergraduate students undertaking independent research projects.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stefano",
   "pi_last_name": "Ermon",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stefano Ermon",
   "pi_email_addr": "ermon@cs.stanford.edu",
   "nsf_id": "000693004",
   "pi_start_date": "2016-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "353 Serra Mall, Room 228",
  "perf_city_name": "Stanford",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943055008",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 90000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Statistical approaches are a key component of modern AI and machine learning techniques. However, dealing with complex, high-dimensional probabilistic models is intractable in the worst case. Hence, heuristic methods are often used in practice. The goal of this proposal was to develop a new class of probabilistic inference and decision making algorithms with good empirical performance and improved theoretical guarantees.</p>\n<p><br />In this NSF-EAGER project, we developed new machine learning algorithms to reason, learn, and take decsions based on complex probabilistic models.</p>\n<p><br />Variational approaches from physics are often used to approximate intractable probability distributions. While often effective in practice, it is known that the approximation error can be arbitrarily large. We proposed a new class of learning objectives for probabilistic models with latent variables. Our approach relies on random projections to simplify the distribution. In contrast to standard variational methods, our approximations are guaranteed to be tight with high probability. We provide a new approach for learning latent variable models based on optimizing our new approximation, and demonstrated empirical improvements on benchmark datasets from computer vision and natural language processing.</p>\n<p>Arising from many applications at the intersection of decision-making and machine learning, Marginal Maximum A Posteriori (Marginal MAP) problems combine maximization (optimization) and marginal inference (estimating probabilities). We proposed XOR_MMAP, a novel approach to solve the Marginal MAP problem, which is based on solving a small number of optimization problems subject to randomly generated constraints. XOR_MMAP provides a constant factor approximation to the Marginal MAP problem. We evaluated our approach in several machine learning and decision-making applications, and show that our approach outperforms several state-of-the-art Marginal MAP solvers.</p>\n<p><br />In addition, these theoretical advances have been used to study properties of random systems of logical equations (in particular, showing when a solution exists), an important problem in artificial intelligence that is often used to benchmark automated reasoning tools.&nbsp;</p>\n<p><br />The methodological advancements from this research have been integrated into courses taught at Stanford: Automated Reasoning and Probabilistic Graphical Models, which are attended by deveral hundred students.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/22/2017<br>\n\t\t\t\t\tModified by: Stefano&nbsp;Ermon</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nStatistical approaches are a key component of modern AI and machine learning techniques. However, dealing with complex, high-dimensional probabilistic models is intractable in the worst case. Hence, heuristic methods are often used in practice. The goal of this proposal was to develop a new class of probabilistic inference and decision making algorithms with good empirical performance and improved theoretical guarantees.\n\n\nIn this NSF-EAGER project, we developed new machine learning algorithms to reason, learn, and take decsions based on complex probabilistic models.\n\n\nVariational approaches from physics are often used to approximate intractable probability distributions. While often effective in practice, it is known that the approximation error can be arbitrarily large. We proposed a new class of learning objectives for probabilistic models with latent variables. Our approach relies on random projections to simplify the distribution. In contrast to standard variational methods, our approximations are guaranteed to be tight with high probability. We provide a new approach for learning latent variable models based on optimizing our new approximation, and demonstrated empirical improvements on benchmark datasets from computer vision and natural language processing.\n\nArising from many applications at the intersection of decision-making and machine learning, Marginal Maximum A Posteriori (Marginal MAP) problems combine maximization (optimization) and marginal inference (estimating probabilities). We proposed XOR_MMAP, a novel approach to solve the Marginal MAP problem, which is based on solving a small number of optimization problems subject to randomly generated constraints. XOR_MMAP provides a constant factor approximation to the Marginal MAP problem. We evaluated our approach in several machine learning and decision-making applications, and show that our approach outperforms several state-of-the-art Marginal MAP solvers.\n\n\nIn addition, these theoretical advances have been used to study properties of random systems of logical equations (in particular, showing when a solution exists), an important problem in artificial intelligence that is often used to benchmark automated reasoning tools. \n\n\nThe methodological advancements from this research have been integrated into courses taught at Stanford: Automated Reasoning and Probabilistic Graphical Models, which are attended by deveral hundred students.\n\n\t\t\t\t\tLast Modified: 11/22/2017\n\n\t\t\t\t\tSubmitted by: Stefano Ermon"
 }
}