{
 "awd_id": "1566359",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CSR: Multi-View Learning Solutions for Next-Generation Computationally-Autonomous Wearables",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2016-05-01",
 "awd_exp_date": "2018-04-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 191000.0,
 "awd_min_amd_letter_date": "2016-04-22",
 "awd_max_amd_letter_date": "2017-05-08",
 "awd_abstract_narration": "Wearables have emerged as a revolutionary technology for many new applications in healthcare, fitness, and human-centered Internet-of-Things (IoT). Computational algorithms, including machine learning and signal processing techniques, are often used to extract valuable information from wearable sensor data continuously and in real-time. These algorithms, however, need to be retrained upon any changes in configuration of the system, such as addition/removal of a sensor to/from the network, sensor displacement/misplacement, sensor upgrade, adoption of the system by new users, and changes in physical and behavioral status of the user. Retraining of the computational algorithms requires collecting sufficient amount of labeled training data, a time consuming, labor-intensive, and expensive process that limits scalability and sustainability of wearable technologies. The goal of this research is to enable automatic reconfiguration of the computational algorithms without need for collecting new labeled data. \r\n\r\nThis proposed research aims to design, develop and validate algorithms and tools for self-configuration of wearables through two overarching research trusts. First, this project investigates synchronous multi-view learning solutions for scenarios where source and target views observe the phenomena of interest simultaneously. In the synchronous learning, direct associations between observations made by the source view and those of the target view are established through context-sensitive learning processes that take the properties of physiological monitoring and human body into account for transfer learning purposes. Second, this research develops asynchronous multi-view learning algorithms to allow for automatic knowledge transfer even in absence of synchronous measurements in the source and target views. The asynchronous learning research devises feature mapping, instance transformation, and data labeling techniques to determine how data instances of the target view are associated with those of the source view while taking into consideration physical and contextual attributes of the user.\r\n\r\nThis project will potentially result in highly sustainable and scalable wearables capable to self-monitor and self-configure in highly dynamic and uncontrolled environments. The true realization of computationally autonomous wearables will allow for conducting high-precision chronic disease management and contribute to availability of new wearable-based consumer applications. This can lead to the development of products and business around the concept of human-centered IoT and their use in automation of health management and many applications that are currently infeasible.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hassan",
   "pi_last_name": "Zadeh",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Hassan G Zadeh",
   "pi_email_addr": "hassan.ghasemzadeh@asu.edu",
   "nsf_id": "000601152",
   "pi_start_date": "2016-04-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington State University",
  "inst_street_address": "240 FRENCH ADMINISTRATION BLDG",
  "inst_street_address_2": "",
  "inst_city_name": "PULLMAN",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "5093359661",
  "inst_zip_code": "991640001",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "WA05",
  "org_lgl_bus_name": "WASHINGTON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "XRJSGX384TD6"
 },
 "perf_inst": {
  "perf_inst_name": "Washington State University",
  "perf_str_addr": "355 Spokane St.",
  "perf_city_name": "Pullman",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "991642752",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "WA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1714",
   "pgm_ref_txt": "SPECIAL PROJECTS - CISE"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 175000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed several techniques for autonomous training of activity recognition model in new settings, called target, based on already trained activity recognition models or labeled datasets collected in a different setting, called source. The developed techniques enable cross-subject and cross-sensor knowledge transfer from a context-invariant source using homogeneous wearable inertial sensors. With these new software algorithms, one can reconfigure/learn activity recognition models in new settings without collecting labeled sensor data. An example is when a new wearable sensor is added to a wearable network and an activity recognition algorithm needs to be trained with the new sensor. In another example, the wearable system is adopted by a new user for whom no labeled training data exist. Another example is when the on-body location of a wearable sensor changes. The developed algorithms allow us to train machine learning algorithms autonomously in new settings (i.e., new sensor, new user, and new on-body location) without collecting and labeling sensor data in those settings. &nbsp;</p>\n<p>These findings are significant because they potentially result in highly sustainable and scalable wearable technologies capable to self-monitor and self-configure in highly dynamic and uncontrolled environments. &nbsp;Furthermore, making wearable technologies computationally autonomous contributes to conducting high-precision chronic disease management in end-user settings. It also contributes to availability of accurate wearable-based consumer applications.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/07/2018<br>\n\t\t\t\t\tModified by: Hassan&nbsp;G&nbsp;Zadeh</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed several techniques for autonomous training of activity recognition model in new settings, called target, based on already trained activity recognition models or labeled datasets collected in a different setting, called source. The developed techniques enable cross-subject and cross-sensor knowledge transfer from a context-invariant source using homogeneous wearable inertial sensors. With these new software algorithms, one can reconfigure/learn activity recognition models in new settings without collecting labeled sensor data. An example is when a new wearable sensor is added to a wearable network and an activity recognition algorithm needs to be trained with the new sensor. In another example, the wearable system is adopted by a new user for whom no labeled training data exist. Another example is when the on-body location of a wearable sensor changes. The developed algorithms allow us to train machine learning algorithms autonomously in new settings (i.e., new sensor, new user, and new on-body location) without collecting and labeling sensor data in those settings.  \n\nThese findings are significant because they potentially result in highly sustainable and scalable wearable technologies capable to self-monitor and self-configure in highly dynamic and uncontrolled environments.  Furthermore, making wearable technologies computationally autonomous contributes to conducting high-precision chronic disease management in end-user settings. It also contributes to availability of accurate wearable-based consumer applications.\n\n \n\n\t\t\t\t\tLast Modified: 06/07/2018\n\n\t\t\t\t\tSubmitted by: Hassan G Zadeh"
 }
}