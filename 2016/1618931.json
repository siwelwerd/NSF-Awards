{
 "awd_id": "1618931",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: A Unified Approach Toward User-specific Improvements of Quality of Experience for Video Streaming",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2016-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 488373.0,
 "awd_amount": 504373.0,
 "awd_min_amd_letter_date": "2016-08-10",
 "awd_max_amd_letter_date": "2017-05-22",
 "awd_abstract_narration": "The number of users streaming mobile video over the Internet has increased at an unprecedented rate throughout the past decade. Because video streaming is a mainstay of mobile computing, it is important that the best possible experience is delivered to users. Many mathematical algorithms have been proposed to improve quality in video-streaming-related domains. Typically, the parameters of these algorithms are established based on machine-centric indicators of video quality. Although researchers have attempted to connect these indicators with true user-perceived quality, in practice, there is often a disconnect. This project aims to improve directly-measurable indicators of user satisfaction in mobile video streaming by taking into account both individual user preferences as well as a user's tolerance for less than perfect quality in a specific video. \r\n\r\nThe proposed research will improve user-specific indicators by connecting problems in video streaming with problems in multi-task learning and collaborative filtering. These machine learning strategies are especially effective for prediction when large amounts of data are available. This effectiveness on large-scale learning fits well into this project's proposed context of improving user-facing indications of satisfaction. These indications include video abandonment, video session times, and collected navigation commands. Unlike user-surveys, these metrics can be collected at large scales through automated tooling in the video player. This research will investigate strategies that combine these large scale measurements with predictions from machine learning approaches toward selecting algorithm parameters that produce the most improvement in user-facing quality. This project will explore such parameter selection strategies in the context of improving user-perceived dynamic adaptive streaming quality. It will also explore such strategies to maintain a fixed level of user-facing quality while reducing mobile display power consumption via backlight scaling. Demonstrations of the approaches produced by this project will be featured in courses at the PI's institution and will be used to draw undergraduate interest toward computer science research.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yao",
   "pi_last_name": "Liu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yao Liu",
   "pi_email_addr": "yao.liu@rutgers.edu",
   "nsf_id": "000663678",
   "pi_start_date": "2016-08-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Binghamton",
  "inst_street_address": "4400 VESTAL PKWY E",
  "inst_street_address_2": "",
  "inst_city_name": "BINGHAMTON",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6077776136",
  "inst_zip_code": "13902",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "L9ZDVULCHCV3",
  "org_uei_num": "NQMVAAQUFU53"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Binghamton",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "139026000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 488373.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Traffic on the Internet today is dominated by video streaming. With the ever-increasing number of user streaming events and demand for higher video resolution and higher quality, it is important that the best possible experience is provided to end users under various constraints including the limited network bandwidth and battery power supply. This project aimed to improve the quality of experience in video streaming via user-centric adaptations. We have proposed an optimization approach that applies a neural network in conjunction with a reinforcement learning strategy to optimize a cost function used to represent a user's perceived streaming quality. To improve streaming of the emerging 360-degree video content, we have designed various approaches that adapt both the representations of the video content and the streaming delivery based on both past user viewing histories and imminent user viewing behavior. We showed that our proposed approaches can deliver higher quality views to users than state-of-the-art approaches. In addition, we have proposed solutions for saving the battery power consumption during video streaming without affecting user-perceived experiences.&nbsp;</p>\n<p>The research supported by this award has resulted in 15 peer-reviewed publications at various conferences, workshops, and journal, including ACM Multimedia Conference, ACM Multimedia Systems Conference, IEEE INFOCOM, etc. The papers have also received one Best Student Paper Award and one Best Paper Award at ACM Multimedia Systems Conferences. We have presented our results at various international conferences and at research seminars at Binghamton University. Four PhD students, three master's students, and four undergraduate students have been supported and trained. Artifacts produced from the project, including ffmpeg360 -- a tool that uses OpenGL for user-view rendering and fast 360-degree video transcoding between different spherical projection schemes, have been open-sourced and are accessible via Github.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/07/2022<br>\n\t\t\t\t\tModified by: Yao&nbsp;Liu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTraffic on the Internet today is dominated by video streaming. With the ever-increasing number of user streaming events and demand for higher video resolution and higher quality, it is important that the best possible experience is provided to end users under various constraints including the limited network bandwidth and battery power supply. This project aimed to improve the quality of experience in video streaming via user-centric adaptations. We have proposed an optimization approach that applies a neural network in conjunction with a reinforcement learning strategy to optimize a cost function used to represent a user's perceived streaming quality. To improve streaming of the emerging 360-degree video content, we have designed various approaches that adapt both the representations of the video content and the streaming delivery based on both past user viewing histories and imminent user viewing behavior. We showed that our proposed approaches can deliver higher quality views to users than state-of-the-art approaches. In addition, we have proposed solutions for saving the battery power consumption during video streaming without affecting user-perceived experiences. \n\nThe research supported by this award has resulted in 15 peer-reviewed publications at various conferences, workshops, and journal, including ACM Multimedia Conference, ACM Multimedia Systems Conference, IEEE INFOCOM, etc. The papers have also received one Best Student Paper Award and one Best Paper Award at ACM Multimedia Systems Conferences. We have presented our results at various international conferences and at research seminars at Binghamton University. Four PhD students, three master's students, and four undergraduate students have been supported and trained. Artifacts produced from the project, including ffmpeg360 -- a tool that uses OpenGL for user-view rendering and fast 360-degree video transcoding between different spherical projection schemes, have been open-sourced and are accessible via Github.\n\n\t\t\t\t\tLast Modified: 06/07/2022\n\n\t\t\t\t\tSubmitted by: Yao Liu"
 }
}