{
 "awd_id": "1640060",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "E2CDA: Type I: Collaborative Research: Energy Efficient Learning Machines (ENIGMA)",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927843",
 "po_email": "sabasu@nsf.gov",
 "po_sign_block_name": "Sankar Basu",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2023-08-31",
 "tot_intn_awd_amt": 1108185.0,
 "awd_amount": 1108185.0,
 "awd_min_amd_letter_date": "2016-08-31",
 "awd_max_amd_letter_date": "2022-08-16",
 "awd_abstract_narration": "The project will aim to develop computing hardware and software that improve the energy efficiency of learning machines by many orders of magnitude. In doing so it will enable large societal adoption of such machines, paving the way for new applications in diverse areas such as manufacturing, healthcare, agriculture, and many others. For example, machines that learn the behavioral trends of individual human beings by collecting data from myriads of sensors may be able to design the most appropriate drugs. Similarly, one may envision machines that learn trends in the weather and thereby assist in predicting the most optimized preparations for the next crop cycle. The possibilities are literally endless. However, the canonical learning machines of today need huge amount of energy, significantly hindering their adoption for widespread applications. The goal of this project will be to explore, evaluate and innovate new hardware and software paradigms that could reduce energy dissipation in learning machines by a significant amount. The team of researchers consists of experts in mathematics, neuroscience, electronic devices and materials and computer circuit and system design that will foster a unique platform for both innovative research and interdisciplinary training of graduate students.\r\n\r\nWe are witnessing a regimental shift in the computing paradigm. For a  vast  number  of  applications, cognitive functions such as classification, recognition, synthesis, decision-making and  learning  are gaining rapid importance in a world that is infused with sensing modalities, often paraphrased under a common term of \"Big Data\", that are in critical need of efficient information-extraction. This is in sharp contrast to the past when the central objective of computing was to perform calculations on numbers and produce results with extreme numerical accuracy. We aim to approach this problem by exploiting cognitive models that have shown efficacy in \"one shot\" learning. In this approach, the information is represented by means of high dimensional (HD) vectors. These vectors follow a set of predetermined mathematical operations that ensure that the resulting vector after such operations is unique. The uniqueness can in turn be used as \"learning\" and the predefined nature of mathematical operations make the learning \"one shot\". When paired with traditional artificial neural network or deep learning algorithms,  such  \"one  shot\" learning could significantly reduce the number of necessary computing operations, leading to orders of magnitude reduction in energy dissipation. We shall explore the entire computer hierarchy, staring from materials and devices, all the way up to system design and optimization to exploit the unique capabilities afforded by the HD computing, with the ultimate objective of realizing energy efficient learning machines (ENIGMA).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sayeef",
   "pi_last_name": "Salahuddin",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sayeef Salahuddin",
   "pi_email_addr": "sayeef@eecs.berkeley.edu",
   "nsf_id": "000510729",
   "pi_start_date": "2016-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jan",
   "pi_last_name": "Rabaey",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jan Rabaey",
   "pi_email_addr": "jan@eecs.Berkeley.edu",
   "nsf_id": "000472478",
   "pi_start_date": "2016-08-31",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Bruno",
   "pi_last_name": "Olshausen",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Bruno A Olshausen",
   "pi_email_addr": "baolshausen@berkeley.edu",
   "nsf_id": "000444415",
   "pi_start_date": "2016-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Berkeley",
  "inst_street_address": "1608 4TH ST STE 201",
  "inst_street_address_2": "",
  "inst_city_name": "BERKELEY",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5106433891",
  "inst_zip_code": "947101749",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "CA12",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF CALIFORNIA, THE",
  "org_prnt_uei_num": "",
  "org_uei_num": "GS3YEVSS12N6"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Berkeley",
  "perf_str_addr": "515 Sutardja Dai Hall",
  "perf_city_name": "Berkeley",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "947201770",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "CA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "015Y00",
   "pgm_ele_name": "Energy Efficient Computing: fr"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7945",
   "pgm_ref_txt": "DES AUTO FOR MICRO & NANO SYST"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 369396.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 369395.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 369394.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In the recent years, there has been increasing interest in finding solutions to computationally challenging problems that are NP-hard and NP-complete, where no exact polynomial time solution exists. These problems include a large number of non-convex optimization problems that we encounter in our daily lives. In this context, it is well recognized that a hardware that can emulate an Ising Hamiltonian could naturally find its ground state asynchronously and in a probabilistic manner &ndash; just like how it happens in the brain. Indeed, motivated by this possibility, substantial theoretical work has gone into mapping real-life, hard optimization problems onto Ising Hamiltonians. However, the hardware implementation to date has mainly focused on some version of deterministic and clocked emulation.&nbsp;</p>\n<p>In this work, we have achieved the first demonstration of an Ising hardware that provides fully asynchronous, probabilistic solution to hard optimization problems. The asynchronous operation affords it a clock-free operation and the probabilistic nature provides parallelism &ndash; both of which work together to provide tremendous speed up. Realization of both asynchronous and probabilistic operation simultaneously also makes it possible for our hardware to embody the dynamics of an Ising Hamiltonian ab initio, as it happens in real physical systems. This has not been achieved before.</p>\n<p>We demonstrated broad applicability of this accelerator on problems ranging from Combinatorial Optimization, Neural Simulation, to Machine Learning. Results show &sim; 200X speedup for optimization compared to an equivalent but clocked computation on a CPU, a 1500X speed improvement and &asymp; 2500X power improvement for generative training and inference compared to a CPU, and, in the context of Neural Simulation, capability to emulate fly decision making in real time.</p>\n<p>Our work has shown that it is indeed possible to develop a probabilistic computing hardware that operates completely asynchronously and, by doing so, provides tremendous speed up.&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n Last Modified: 09/09/2024<br>\nModified by: Sayeef&nbsp;Salahuddin</p></div>\n<div class=\"porSideCol\"\n><div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2024/1640060/1640060_10457015_1725856524727_hardware--rgov-214x142.png\" original=\"/por/images/Reports/POR/2024/1640060/1640060_10457015_1725856524727_hardware--rgov-800width.png\" title=\"PASS Hardware\"><img src=\"/por/images/Reports/POR/2024/1640060/1640060_10457015_1725856524727_hardware--rgov-66x44.png\" alt=\"PASS Hardware\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Pass Chip Designed by UC Berkeley</div>\n<div class=\"imageCredit\">Saavan Patel and Sayeef Salahuddin</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Sayeef&nbsp;Salahuddin\n<div class=\"imageTitle\">PASS Hardware</div>\n</div>\n</li></ul>\n</div>\n</div></div>\n</div>\n",
  "por_txt_cntn": "\n\nIn the recent years, there has been increasing interest in finding solutions to computationally challenging problems that are NP-hard and NP-complete, where no exact polynomial time solution exists. These problems include a large number of non-convex optimization problems that we encounter in our daily lives. In this context, it is well recognized that a hardware that can emulate an Ising Hamiltonian could naturally find its ground state asynchronously and in a probabilistic manner  just like how it happens in the brain. Indeed, motivated by this possibility, substantial theoretical work has gone into mapping real-life, hard optimization problems onto Ising Hamiltonians. However, the hardware implementation to date has mainly focused on some version of deterministic and clocked emulation.\n\n\nIn this work, we have achieved the first demonstration of an Ising hardware that provides fully asynchronous, probabilistic solution to hard optimization problems. The asynchronous operation affords it a clock-free operation and the probabilistic nature provides parallelism  both of which work together to provide tremendous speed up. Realization of both asynchronous and probabilistic operation simultaneously also makes it possible for our hardware to embody the dynamics of an Ising Hamiltonian ab initio, as it happens in real physical systems. This has not been achieved before.\n\n\nWe demonstrated broad applicability of this accelerator on problems ranging from Combinatorial Optimization, Neural Simulation, to Machine Learning. Results show  200X speedup for optimization compared to an equivalent but clocked computation on a CPU, a 1500X speed improvement and  2500X power improvement for generative training and inference compared to a CPU, and, in the context of Neural Simulation, capability to emulate fly decision making in real time.\n\n\nOur work has shown that it is indeed possible to develop a probabilistic computing hardware that operates completely asynchronously and, by doing so, provides tremendous speed up.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\t\t\t\t\tLast Modified: 09/09/2024\n\n\t\t\t\t\tSubmitted by: SayeefSalahuddin\n"
 }
}