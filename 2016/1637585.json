{
 "awd_id": "1637585",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AitF: Collaborative Research: Algorithms for Probabilistic Inference in the Real World",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 399939.0,
 "awd_amount": 399939.0,
 "awd_min_amd_letter_date": "2016-08-30",
 "awd_max_amd_letter_date": "2016-08-30",
 "awd_abstract_narration": "Statistical models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data.  The process of using a model to answer specific questions, such as inferring the state of several random variables given evidence observed about others, is called probabilistic inference.  Probabilistic graphical models, a type of statistical model, are often used in diverse applications such as medical diagnosis, understanding protein and gene regulatory networks, computer vision, and language understanding.  On account of the central role played by probabilistic graphical models in a wide range of automated reasoning applications, designing efficient algorithms for probabilistic inference is a fundamental problem in artificial intelligence and machine learning.\r\n \r\nProbabilistic inference in many of these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve.  However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently.  This project focuses on bridging the gap between theory and practice for probabilistic inference problems in large-scale machine learning systems.  The PIs will identify structural properties and methods of analysis that differentiate real-world instances from worst-case instances used to show NP-hardness, and will design efficient algorithms with provable guarantees that would apply to most real-world instances.  The project will also study why heuristics like linear programming and other convex relaxations are so successful on real-world instances.  The efficient algorithms for probabilistic inference developed as part of this project have the potential to be transformative in machine learning, statistics, and more applied areas like computer vision, social networks and computational biology.  To help disseminate the research and foster new collaborations, a series of workshops will be organized bringing together the theoretical computer science and machine learning communities.  Additionally, undergraduate curricula will be developed that use machine learning to introduce students to concepts in theoretical computer science.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Aravindan",
   "pi_last_name": "Vijayaraghavan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Aravindan Vijayaraghavan",
   "pi_email_addr": "aravindv@northwestern.edu",
   "nsf_id": "000692489",
   "pi_start_date": "2016-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Rd.",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602083118",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "723900",
   "pgm_ele_name": "Algorithms in the Field"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 399939.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p dir=\"ltr\">Probabilistic models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data. These models are frequently used to make predictions in settings with limited training data such as in health care (medical diagnosis from symptoms), biology (inferring protein regulatory networks), computer vision (stereopsis), and natural language processing (parsing and text generation). Using these models requires performing probabilistic inference, which takes evidence about observed variables to draw conclusions about unobserved variables. Inference in these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve. However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently. This project focused on algorithms and theory for probabilistic inference problems in large-scale machine learning systems.</p>\n<p dir=\"ltr\">A major contribution of this project was bridging the gap between theory and practice for finding the most probable assignment of the unobserved variables (MAP inference) in a special case of probabilistic models (Potts models). Heuristics based on iterative techniques (alpha-expansion) and linear programming relaxations have been shown empirically to return solutions that are either globally optimal, or close to globally optimal. PIs David Sontag and Aravindan Vijayaraghavan with PhD students Hunter Lang (MIT) and Aravind Reddy (Northwestern) showed through both theoretical and empirical results published in a series of works (AISTATS 2018, AISTATS 2019, ICML 2021, AISTATS 2021) that variants of a natural notion called stability could explain the tractability of these instances in practice.</p>\n<p dir=\"ltr\">Specifically, for the alpha-expansion algorithm, we proved (in Lang et al., ICML 2021) that it always returns a globally optimal assignment for Potts models, with a catch: the returned assignment is only guaranteed to be optimal for an instance within a small perturbation of the original problem instance. Intuitively, we expect that for robust models used in applications, small perturbations to their parameters should have similar optimal assignments, which would imply that alpha-expansion provides near-optimal assignments for the original models. Moreover, for a linear programming relaxation, we proved that it is close to integral when the instance is close to stable or satisfies a condition called block stability (AISTATS 2019, AISTATS 2021). We then designed algorithms that can certify whether models satisfy these conditions. Using our new methods for certifying stability, we were able to demonstrate that several computer vision models indeed satisfy these stability conditions. Taken together, these results give a cohesive explanation for the good performance of the above heuristics in practice.&nbsp;</p>\n<p dir=\"ltr\">Our results also suggested a monotonicity principle for algorithm design for the linear programming relaxation: we showed that the relaxation performs well when the input is generated as a simpler tractable part of the model and remaining factors are random but slightly biased toward the ground truth.</p>\n<p dir=\"ltr\">The project also led to theory-inspired improvements for emerging paradigms in machine learning like weak supervision, where one seeks to learn from imperfect labels that domain experts provide (e.g., that any review with the word ?great? should be labeled as positive sentiment). Under the assumption of conditional independence between the weak labels and the features, in joint work of the PIs with MIT PhD student Hunter Lang (published in NeurIPS 2022), we proved that there is a trade-off between the number of data points ?covered? by the weak labels and their noise rates. We then showed that we could use the popular ?cut statistic? heuristic to rank data points by a measure of the confidence in their weak labels; finally, we train the downstream classifier on the most confident of these. Surprisingly, we found that this technique improved the performance of every single weak supervision method previously published, often by large amounts.&nbsp;</p>\n<p dir=\"ltr\">Other research highlights from this project include new theory and algorithms for clustering Euclidean instances that are stable (Dutta et al., NeurIPS ?17), new algorithms with provable guarantees for learning depth-2 neural networks (Awasthi et al., NeurIPS ?21), improved algorithms using ideas from co-training for prompt-based learning with large language models and unlabeled data (Lang et al., ICML ?22), as well as new algorithms and provable guarantees for human-AI interaction (Mozannar et al., AAAI '22) and self-supervised learning tasks that arise in healthcare (Agrawal et al., AISTATS ?22).&nbsp;</p>\n<p dir=\"ltr\">The PIs also organized activities and workshops with the goal of reaching out to the broader scientific community interested in topics related to the project. PI Vijayaraghavan co-organized (along with Aleksander Madry and Daniel Hsu) the <a href=\"https://sites.google.com/view/focs2021ml/home\">FOCS 2021 workshop on New Directions in Machine Learning</a>. PI Vijayaraghavan also co-organized <a href=\"https://theory.cs.northwestern.edu/events/\">several day-long theory workshops</a> at Northwestern University that got broad attendance from theory faculty, postdocs and students in many mid-west universities in and near Chicago. Two of these workshops were closely related to the topic of this project. These workshops were open to the public, and videos are publicly accessible on the website.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/20/2023<br>\n\t\t\t\t\tModified by: Aravindan&nbsp;Vijayaraghavan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1637585/1637585_10456488_1673661054633_nsf_aitf_first--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1637585/1637585_10456488_1673661054633_nsf_aitf_first--rgov-800width.jpg\" title=\"Graph Cuts Always Find a Global Optimum for Potts Models (with a Catch)\"><img src=\"/por/images/Reports/POR/2023/1637585/1637585_10456488_1673661054633_nsf_aitf_first--rgov-66x44.jpg\" alt=\"Graph Cuts Always Find a Global Optimum for Potts Models (with a Catch)\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Our certification algorithms guarantee that the Hamming error of any local optimum of alpha expansion is small on these instances.</div>\n<div class=\"imageCredit\">Hunter Lang</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Aravindan&nbsp;Vijayaraghavan</div>\n<div class=\"imageTitle\">Graph Cuts Always Find a Global Optimum for Potts Models (with a Catch)</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1637585/1637585_10456488_1672431382955_nsf_aitf_third--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1637585/1637585_10456488_1672431382955_nsf_aitf_third--rgov-800width.jpg\" title=\"Training Subset Selection for Weak Supervision\"><img src=\"/por/images/Reports/POR/2022/1637585/1637585_10456488_1672431382955_nsf_aitf_third--rgov-66x44.jpg\" alt=\"Training Subset Selection for Weak Supervision\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">By choosing a confident subset of training data points to use for training, we improve the accuracy of all previously published algorithms for weak supervision.</div>\n<div class=\"imageCredit\">Hunter Lang</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Aravindan&nbsp;Vijayaraghavan</div>\n<div class=\"imageTitle\">Training Subset Selection for Weak Supervision</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1637585/1637585_10456488_1673661109163_nsf_aitf_second--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1637585/1637585_10456488_1673661109163_nsf_aitf_second--rgov-800width.jpg\" title=\"Beyond Perturbation Stability: LP Recovery Guarantees for MAP Inference on Noisy Stable Instances\"><img src=\"/por/images/Reports/POR/2023/1637585/1637585_10456488_1673661109163_nsf_aitf_second--rgov-66x44.jpg\" alt=\"Beyond Perturbation Stability: LP Recovery Guarantees for MAP Inference on Noisy Stable Instances\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Illustration of how solving the LP relaxation on a (slightly) corrupted stable instance approximately recovers the original MAP assignment.</div>\n<div class=\"imageCredit\">Hunter Lang and Aravind Reddy</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Aravindan&nbsp;Vijayaraghavan</div>\n<div class=\"imageTitle\">Beyond Perturbation Stability: LP Recovery Guarantees for MAP Inference on Noisy Stable Instances</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "Probabilistic models provide a powerful means of quantifying uncertainty, modeling prior beliefs, and describing complex dependencies in data. These models are frequently used to make predictions in settings with limited training data such as in health care (medical diagnosis from symptoms), biology (inferring protein regulatory networks), computer vision (stereopsis), and natural language processing (parsing and text generation). Using these models requires performing probabilistic inference, which takes evidence about observed variables to draw conclusions about unobserved variables. Inference in these applications corresponds to a complex combinatorial optimization problem that at first glance appears to be extremely difficult to solve. However, practitioners have made significant strides in designing heuristic algorithms to perform real-world inference accurately and efficiently. This project focused on algorithms and theory for probabilistic inference problems in large-scale machine learning systems.\nA major contribution of this project was bridging the gap between theory and practice for finding the most probable assignment of the unobserved variables (MAP inference) in a special case of probabilistic models (Potts models). Heuristics based on iterative techniques (alpha-expansion) and linear programming relaxations have been shown empirically to return solutions that are either globally optimal, or close to globally optimal. PIs David Sontag and Aravindan Vijayaraghavan with PhD students Hunter Lang (MIT) and Aravind Reddy (Northwestern) showed through both theoretical and empirical results published in a series of works (AISTATS 2018, AISTATS 2019, ICML 2021, AISTATS 2021) that variants of a natural notion called stability could explain the tractability of these instances in practice.\nSpecifically, for the alpha-expansion algorithm, we proved (in Lang et al., ICML 2021) that it always returns a globally optimal assignment for Potts models, with a catch: the returned assignment is only guaranteed to be optimal for an instance within a small perturbation of the original problem instance. Intuitively, we expect that for robust models used in applications, small perturbations to their parameters should have similar optimal assignments, which would imply that alpha-expansion provides near-optimal assignments for the original models. Moreover, for a linear programming relaxation, we proved that it is close to integral when the instance is close to stable or satisfies a condition called block stability (AISTATS 2019, AISTATS 2021). We then designed algorithms that can certify whether models satisfy these conditions. Using our new methods for certifying stability, we were able to demonstrate that several computer vision models indeed satisfy these stability conditions. Taken together, these results give a cohesive explanation for the good performance of the above heuristics in practice. \nOur results also suggested a monotonicity principle for algorithm design for the linear programming relaxation: we showed that the relaxation performs well when the input is generated as a simpler tractable part of the model and remaining factors are random but slightly biased toward the ground truth.\nThe project also led to theory-inspired improvements for emerging paradigms in machine learning like weak supervision, where one seeks to learn from imperfect labels that domain experts provide (e.g., that any review with the word ?great? should be labeled as positive sentiment). Under the assumption of conditional independence between the weak labels and the features, in joint work of the PIs with MIT PhD student Hunter Lang (published in NeurIPS 2022), we proved that there is a trade-off between the number of data points ?covered? by the weak labels and their noise rates. We then showed that we could use the popular ?cut statistic? heuristic to rank data points by a measure of the confidence in their weak labels; finally, we train the downstream classifier on the most confident of these. Surprisingly, we found that this technique improved the performance of every single weak supervision method previously published, often by large amounts. \nOther research highlights from this project include new theory and algorithms for clustering Euclidean instances that are stable (Dutta et al., NeurIPS ?17), new algorithms with provable guarantees for learning depth-2 neural networks (Awasthi et al., NeurIPS ?21), improved algorithms using ideas from co-training for prompt-based learning with large language models and unlabeled data (Lang et al., ICML ?22), as well as new algorithms and provable guarantees for human-AI interaction (Mozannar et al., AAAI '22) and self-supervised learning tasks that arise in healthcare (Agrawal et al., AISTATS ?22). \nThe PIs also organized activities and workshops with the goal of reaching out to the broader scientific community interested in topics related to the project. PI Vijayaraghavan co-organized (along with Aleksander Madry and Daniel Hsu) the FOCS 2021 workshop on New Directions in Machine Learning. PI Vijayaraghavan also co-organized several day-long theory workshops at Northwestern University that got broad attendance from theory faculty, postdocs and students in many mid-west universities in and near Chicago. Two of these workshops were closely related to the topic of this project. These workshops were open to the public, and videos are publicly accessible on the website.\n\n\t\t\t\t\tLast Modified: 01/20/2023\n\n\t\t\t\t\tSubmitted by: Aravindan Vijayaraghavan"
 }
}