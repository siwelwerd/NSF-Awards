{
 "awd_id": "1551631",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: From Grasp Quality to Hand Quality: Analysis and Optimization for Effective Robot Hands",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Juan Wachs",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 546505.0,
 "awd_amount": 546505.0,
 "awd_min_amd_letter_date": "2015-12-31",
 "awd_max_amd_letter_date": "2020-07-07",
 "awd_abstract_narration": "Robotic manipulators often exhibit high precision, repeatability, and grip strength, characteristics which have enabled many applications, primarily in industrial settings. However, robot hands still lack versatility: once a manipulation task implies variation, it quickly falls beyond the capabilities of today's robots. This prevents robot manipulators from operating in many environments, from cluttered store rooms and warehouses to typical homes and other human settings. This project aims to develop and demonstrate more versatile robot hands, able to manipulate a wide range of objects and to operate in clutter. Robots equipped with such hands could perform what are otherwise injury-prone tasks like kitting and bin picking (in manufacturing), or order picking and packing (in logistics). In healthcare, more versatile robotic manipulators could assist with activities of daily living, many of which involve contact and manipulation. From an educational perspective, this project aims to encourage interdisciplinary training by combining areas of robotics traditionally spanning multiple engineering disciplines, and to promote diversity in engineering education by inspiring and preparing young students for STEM careers, at both the high school and undergraduate levels.\r\n\r\nThe key research objective of this project is to find new ways of building and using robot hands, where the high level grasp planning algorithms, the low-level control loops, and the hardware design itself are optimized simultaneously, in a tight loop, and taking each other into account. This represents a departure from the \"build, then program\" approach, where algorithms for performing complex tasks (such as grasping and manipulation) are researched only after the underlying hardware (the hand) has been designed and constructed. By combining these stages, we can jointly optimize algorithms, sensor arrays, control strategies and mechanism structures that fit and complement each other. Both mechanical and algorithmic complexity can then be increased based strictly on provable performance gains.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Matei",
   "pi_last_name": "Ciocarlie",
   "pi_mid_init": "T",
   "pi_sufx_name": "",
   "pi_full_name": "Matei T Ciocarlie",
   "pi_email_addr": "mtc2103@columbia.edu",
   "nsf_id": "000674926",
   "pi_start_date": "2015-12-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Columbia University",
  "inst_street_address": "615 W 131ST ST",
  "inst_street_address_2": "MC 8741",
  "inst_city_name": "NEW YORK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "2128546851",
  "inst_zip_code": "100277922",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "NY13",
  "org_lgl_bus_name": "THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK",
  "org_prnt_uei_num": "",
  "org_uei_num": "F4N1QNPB95M4"
 },
 "perf_inst": {
  "perf_inst_name": "Columbia University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "100276902",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "NY13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 98215.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 111559.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 114598.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 117733.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 104400.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project advanced the area of dexterous robotic manipulation from multiple perspectives: theoretical foundations, development of tactile robotic fingers, and development of new methods for performing complex manipulation tasks.&nbsp;</p>\n<p>Intellectual merit:</p>\n<p>From a theoretical perspective, we advanced the understanding of friction between a robot fingers and the grasped object as a key contributor to grasp stability. Using these advances, we introduced a method that can, for the first time, distinguish between external disturbances that a grasp can resist passively and those that require an active adjustment of motor forces and the hand's joints.</p>\n<p>We also introduced advances in the development of robot fingers equipped with the sense of touch. Human hands are equipped with complex tactile sensing capabilities which are known to be critical for dexterous manipulation; however, their robotic counterparts lag behind in this respect. In this project, we introduced the first robotic tactile fingers able to localize touch with sub-millimeter accuracy over a multicurved finger surface. Our novel fingers, which are available open-source to the research community, are based on a multitude of light emitters and receivers embedded in a transparent layer under an opaque skin.</p>\n<p>Finally, we showed that the tactile information provided by our fingers can enable highly dexterous tasks, such as in-hand object reorientation, demonstrated in a physics simulator. We showed that this level of dexterity, never before demonstrated using only tactile and proprioceptive sensing, can be achieved by using reinforcement learning methods with the appropriate sensing input and adapted to the dexterous manipulation problem.</p>\n<p>Broader Impacts:</p>\n<p>These advances in robotic dexterity are needed in areas ranging from manufacturing to logistics, where effective robotic tools, of which manipulation is a key component, can help increase competitiveness for manufacturers and increase the efficiency of the supply chain.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/27/2022<br>\n\t\t\t\t\tModified by: Matei&nbsp;T&nbsp;Ciocarlie</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294800469_Baseball--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294800469_Baseball--rgov-800width.jpg\" title=\"Tactile robot hand\"><img src=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294800469_Baseball--rgov-66x44.jpg\" alt=\"Tactile robot hand\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Robot hand equipped with tactile fingers developed in this project</div>\n<div class=\"imageCredit\">Matei Ciocarlie / Columbia University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Matei&nbsp;T&nbsp;Ciocarlie</div>\n<div class=\"imageTitle\">Tactile robot hand</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294506150_columbia_tactile_manufacture--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294506150_columbia_tactile_manufacture--rgov-800width.jpg\" title=\"Manufacturing stages for tactile finger\"><img src=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294506150_columbia_tactile_manufacture--rgov-66x44.jpg\" alt=\"Manufacturing stages for tactile finger\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">From left to right: 3D-printed skeleton, addition of flexible circuit board with light emitters and receivers, addition of transparent layer, addition of opaque skin layer.</div>\n<div class=\"imageCredit\">Matei Ciocarlie / Columbia University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Matei&nbsp;T&nbsp;Ciocarlie</div>\n<div class=\"imageTitle\">Manufacturing stages for tactile finger</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294403812_columbia_tactile_lightshow_2--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294403812_columbia_tactile_lightshow_2--rgov-800width.jpg\" title=\"Optics-based tactile robot finger\"><img src=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664294403812_columbia_tactile_lightshow_2--rgov-66x44.jpg\" alt=\"Optics-based tactile robot finger\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Optics-based tactile finger developed in this project shown without external skin layer.</div>\n<div class=\"imageCredit\">Matei Ciocarlie / Columbia University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Matei&nbsp;T&nbsp;Ciocarlie</div>\n<div class=\"imageTitle\">Optics-based tactile robot finger</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664295059819_IHM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664295059819_IHM--rgov-800width.jpg\" title=\"Dexterous in-hand manipulation\"><img src=\"/por/images/Reports/POR/2022/1551631/1551631_10406528_1664295059819_IHM--rgov-66x44.jpg\" alt=\"Dexterous in-hand manipulation\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Control policy for in-hand manipulation trained in a physics simulator and based on tactile and proprioceptive sensing</div>\n<div class=\"imageCredit\">Columbia University</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Matei&nbsp;T&nbsp;Ciocarlie</div>\n<div class=\"imageTitle\">Dexterous in-hand manipulation</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThis project advanced the area of dexterous robotic manipulation from multiple perspectives: theoretical foundations, development of tactile robotic fingers, and development of new methods for performing complex manipulation tasks. \n\nIntellectual merit:\n\nFrom a theoretical perspective, we advanced the understanding of friction between a robot fingers and the grasped object as a key contributor to grasp stability. Using these advances, we introduced a method that can, for the first time, distinguish between external disturbances that a grasp can resist passively and those that require an active adjustment of motor forces and the hand's joints.\n\nWe also introduced advances in the development of robot fingers equipped with the sense of touch. Human hands are equipped with complex tactile sensing capabilities which are known to be critical for dexterous manipulation; however, their robotic counterparts lag behind in this respect. In this project, we introduced the first robotic tactile fingers able to localize touch with sub-millimeter accuracy over a multicurved finger surface. Our novel fingers, which are available open-source to the research community, are based on a multitude of light emitters and receivers embedded in a transparent layer under an opaque skin.\n\nFinally, we showed that the tactile information provided by our fingers can enable highly dexterous tasks, such as in-hand object reorientation, demonstrated in a physics simulator. We showed that this level of dexterity, never before demonstrated using only tactile and proprioceptive sensing, can be achieved by using reinforcement learning methods with the appropriate sensing input and adapted to the dexterous manipulation problem.\n\nBroader Impacts:\n\nThese advances in robotic dexterity are needed in areas ranging from manufacturing to logistics, where effective robotic tools, of which manipulation is a key component, can help increase competitiveness for manufacturers and increase the efficiency of the supply chain.\n\n\t\t\t\t\tLast Modified: 09/27/2022\n\n\t\t\t\t\tSubmitted by: Matei T Ciocarlie"
 }
}