{
 "awd_id": "1617286",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF: Small: Collaborative Research: Analytics on Edge-labeled Hypergraphs: Limits to De-anonymization",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2019-06-30",
 "tot_intn_awd_amt": 250000.0,
 "awd_amount": 250000.0,
 "awd_min_amd_letter_date": "2016-06-28",
 "awd_max_amd_letter_date": "2016-06-28",
 "awd_abstract_narration": "Data analytics is a rapidly growing field, aided by the availability of huge amounts of data and significant computing power. The immense potential of data analytics to provide benefits to the society in application areas such as health, economics, and finance, is reliant on the fundamental and urgent challenge of protecting privacy of users. In this project, new theoretical paradigms and approaches to address privacy vulnerability of users in network environments in presence of big data are studied. The vulnerability results from the indigenous structural dependencies in the network as well as the presence of exogenous auxiliary information outside of the network that permits deanonymization of the users. This project has transformative potential to impact a broad class of applications where user privacy is critical. The project?s inherently inter-disciplinary nature and real-world technological potential complements the investigators? on-going efforts to engage more students (especially women and minorities) to study topics at the intersection of application and quantitative reasoning in the STEM disciplines. \r\n\r\nThe research is divided into three thrusts: (1) Development of information-theoretic converses for deanonymization problem in random edge-labeled hyper-graphs for adversaries with access to correlated information sources. Such converses enable deriving necessary conditions under which the adversary cannot deanonymize the system, no matter how much computational power or storage is available. (2) Research practical achievable schemes: Besides tight (but not necessarily efficient) achievable schemes required for calibrating the converses, the design of practical deanonymization algorithms to quantify how much attackers can learn when the released datasets do not meet the necessary conditions of the converse, are explored. (3) Real-world evaluations: The performance of the algorithms and their practical applicability are evaluated on real world datasets.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Prateek",
   "pi_last_name": "Mittal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Prateek Mittal",
   "pi_email_addr": "pmittal@princeton.edu",
   "nsf_id": "000656737",
   "pi_start_date": "2016-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Princeton University",
  "perf_str_addr": "87 Prospect Avenue, 2nd floor",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779700",
   "pgm_ele_name": "Comm & Information Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7797",
   "pgm_ref_txt": "COMM & INFORMATION FOUNDATIONS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7935",
   "pgm_ref_txt": "COMM & INFORMATION THEORY"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 250000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p id=\"docs-internal-guid-d5b765c4-7fff-7e80-52ac-1d6b7935bcbb\" style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">This project developed a science for data anonymization and deanonymization, focusing on graph-theoretic data, such as social network data and communication network data.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">First, this work computed theoretical limits for when data can be de-anonymized using auxiliary sources of correlated information. A unique perspective in our investigation was the use of techniques from the domain of information theory. Our results include the derivation of necessary conditions under which the adversary cannot deanonymize the system, no matter how much computational power or storage is available.</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Second, this research led to the development of practical deanonymization mechanisms that provide guidance to dataset owners in terms of real privacy risks of publishing their data. Our mechanisms outperform prior works both in terms of accuracy of deanonymization, as well as in terms of requiring less prior information for successful deanonymization.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Finally, this project designed principled defense mechanisms that provide provable privacy protection for sensitive data while enabling data analytics.&nbsp; These include frameworks for publishing the entire dataset itself in a privacy-preserving manner, and frameworks for performing complex matrix-level queries over sensitive data.&nbsp;</span></p>\n<p>&nbsp;</p>\n<p style=\"line-height: 1.38; margin-top: 0pt; margin-bottom: 0pt;\" dir=\"ltr\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Source code developed in this project has been integrated in open source frameworks for graph-data privacy. In addition, our research has been broadly disseminated in the research community, and led to training opportunities for both graduate students and undergraduate students.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/08/2019<br>\n\t\t\t\t\tModified by: Prateek&nbsp;Mittal</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "This project developed a science for data anonymization and deanonymization, focusing on graph-theoretic data, such as social network data and communication network data. \n\n \nFirst, this work computed theoretical limits for when data can be de-anonymized using auxiliary sources of correlated information. A unique perspective in our investigation was the use of techniques from the domain of information theory. Our results include the derivation of necessary conditions under which the adversary cannot deanonymize the system, no matter how much computational power or storage is available.\n\n \nSecond, this research led to the development of practical deanonymization mechanisms that provide guidance to dataset owners in terms of real privacy risks of publishing their data. Our mechanisms outperform prior works both in terms of accuracy of deanonymization, as well as in terms of requiring less prior information for successful deanonymization. \n\n \nFinally, this project designed principled defense mechanisms that provide provable privacy protection for sensitive data while enabling data analytics.  These include frameworks for publishing the entire dataset itself in a privacy-preserving manner, and frameworks for performing complex matrix-level queries over sensitive data. \n\n \nSource code developed in this project has been integrated in open source frameworks for graph-data privacy. In addition, our research has been broadly disseminated in the research community, and led to training opportunities for both graduate students and undergraduate students.\n\n\t\t\t\t\tLast Modified: 12/08/2019\n\n\t\t\t\t\tSubmitted by: Prateek Mittal"
 }
}