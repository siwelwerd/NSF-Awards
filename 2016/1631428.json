{
 "awd_id": "1631428",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NCS-FO: Collaborative Research: Operationalizing Students' Textbooks Annotations to Improve Comprehension and Long-Term Retention",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032928333",
 "po_email": "gesolomo@nsf.gov",
 "po_sign_block_name": "Gregg Solomon",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 299976.0,
 "awd_amount": 307176.0,
 "awd_min_amd_letter_date": "2016-08-17",
 "awd_max_amd_letter_date": "2017-05-10",
 "awd_abstract_narration": "While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read. With a better understanding of a learner's state of mind, textbooks can make personalized recommendations for further study and review. How can the learner's state of mind be determined? Open a used printed textbook and the answer is clear: students feel compelled to engage with their texts by annotating key passages with highlights, tags, questions, and notes. Despite students' spontaneous desire to annotate as they read, this form of interaction has reaped few educational benefits in the past. At best, highlighted passages are re-read to study for exams, a strategy not nearly as effective as other strategies such as self-quizzing. This project will develop a new methodology that: assesses student knowledge level automatically based on annotations, transforms highlighted passages into appropriate study questions, and provides each student with well-timed, personalized review. Because the project is based on free, peer-reviewed, openly licensed materials from OpenStax that have been widely adopted at a range of institutions, particularly community colleges, the technology will reach beyond elite institutions to provide a broad spectrum of underserved students with access to a potentially powerful learning tool.\r\n\r\nThis project adopts a big-data approach that involves collecting annotations from a population of learners to draw inferences about individual learners. The project will determine how to exploit these data to model cognitive state, enabling the team to infer students' depth of understanding of facts and concepts, predict subsequent test performance, and perform interventions that improve learning outcomes. A tool will be developed that administers appropriately timed quizzes on material related to a student's highlights. A collaborative-filtering methodology will be employed that leverages population data to suggest specific passages for an individual to review. The proposed tool will reformulate selected passages into review questions that encourage the active reconstruction and elaboration of knowledge. The design and implementation of the tool will be informed by both randomized controlled studies within the innovative OpenStax textbook platform and coordinated laboratory studies. These studies will address basic scientific questions pertaining to why students annotate, how to improve their annotation skills, and techniques to optimize the use of annotations for guiding active review.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Mozer",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Michael C Mozer",
   "pi_email_addr": "mozer@cs.colorado.edu",
   "nsf_id": "000467581",
   "pi_start_date": "2016-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Colorado at Boulder",
  "inst_street_address": "3100 MARINE ST",
  "inst_street_address_2": "STE 481 572 UCB",
  "inst_city_name": "Boulder",
  "inst_state_code": "CO",
  "inst_state_name": "Colorado",
  "inst_phone_num": "3034926221",
  "inst_zip_code": "803090001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CO02",
  "org_lgl_bus_name": "THE REGENTS OF THE UNIVERSITY OF COLORADO",
  "org_prnt_uei_num": "",
  "org_uei_num": "SPVKK1RC2MZ3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Colorado Boulder",
  "perf_str_addr": "3100 Marine Street, Room 479",
  "perf_city_name": "Boulder",
  "perf_st_code": "CO",
  "perf_st_name": "Colorado",
  "perf_zip_code": "803031058",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CO02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  },
  {
   "pgm_ele_code": "862400",
   "pgm_ele_name": "IntgStrat Undst Neurl&Cogn Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  },
  {
   "pgm_ref_code": "8816",
   "pgm_ref_txt": "Workforce Development"
  },
  {
   "pgm_ref_code": "8817",
   "pgm_ref_txt": "STEM Learning & Learning Environments"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0416",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001617DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  },
  {
   "app_code": "0417",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001718DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 299976.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 7200.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read, make personalized recommendations for further study and review, and to thereby promote long-term retention and conceptual understanding. Our project explored this objective by instrumenting digital textbooks and e-readers to collect data from learners as they read and interact with the material. Two data sources were considered: (1) highlighting annotations that learners make as they read, indicating material the learner considers to be key content, and (2) and finger-scrolling actions using an electronic e-reader.</p>\n<p><span>Although students believe that highlighting and subsequent review of the highlights will further their educational goals, the psychological literature provides little evidence of benefits. Nonetheless, students' choice of text for highlighting may serve as a window into their mental state&mdash;their level of comprehension, grasp of the key ideas, reading goals, and so on. We explored this hypothesis via an experiment in which 400 participants read three sections from a college-level biology text, briefly reviewed the text, and then took a quiz on the material. During initial reading, participants were able to highlight words, phrases, and sentences, and these highlights were displayed along with the complete text during the subsequent review. Consistent with past research, the amount of highlighted material is unrelated to quiz performance. However, we found that the specific content highlighted could help us to predict quiz performance. We explored a range of models and a range of highlighting representations to determine which combination yielded the best predictive accuracy. We also explored matrix factorization models that allowed us to show that individuals' highlighting pattern is informative of what they highlight elsewhere, which could be useful for content-recommendation engines.</span></p>\n<p>We moved from laboratory experiments to an analysis of a large-scale corpus of highlighting data collected in a genuine educational context by a digital open-access platform, OpenStax. The corpus consisted of data from over 11,000 students and nearly 900 sections from College Biology and Physics textbooks. In addition to highlighting data, the corpus provided scores on delayed quizzes associated with the sections. We considered two approaches to encoding highlighting patterns. A <em>positional representation</em> indicated where highlights were made in the stream of text for a particular section. A <em>semantic representation</em>&nbsp;was based on a state-of-the-art deep-learning sentence embedding technique (SBERT) that captures the content-based similarity between quiz questions and highlighted (as well as non-highlighted) sentences in the text. We construct regression models that include latent variables for student skill level and question difficulty and augment the models with highlighting features. We find that both positional and semantic highlighting features reliably boost model performance, with semantic features being the more predictive. We conduct experiments that validate models on held-out questions, students, and student-questions and find strong generalization for the latter two but not for held-out questions. Surprisingly, highlighting features improve models for questions at all levels of the Bloom taxonomy, from straightforward recall questions to inferential synthesis/evaluation/creation questions.</p>\n<p>Highlights explain only a portion of observed variability in performance. As is typical in big-data applications, one seeks multiple weak predictor variables which in combination can make strong predictions. Toward this goal, we examined readers' scrolling patterns on a personal e-reader (table, phone). We collected a data set consisting of 20 readers reading 20 newspaper articles. The data indicated the exact timing of finger motions and flicks, allowing us to determine how long text appeared on the screen, and thus allowed us to infer content-specific reading rates. We found that we could predict difficulty of content from reading rates and we could identify individual differences in scrolling patterns. In follow up work, we plan to explore the relationship between scrolling patterns and comprehension and retention.</p>\n<p>Our long-term goal is to design digital textbooks that serve not only as conduits of information into the reader&rsquo;s mind but also allow us to draw inferences about the reader at a point where interventions may increase the effectiveness of the material. Interventions might include alterting the instructor, posing questions that allow students to evaluate their understanding, or guiding students to improve by suggesting content to review.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/29/2021<br>\n\t\t\t\t\tModified by: Michael&nbsp;C&nbsp;Mozer</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nWhile traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read, make personalized recommendations for further study and review, and to thereby promote long-term retention and conceptual understanding. Our project explored this objective by instrumenting digital textbooks and e-readers to collect data from learners as they read and interact with the material. Two data sources were considered: (1) highlighting annotations that learners make as they read, indicating material the learner considers to be key content, and (2) and finger-scrolling actions using an electronic e-reader.\n\nAlthough students believe that highlighting and subsequent review of the highlights will further their educational goals, the psychological literature provides little evidence of benefits. Nonetheless, students' choice of text for highlighting may serve as a window into their mental state&mdash;their level of comprehension, grasp of the key ideas, reading goals, and so on. We explored this hypothesis via an experiment in which 400 participants read three sections from a college-level biology text, briefly reviewed the text, and then took a quiz on the material. During initial reading, participants were able to highlight words, phrases, and sentences, and these highlights were displayed along with the complete text during the subsequent review. Consistent with past research, the amount of highlighted material is unrelated to quiz performance. However, we found that the specific content highlighted could help us to predict quiz performance. We explored a range of models and a range of highlighting representations to determine which combination yielded the best predictive accuracy. We also explored matrix factorization models that allowed us to show that individuals' highlighting pattern is informative of what they highlight elsewhere, which could be useful for content-recommendation engines.\n\nWe moved from laboratory experiments to an analysis of a large-scale corpus of highlighting data collected in a genuine educational context by a digital open-access platform, OpenStax. The corpus consisted of data from over 11,000 students and nearly 900 sections from College Biology and Physics textbooks. In addition to highlighting data, the corpus provided scores on delayed quizzes associated with the sections. We considered two approaches to encoding highlighting patterns. A positional representation indicated where highlights were made in the stream of text for a particular section. A semantic representation was based on a state-of-the-art deep-learning sentence embedding technique (SBERT) that captures the content-based similarity between quiz questions and highlighted (as well as non-highlighted) sentences in the text. We construct regression models that include latent variables for student skill level and question difficulty and augment the models with highlighting features. We find that both positional and semantic highlighting features reliably boost model performance, with semantic features being the more predictive. We conduct experiments that validate models on held-out questions, students, and student-questions and find strong generalization for the latter two but not for held-out questions. Surprisingly, highlighting features improve models for questions at all levels of the Bloom taxonomy, from straightforward recall questions to inferential synthesis/evaluation/creation questions.\n\nHighlights explain only a portion of observed variability in performance. As is typical in big-data applications, one seeks multiple weak predictor variables which in combination can make strong predictions. Toward this goal, we examined readers' scrolling patterns on a personal e-reader (table, phone). We collected a data set consisting of 20 readers reading 20 newspaper articles. The data indicated the exact timing of finger motions and flicks, allowing us to determine how long text appeared on the screen, and thus allowed us to infer content-specific reading rates. We found that we could predict difficulty of content from reading rates and we could identify individual differences in scrolling patterns. In follow up work, we plan to explore the relationship between scrolling patterns and comprehension and retention.\n\nOur long-term goal is to design digital textbooks that serve not only as conduits of information into the reader\u2019s mind but also allow us to draw inferences about the reader at a point where interventions may increase the effectiveness of the material. Interventions might include alterting the instructor, posing questions that allow students to evaluate their understanding, or guiding students to improve by suggesting content to review.\n\n\t\t\t\t\tLast Modified: 10/29/2021\n\n\t\t\t\t\tSubmitted by: Michael C Mozer"
 }
}