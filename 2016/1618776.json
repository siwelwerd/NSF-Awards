{
 "awd_id": "1618776",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: Experimental-based Research on Effective Models of Parallel Application Execution Time, Power, and Resilience",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 200000.0,
 "awd_min_amd_letter_date": "2016-09-06",
 "awd_max_amd_letter_date": "2016-09-06",
 "awd_abstract_narration": "The increasing scale and complexity of parallel systems present enormous challenges to parallel applications. One such challenge is the integration and balancing of execution time, power, and resilience for parallel applications. The MuMMI_R project seeks to advance the scientific understanding of the interdependence among power, execution time, and resilience for various application-system configurations. The broader impacts include training of undergraduate and graduate students and the participation in programs such as REUs, CREU, and DREU to increase the participation of students from underrepresented groups in the project.\r\n\r\nThe MuMMI_R research aims to develop effective techniques for quantifying the complicated tradeoffs among execution time, power, and resilience, and to provide a tuning mechanism for user-defined metrics. Toward this goal, the research focuses on three interrelated research thrusts: (1) experimental research to conduct extensive experiments of a suite of representative application under different resilience strategies on various parallel architectures, (2) application-level co-modeling to develop analytical models and colored Petri net based simulation for quantifying the correlations and tradeoffs between execution time, power, and resilience, and (3) model-based analysis to examine the tradeoffs among resilience, execution time, and power for different application-system configurations, and to tune application implementations for a user-defined target metric on current and future systems. The resulting framework, MuMMI_R, will provide valuable insights into application-system interactions and aid in the design of efficient parallel applications (with respect to execution time, power requirements, and resilience), runtime systems, and computer architectures.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhiling",
   "pi_last_name": "Lan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zhiling Lan",
   "pi_email_addr": "zlan@uic.edu",
   "nsf_id": "000304384",
   "pi_start_date": "2016-09-06",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Illinois Institute of Technology",
  "inst_street_address": "10 W 35TH ST",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125673035",
  "inst_zip_code": "606163717",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "ILLINOIS INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "E2NDENMDUEG8"
 },
 "perf_inst": {
  "perf_inst_name": "Illinois Institute of Technology",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606163717",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 200000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span>The increasing scale and complexity of parallel systems present enormous challenges to parallel applications. One such challenge is the integration and balancing of execution time, power, and resilience for parallel applications. The goal of this project was to advance the scientific understanding of the interdependence among power, execution time, and resilience for various application-system configurations. More specifically, it developed effective techniques for quantifying the complicated tradeoffs among execution time, power, and resilience, and provided a tuning mechanism for user-defined metrics.</span></p>\n<p><span>&nbsp;</span></p>\n<p><span>The project has three key outcomes. First is&nbsp;extensive experimental data of representative applications/benchmarks on various production supercomputers. Second is performance-power models built on machine learning techniques. Third is an open-source, application-level dynamic power capping library for the community. The models, along with the large amount of the experimental data, provide a deeper understanding of application performance and energy impact under different resilience and power management options provided on the state-of-the-art supercomputers. The dynamic power capping library addresses the need for software tools at the user level to automatically perform application power capping during application execution without offline profiling. Together, these outcomes provide effective technologies for quantifying the complicated tradeoffs among execution time, power, and resilience, and an automatic power management tool for the hierarchical power management proposed by the HPC PowerStack initiative which two of the project PIs actively involves.</span></p>\n<p><span>The project advances the scientific understanding of the interdependence among power, execution time and resilience for various application-system configurations. It impacts not only the conventional computational fields, but also the emerging machine learning and data processing fields that utilize enormous computing power provided by supercomputers.</span></p>\n<p><span>This project results in </span><span>ten</span><span> technical papers at HPC conferences/workshops, a large amount of real experimental data (runtime, power, hardware counters, etc), and an application-level software library for dynamic power capping. The software library and the data are all freely available to the community. Another key impact is the training of a group of </span><span>seven</span><span> students, ranging from undergraduate students to doctoral students, in the field of high-performance computing. The PIs are dedicated to enhancing diversity in computing. Among the five participating students, two are from underrepresented groups.</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/17/2021<br>\n\t\t\t\t\tModified by: Zhiling&nbsp;Lan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe increasing scale and complexity of parallel systems present enormous challenges to parallel applications. One such challenge is the integration and balancing of execution time, power, and resilience for parallel applications. The goal of this project was to advance the scientific understanding of the interdependence among power, execution time, and resilience for various application-system configurations. More specifically, it developed effective techniques for quantifying the complicated tradeoffs among execution time, power, and resilience, and provided a tuning mechanism for user-defined metrics.\n\n \n\nThe project has three key outcomes. First is extensive experimental data of representative applications/benchmarks on various production supercomputers. Second is performance-power models built on machine learning techniques. Third is an open-source, application-level dynamic power capping library for the community. The models, along with the large amount of the experimental data, provide a deeper understanding of application performance and energy impact under different resilience and power management options provided on the state-of-the-art supercomputers. The dynamic power capping library addresses the need for software tools at the user level to automatically perform application power capping during application execution without offline profiling. Together, these outcomes provide effective technologies for quantifying the complicated tradeoffs among execution time, power, and resilience, and an automatic power management tool for the hierarchical power management proposed by the HPC PowerStack initiative which two of the project PIs actively involves.\n\nThe project advances the scientific understanding of the interdependence among power, execution time and resilience for various application-system configurations. It impacts not only the conventional computational fields, but also the emerging machine learning and data processing fields that utilize enormous computing power provided by supercomputers.\n\nThis project results in ten technical papers at HPC conferences/workshops, a large amount of real experimental data (runtime, power, hardware counters, etc), and an application-level software library for dynamic power capping. The software library and the data are all freely available to the community. Another key impact is the training of a group of seven students, ranging from undergraduate students to doctoral students, in the field of high-performance computing. The PIs are dedicated to enhancing diversity in computing. Among the five participating students, two are from underrepresented groups.\n\n \n\n\t\t\t\t\tLast Modified: 10/17/2021\n\n\t\t\t\t\tSubmitted by: Zhiling Lan"
 }
}