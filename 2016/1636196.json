{
 "awd_id": "1636196",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Ultraviolet(UV)-MultiSpectral-Polarization 3D Imaging of the Underwater World",
 "cfda_num": "47.050",
 "org_code": "06040100",
 "po_phone": "7032927577",
 "po_email": "kbinkley@nsf.gov",
 "po_sign_block_name": "Kandace Binkley",
 "awd_eff_date": "2016-09-15",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 630448.0,
 "awd_amount": 630448.0,
 "awd_min_amd_letter_date": "2016-09-15",
 "awd_max_amd_letter_date": "2016-09-15",
 "awd_abstract_narration": "Fine-scale mapping of the underwater world is currently elusive because of a fundamental property of aquatic environments--they are in constant motion. Three-Dimensional mapping of the underwater world in an ecologically relevant way requires mapping not only the physical limits of a specific arena but also the biology within it. Here, the researchers propose to revolutionize the way scientists build near-scale (5-10m) underwater maps by the construction of a UV-Multispectral-Polarization imager with complete multilevel imaging features enabling 3D mapping and full optical characterization of underwater environments. The proposed 3D imager will overcome the challenge of a moving and scattering medium; overcome the problems that cripple conventional scanning devices (e.g. co-registration); while simultaneously filling in the 3D map with biologically meaningful information with images and complete characterization of the light field. With such a device, one will have the capability to map the physical footprint of the underwater world, but also extract species identification from optical characteristics, movement characteristics of organisms within it, health/condition status of biological organisms (e.g. coral reefs, oil spills, plastic contaminants), and comprehensive optical characterization.  In addition to providing fine scale mapping of underwater worlds that will serve both biological and conservation missions, the researchers will also use this technology to engage STEM programs in both the Austin and St. Louis areas.\r\n\r\nThis is a Collaborative OTIC award to develop a state-of-the-art 3D imaging device whose purpose is to transform the way researchers map underwater environments and biologically characterize the features within it. The principle investigators propose to develop a high spatial and temporal resolution multispectral polarimeter capable of measuring polarization information in RGB bandwidths combined with three separate and distinct narrow spectral bandwidth channels, one of which being in the UV spectrum.  This will produce 12 distinct optical channels that are inherently co-registered, with polarization detection allowing for dehazing capabilities to greatly increase the effectiveness of visual simultaneous localization and mapping algorithms (VSLAM) for obtaining 3D map reconstruction. The co-registered channels will overlay maps with optical information for identifying and measuring benthic characteristics. This next generation underwater mapping device will provide scientists with simultaneous information on (i) physical dimensional space (3D depth), (ii) surface characteristics that identify benthos and organisms within the environment (imaging), (iii) optical characterization of the water column and benthos, as well as (iv) allow for fine-scale tracking of organisms within these underwater environments.  This device will enable broad ranges of research questions from oceanographers and marine scientists interested in monitoring coral reefs, animal behaviorists studying 3D camouflage and communication properties, to conservation scientists interested in monitoring environmental degradation (oil and plastic contaminants).  This collaborative effort will (a) produce a polarization imaging sensor that captures multispectral polarization information in real-time (~20fps), with low power dissipation and with high spatial resolution, (b) provide dynamic multispectral information on underwater features that were previously unattainable due to scanning technologies with low temporal resolution (~1min), (c) develop software to map and track underwater environments modifying currently developed open source VSLAM software, and (d) test emerging biological hypotheses on camouflage, communication and coral reef monitoring.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "GEO",
 "org_dir_long_name": "Directorate for Geosciences",
 "div_abbr": "OCE",
 "org_div_long_name": "Division Of Ocean Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Parrish",
   "pi_last_name": "Brady",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Parrish C Brady",
   "pi_email_addr": "parrishbrady@utexas.edu",
   "nsf_id": "000675441",
   "pi_start_date": "2016-09-15",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Molly",
   "pi_last_name": "Cummings",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Molly Cummings",
   "pi_email_addr": "mcummings@austin.utexas.edu",
   "nsf_id": "000338079",
   "pi_start_date": "2016-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "101 E. 27th Street, Suite 5.300",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121532",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "168000",
   "pgm_ele_name": "OCEAN TECH & INTERDISC COORDIN"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 630448.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>How animals perceive each other has had a significant impact on our planet, from predation to species propagation.&nbsp; However, there is much we do not understand concerning the mechanisms by which animals sense each other, particularly their methods of visual detection.&nbsp; Animals visually sense the environment in ways much different from our visual capabilities (e.g., polarization vision and UV vision). The ways animals produce visual patterns can be equally complex (e.g., iridescent and polarization signals that are viewing and illumination angle dependant). &nbsp;The project&rsquo;s scope incorporated advanced geometrical and computer vision techniques with specialized cameras for biological measurements that measure animals&rsquo; perception of one another in the underwater realms. &nbsp;&nbsp;The project involved developing and using an underwater RGB polarization imager with an internal compass and the development of the mapping and tracking software called PATMOS_MIDOM (Paths And Tessellated Meshes from ORB_SLAM2 and Mapping Image Data Onto Meshes).&nbsp;</p>\n<p>PATMOS involves measurement techniques that used the open-source software ORB_SLAM2, two handheld GoPros, and a fiducial object to map environments and to track animals within the environment.&nbsp; This functionally simple setup provides powerful results.&nbsp; Flying or swimming animals can be tracked with just two handheld GoPros and distances can be measured between the animal path and a virtual map of the environment. &nbsp;MIDOM mapped complex RGB polarization data, a very angle dependent quantity, onto three-dimensional virtual models of animals over many different views of the animal.&nbsp; We used computer vision technology similar to facial recondition to measure the camera&rsquo;s pose to an animal.&nbsp; MIDOM collected the three-dimensional data along with all other data associated with the projection into one data container.&nbsp; Data was extracted from this data container dependent on the animal&rsquo;s geometry and not from that animal&rsquo;s image.</p>\n<p>Using PATMOS we were able to make several important observations of animals in the Belizean coral reef system.&nbsp; We characterized the paths of a damselfish guarding a territory against an octopus.&nbsp;&nbsp; We measured the complex schooling structure of reef squid.&nbsp; Reef squids are well known for the high spatial correlation of body positioning in schools and dramatic color changes. &nbsp;We measured how visual signals propagated through their schools.&nbsp; Using MIDOM and the underwater polarimeter, we characterized the radiance and polarization camouflage of two dissimilar fish in Belize.&nbsp; The bar jack and the creole wrasse are unrelated fish with two very different strategies for reflecting color.&nbsp; We demonstrated that the normally blue-colored creole wrasse and the silver-colored bar jack produced similar color contrast values in their blue pelagic environments. However, we demonstrated that the creole wrasse outperformed the bar jack in polarization contrast, making them more invisible to their polarization-sensitive copepod prey. &nbsp;&nbsp;Using MIDOM, we were also able to simulate polarization ray-tracing calculations on virtual fish models to investigate the origins of the fish&rsquo;s reflectance.&nbsp; Using MIDOM were also able to quantify the polarization patterns of schooling reef squid and cuttlefish.&nbsp;&nbsp;</p>\n<p>This project&rsquo;s broader impacts include the measurement paradigm, PATMOS, which can quantify animal movement in 3D using only handheld GoPros.&nbsp; This system can quantify small animal movement (e.g., insect flight) in remote environments where heavy and fragile equipment use is challenging. &nbsp;For uses across broad disciplines, a diverse array of animals, each with their specific movement behaviors, could be measured with this setup. &nbsp;The broader impacts of the MIDOM technology can quantify animals&rsquo; reflections that are based on the viewing angle and geometrically dependent, like iridescence. &nbsp;In this project, we demonstrated the polarimeters utility beyond mapping environments or measuring animal reflections. With the polarimeter, we were able to measure a discarded transparent plastic bag floating among thousands of comb jellies.&nbsp; We found that the color contrast between the bag and comb jellies was nearly identical, but the polarization contrast was very high.&nbsp; Plastic waste is problematic for the world&rsquo;s oceans, and many animals die from plastic ingestion, and the plastic&rsquo;s high polarization visibility may contribute to plastic consumption among various animal groups.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/29/2020<br>\n\t\t\t\t\tModified by: Parrish&nbsp;C&nbsp;Brady</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nHow animals perceive each other has had a significant impact on our planet, from predation to species propagation.  However, there is much we do not understand concerning the mechanisms by which animals sense each other, particularly their methods of visual detection.  Animals visually sense the environment in ways much different from our visual capabilities (e.g., polarization vision and UV vision). The ways animals produce visual patterns can be equally complex (e.g., iridescent and polarization signals that are viewing and illumination angle dependant).  The project\u2019s scope incorporated advanced geometrical and computer vision techniques with specialized cameras for biological measurements that measure animals\u2019 perception of one another in the underwater realms.   The project involved developing and using an underwater RGB polarization imager with an internal compass and the development of the mapping and tracking software called PATMOS_MIDOM (Paths And Tessellated Meshes from ORB_SLAM2 and Mapping Image Data Onto Meshes). \n\nPATMOS involves measurement techniques that used the open-source software ORB_SLAM2, two handheld GoPros, and a fiducial object to map environments and to track animals within the environment.  This functionally simple setup provides powerful results.  Flying or swimming animals can be tracked with just two handheld GoPros and distances can be measured between the animal path and a virtual map of the environment.  MIDOM mapped complex RGB polarization data, a very angle dependent quantity, onto three-dimensional virtual models of animals over many different views of the animal.  We used computer vision technology similar to facial recondition to measure the camera\u2019s pose to an animal.  MIDOM collected the three-dimensional data along with all other data associated with the projection into one data container.  Data was extracted from this data container dependent on the animal\u2019s geometry and not from that animal\u2019s image.\n\nUsing PATMOS we were able to make several important observations of animals in the Belizean coral reef system.  We characterized the paths of a damselfish guarding a territory against an octopus.   We measured the complex schooling structure of reef squid.  Reef squids are well known for the high spatial correlation of body positioning in schools and dramatic color changes.  We measured how visual signals propagated through their schools.  Using MIDOM and the underwater polarimeter, we characterized the radiance and polarization camouflage of two dissimilar fish in Belize.  The bar jack and the creole wrasse are unrelated fish with two very different strategies for reflecting color.  We demonstrated that the normally blue-colored creole wrasse and the silver-colored bar jack produced similar color contrast values in their blue pelagic environments. However, we demonstrated that the creole wrasse outperformed the bar jack in polarization contrast, making them more invisible to their polarization-sensitive copepod prey.   Using MIDOM, we were also able to simulate polarization ray-tracing calculations on virtual fish models to investigate the origins of the fish\u2019s reflectance.  Using MIDOM were also able to quantify the polarization patterns of schooling reef squid and cuttlefish.  \n\nThis project\u2019s broader impacts include the measurement paradigm, PATMOS, which can quantify animal movement in 3D using only handheld GoPros.  This system can quantify small animal movement (e.g., insect flight) in remote environments where heavy and fragile equipment use is challenging.  For uses across broad disciplines, a diverse array of animals, each with their specific movement behaviors, could be measured with this setup.  The broader impacts of the MIDOM technology can quantify animals\u2019 reflections that are based on the viewing angle and geometrically dependent, like iridescence.  In this project, we demonstrated the polarimeters utility beyond mapping environments or measuring animal reflections. With the polarimeter, we were able to measure a discarded transparent plastic bag floating among thousands of comb jellies.  We found that the color contrast between the bag and comb jellies was nearly identical, but the polarization contrast was very high.  Plastic waste is problematic for the world\u2019s oceans, and many animals die from plastic ingestion, and the plastic\u2019s high polarization visibility may contribute to plastic consumption among various animal groups.\n\n \n\n\t\t\t\t\tLast Modified: 12/29/2020\n\n\t\t\t\t\tSubmitted by: Parrish C Brady"
 }
}