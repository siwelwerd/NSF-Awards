{
 "awd_id": "1618193",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "RI: Small: Linguistic Semantics and Discourse from Leaky Distant Supervision",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 406792.0,
 "awd_amount": 413116.0,
 "awd_min_amd_letter_date": "2016-08-08",
 "awd_max_amd_letter_date": "2020-07-14",
 "awd_abstract_narration": "This project studies novel algorithms for building artificial intelligence (AI) systems that can learn to improve their performance with a human in the loop. Many recent AI successes are driven by large, expensive and difficult-to-collect datasets. This yields systems that are deep, but narrow. The goal of this project is to build technology that will allow AI systems to learn from their interactions with people. The project focuses on key applications related to natural language understanding: building technology to understand the meanings of individual sentences, and integrate those meanings into the meaning of a discourse or dialog.  One specific application pursued herein relates to extracting biomedical knowledge from text, which will pave the way to helping biomedical researchers develop novel hypotheses.  The work will fund students from underrepresented groups in STEM, and encourage cross-disciplinary education at the graduate and undergraduate levels. Finally, the work will be communicated to the public not just with scientific papers, but internationally through social media and locally through visits to middle schools and high schools.\r\n\r\nNatural language processing (and other fields of artificial intelligence) have had enormous success by training supervised  learning systems on large labeled datasets (\"corpora\").  Unfortunately, curating such corpora is infeasible except for very specific problems. This happens either because it is too expensive, or it is too difficult to get human labelers to agree on an annotation standard.  Instead of relying solely on human labeled data, this project develops algorithms that can learn from human interaction.  These systems can continually improve their performance based on downstream performance supervision, often with a human in the loop. This work leverages recent developments on the structured contextual bandits learning framework which provides a theoretically grounded and computationally efficient way in which to develop novel approaches to distant supervision. This resulting learning techniques will push advances in natural language understanding: semantic parsing and discourse interpretation. Furthermore, the underlying imitation learning technology is broadly applicable, including novel applications to recurrent neural network models.  To aid adoption by the research community, code and data from this project will be released open source.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Hal",
   "pi_last_name": "Daume",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hal Daume",
   "pi_email_addr": "hal@umiacs.umd.edu",
   "nsf_id": "000445461",
   "pi_start_date": "2016-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 209926.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 196866.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 6324.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The machine learning algorithms that have driven much progress in the past few years in natural language processing (among other AI disciplines) have led to significant advances across a number of applications. Yet, training such systems typically relies on very large training sets that have been painstakingly labeled by expert human annotators. This approach does not scale across languages, tasks, or domains. The main aim of this project was to develop novel algorithms that enable systems to learn from information sources other than just fully labeled data.</p>\n<p>The key outcomes of this project have been the development of several new algorithms, each focusing on different types of relevant learning feedback, as well as the application of these and related algorithms to a variety of natural language processing problems, ranging from generating database programs based on language descriptions to training articial agents that aim to diversify their behavior. This includes algorithms that learn complex behavior from only scalar reward signals (Reslope) to ones that learn to explore their environments (Melee), as well as algorithms for learning when the goal is to simultaneously satisfy a number of pre-defined constraints (Apropos), and methods that reduce the amount of labeled data a human must provide (Leaqi).</p>\n<p>The major results from this project were published in leading conferences in the fields of natural language processing and machine learning, have formed the basis of multiple PhD dissertations, and have been the subject of several invited talks at workshops in both natural language and machine learning venues. Three PhD students funded by this project have graduated and gone on to research scientist positions in industry, and one undergraduate has gone on to a PhD at MIT. As part of this work, we have also participated in outreach to local high schools and inreach to beginning computer science students to show them the breadth of possible things that can be worked on with a degree in computer science (many of these focusing on populations that are currently underrepresented in computer science).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/27/2021<br>\n\t\t\t\t\tModified by: Hal&nbsp;Daume</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe machine learning algorithms that have driven much progress in the past few years in natural language processing (among other AI disciplines) have led to significant advances across a number of applications. Yet, training such systems typically relies on very large training sets that have been painstakingly labeled by expert human annotators. This approach does not scale across languages, tasks, or domains. The main aim of this project was to develop novel algorithms that enable systems to learn from information sources other than just fully labeled data.\n\nThe key outcomes of this project have been the development of several new algorithms, each focusing on different types of relevant learning feedback, as well as the application of these and related algorithms to a variety of natural language processing problems, ranging from generating database programs based on language descriptions to training articial agents that aim to diversify their behavior. This includes algorithms that learn complex behavior from only scalar reward signals (Reslope) to ones that learn to explore their environments (Melee), as well as algorithms for learning when the goal is to simultaneously satisfy a number of pre-defined constraints (Apropos), and methods that reduce the amount of labeled data a human must provide (Leaqi).\n\nThe major results from this project were published in leading conferences in the fields of natural language processing and machine learning, have formed the basis of multiple PhD dissertations, and have been the subject of several invited talks at workshops in both natural language and machine learning venues. Three PhD students funded by this project have graduated and gone on to research scientist positions in industry, and one undergraduate has gone on to a PhD at MIT. As part of this work, we have also participated in outreach to local high schools and inreach to beginning computer science students to show them the breadth of possible things that can be worked on with a degree in computer science (many of these focusing on populations that are currently underrepresented in computer science).\n\n\t\t\t\t\tLast Modified: 01/27/2021\n\n\t\t\t\t\tSubmitted by: Hal Daume"
 }
}