{
 "awd_id": "1631556",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "NCS-FO: Collaborative Research: Operationalizing Students' Textbooks Annotations to Improve Comprehension and Long-Term Retention",
 "cfda_num": "47.076",
 "org_code": "11090000",
 "po_phone": "7032928333",
 "po_email": "gesolomo@nsf.gov",
 "po_sign_block_name": "Gregg Solomon",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 400000.0,
 "awd_amount": 400000.0,
 "awd_min_amd_letter_date": "2016-08-17",
 "awd_max_amd_letter_date": "2021-08-05",
 "awd_abstract_narration": "While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read. With a better understanding of a learner's state of mind, textbooks can make personalized recommendations for further study and review. How can the learner's state of mind be determined? Open a used printed textbook and the answer is clear: students feel compelled to engage with their texts by annotating key passages with highlights, tags, questions, and notes. Despite students' spontaneous desire to annotate as they read, this form of interaction has reaped few educational benefits in the past. At best, highlighted passages are re-read to study for exams, a strategy not nearly as effective as other strategies such as self-quizzing. This project will develop a new methodology that: assesses student knowledge level automatically based on annotations, transforms highlighted passages into appropriate study questions, and provides each student with well-timed, personalized review. Because the project is based on free, peer-reviewed, openly licensed materials from OpenStax that have been widely adopted at a range of institutions, particularly community colleges, the technology will reach beyond elite institutions to provide a broad spectrum of underserved students with access to a potentially powerful learning tool.\r\n\r\nThis project adopts a big-data approach that involves collecting annotations from a population of learners to draw inferences about individual learners. The project will determine how to exploit these data to model cognitive state, enabling the team to infer students' depth of understanding of facts and concepts, predict subsequent test performance, and perform interventions that improve learning outcomes. A tool will be developed that administers appropriately timed quizzes on material related to a student's highlights. A collaborative-filtering methodology will be employed that leverages population data to suggest specific passages for an individual to review. The proposed tool will reformulate selected passages into review questions that encourage the active reconstruction and elaboration of knowledge. The design and implementation of the tool will be informed by both randomized controlled studies within the innovative OpenStax textbook platform and coordinated laboratory studies. These studies will address basic scientific questions pertaining to why students annotate, how to improve their annotation skills, and techniques to optimize the use of annotations for guiding active review.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "EDU",
 "org_dir_long_name": "Directorate for STEM Education",
 "div_abbr": "DRL",
 "org_div_long_name": "Division of Research on Learning in Formal and Informal Settings (DRL)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Richard",
   "pi_last_name": "Baraniuk",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Richard G Baraniuk",
   "pi_email_addr": "richb@rice.edu",
   "nsf_id": "000334750",
   "pi_start_date": "2016-08-17",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Phillip",
   "pi_last_name": "Grimaldi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Phillip Grimaldi",
   "pi_email_addr": "phillip.grimaldi@rice.edu",
   "nsf_id": "000716832",
   "pi_start_date": "2016-08-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "William Marsh Rice University",
  "inst_street_address": "6100 MAIN ST",
  "inst_street_address_2": "",
  "inst_city_name": "Houston",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "7133484820",
  "inst_zip_code": "770051827",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "TX09",
  "org_lgl_bus_name": "WILLIAM MARSH RICE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "K51LECU1G8N3"
 },
 "perf_inst": {
  "perf_inst_name": "William Marsh Rice University",
  "perf_str_addr": "6100 Main Street - MS 16",
  "perf_city_name": "Houston",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "770051827",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "TX09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "798000",
   "pgm_ele_name": "ECR-EDU Core Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8089",
   "pgm_ref_txt": "Understanding the Brain/Cognitive Scienc"
  },
  {
   "pgm_ref_code": "8091",
   "pgm_ref_txt": "BRAIN Initiative Res Support"
  },
  {
   "pgm_ref_code": "8551",
   "pgm_ref_txt": "IntgStrat Undst Neurl&Cogn Sys"
  },
  {
   "pgm_ref_code": "8817",
   "pgm_ref_txt": "STEM Learning & Learning Environments"
  }
 ],
 "app_fund": [
  {
   "app_code": "0416",
   "app_name": "NSF Education & Human Resource",
   "app_symb_id": "040106",
   "fund_code": "04001617DB",
   "fund_name": "NSF Education & Human Resource",
   "fund_symb_id": "040106"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 400000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-46c3ca33-7fff-5e1f-3e79-6c42c4c5b5d9\"> </span></p>\n<p dir=\"ltr\"><span>While traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read, make personalized recommendations for further study and review, and to thereby promote long-term retention and conceptual understanding. This collaborative project made significant strides toward this objective. First, we successfully implemented instrumentation of digital textbooks to collect student behavior logs and annotation data (e.g., highlights, notes) as they read and interacted with the textbook. Second, we used machine learning based clustering techniques to analyze individual differences in annotation patterns. Third, we developed collaborative filtering to draw inferences about individual learners from population data. Fourth, we utilized student created highlights to generate questions for student self-assessment.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Initial explorations of student highlights showed little to no relationship with quiz scores (Winchell et al., 2018). Subsequent investigations (Winchell et al., 2020) revealed that prediction accuracy of quiz performance reliably improves with the inclusion of highlighting data. Moreover, an individual's pattern of highlights remains consistent across content areas (Winchell et al., 2020).&nbsp;</span></p>\n<p dir=\"ltr\"><span>We further developed a semantic representation of highlights (content based similarity between quiz questions and highlighted and non-highlighted sentences) beyond a more commonly used positional representation of highlights (where in a stream of text the highlight occurs) (Kim et al., 2021). We found that both semantic and positional features of highlights boost prediction accuracy of student performance on later assessment (Kim et al., 2021). Moreover, the model with semantic highlight encodings outperformed positional highlight encoding (Kim et al., under preparation). This improvement of model prediction was observed agnostic of Bloom?s taxonomy levels of questions. Validation of this feature using established item-response theory techniques showed the potential for this feature to be used as an index of student comprehension (Kim et al., under preparation).</span></p>\n<p dir=\"ltr\"><span>This line of work helped bring to light the nuances to how highlighting impacts student comprehension and retention. We have several lines of investigation including methodological investigations such as varying the granularity of highlighting segments (e.g., complete sentences vs. words or segments), as well as use-inspired research to identify different interventional strategies that when combined with highlighting result in longer term retention and better comprehension.</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/22/2022<br>\n\t\t\t\t\tModified by: Richard&nbsp;G&nbsp;Baraniuk</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nWhile traditional textbooks are designed to transmit information from the printed page to the learner, contemporary digital textbooks offer the opportunity to study learners as they interpret and process information being read, make personalized recommendations for further study and review, and to thereby promote long-term retention and conceptual understanding. This collaborative project made significant strides toward this objective. First, we successfully implemented instrumentation of digital textbooks to collect student behavior logs and annotation data (e.g., highlights, notes) as they read and interacted with the textbook. Second, we used machine learning based clustering techniques to analyze individual differences in annotation patterns. Third, we developed collaborative filtering to draw inferences about individual learners from population data. Fourth, we utilized student created highlights to generate questions for student self-assessment. \nInitial explorations of student highlights showed little to no relationship with quiz scores (Winchell et al., 2018). Subsequent investigations (Winchell et al., 2020) revealed that prediction accuracy of quiz performance reliably improves with the inclusion of highlighting data. Moreover, an individual's pattern of highlights remains consistent across content areas (Winchell et al., 2020). \nWe further developed a semantic representation of highlights (content based similarity between quiz questions and highlighted and non-highlighted sentences) beyond a more commonly used positional representation of highlights (where in a stream of text the highlight occurs) (Kim et al., 2021). We found that both semantic and positional features of highlights boost prediction accuracy of student performance on later assessment (Kim et al., 2021). Moreover, the model with semantic highlight encodings outperformed positional highlight encoding (Kim et al., under preparation). This improvement of model prediction was observed agnostic of Bloom?s taxonomy levels of questions. Validation of this feature using established item-response theory techniques showed the potential for this feature to be used as an index of student comprehension (Kim et al., under preparation).\nThis line of work helped bring to light the nuances to how highlighting impacts student comprehension and retention. We have several lines of investigation including methodological investigations such as varying the granularity of highlighting segments (e.g., complete sentences vs. words or segments), as well as use-inspired research to identify different interventional strategies that when combined with highlighting result in longer term retention and better comprehension.\n\n\t\t\t\t\tLast Modified: 12/22/2022\n\n\t\t\t\t\tSubmitted by: Richard G Baraniuk"
 }
}