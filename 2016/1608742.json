{
 "awd_id": "1608742",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Cyberinfrastructure (CI) for NSF Large Facilities Workshop",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032927886",
 "po_email": "wlmiller@nsf.gov",
 "po_sign_block_name": "William Miller",
 "awd_eff_date": "2015-12-15",
 "awd_exp_date": "2016-05-31",
 "tot_intn_awd_amt": 47620.0,
 "awd_amount": 47620.0,
 "awd_min_amd_letter_date": "2015-12-10",
 "awd_max_amd_letter_date": "2015-12-10",
 "awd_abstract_narration": "Many large experimental and observational facilities are deployed in diverse research fields from physics and materials science, to the biological sciences and geosciences, to astronomical science, ocean science, and engineering research.  Large facilities engage in the collection, management and public distribution of massive scientific datasets that are expected remain be useful even beyond the lifetimes of the facilities themselves; and provide shared computational and analytic tools, as well as education and training related to these activities. Facility users also want to compare the large scale data to state-of-the-art simulations, which in turn can guide which future experiments to perform. To support these scientific missions and users, large facilities increasingly rely on national-scale cyberinfrastructure (CI), including high performance computing, advanced data platforms and analysis and visualization software infrastructure, and high-speed networking resources. There is increasing need for synergy between facilities and advanced CI resources, as emerging new technologies reshape the computational and data analysis environment and change the way scientific discovery is conducted.\r\n\r\nThis project will support a two-day community workshop on Cyberinfrastructure for Large Facilities. The purpose of the workshop is to bring the members of both the facility and CI communities together, to consider the CI needs of facilities, explore how large facilities can collaborate better with developers of cyberinfrastructure to achieve their science missions and serve their users, exchange best practices and novel CI solutions, and start a planning process can lead to a sustainable resource and data ecosystem for large scale science that can respond to new emerging scientific needs and CI technologies.  Desired outcomes also include inspiring new CI research and development activities that accelerate discovery across large scale science, and improving the connectedness of the national ecosystem of facilities and cyberinfrastructure in support of scientific discovery. This project was co-funded by several NSF directorates.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Szalay",
   "pi_mid_init": "S",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander S Szalay",
   "pi_email_addr": "aszalay1@jhu.edu",
   "nsf_id": "000472256",
   "pi_start_date": "2015-12-10",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Johns Hopkins University",
  "inst_street_address": "3400 N CHARLES ST",
  "inst_street_address_2": "",
  "inst_city_name": "BALTIMORE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4439971898",
  "inst_zip_code": "212182608",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MD07",
  "org_lgl_bus_name": "THE JOHNS HOPKINS UNIVERSITY",
  "org_prnt_uei_num": "GS4PNKTRNKL3",
  "org_uei_num": "FTMTDMBR29C7"
 },
 "perf_inst": {
  "perf_inst_name": "Johns Hopkins University",
  "perf_str_addr": "",
  "perf_city_name": "Baltimore",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "212182608",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MD07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "723100",
   "pgm_ele_name": "CYBERINFRASTRUCTURE"
  },
  {
   "pgm_ele_code": "769900",
   "pgm_ele_name": "Integrat & Collab Ed & Rsearch"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "020Z",
   "pgm_ref_txt": "OAC Facility Cyberinfrastructure"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 47620.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Large experimental and observational NSF facilities are creating unprecedented amounts of data, on all scales of the physical world, from particle physics to galaxies. Such facilities now include environmental systems, studies of the oceans, and various biological systems as well. These facilities increasingly depend on technologies related to CyberInfrastructure (CI), and the scale of the data are growing beyond our expectations.</p>\n<p>These facilities rely on CI to support their user communities, including the collection, management and public distribution of these data sets approaching petabytes. The challenges also include the creation, distribution and curation of tools, capturing data provenance, security practices and providing education and training. Data from these large experiments will remain to be useful even when the experiments are turned off.</p>\n<p>These facilities do not exist in isolation, they are connected also to a network of large national supercomputing and data facilities, with their software stack and user communities. There is an increasing synergy between these supercomputers and the observational and experimental facilities. Users want to compare the results of their experiments to state-of-the-art simulations, in some cases have simulations decide which experiments to perform.</p>\n<p>The purpose of the workshop was to bring the members of both of these communities together. During the meeting they can start a process of drawing a plan that can lead to a sustainable ecosystem where all these pieces interoperate and can respond to new emerging technologies.</p>\n<p>&nbsp;The main objectives of the workshop were to:</p>\n<p><strong>&nbsp;</strong></p>\n<ul>\n<li>Learn how NSF large facilities currently deploy, implement and apply cyberinfrastructure to accomplish their scientific missions and discuss their current and near-term CI needs</li>\n<li>Learn from the CI community about existing resources, capabilities and technology trends that can potentially serve the facilities community</li>\n<li>Exchange best practices and novel CI solutions among facilities and between facilities and the CI developer community</li>\n<li>Define a broad vision on a 20 year timescale that can lead to a scalable and sustainable data ecosystem and ensure the long term curation of the facility data sets</li>\n</ul>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/06/2016<br>\n\t\t\t\t\tModified by: Alexander&nbsp;S&nbsp;Szalay</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nLarge experimental and observational NSF facilities are creating unprecedented amounts of data, on all scales of the physical world, from particle physics to galaxies. Such facilities now include environmental systems, studies of the oceans, and various biological systems as well. These facilities increasingly depend on technologies related to CyberInfrastructure (CI), and the scale of the data are growing beyond our expectations.\n\nThese facilities rely on CI to support their user communities, including the collection, management and public distribution of these data sets approaching petabytes. The challenges also include the creation, distribution and curation of tools, capturing data provenance, security practices and providing education and training. Data from these large experiments will remain to be useful even when the experiments are turned off.\n\nThese facilities do not exist in isolation, they are connected also to a network of large national supercomputing and data facilities, with their software stack and user communities. There is an increasing synergy between these supercomputers and the observational and experimental facilities. Users want to compare the results of their experiments to state-of-the-art simulations, in some cases have simulations decide which experiments to perform.\n\nThe purpose of the workshop was to bring the members of both of these communities together. During the meeting they can start a process of drawing a plan that can lead to a sustainable ecosystem where all these pieces interoperate and can respond to new emerging technologies.\n\n The main objectives of the workshop were to:\n\n \n\nLearn how NSF large facilities currently deploy, implement and apply cyberinfrastructure to accomplish their scientific missions and discuss their current and near-term CI needs\nLearn from the CI community about existing resources, capabilities and technology trends that can potentially serve the facilities community\nExchange best practices and novel CI solutions among facilities and between facilities and the CI developer community\nDefine a broad vision on a 20 year timescale that can lead to a scalable and sustainable data ecosystem and ensure the long term curation of the facility data sets\n\n\n \n\n\t\t\t\t\tLast Modified: 06/06/2016\n\n\t\t\t\t\tSubmitted by: Alexander S Szalay"
 }
}