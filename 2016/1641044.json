{
 "awd_id": "1641044",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "WORKSHOP: Doctoral Consortium at the International Conference on Multimodal Interaction (ICMI 2016)",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Ephraim Glinert",
 "awd_eff_date": "2016-06-01",
 "awd_exp_date": "2022-05-31",
 "tot_intn_awd_amt": 27000.0,
 "awd_amount": 27000.0,
 "awd_min_amd_letter_date": "2016-06-03",
 "awd_max_amd_letter_date": "2021-03-23",
 "awd_abstract_narration": "This is funding to support participation by about 6 graduate students from U.S. institutions, along with about 5 senior members of the ICMI community who will serve as mentors, in a Doctoral Consortium (workshop) to be held in conjunction with and immediately preceding the 18th International Conference on Multimodal Interaction (ICMI 2016), which will take place November 12-16, 2016, in Tokyo, Japan, and which is organized by the Association for Computing Machinery (ACM). The ICMI conference series is the premier international forum for multidisciplinary research on multimodal human-human and human-computer interaction, interfaces, and system development. The conference focuses on theoretical and empirical foundations, component technologies, and combined multimodal processing techniques that define the field of multimodal interaction analysis, interface design, and system development. Topics of special interest to the conference this year include: multimodal interaction processing; interactive systems and applications; modeling human communication patterns; data, evaluation and standards for multimodal interactive systems; and urban interactions. ICMI 2016 will feature a single-track main conference which includes: keynote speakers, technical full and short papers (including oral and poster presentations), special sessions, demonstrations, exhibits and doctoral spotlight papers. The ICMI 2016 proceedings will be published by ACM Press and included in the ACM Digital Library. As a further incentive for high-quality student participation ICMI 2016 will be awarding outstanding paper awards, with a special category for student papers. More information about the conference may be found online at http://icmi.acm.org/2016/. \r\n\r\nThe goal of the ICMI Doctoral Consortium is to provide PhD students with an opportunity to present their work to a group of mentors and peers from a diverse set of academic and industrial institutions, to receive feedback on their doctoral research plan and progress, and to build a cohort of young researchers interested in designing multimodal interfaces. Student participants will present their ongoing thesis research as a short talk at the Consortium and also as a poster at the conference Doctoral Spotlight Session. Following the fruitful experience of last year's ICMI conference and doctoral consortium, and with the goal of providing more opportunities for interaction between the students and senior members of the field, the program will once again include a lunch on the day of the workshop for students and mentors, a career panel that will provide the students and mentors the opportunity to ask and answer questions and discuss challenges and opportunities in the field, and a dinner that will provide the students with the opportunity to hold informal conversations among themselves as well as with the organizers and mentors.  The Doctoral Consortium will give student participants exposure to their new research community, both by presenting their own work and by observing and interacting with established professionals in the field. It will encourage students at this critical time in their careers to begin building a social support network of peers and mentors. The organizers will take steps proactively to achieve a diversity of research topics, disciplinary backgrounds, methodological approaches, and home institutions among the students. To further increase diversity, the organizers have committed that no more than one student will be invited from any given U.S. institution of higher learning.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Emily",
   "pi_last_name": "Provost",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Emily M Provost",
   "pi_email_addr": "emilykmp@umich.edu",
   "nsf_id": "000607930",
   "pi_start_date": "2016-06-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "7556",
   "pgm_ref_txt": "CONFERENCE AND WORKSHOPS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 27000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This grant supported the attendance of doctoral students enrolled in U.S. institutions at the International Conference on Multimodal Interaction (ICMI) in 2016-2021.&nbsp;&nbsp;The ICMI conference series represents the growing interest in the next generation of perceptive, adaptive, and multimodal user interfaces. Multimodal and perceptual interfaces represent an emerging interdisciplinary research direction including topics such as spoken language understanding, natural language understanding, image processing, computer vision, pattern recognition, and experimental psychology. These interfaces seek to achieve efficient, intuitive, and natural human-computer interaction. Multimodal interfaces will ultimately enable users to interact with computers using everyday skills.&nbsp;&nbsp;These new interfaces are especially well suited for interpreting natural communication and activity patterns in real-world environments. Their emergence represents a radical departure from previous computing and interface paradigms and a rapid transformation in current human-computer interaction paradigms by creating more natural, expressive, flexible, and robust means of interacting with computers.&nbsp;</p>\n<p>The Doctoral Consortium provides PhD students with an opportunity to present their work to a group of mentors and peers from a diverse set of academic and industrial institutions, to receive feedback on their doctoral research plan and progress, and to build a cohort of young researchers in the field.&nbsp;&nbsp;This has helped students to build a social support network of peers and mentors at a critical and formative time in their research careers and provide the community of researchers with an opportunity to get involved in the training of the next generation of researchers in multimodal interfaces.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/17/2022<br>\n\t\t\t\t\tModified by: Emily&nbsp;Provost</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis grant supported the attendance of doctoral students enrolled in U.S. institutions at the International Conference on Multimodal Interaction (ICMI) in 2016-2021.  The ICMI conference series represents the growing interest in the next generation of perceptive, adaptive, and multimodal user interfaces. Multimodal and perceptual interfaces represent an emerging interdisciplinary research direction including topics such as spoken language understanding, natural language understanding, image processing, computer vision, pattern recognition, and experimental psychology. These interfaces seek to achieve efficient, intuitive, and natural human-computer interaction. Multimodal interfaces will ultimately enable users to interact with computers using everyday skills.  These new interfaces are especially well suited for interpreting natural communication and activity patterns in real-world environments. Their emergence represents a radical departure from previous computing and interface paradigms and a rapid transformation in current human-computer interaction paradigms by creating more natural, expressive, flexible, and robust means of interacting with computers. \n\nThe Doctoral Consortium provides PhD students with an opportunity to present their work to a group of mentors and peers from a diverse set of academic and industrial institutions, to receive feedback on their doctoral research plan and progress, and to build a cohort of young researchers in the field.  This has helped students to build a social support network of peers and mentors at a critical and formative time in their research careers and provide the community of researchers with an opportunity to get involved in the training of the next generation of researchers in multimodal interfaces.\n\n \n\n\t\t\t\t\tLast Modified: 08/17/2022\n\n\t\t\t\t\tSubmitted by: Emily Provost"
 }
}