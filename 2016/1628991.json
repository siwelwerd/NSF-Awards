{
 "awd_id": "1628991",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: FULL: Collaborative Research: Enabling Scalable Cloud And Edge-device Integration Using Cross-layer Parallelism",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 577987.0,
 "awd_amount": 593987.0,
 "awd_min_amd_letter_date": "2016-08-25",
 "awd_max_amd_letter_date": "2020-06-18",
 "awd_abstract_narration": "The importance of energy efficiency today is felt across all domains of computing.  In particular, personal computing platforms are becoming increasingly wireless and miniaturized, but limited by trade-offs between battery lifetimes and computational requirements. Developing energy-efficient solutions is critical to the survival of the semiconductor industry. This project seeks to develop new abstractions to effectively utilize network and cloud resources to enable a scalable and energy-efficient mobile computing paradigm.  The proposed hierarchical cloud computing architecture with cross-layer parallelism provides innovation for teaching networking, system, and architecture courses. It provides a platform to engage undergraduate students and community service agencies. Finally, this project is expected to have a high impact on global societies and economies.\r\n\r\nThe proposed distributed system architecture leverages cross-layer parallelism to enable scalable, adaptive, and intelligent integration between edge mobile devices and clouds by intelligently partitioning and replicating computation between mobile devices and the cloud.  This project redefines two classes of programming abstractions that enable seamless usage of: (1) network resources at transport layers and (2) any form of cloud resources whether local or remote.  The proposed architecture strategically leverages network-level parallelism that transparently utilizes multiple network paths, in-network cloudlets that offer highly customized accelerators for offloaded computation, and remote cloud servers with more plentiful resources. These three components work in a coordinated way with awareness of the dynamic communication overhead, thereby ensuring scalability and energy efficiency of supporting both compute and network intensive distributed applications on mobile platforms.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zhuoqing",
   "pi_last_name": "Mao",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Zhuoqing M Mao",
   "pi_email_addr": "zmao@umich.edu",
   "nsf_id": "000490161",
   "pi_start_date": "2016-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Scott",
   "pi_last_name": "Mahlke",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Scott Mahlke",
   "pi_email_addr": "mahlke@eecs.umich.edu",
   "nsf_id": "000296943",
   "pi_start_date": "2016-08-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  },
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7354",
   "pgm_ref_txt": "COMPUTER SYSTEMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 577987.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The main goal of this project is to develop a distributed system architecture that leverages cross-layer parallelism to enable scalable, adaptive, and intelligent integration between edge mobile devices and clouds.</p>\n<p>We have done numerous projects during the lifetime of this award. We highlight some of the key innovations here:</p>\n<p>MPBond: Efficient Network-level Collaboration Among Personal Mobile Devices:&nbsp; MPBond is an efficient system allowing multiple personal mobile devices to collaboratively fetch content from the Internet. For example, a smartwatch can assist its paired smartphone with downloading data. Inspired by the success of MPTCP, MPBond applies the concept of distributed multipath transport where multiple subflows can traverse different devices. We develop a cross-device connection management scheme, a buffering strategy, a packet scheduling algorithm, and a policy framework tailored to MPBond&rsquo;s architecture.&nbsp;</p>\n<p>&nbsp;A First Look at Commercial 5G Performance on Smartphones:&nbsp;We conduct to our knowledge a first measurement study of commercial 5G performance on smartphones by closely examining 5G networks of three carriers (two mmWave carriers, one mid-band carrier) in three U.S. cities. We conduct extensive field tests on 5G performance in diverse urban environments. We systematically analyze the handoff mechanisms in 5G and their impact on network performance. We study how 5G and 4G can be jointly leveraged to achieve effective network-level parallelism and to boost network performance. We also explore the feasibility of using location and possibly other environmental information to predict the network performance.&nbsp;</p>\n<p>Firefly: Untethered Multi-user VR for Commodity Mobile Devices:&nbsp;We design and implement Firefly, an untethered multi-user virtual reality (VR) system for commodity mobile devices. It supports more than 10 users to concurrently enjoy high-quality VR content using a single commodity server, a single WiFi access point, and commercial off-the-shelf mobile devices. Firefly employs a series of techniques including offline content preparation, viewport-adaptive streaming with motion prediction, edge-assisted adaptive content quality control, to name a few, to ensure good image quality, low motion-to-photon delay, a high frame rate at 60 FPS, scalability with respect to the number of users, and fairness among users.</p>\n<p>DeepVista: Edge-assisted 16K Panoramic Video Streaming on Smartphones:&nbsp;We design, implement, and evaluate DeepVista, which is to our knowledge the first consumer-class system that streams panoramic videos far beyond the ultra high-definition (UHD) resolution (up to 16K) to mobile devices, offering truly immersive experiences. Such an immense resolution makes streaming video-on-demand (VoD) content extremely resource-demanding. To tackle this challenge, DeepVista introduces a novel framework that leverages an edge server to perform efficient, intelligent, and quality-guaranteed content transcoding, by extracting from panoramic frames the viewport stream that will be delivered to the client. To support real-time transcoding of 16K content, DeepVista employs several key mechanisms such as dual-GPU acceleration, lossless viewport extraction, deep viewport prediction, and a two-layer streaming design.&nbsp;</p>\n<p>CSI: Inferring Mobile ABR Video Adaptation Behavior under HTTPS and QUIC: We develop CSI (Chunk Sequence Inferencer), a general system that enables third-parties to conduct active measurements and infer mobile ABR video adaptation behavior based on packet size and timing information still available in the encrypted traffic. Such a system is helpful for enhancing video adaptation logic when network performance is poor by leveraging network parallelism such as multipaths. We perform extensive evaluations and demonstrate that CSI achieves high inference accuracy for video encodings of popular streaming services covering various ABR system designs.&nbsp;</p>\n<p>SIEVE: Speculative Inference on the Edge with Versatile Exportation:<br />We develop SIEVE, or Speculative Inference on the Edge with Versatile Exportation, which dynamically distributes neural network (NN) computation between the cloud and edge device based on the input data and environmental conditions to maximize efficiency and performance. A speculative NN is created through aggressive compression techniques to run most of the inferences on the edge device, while the original CNN is run on the cloud server. A runtime system directs each input to either the edge or cloud and decides whether to accept speculative inferences made on the edge or invoke recovery by replaying the inference on the cloud.</p>\n<p>TF-Net: Deploying Sub-Byte Deep Neural Networks on Edge Microcontrollers:<br />We designed and developed the TF-Net pipeline to efficiently deploy sub-byte neural networks (NNs) on edge device processors and microcontrollers. While TF-Net allows for a range of weight and input precision, we find Ternary weights and Four-bit inputs provide the optimal balance between model accuracy, computation performance, and energy efficiency. TFNet first includes a training framework for sub-byte low-precision NN models. Two algorithms are then introduced to accelerate the trained models. The first, direct buffer convolution, amortizes unpacking overhead by caching unpacked inputs. The second, packed sub-byte multiply-accumulate, utilizes a single multiplication instruction to perform multiple sub-byte multiply-accumulate computations. To further accelerate NN computation, we propose two instructions, Multiply-Shift-Accumulate and Unpack, to extend the existing processor instruction sets.</p>\n<p>For all these projects, we have released the source code and data to enable follow-up.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/04/2021<br>\n\t\t\t\t\tModified by: Zhuoqing&nbsp;M&nbsp;Mao</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe main goal of this project is to develop a distributed system architecture that leverages cross-layer parallelism to enable scalable, adaptive, and intelligent integration between edge mobile devices and clouds.\n\nWe have done numerous projects during the lifetime of this award. We highlight some of the key innovations here:\n\nMPBond: Efficient Network-level Collaboration Among Personal Mobile Devices:  MPBond is an efficient system allowing multiple personal mobile devices to collaboratively fetch content from the Internet. For example, a smartwatch can assist its paired smartphone with downloading data. Inspired by the success of MPTCP, MPBond applies the concept of distributed multipath transport where multiple subflows can traverse different devices. We develop a cross-device connection management scheme, a buffering strategy, a packet scheduling algorithm, and a policy framework tailored to MPBond\u2019s architecture. \n\n A First Look at Commercial 5G Performance on Smartphones: We conduct to our knowledge a first measurement study of commercial 5G performance on smartphones by closely examining 5G networks of three carriers (two mmWave carriers, one mid-band carrier) in three U.S. cities. We conduct extensive field tests on 5G performance in diverse urban environments. We systematically analyze the handoff mechanisms in 5G and their impact on network performance. We study how 5G and 4G can be jointly leveraged to achieve effective network-level parallelism and to boost network performance. We also explore the feasibility of using location and possibly other environmental information to predict the network performance. \n\nFirefly: Untethered Multi-user VR for Commodity Mobile Devices: We design and implement Firefly, an untethered multi-user virtual reality (VR) system for commodity mobile devices. It supports more than 10 users to concurrently enjoy high-quality VR content using a single commodity server, a single WiFi access point, and commercial off-the-shelf mobile devices. Firefly employs a series of techniques including offline content preparation, viewport-adaptive streaming with motion prediction, edge-assisted adaptive content quality control, to name a few, to ensure good image quality, low motion-to-photon delay, a high frame rate at 60 FPS, scalability with respect to the number of users, and fairness among users.\n\nDeepVista: Edge-assisted 16K Panoramic Video Streaming on Smartphones: We design, implement, and evaluate DeepVista, which is to our knowledge the first consumer-class system that streams panoramic videos far beyond the ultra high-definition (UHD) resolution (up to 16K) to mobile devices, offering truly immersive experiences. Such an immense resolution makes streaming video-on-demand (VoD) content extremely resource-demanding. To tackle this challenge, DeepVista introduces a novel framework that leverages an edge server to perform efficient, intelligent, and quality-guaranteed content transcoding, by extracting from panoramic frames the viewport stream that will be delivered to the client. To support real-time transcoding of 16K content, DeepVista employs several key mechanisms such as dual-GPU acceleration, lossless viewport extraction, deep viewport prediction, and a two-layer streaming design. \n\nCSI: Inferring Mobile ABR Video Adaptation Behavior under HTTPS and QUIC: We develop CSI (Chunk Sequence Inferencer), a general system that enables third-parties to conduct active measurements and infer mobile ABR video adaptation behavior based on packet size and timing information still available in the encrypted traffic. Such a system is helpful for enhancing video adaptation logic when network performance is poor by leveraging network parallelism such as multipaths. We perform extensive evaluations and demonstrate that CSI achieves high inference accuracy for video encodings of popular streaming services covering various ABR system designs. \n\nSIEVE: Speculative Inference on the Edge with Versatile Exportation:\nWe develop SIEVE, or Speculative Inference on the Edge with Versatile Exportation, which dynamically distributes neural network (NN) computation between the cloud and edge device based on the input data and environmental conditions to maximize efficiency and performance. A speculative NN is created through aggressive compression techniques to run most of the inferences on the edge device, while the original CNN is run on the cloud server. A runtime system directs each input to either the edge or cloud and decides whether to accept speculative inferences made on the edge or invoke recovery by replaying the inference on the cloud.\n\nTF-Net: Deploying Sub-Byte Deep Neural Networks on Edge Microcontrollers:\nWe designed and developed the TF-Net pipeline to efficiently deploy sub-byte neural networks (NNs) on edge device processors and microcontrollers. While TF-Net allows for a range of weight and input precision, we find Ternary weights and Four-bit inputs provide the optimal balance between model accuracy, computation performance, and energy efficiency. TFNet first includes a training framework for sub-byte low-precision NN models. Two algorithms are then introduced to accelerate the trained models. The first, direct buffer convolution, amortizes unpacking overhead by caching unpacked inputs. The second, packed sub-byte multiply-accumulate, utilizes a single multiplication instruction to perform multiple sub-byte multiply-accumulate computations. To further accelerate NN computation, we propose two instructions, Multiply-Shift-Accumulate and Unpack, to extend the existing processor instruction sets.\n\nFor all these projects, we have released the source code and data to enable follow-up. \n\n\t\t\t\t\tLast Modified: 10/04/2021\n\n\t\t\t\t\tSubmitted by: Zhuoqing M Mao"
 }
}