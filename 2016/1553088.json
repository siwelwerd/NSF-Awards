{
 "awd_id": "1553088",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Towards Methodologies and Tools for Conducting Algorithm Audits",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "William Bainbridge",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2022-06-30",
 "tot_intn_awd_amt": 535139.0,
 "awd_amount": 543139.0,
 "awd_min_amd_letter_date": "2016-05-20",
 "awd_max_amd_letter_date": "2020-07-28",
 "awd_abstract_narration": "This project will develop methodologies and tools for conducting algorithm audits. An algorithm audit uses controlled experiments to examine an algorithmic system, such as an online service or big data information archive, and ascertain (1) how it functions, and (2) whether it may cause harm. Examples of documented harms by algorithms include discrimination, racism, and unfair trade practices. Although there is rising awareness of the potential for algorithmic systems to cause harm, actually detecting this harm in practice remains a key challenge. Given that most algorithms of concern are proprietary and non-transparent, there is a clear need for methods to conduct black-box analyses of these systems. Numerous regulators and governments have expressed concerns about algorithms, as well as a desire to increase transparency and accountability in this area.\r\n\r\nThis research will develop methodologies to audit algorithms in three domains that impact many people: online markets, hiring websites, and financial services. Auditing algorithms in these three domains will require solving fundamental methodological challenges, such as how to analyze systems with large, unknown feature sets, and how to estimate feature values without ground-truth data. To address these broad challenges, the research will draw on insights from prior experience auditing personalization algorithms. Additionally, each domain also brings unique challenges that will be addressed individually. For example, novel auditing tools will be constructed that leverage extensive online and offline histories. These new tools will allow examination of systems that were previously inaccessible to researchers, including financial services companies. Methodologies, open-source code, and datasets will be made available to other academic researchers and regulators.  This project includes two integrated educational objectives: (1) to create a new computer science course on big data ethics, teaching how to identify and mitigate harmful side-effects of big data technologies, and (2) production of web-based versions of the auditing tools that are designed to be accessible and informative to the general public, that will increase transparency around specific, prominent algorithmic systems, as well as promote general education about the proliferation and impact of algorithmic systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christopher",
   "pi_last_name": "Wilson",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christopher Wilson",
   "pi_email_addr": "c.wilson@neu.edu",
   "nsf_id": "000635458",
   "pi_start_date": "2016-05-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northeastern University",
  "inst_street_address": "360 HUNTINGTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BOSTON",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6173735600",
  "inst_zip_code": "021155005",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "MA07",
  "org_lgl_bus_name": "NORTHEASTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HLTMVS2JZBS6"
 },
 "perf_inst": {
  "perf_inst_name": "Northeastern University",
  "perf_str_addr": "360 Huntington Ave",
  "perf_city_name": "Boston",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021155005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "MA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736700",
   "pgm_ele_name": "HCC-Human-Centered Computing"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7367",
   "pgm_ref_txt": "Cyber-Human Systems"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 100796.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 103819.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 106933.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 110143.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 121448.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The idea that algorithms operating in the public sphere can and should be scrutinized by independent experts has come a long way in the last six years. When this project began, \"algorithm auditing\" was in its infancy: the term itself was not well-known and the practices and methods for conducting successful audits of black-box algorithms were still being developed and proven. Yet today, regulators and lawmakers around the world are beginning to incorporate algorithm auditing into proposals for ensuring safe and trustworthy artificial intelligence and automated decision making systems.</p>\n<p><br />The aim of this research was to develop novel methods for auditing black box, online systems across a variety of high-impact real-world contexts, such as e-commerce, candidate screening, and search. The underlying motivation for this work is that online, data-driven systems increasingly intermediate peoples' lives, yet surprisingly little is known about how these systems operate, the data they collect, or the impact they have on human behavior. Algorithm auditing techniques allow external researchers to rigorously probe these black box systems to understand how they work and measure their potential impacts.</p>\n<p><br />The studies conducted under this grant broke new ground in the development of methods for algorithm auditing. Examples include methods for investigating ride sharing platforms and recruiting search engines. These studies also expanded the scope of the kinds of investigative work that can be performed using algorithm auditing methods, including work that examined the accuracy of inferences made by online advertisers, biases in content moderation systems, and compliance with privacy laws. Finally, these audits have demonstrated the breadth of social concerns that can be explored within sociotechnical systems, including fairness and bias, mis- and disinformation, personal privacy, and individual autonomy.</p>\n<p><br /><strong>Intellectual Merit: </strong>The research funded under this grant has had a foundational impact on the practice of algorithm auditing. The methods we developed are now widely adopted by teams auditing other online platforms. The papers produced under this grant have appeared in top-tier computer science venues, such as the ACM Conference on Fairness, Accountability, and Transparency (FAccT), the Networks and Distributed Systems Security Symposium (NDSS), the Web Conference (WWW), the International Conference on Weblogs and Social Media (ICWSM), the ACM Conference on Computer Supported and Cooperative Work (CSCW), the ACM Conference on Computer Human Interaction (CHI), the Privacy Enhancing Technologies Symposium (PETS), and others. Three papers won awards for their research contributions.</p>\n<p><br />This grant funded the research of at least six doctoral students, two of whom have subsequently graduated. This grant also funded two undergraduate researchers.</p>\n<p><br /><strong>Broader Impacts:</strong> The research funded under this grant has had significant impact outside the academy. Our research on ride sharing led to a collaboration with the San Francisco County Transportation Authority that produced a number of reports to the public and the city council about the impact of ride sharing on the Bay Area. Our results on compliance with the California Consumer Protection Act (CCPA) have been shared with the relevant regulators. Other research produced under this grant has received significant attention in the press, helping to educate the public about the use of algorithms in public spaces and their privacy implications.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/21/2022<br>\n\t\t\t\t\tModified by: Christopher&nbsp;Wilson</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe idea that algorithms operating in the public sphere can and should be scrutinized by independent experts has come a long way in the last six years. When this project began, \"algorithm auditing\" was in its infancy: the term itself was not well-known and the practices and methods for conducting successful audits of black-box algorithms were still being developed and proven. Yet today, regulators and lawmakers around the world are beginning to incorporate algorithm auditing into proposals for ensuring safe and trustworthy artificial intelligence and automated decision making systems.\n\n\nThe aim of this research was to develop novel methods for auditing black box, online systems across a variety of high-impact real-world contexts, such as e-commerce, candidate screening, and search. The underlying motivation for this work is that online, data-driven systems increasingly intermediate peoples' lives, yet surprisingly little is known about how these systems operate, the data they collect, or the impact they have on human behavior. Algorithm auditing techniques allow external researchers to rigorously probe these black box systems to understand how they work and measure their potential impacts.\n\n\nThe studies conducted under this grant broke new ground in the development of methods for algorithm auditing. Examples include methods for investigating ride sharing platforms and recruiting search engines. These studies also expanded the scope of the kinds of investigative work that can be performed using algorithm auditing methods, including work that examined the accuracy of inferences made by online advertisers, biases in content moderation systems, and compliance with privacy laws. Finally, these audits have demonstrated the breadth of social concerns that can be explored within sociotechnical systems, including fairness and bias, mis- and disinformation, personal privacy, and individual autonomy.\n\n\nIntellectual Merit: The research funded under this grant has had a foundational impact on the practice of algorithm auditing. The methods we developed are now widely adopted by teams auditing other online platforms. The papers produced under this grant have appeared in top-tier computer science venues, such as the ACM Conference on Fairness, Accountability, and Transparency (FAccT), the Networks and Distributed Systems Security Symposium (NDSS), the Web Conference (WWW), the International Conference on Weblogs and Social Media (ICWSM), the ACM Conference on Computer Supported and Cooperative Work (CSCW), the ACM Conference on Computer Human Interaction (CHI), the Privacy Enhancing Technologies Symposium (PETS), and others. Three papers won awards for their research contributions.\n\n\nThis grant funded the research of at least six doctoral students, two of whom have subsequently graduated. This grant also funded two undergraduate researchers.\n\n\nBroader Impacts: The research funded under this grant has had significant impact outside the academy. Our research on ride sharing led to a collaboration with the San Francisco County Transportation Authority that produced a number of reports to the public and the city council about the impact of ride sharing on the Bay Area. Our results on compliance with the California Consumer Protection Act (CCPA) have been shared with the relevant regulators. Other research produced under this grant has received significant attention in the press, helping to educate the public about the use of algorithms in public spaces and their privacy implications.\n\n\t\t\t\t\tLast Modified: 10/21/2022\n\n\t\t\t\t\tSubmitted by: Christopher Wilson"
 }
}