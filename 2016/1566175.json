{
 "awd_id": "1566175",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: CSR: Large-scale Systems Software Atop Scale-out In-memory Storage",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2016-05-15",
 "awd_exp_date": "2019-04-30",
 "tot_intn_awd_amt": 174949.0,
 "awd_amount": 174949.0,
 "awd_min_amd_letter_date": "2016-01-13",
 "awd_max_amd_letter_date": "2016-01-13",
 "awd_abstract_narration": "Research over the past 5 years on in-memory data center storage has resulted in systems that can provide on-demand access to billions of pieces of information per second. However, the benefits of these fast systems has not resulted in more powerful and interesting applications for users. The key problem is that these new storage systems are stripped down to provide speed and can only fulfill very basic requests for information. To compensate, applications must make many requests to these storage systems to perform the same operations they were able to perform with a single request to older database systems.  The result is that applications spend most of the performance benefits they gain from these systems overcoming their limited programming model.\r\n\r\nThis work seeks to understand the hidden costs of the limited interfaces of these large-scale in-memory key-value stores and to alleviate those costs with a new stored procedure model uniquely suited to these systems. To explore these costs, data-intensive applications from three different domains will be prototyped on today?s low-latency key-value stores, first with their conventional interfaces and then again with custom application logic built into the storage system. The results of this exploration will motivate and aid in the design of the main contribution of this work: a generalized model for safely collocating application logic inside of key-value stores. Application prototypes will include a scale-out database kernel, a simple scale-out graph database, and large-scale machine learning algorithms.\r\n\r\nA rich programming model for developing large-scale software systems will lower the barrier for building information-intensive applications: an art that requires specialized expertise. Low-latency systems equipped with fast stored procedures will be a powerful tool for building new, data-intensive systems in industry, science, and the military. They will enable deep real-time analysis of social and natural graphs; rich, interactive worlds where millions of users manipulate and modify a shared environment; the fine-grained coordination and routing of millions of autonomous vehicles on the highways in a metropolitan area; and real-time decision support for military intelligence. All components will be built as a practical and usable software system with all development done publicly and available as open-source.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ryan",
   "pi_last_name": "Stutsman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ryan Stutsman",
   "pi_email_addr": "stutsman@cs.utah.edu",
   "nsf_id": "000688499",
   "pi_start_date": "2016-01-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "75 South 2000 East",
  "perf_city_name": "Salt Lake City",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841128930",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 174949.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project developed a new approach to computing on data stored in large, distributed storage systems in data centers and the cloud. Emerging distributed storage systems (ones relying on in-memory storage and kernel-bypass-based networking) have been able to increase performance by removing features; however, this has made it so that they can only answer simple queries for data. The end result is that applications interacting with data must resort to fetching it from storage to perform computation on it, which is inefficient. The work of this project has helped to reverse that trend.<br /><br />Specifically, the results include:</p>\n<ul>\n<li>a new scheme for moving small programs to data that preserve the fast operation of these new networked storage systems while eliminating the need to move all data over the network to compute on it;</li>\n<li>demonstration of this new approach for online and batch graph algorithms (common, for example, in social networking applications), in machine learning (for example, to do sediment analysis on text), and aggregation/analytical queries over data (for example, that return statistics over large data sets);</li>\n<li>the realization of a new approach to splitting computation over data between applications and distributed storage machines that dynamically adapts where to run code based on the costs of moving data over the network;</li>\n<li>and the realization that network and CPU hardware trends combined with shifting patterns of workloads in the cloud will increasingly place pressure on existing CPU hardware designs for isolating computer code in the cloud.</li>\n</ul>\n<p><br />This final finding has led to new work in distributed storage systems focused on overcoming these CPU hardware limitations by trying software-based and alternative hardware-software designs to support future cloud workloads.&nbsp; Findings from this work have led to multiple pieces of open-source software, some used in other researcher's work. Also, it has contributed to two projects that are joint with an industrial research laboratory, including direct integration of data migration approaches developed as part of this project into an open-source project developed primarily by that industrial lab. To date, the project has supported 6 peer reviewed conference and workshop papers along with a Master's and Bachelor's thesis.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/31/2019<br>\n\t\t\t\t\tModified by: Ryan&nbsp;Stutsman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project developed a new approach to computing on data stored in large, distributed storage systems in data centers and the cloud. Emerging distributed storage systems (ones relying on in-memory storage and kernel-bypass-based networking) have been able to increase performance by removing features; however, this has made it so that they can only answer simple queries for data. The end result is that applications interacting with data must resort to fetching it from storage to perform computation on it, which is inefficient. The work of this project has helped to reverse that trend.\n\nSpecifically, the results include:\n\na new scheme for moving small programs to data that preserve the fast operation of these new networked storage systems while eliminating the need to move all data over the network to compute on it;\ndemonstration of this new approach for online and batch graph algorithms (common, for example, in social networking applications), in machine learning (for example, to do sediment analysis on text), and aggregation/analytical queries over data (for example, that return statistics over large data sets);\nthe realization of a new approach to splitting computation over data between applications and distributed storage machines that dynamically adapts where to run code based on the costs of moving data over the network;\nand the realization that network and CPU hardware trends combined with shifting patterns of workloads in the cloud will increasingly place pressure on existing CPU hardware designs for isolating computer code in the cloud.\n\n\n\nThis final finding has led to new work in distributed storage systems focused on overcoming these CPU hardware limitations by trying software-based and alternative hardware-software designs to support future cloud workloads.  Findings from this work have led to multiple pieces of open-source software, some used in other researcher's work. Also, it has contributed to two projects that are joint with an industrial research laboratory, including direct integration of data migration approaches developed as part of this project into an open-source project developed primarily by that industrial lab. To date, the project has supported 6 peer reviewed conference and workshop papers along with a Master's and Bachelor's thesis.\n\n\t\t\t\t\tLast Modified: 05/31/2019\n\n\t\t\t\t\tSubmitted by: Ryan Stutsman"
 }
}