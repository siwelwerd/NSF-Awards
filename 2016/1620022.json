{
 "awd_id": "1620022",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research:   Algorithms for Large-Scale Stochastic and Nonlinear Optimization",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 270000.0,
 "awd_amount": 270000.0,
 "awd_min_amd_letter_date": "2016-06-17",
 "awd_max_amd_letter_date": "2016-06-17",
 "awd_abstract_narration": "The promise of artificial intelligence has been a topic of both public and private interest for decades. Starting in the 1990s the field has been benefited from the rapidly evolving and expanding field of machine learning. The intelligent systems that have been borne out of machine learning, such as search engines, recommendation platforms, and speech and image recognition software, have become an indispensable part of modern society.  Rooted in statistics and relying heavily on the efficiency of numerical algorithms, machine learning techniques capitalize on increasingly powerful computing platforms and the availability of very large datasets.  One of the pillars of machine learning is mathematical optimization, which, in this context, involves the computation of parameters for a system designed to make decisions based on yet unseen data. The goal of this project is to develop new optimization algorithms that will enable the continuing rise of the field of machine learning.\r\n  \r\nThe research consists of two projects, which are thematically related and address the solution of optimization problems that are nonlinear, high dimensional, stochastic, involve very large data sets and in some cases are non-convex. Two families of algorithms will be developed to garner the benefits of both stochastic gradient methods and batch methods, while avoiding their shortcomings. One of these algorithms uses a gradient aggregation approach that re-uses gradient values computed at previous iterations. The challenge is to design an algorithm that is efficient in minimizing testing error, not just training error. The second approach employs adaptive sampling techniques to reduce the noise in stochastic gradient approximations as the optimization progresses. An important aspect of this research is the design of an efficient strategy for incorporating second-order information that captures curvature of the optimized loss function, even in the case when Hessian estimates are based on inaccurate gradients. In all cases, the goal is research is to design and implement algorithms in software, and test them on realistic machine learning applications.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jorge",
   "pi_last_name": "Nocedal",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jorge Nocedal",
   "pi_email_addr": "j-nocedal@northwestern.edu",
   "nsf_id": "000375872",
   "pi_start_date": "2016-06-17",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Northwestern University",
  "perf_str_addr": "2145 Sheridan Road",
  "perf_city_name": "Evanston",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "602083113",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IL09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "006Y00",
   "pgm_ele_name": "OE Operations Engineering"
  },
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "071E",
   "pgm_ref_txt": "MFG ENTERPRISE OPERATIONS"
  },
  {
   "pgm_ref_code": "072E",
   "pgm_ref_txt": "NETWORKS & QUEUING SYSTEMS"
  },
  {
   "pgm_ref_code": "073E",
   "pgm_ref_txt": "OPTIMIZATION & DECISION MAKING"
  },
  {
   "pgm_ref_code": "077E",
   "pgm_ref_txt": "SIMULATION MODELS"
  },
  {
   "pgm_ref_code": "078E",
   "pgm_ref_txt": "ENTERPRISE DESIGN & LOGISTICS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 270000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The most important advances in artificial intelligence in the last decade have been achieved through machine learning. This field creates intelligent algorithms that learn through data; a notable example is the class of predictors referred to as deep neural networks. The process of assimilating data so that the intelligent algorithms perform well in unseen circumstances is done by means of optimization methods. Finding the optimal parameters of the intelligent algorithms is a formidable optimization problem since this problem is nonlinear and involves the determination of millions of unknowns. The goal of this project was to design a novel optimization method for machine learning that makes effective use of modern computer architectures and is able to exploit parallelism. The new optimization method created in this project, which is referred to as a progressive batching algorithm, is based on the observation that efficient training is achieved by employing a small amount of data at the start and increasing it as the training finishes. The design of this optimization method was worked out in detail, and its software implementation was successfully tested on realistic applications. It was also shown that the new optimization method is guaranteed to converge, a vital consideration in ensuring robustness of the training process.</p>\n<p>A second goal of the project addresses a challenge arising in many engineering disciplines, where one wishes to optimize a system that cannot be completely observed. In other words, one can observe the input and output of a black-box system, which is typically noisy, and with that information one must find an optimal configuration of the system. Mathematically this is posed as a derivative-free optimization problem. The project began with an exploration of all existing methods and led to the conclusion that one could improve upon all these techniques by using a different approach based on gradient estimation . Rather than performing grid searches or creating models through function interpolation, it was found to be more efficient to devote computational resources to the estimation of a gradient approximation, even when the system is noisy. It was shown that this approximate gradient information can be employed within a quasi-Newton method to give rise to a powerful class of methods for derivative-free optimization, which are very simple to implement. The new algorithms were successfully tested on optimization problems arising in machine learning and on simulation-based models.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/03/2020<br>\n\t\t\t\t\tModified by: Jorge&nbsp;Nocedal</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe most important advances in artificial intelligence in the last decade have been achieved through machine learning. This field creates intelligent algorithms that learn through data; a notable example is the class of predictors referred to as deep neural networks. The process of assimilating data so that the intelligent algorithms perform well in unseen circumstances is done by means of optimization methods. Finding the optimal parameters of the intelligent algorithms is a formidable optimization problem since this problem is nonlinear and involves the determination of millions of unknowns. The goal of this project was to design a novel optimization method for machine learning that makes effective use of modern computer architectures and is able to exploit parallelism. The new optimization method created in this project, which is referred to as a progressive batching algorithm, is based on the observation that efficient training is achieved by employing a small amount of data at the start and increasing it as the training finishes. The design of this optimization method was worked out in detail, and its software implementation was successfully tested on realistic applications. It was also shown that the new optimization method is guaranteed to converge, a vital consideration in ensuring robustness of the training process.\n\nA second goal of the project addresses a challenge arising in many engineering disciplines, where one wishes to optimize a system that cannot be completely observed. In other words, one can observe the input and output of a black-box system, which is typically noisy, and with that information one must find an optimal configuration of the system. Mathematically this is posed as a derivative-free optimization problem. The project began with an exploration of all existing methods and led to the conclusion that one could improve upon all these techniques by using a different approach based on gradient estimation . Rather than performing grid searches or creating models through function interpolation, it was found to be more efficient to devote computational resources to the estimation of a gradient approximation, even when the system is noisy. It was shown that this approximate gradient information can be employed within a quasi-Newton method to give rise to a powerful class of methods for derivative-free optimization, which are very simple to implement. The new algorithms were successfully tested on optimization problems arising in machine learning and on simulation-based models.\n\n \n\n \n\n\t\t\t\t\tLast Modified: 10/03/2020\n\n\t\t\t\t\tSubmitted by: Jorge Nocedal"
 }
}