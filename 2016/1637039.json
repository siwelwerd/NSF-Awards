{
 "awd_id": "1637039",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: A Visual System for Autonomous Foraminifera Identification",
 "cfda_num": "47.050",
 "org_code": "06040100",
 "po_phone": "7032927577",
 "po_email": "kbinkley@nsf.gov",
 "po_sign_block_name": "Kandace Binkley",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 173659.0,
 "awd_amount": 173659.0,
 "awd_min_amd_letter_date": "2016-04-22",
 "awd_max_amd_letter_date": "2016-04-22",
 "awd_abstract_narration": "The goal of this project is to develop an automated system for identification of foraminifera (single-celled organisms with shells). Currently undergraduate workers are often employed to hand pick several thousands of specimens from ocean sediments for each study. This is tedious and time consuming work. By automating the bulk of the identification process, user expertise can be focused on verification and identification of subtle differences.\r\n\r\nA visual identification system will be developed in order to automate the identification of target microorganisms. The visual system will incorporate a controllable LED lighting ring used to capture images by illuminating the specimens from several directions, mimicking an important step in the traditional identification process. These images will be used to create a 3D model of the organism in real-time within a second. Computer vision and pattern recognition techniques will be tuned to acceptable recognition rates set by feedback from an expert in paleoceanography who will also provide labeled samples for training and validation. The initial proof of concept study will focus on identifying six species of planktonic foraminifera, and their morphotypes, that are widely used by paleoceanographers.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "GEO",
 "org_dir_long_name": "Directorate for Geosciences",
 "div_abbr": "OCE",
 "org_div_long_name": "Division Of Ocean Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Edgar",
   "pi_last_name": "Lobaton",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Edgar J Lobaton",
   "pi_email_addr": "edgar.lobaton@ncsu.edu",
   "nsf_id": "000603424",
   "pi_start_date": "2016-04-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "North Carolina State University",
  "inst_street_address": "2601 WOLF VILLAGE WAY",
  "inst_street_address_2": "",
  "inst_city_name": "RALEIGH",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9195152444",
  "inst_zip_code": "276950001",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NC02",
  "org_lgl_bus_name": "NORTH CAROLINA STATE UNIVERSITY",
  "org_prnt_uei_num": "U3NVH931QJJ3",
  "org_uei_num": "U3NVH931QJJ3"
 },
 "perf_inst": {
  "perf_inst_name": "North Carolina State University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "276957911",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NC02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "168000",
   "pgm_ele_name": "OCEAN TECH & INTERDISC COORDIN"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 173659.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aimed to develop a visual system for autonomous recognition of microscopic single celled organisms called foraminifera, forams for short. Forams are found on ocean sediments and are essential for paleoceanography. Scientists may require to picks several thousands of them per study, which is currently done manually one foram at the time by picking them from a sample under a microscope. In this award, the team developed an imaging systems based on an LED ring attached to an existing microscope with a USB camera. This system is the first step towards an autonomous sorting robotic platform which could reduce the burden of manual segmentation and remove human variability from the process. The LED ring allows for images to be captured for each foram under different lighting conditions. These images capture information about the shape of the geometry which was used to train machine learning algorithms to recognize the different species and to identify the different components in the structure of the foram. The study focused on the recognition of six species, and over a thousand forams were imaged. The outcomes of the machine system were compared against expert and novice labels, and found that the machine can perform just as well as the best expert at recognizing forams from the images.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/04/2019<br>\n\t\t\t\t\tModified by: Edgar&nbsp;Lobaton</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aimed to develop a visual system for autonomous recognition of microscopic single celled organisms called foraminifera, forams for short. Forams are found on ocean sediments and are essential for paleoceanography. Scientists may require to picks several thousands of them per study, which is currently done manually one foram at the time by picking them from a sample under a microscope. In this award, the team developed an imaging systems based on an LED ring attached to an existing microscope with a USB camera. This system is the first step towards an autonomous sorting robotic platform which could reduce the burden of manual segmentation and remove human variability from the process. The LED ring allows for images to be captured for each foram under different lighting conditions. These images capture information about the shape of the geometry which was used to train machine learning algorithms to recognize the different species and to identify the different components in the structure of the foram. The study focused on the recognition of six species, and over a thousand forams were imaged. The outcomes of the machine system were compared against expert and novice labels, and found that the machine can perform just as well as the best expert at recognizing forams from the images.\n\n\t\t\t\t\tLast Modified: 08/04/2019\n\n\t\t\t\t\tSubmitted by: Edgar Lobaton"
 }
}