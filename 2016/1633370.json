{
 "awd_id": "1633370",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "BIGDATA: Collaborative Research: F: Efficient and Exact Methods for Big Data Reduction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2022-08-31",
 "tot_intn_awd_amt": 499653.0,
 "awd_amount": 499653.0,
 "awd_min_amd_letter_date": "2016-09-07",
 "awd_max_amd_letter_date": "2021-09-22",
 "awd_abstract_narration": "Research in big data involves analyzing growing data sets with huge numbers of samples, very high-dimensional feature vectors, and complex and diverse structures. The ever-growing volume and complexity of these data sets make many traditional techniques inadequate to extract knowledge from them. An emerging area, known as sparse learning, has achieved great success in learning from big data by identifying a small set of explanatory features and/or samples. Typical examples include selecting features that are most indicative of users? preferences for recommendation systems, identifying brain regions that are predictive of neurological disorders based on imaging data, and extracting semantic information from raw images for object recognition. However, training sparse learning models can be computationally prohibitive due to the sparsity-inducing regularization, which is non-smooth and can be highly complex when incorporating complex structures. This project aims at developing algorithms and tools to significantly accelerate the training process of sparse learning models for big data applications. The key idea is to efficiently identify redundant features and/or samples, which can be removed from the training phase without losing useful information of interests. Success in these unique techniques is expected to dramatically scaling up sparse learning for big data by orders of magnitude in terms of both time and space. The PIs plan to integrate the big data reduction tools developed in this project into their education and outreach activities, including development of new courses and integration of project components into existing courses. The PIs will make special efforts to recruit female and underrepresented students to this project.\r\n\r\nThe major technical innovations of this project include the following components: (1) the PIs will develop efficient feature reduction methods for the generic scenario where the structures of both input and output can be represented by directed acyclic graphs; the proposed formulations include many existing approaches as special cases; (2) the PIs will develop efficient methods to reduce the numbers of features and samples simultaneously under a unified formulation, which can also incorporate various structures; (3) the PIs will develop efficient methods to discard irrelevant data subspaces to accelerate the process of uncovering low-rank structures commonly seen in big data. All the proposed data reduction methods are exact, i.e., the models learned on the reduced data sets are identical to the ones learned on the full data sets. This project heavily relies on optimization theory, especially on sensitivity analysis and convex geometry. The outcome of this project includes a unified approach to accelerate sparse learning and provide a systematic framework for developing efficient and exact data reduction methods. The systematic study and in-depth exploration of redundant data identification is expected to deepen the understanding of sparse learning techniques and dramatically enhance their applications in big data analytics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Qiaozhu",
   "pi_last_name": "Mei",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Qiaozhu Mei",
   "pi_email_addr": "qmei@umich.edu",
   "nsf_id": "000537865",
   "pi_start_date": "2017-08-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Jie",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jie Wang",
   "pi_email_addr": "jwangumi@umich.edu",
   "nsf_id": "000703900",
   "pi_start_date": "2016-09-07",
   "pi_end_date": "2017-08-25"
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "808300",
   "pgm_ele_name": "Big Data Science &Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8083",
   "pgm_ref_txt": "Big Data Science &Engineering"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 499653.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-0ba20983-7fff-c931-9777-91d582063a76\"> <span id=\"docs-internal-guid-660d9ad7-7fff-6365-aabb-95303727ce4e\">\n<p dir=\"ltr\"><span>We developed a family of computational methods to process and analyze large-scale, high-dimensional data that have rich and complex structures. These new techniques either reduce the size or the complexity of the data to a manageable scale before feeding them into a machine learning algorithm, or they utilize the sparse graph structures in the data to improve the performance of the machine learning tasks.&nbsp; These methods successfully construct sparse graphs from real world data, characterize and analyze these graphs, train neural networks to make predictions about the nodes, edges, and entire graphs, and analyze the fairness and robustness of the predictions.&nbsp;&nbsp;</span></p>\n<p dir=\"ltr\"><span>Methods developed in this project are applied to various data science tasks, to generate explanations for the decisions of complex neural network models, to generate simplified and readable versions of complex text,&nbsp; to utilize knowledge graphs to filter effective features for various text mining tasks, and to use emojis as sparse representations of rich emotions in text. These techniques share one common theme: to select or generate sparse and simplified representations of real world data, as alternatives of the dense and complex originals, to maintain or improve the performance of downstream machine learning tasks. These techniques have improved the performance of big data analytics in multiple real world scenarios such as social media moderation, text simplification, medical text mining, sentiment classification, emotion sensing at remote work, air quality prediction, and drug discovery.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Research work in this project has generated more than 30 publications in prestigious journals and peer-reviewed conferences, such as the International Conference on Machine Learning, Neural Information Processing Systems, and the ACM Web Conference (including winning a Best Long Paper Award there).&nbsp; Research results of the project have been disseminated to the broad audience through technical talks at academic institutes and companies, invited talks at conferences and workshops, articles covered by multiple news media outlets, tutorials for researchers from multiple disciplines, as well as introductory talks to high school students. Many of the techniques, data sets, and materials have been open sourced and disseminated through the scientific publications. The PI&rsquo;s team has created a dataset that contains COVID-19 related Tweets since the start of the pandemic and disseminated it through the Michigan Institute for Data Science, which has been widely used by researchers at the University of Michigan.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Research results of the project have also been integrated into education. More than 10 doctoral, masters, and undergraduate students have participated in the project, advanced their knowledge and training in data science, and moved on to the next era of their careers in academia, industry, or graduate programs. The PI has directed the development of one of the first online master degree programs at the University of Michigan, Master of Applied Data Science, through which over a thousand students have been trained with end-to-end data science skills. The PI himself has taught three core courses as well as the Capstone course in the program. Multiple components in these courses, which were highly reviewed by the students, have directly covered data sets, research tasks, and the state-of-the-art methods from this project.</span></p>\n<span>Through working on this project, we have enhanced our end-to-end view of the broader field of data science, especially from a human-centered perspective.&nbsp; We consider that it is critical for the research community to work together and contribute richer and more diverse benchmarks for the related research tasks, especially graph learning. We have taken the initiative to organize multiple workshops along this direction and have designed a benchmark curation platform for graph learning (namely the </span><span>Graph Learning Indexer</span><span>) that is curator-friendly.&nbsp; </span></span>\n<p dir=\"ltr\">&nbsp;</p>\n</span></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/13/2023<br>\n\t\t\t\t\tModified by: Qiaozhu&nbsp;Mei</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nWe developed a family of computational methods to process and analyze large-scale, high-dimensional data that have rich and complex structures. These new techniques either reduce the size or the complexity of the data to a manageable scale before feeding them into a machine learning algorithm, or they utilize the sparse graph structures in the data to improve the performance of the machine learning tasks.  These methods successfully construct sparse graphs from real world data, characterize and analyze these graphs, train neural networks to make predictions about the nodes, edges, and entire graphs, and analyze the fairness and robustness of the predictions.  \nMethods developed in this project are applied to various data science tasks, to generate explanations for the decisions of complex neural network models, to generate simplified and readable versions of complex text,  to utilize knowledge graphs to filter effective features for various text mining tasks, and to use emojis as sparse representations of rich emotions in text. These techniques share one common theme: to select or generate sparse and simplified representations of real world data, as alternatives of the dense and complex originals, to maintain or improve the performance of downstream machine learning tasks. These techniques have improved the performance of big data analytics in multiple real world scenarios such as social media moderation, text simplification, medical text mining, sentiment classification, emotion sensing at remote work, air quality prediction, and drug discovery. \nResearch work in this project has generated more than 30 publications in prestigious journals and peer-reviewed conferences, such as the International Conference on Machine Learning, Neural Information Processing Systems, and the ACM Web Conference (including winning a Best Long Paper Award there).  Research results of the project have been disseminated to the broad audience through technical talks at academic institutes and companies, invited talks at conferences and workshops, articles covered by multiple news media outlets, tutorials for researchers from multiple disciplines, as well as introductory talks to high school students. Many of the techniques, data sets, and materials have been open sourced and disseminated through the scientific publications. The PI\u2019s team has created a dataset that contains COVID-19 related Tweets since the start of the pandemic and disseminated it through the Michigan Institute for Data Science, which has been widely used by researchers at the University of Michigan. \nResearch results of the project have also been integrated into education. More than 10 doctoral, masters, and undergraduate students have participated in the project, advanced their knowledge and training in data science, and moved on to the next era of their careers in academia, industry, or graduate programs. The PI has directed the development of one of the first online master degree programs at the University of Michigan, Master of Applied Data Science, through which over a thousand students have been trained with end-to-end data science skills. The PI himself has taught three core courses as well as the Capstone course in the program. Multiple components in these courses, which were highly reviewed by the students, have directly covered data sets, research tasks, and the state-of-the-art methods from this project.\nThrough working on this project, we have enhanced our end-to-end view of the broader field of data science, especially from a human-centered perspective.  We consider that it is critical for the research community to work together and contribute richer and more diverse benchmarks for the related research tasks, especially graph learning. We have taken the initiative to organize multiple workshops along this direction and have designed a benchmark curation platform for graph learning (namely the Graph Learning Indexer) that is curator-friendly.  \n \n\n\n\t\t\t\t\tLast Modified: 01/13/2023\n\n\t\t\t\t\tSubmitted by: Qiaozhu Mei"
 }
}