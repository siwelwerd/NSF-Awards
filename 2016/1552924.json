{
 "awd_id": "1552924",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Ubiquitous Sensing Using Computational Light",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alexander Sprintson",
 "awd_eff_date": "2016-03-01",
 "awd_exp_date": "2022-02-28",
 "tot_intn_awd_amt": 542403.0,
 "awd_amount": 542403.0,
 "awd_min_amd_letter_date": "2016-02-25",
 "awd_max_amd_letter_date": "2020-04-07",
 "awd_abstract_narration": "The ability to sense and detect human movement is critical to the development of data-driven mobile health systems. It can help detect disease and foster behavioral changes to cultivate healthy lifestyles. Existing sensing technologies either require users to constantly wear or carry on-body potentially cumbersome devices, are vulnerable to electromagnetic interference, or present severe privacy risks involving leaking of sensitive data and images. This project takes a entirely different approach to addressing these issues. It exploits the use of ubiquitous light as a low-cost, unobtrusive, and accurate sensing medium capable of simultaneously sensing people and their surrounding context. The proposed vision \" LightSense \" consists of off-the-shelf LED lights on the ceiling and a few low-cost photodiode sensors sprinkled in the environment. The photodiodes passively capture light blockage created by the human body and reconstruct fine-grained user behaviors in real time. LightSense leverages light to turn a space into a cognitive space, which recognizes our presence, senses our behaviors such as postures and high-level activities while monitoring our health status indicators such as levels of stress. \r\n\r\nLightSense is empowered by Visible Light Communication (VLC) that turns the visible light into computational light. It contains the following novel systems and algorithmic designs: 1) a novel VLC network architecture with LED panels and sparse photodiodes to ease system deployment; 2) algorithmic and systems designs to separate light rays from dense LEDs, optimize the placement of photodiodes, and overcome the blockage of other objects (e.g., furniture, other users); 3) a new VLC primitive that allows light communication and sensing to be sustained even under extremely low light conditions; and 4) learning algorithms to infer physical activities, derive movement characteristics, and monitor psychological state. LightSense will be evaluated using real-scale testbeds and user studies. Results from this project will establish the foundational pieces to define a new research space (visible light sensing), and will generate far-reaching impact on promoting innovative interaction designs and enabling new types of precise health monitoring.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xia",
   "pi_last_name": "Zhou",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xia Zhou",
   "pi_email_addr": "xia@cs.columbia.edu",
   "nsf_id": "000659637",
   "pi_start_date": "2016-02-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Dartmouth College",
  "inst_street_address": "7 LEBANON ST",
  "inst_street_address_2": "",
  "inst_city_name": "HANOVER",
  "inst_state_code": "NH",
  "inst_state_name": "New Hampshire",
  "inst_phone_num": "6036463007",
  "inst_zip_code": "037552170",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "NH02",
  "org_lgl_bus_name": "TRUSTEES OF DARTMOUTH COLLEGE",
  "org_prnt_uei_num": "T4MWFG59C6R3",
  "org_uei_num": "EB8ASJBCFER9"
 },
 "perf_inst": {
  "perf_inst_name": "Dartmouth College",
  "perf_str_addr": "6211 Sudikoff Laboratory",
  "perf_city_name": "Hanover",
  "perf_st_code": "NH",
  "perf_st_name": "New Hampshire",
  "perf_zip_code": "037553510",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "NH02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  },
  {
   "pgm_ele_code": "736300",
   "pgm_ele_name": "Networking Technology and Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 97789.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 149738.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 56221.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 116954.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 121701.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The overall goal is to advance the state of art on human behavioral sensing and object tracking by exploring a new sensing paradigm that exploits ubiquitous visible light to sense users/objects and their contextual information.&nbsp;<br /><br />== Intellectual merits&nbsp;<br />During the project period, the team have made following intellectual contributions.&nbsp;<br />1. Human sensing<br />1) The design, implementation, and evaluation of a light sensing system that reconstructs skeleton poses in real time, without needing cameras or on-body sensors. The optimization of photodiode placement to mitigate the impact of furniture blockage on light sensing. Refinement on the skeleton pose reconstruction algorithm to deal with a mobile user with unknown orientation and location.&nbsp;&nbsp;<br />2) Algorithmic design to enable the reconstruction of hand skeleton poses using a table lamp augmented by light sensing. It consists of an LED panel inside the lampshade and a grid of 16 low-cost photodiodes embedded in the lamp base.&nbsp;<br />3) The design, implementation, and evaluation of a self-powered module that reuses ambient light for both finger gesture sensing and energy harvesting. It consists of arrays of photodiodes operating in the photovoltaic mode, harvesting energy from ambient light while recognizing finger gestures based on changes in instantaneously harvested power. Recognition algorithm was designed to enable robust gesture recognition in diverse ambient light settings.&nbsp;<br />4) The design, implementation, and evaluation of battery-free light sensing systems that track gaze direction and pupil movement/size. Novel hardware designs to sense light reflected by the eye while addressing ambient light dynamics. Algorithmic designs and machine learning models to address user diversity and adapt system's sensing frequency.&nbsp;<br />5) The design, implementation, and evaluation of a wearable technology that uses near-infrared light to sense body distance and relative body orientation during face-to-face social interactions. A fusion algorithm is designed to fuse light signals and inertial sensor readings to improve sensing robustness.&nbsp;<br />6) The design, implementation, and evaluation of an ear-worn system that detects faces touches in sensitive/muscosal zones. It combines thermal infrared sensing to detect an approaching hand and physiological sensing to detect impedance changes caused by skin deformation during a touch. A convolutional neural network model is developed for multi-modal sensing.<br /><br />2. Object Sensing/Tracking&nbsp;<br />1) Integration of light and inertial sensing to achieve accurate and robust object tracking. A novel light cover design casts polarization patterns in the space and provide external landmarks for calibrating inertial sensor's drift errors.&nbsp;<br />2) The design, implementation, and evaluation of a novel optical tag design that is passive and imperceptible. Algorithmic designs encode data while dealing with partial occlusion, detect the tag from background scenery, and decode data against ambient light interference and off-axis viewing.&nbsp;<br />3) The design, implementation, and evaluation of a laser-based localization technique that allows an aerial drone to directly locate underwater robots without any relays on water's surface. A novel optic-fiber sensing ring senses extremely-weak retro-reflected light from the underwater robot. A pin-hole based incident angle sensing scheme deals with the sensing skew at the air-water boundary. A laser-optimized backscatter communication modulates retro-reflected light to send back robot's angle and depth information.&nbsp;<br /><br />== Broad impacts<br />Research outcomes have been disseminated 15 publications in top conferences and workshops. The project has also led to one technical report and two PhD theses. Results have also been integrated into PI's courses.&nbsp;<br /><br />They have triggered or been cited by active follow-up works.&nbsp;Dataset, source code, and demo video are available at project website: http://dartnets.cs.dartmouth.edu/career<br /><br />Project demo videos were produced and disseminated in the lab YouTuble channel: https://www.youtube.com/channel/UCQhj_t5VL-SnOAj24EJcwaw&nbsp;<br /><br />Research results have been disseminated in PI's 13 seminar talks, 5 keynotes, and 5 invited talks. The project has provided opportunities to train 1 post-doc researcher, 5 PhD students, 4 Master students, and 10 undergraduate students.<br /><br />The team have broadly disseminated results in local community and engaged the public.&nbsp;<br />- In 2016, the PI participated in Workshop on Exploring Graduate Study in Computer Science and delivered a talk on light communication and sensing to a group of 20 undergraduate students.<br />- In 2016, 2017, and 2019, the PI participated in the Hour of Code session at the local Ray Elementary School , for 40+ Grade-5 students, 87 Grade-5 students, and 89 Grade-4 students, respectively.&nbsp;<br />- In February 2019, the PI participated in the 2nd Annual \"Introduce a Girl to an Engineer\" day at the American Precision Museum in Windsor, Vermont, where the PI introduced the concept of light communication and sensing.&nbsp;<br />- In March 2019, project results are featured in an NSF Science Nation video (https://www.nsf.gov/news/special_reports/science_nation/visiblelightcommunication.jsp).&nbsp;<br />- In April 2019, the PI delivered a keynote introducing the research of this project at the 2019 TechWomen | TechGirls annual awards luncheon, the New Hampshire Tech Alliance.<br />- In October 2019, the PI has disseminated the results via the STEM Pathways program at Hanover High School. The PI introduced the concept of light communication and sensing to 20+ high school students.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/23/2022<br>\n\t\t\t\t\tModified by: Xia&nbsp;Zhou</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe overall goal is to advance the state of art on human behavioral sensing and object tracking by exploring a new sensing paradigm that exploits ubiquitous visible light to sense users/objects and their contextual information. \n\n== Intellectual merits \nDuring the project period, the team have made following intellectual contributions. \n1. Human sensing\n1) The design, implementation, and evaluation of a light sensing system that reconstructs skeleton poses in real time, without needing cameras or on-body sensors. The optimization of photodiode placement to mitigate the impact of furniture blockage on light sensing. Refinement on the skeleton pose reconstruction algorithm to deal with a mobile user with unknown orientation and location.  \n2) Algorithmic design to enable the reconstruction of hand skeleton poses using a table lamp augmented by light sensing. It consists of an LED panel inside the lampshade and a grid of 16 low-cost photodiodes embedded in the lamp base. \n3) The design, implementation, and evaluation of a self-powered module that reuses ambient light for both finger gesture sensing and energy harvesting. It consists of arrays of photodiodes operating in the photovoltaic mode, harvesting energy from ambient light while recognizing finger gestures based on changes in instantaneously harvested power. Recognition algorithm was designed to enable robust gesture recognition in diverse ambient light settings. \n4) The design, implementation, and evaluation of battery-free light sensing systems that track gaze direction and pupil movement/size. Novel hardware designs to sense light reflected by the eye while addressing ambient light dynamics. Algorithmic designs and machine learning models to address user diversity and adapt system's sensing frequency. \n5) The design, implementation, and evaluation of a wearable technology that uses near-infrared light to sense body distance and relative body orientation during face-to-face social interactions. A fusion algorithm is designed to fuse light signals and inertial sensor readings to improve sensing robustness. \n6) The design, implementation, and evaluation of an ear-worn system that detects faces touches in sensitive/muscosal zones. It combines thermal infrared sensing to detect an approaching hand and physiological sensing to detect impedance changes caused by skin deformation during a touch. A convolutional neural network model is developed for multi-modal sensing.\n\n2. Object Sensing/Tracking \n1) Integration of light and inertial sensing to achieve accurate and robust object tracking. A novel light cover design casts polarization patterns in the space and provide external landmarks for calibrating inertial sensor's drift errors. \n2) The design, implementation, and evaluation of a novel optical tag design that is passive and imperceptible. Algorithmic designs encode data while dealing with partial occlusion, detect the tag from background scenery, and decode data against ambient light interference and off-axis viewing. \n3) The design, implementation, and evaluation of a laser-based localization technique that allows an aerial drone to directly locate underwater robots without any relays on water's surface. A novel optic-fiber sensing ring senses extremely-weak retro-reflected light from the underwater robot. A pin-hole based incident angle sensing scheme deals with the sensing skew at the air-water boundary. A laser-optimized backscatter communication modulates retro-reflected light to send back robot's angle and depth information. \n\n== Broad impacts\nResearch outcomes have been disseminated 15 publications in top conferences and workshops. The project has also led to one technical report and two PhD theses. Results have also been integrated into PI's courses. \n\nThey have triggered or been cited by active follow-up works. Dataset, source code, and demo video are available at project website: http://dartnets.cs.dartmouth.edu/career\n\nProject demo videos were produced and disseminated in the lab YouTuble channel: https://www.youtube.com/channel/UCQhj_t5VL-SnOAj24EJcwaw \n\nResearch results have been disseminated in PI's 13 seminar talks, 5 keynotes, and 5 invited talks. The project has provided opportunities to train 1 post-doc researcher, 5 PhD students, 4 Master students, and 10 undergraduate students.\n\nThe team have broadly disseminated results in local community and engaged the public. \n- In 2016, the PI participated in Workshop on Exploring Graduate Study in Computer Science and delivered a talk on light communication and sensing to a group of 20 undergraduate students.\n- In 2016, 2017, and 2019, the PI participated in the Hour of Code session at the local Ray Elementary School , for 40+ Grade-5 students, 87 Grade-5 students, and 89 Grade-4 students, respectively. \n- In February 2019, the PI participated in the 2nd Annual \"Introduce a Girl to an Engineer\" day at the American Precision Museum in Windsor, Vermont, where the PI introduced the concept of light communication and sensing. \n- In March 2019, project results are featured in an NSF Science Nation video (https://www.nsf.gov/news/special_reports/science_nation/visiblelightcommunication.jsp). \n- In April 2019, the PI delivered a keynote introducing the research of this project at the 2019 TechWomen | TechGirls annual awards luncheon, the New Hampshire Tech Alliance.\n- In October 2019, the PI has disseminated the results via the STEM Pathways program at Hanover High School. The PI introduced the concept of light communication and sensing to 20+ high school students.\n\n\t\t\t\t\tLast Modified: 05/23/2022\n\n\t\t\t\t\tSubmitted by: Xia Zhou"
 }
}