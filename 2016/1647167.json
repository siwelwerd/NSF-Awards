{
 "awd_id": "1647167",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "US Ignite: Collaborative Research: Focus Area 1: Fleet Management of Large-Scale Connected and Autonomous Vehicles in Urban Settings",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2017-01-01",
 "awd_exp_date": "2020-12-31",
 "tot_intn_awd_amt": 299359.0,
 "awd_amount": 299359.0,
 "awd_min_amd_letter_date": "2016-09-07",
 "awd_max_amd_letter_date": "2016-09-07",
 "awd_abstract_narration": "The massive deployment of autonomous vehicles on public roadway systems is now on the horizon, and will undoubtedly revolutionize the transportation ecosystem in the near future. Though autonomous vehicles hold much promise, major hurdles, such as safety and efficiency, must be first overcome. For example, if an autonomous vehicle runs into a heavy storm, the functioning of the GPS system or the sensing systems might be degraded. Therefore, the vehicle must incorporate substantial situational awareness by taking advantage of real-time data from the transportation infrastructure or other vehicles. This award supports fundamental research on large-scale fleet management/coordination in extreme/complex urban driving scenarios. In addition, an advanced wireless infrastructure is initiated for next-generation vehicular communications with extremely low-latency requirements and severe data demand. The gigabit fiber optic networks available in Chattanooga, TN will serve as a backbone for such an infrastructure. Connected autonomous vehicles together with the gigabit wireless/wired connections can change urban dynamics and may eventually lead to Smart & Connected Communities. The award can also foster workforce development, engineering education, and multi-disciplinary research.\r\n\r\nThe objective of this proposal is to investigate fleet management/coordination of large-scale connected autonomous vehicles, fully explore unprecedented opportunities brought by such vehicles, and address the corresponding challenges. An advanced wireless infrastructure, which integrates Dedicated Short Range Communications (DSRC) with urban ultra-dense small cells, will be explored together with prescriptive analytics, dynamic spectrum access for millimeter wave communications, and innovative computing paradigms to substantially improve broadband connectivity for connected autonomous vehicles in terms of latency, throughput, and reliability. Real-time fleet management will be enabled by broadband multimedia streaming and sensor data sharing. Based on advanced wireless communications, the research team will study cooperative sensing and mobility of connected autonomous vehicles in extreme/complex urban driving scenarios, which fills a gap in the existing research with a focus only on a single autonomous vehicle or a small number of connected vehicles under normal driving conditions. Finally, pilot studies will be performed and novel application prototypes will be demonstrated in both Atlanta and Chattanooga with support from government and industry partners.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Alexander",
   "pi_last_name": "Samoylov",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Alexander Samoylov",
   "pi_email_addr": "alexander.samoylov@gtri.gatech.edu",
   "nsf_id": "000719514",
   "pi_start_date": "2016-09-07",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Gary",
   "pi_last_name": "McMurray",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Gary McMurray",
   "pi_email_addr": "Gary.McMurray@gtri.gatech.edu",
   "nsf_id": "000602413",
   "pi_start_date": "2016-09-07",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Applied Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH APPLIED RESEARCH CORP",
  "org_prnt_uei_num": "L3G5SBQ2PLK5",
  "org_uei_num": "L3G5SBQ2PLK5"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Tech Applied Research Corporation",
  "perf_str_addr": "925 Dalney Street",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "289000",
   "pgm_ele_name": "CISE Research Resources"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "015Z",
   "pgm_ref_txt": "US Ignite"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 299359.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>To create a safer, less congested, and more efficient mobility operating environment, the teams from the University of Tennessee at Chattanooga and the Georgia Tech Research Institute explored the concept of cooperative sensing and cooperative mobility. Typical vehicles capable of sensing surrounding environments rely on sensors that can sense within the line of sight of the sensor. If the line of sight is broken the vehicle might lose awareness of what happens beyond the sensing field of view. Even a bus that stopped on the side of the road can significantly impede the sensory data collection, not to mention the presence of buildings or road curvature or changing road grade. However, to efficiently and safely navigate and operate vehicles need to be aware of changing conditions not only next to the vehicle but also at some distance on the route. To address this problem, we introduce the concepts of cooperative sensing and cooperative mobility, which use streams of data from multiple sensors to work together to provide united information for the users. The data collected from cooperative sensing and cooperative mobility is creating safer driving environments by collecting information about current road conditions and using Inter-Vehicle Communications (IVC), Vehicle-to-Infrastructure Communications (V2I), and Infrastructure-to-Vehicle Communications (I2V) to propagate the information throughout the fleet.</p>\n<p>Our research has addressed three major research questions to tackle problems related to connected automated vehicles in urban environments: 1) How to take advantage of connectivity to improve transportation performance in terms of mobility, safety, and reliability, 2) Which wireless communication technologies to adopt while taking advantage of the 10Gbps fiber optic network available in Chattanooga, TN, and 3) How to implement and evaluate the proposed system in a real-world setting. In order to answer those questions we devised several tasks:</p>\n<p>a. Cooperative Sensing for Real-Time Traffic Monitoring and Scene Understanding</p>\n<p>b. Cooperative Mobility for Optimal Routing</p>\n<p>c. Pilot Studies and Early Demonstrations in Downtown Chattanooga, TN.</p>\n<p>The project was done jointly in collaboration with community members in Chattanooga including the City of Chattanooga, Chattanooga Department of Transportation (CDOT), EPB (Chattanooga&rsquo;s electric power distribution and telecommunications company), and the Enterprise Center (TEC). For a) we have developed a novel event-driven data architecture and a web portal to ingest and store streaming real-time and historical data from the environment surrounding the vehicle or the user. Then we developed several algorithms to process data (computer vision, LiDAR processing, object tracing, object re-identification) from several sources to build a holistic view of urban traffic and gain enough knowledge about interactions in the specific scene area to improve public safety, transportation management, and vehicle control. For b) we have created routing based on the real-time data from the previous task and simulated future conditions based on the data to assign the most optimal route. In addition, we implemented a re-routing function that can reroute vehicles based on road blockages gathered by real-time, computer vision data. There are some real-time dynamic changes on the route such as accidents, road construction, or debris on the road that might affect the driver experience. Although some collect user-reported data from its application it only uses GPS coordinates emitted from mobile devices to plot users and locations of interest. The approach explored for this project is to provide systematic real-time data collection from the vehicles or roadside sensor units to more fully and accurately represent the route conditions and display them to users. For c) in collaboration with the City of Chattanooga, Chattanooga Department of Transportation (CDOT), EPB (Chattanooga&rsquo;s electric power distribution and telecommunications company), and the Enterprise Center (TEC), we have established a smart corridor along the M.L. King Boulevard (next to UTC campus) as an urban testbed. The MLK Smart Corridor is part of the city&rsquo;s dense and walkable urban core. With bike and car share stations, bike lanes, and transit stops, this area allowed us to validate results in a city-scale environment. The MLK Smart Corridor extends over 1.25 miles and consists of 10 signalized intersections, each containing some combination of the following: (1) Sensors: 1080p cameras, 4k cameras, air quality sensors, and audio sensors. (2) EDGE Computing: Nvidia Jetson TX2 and Raspberry Pi. (3) Communication capabilities: WiFi, DSRC, LoRa Gateways, and fiber-optic network. The poles are backhauled via the existing EPB&rsquo;s city-wide 10Gbps fiber network, allowing data transmission at the low latency and high throughput needed for real-time processes.&nbsp; We then created a mobile application that fuses data from the MLK Smart Corridor and applies different machine learning to create an all-in-one detection and routing mobile application that displays a holistic view of the user&rsquo;s environment, including pedestrian locations, which gives the user a better understanding of their surrounding area beyond their physical field of view.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/23/2021<br>\n\t\t\t\t\tModified by: Alexander&nbsp;Samoylov</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nTo create a safer, less congested, and more efficient mobility operating environment, the teams from the University of Tennessee at Chattanooga and the Georgia Tech Research Institute explored the concept of cooperative sensing and cooperative mobility. Typical vehicles capable of sensing surrounding environments rely on sensors that can sense within the line of sight of the sensor. If the line of sight is broken the vehicle might lose awareness of what happens beyond the sensing field of view. Even a bus that stopped on the side of the road can significantly impede the sensory data collection, not to mention the presence of buildings or road curvature or changing road grade. However, to efficiently and safely navigate and operate vehicles need to be aware of changing conditions not only next to the vehicle but also at some distance on the route. To address this problem, we introduce the concepts of cooperative sensing and cooperative mobility, which use streams of data from multiple sensors to work together to provide united information for the users. The data collected from cooperative sensing and cooperative mobility is creating safer driving environments by collecting information about current road conditions and using Inter-Vehicle Communications (IVC), Vehicle-to-Infrastructure Communications (V2I), and Infrastructure-to-Vehicle Communications (I2V) to propagate the information throughout the fleet.\n\nOur research has addressed three major research questions to tackle problems related to connected automated vehicles in urban environments: 1) How to take advantage of connectivity to improve transportation performance in terms of mobility, safety, and reliability, 2) Which wireless communication technologies to adopt while taking advantage of the 10Gbps fiber optic network available in Chattanooga, TN, and 3) How to implement and evaluate the proposed system in a real-world setting. In order to answer those questions we devised several tasks:\n\na. Cooperative Sensing for Real-Time Traffic Monitoring and Scene Understanding\n\nb. Cooperative Mobility for Optimal Routing\n\nc. Pilot Studies and Early Demonstrations in Downtown Chattanooga, TN.\n\nThe project was done jointly in collaboration with community members in Chattanooga including the City of Chattanooga, Chattanooga Department of Transportation (CDOT), EPB (Chattanooga\u2019s electric power distribution and telecommunications company), and the Enterprise Center (TEC). For a) we have developed a novel event-driven data architecture and a web portal to ingest and store streaming real-time and historical data from the environment surrounding the vehicle or the user. Then we developed several algorithms to process data (computer vision, LiDAR processing, object tracing, object re-identification) from several sources to build a holistic view of urban traffic and gain enough knowledge about interactions in the specific scene area to improve public safety, transportation management, and vehicle control. For b) we have created routing based on the real-time data from the previous task and simulated future conditions based on the data to assign the most optimal route. In addition, we implemented a re-routing function that can reroute vehicles based on road blockages gathered by real-time, computer vision data. There are some real-time dynamic changes on the route such as accidents, road construction, or debris on the road that might affect the driver experience. Although some collect user-reported data from its application it only uses GPS coordinates emitted from mobile devices to plot users and locations of interest. The approach explored for this project is to provide systematic real-time data collection from the vehicles or roadside sensor units to more fully and accurately represent the route conditions and display them to users. For c) in collaboration with the City of Chattanooga, Chattanooga Department of Transportation (CDOT), EPB (Chattanooga\u2019s electric power distribution and telecommunications company), and the Enterprise Center (TEC), we have established a smart corridor along the M.L. King Boulevard (next to UTC campus) as an urban testbed. The MLK Smart Corridor is part of the city\u2019s dense and walkable urban core. With bike and car share stations, bike lanes, and transit stops, this area allowed us to validate results in a city-scale environment. The MLK Smart Corridor extends over 1.25 miles and consists of 10 signalized intersections, each containing some combination of the following: (1) Sensors: 1080p cameras, 4k cameras, air quality sensors, and audio sensors. (2) EDGE Computing: Nvidia Jetson TX2 and Raspberry Pi. (3) Communication capabilities: WiFi, DSRC, LoRa Gateways, and fiber-optic network. The poles are backhauled via the existing EPB\u2019s city-wide 10Gbps fiber network, allowing data transmission at the low latency and high throughput needed for real-time processes.  We then created a mobile application that fuses data from the MLK Smart Corridor and applies different machine learning to create an all-in-one detection and routing mobile application that displays a holistic view of the user\u2019s environment, including pedestrian locations, which gives the user a better understanding of their surrounding area beyond their physical field of view.\n\n\t\t\t\t\tLast Modified: 04/23/2021\n\n\t\t\t\t\tSubmitted by: Alexander Samoylov"
 }
}