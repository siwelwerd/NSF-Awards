{
 "awd_id": "1632793",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Single Observation Simulation Optimization",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": "7032922443",
 "po_email": "gaklutke@nsf.gov",
 "po_sign_block_name": "Georgia-Ann Klutke",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 294548.0,
 "awd_amount": 294548.0,
 "awd_min_amd_letter_date": "2016-07-18",
 "awd_max_amd_letter_date": "2016-07-18",
 "awd_abstract_narration": "Many systems in diverse areas, spanning engineering, economics, computer science, business and biological science, rely on optimizing the performance of the system to choose design or decision variables.  In these complex systems, the system performance is typically observed numerically by running a computer discrete-event simulation many times to both estimate the performance of the system and explore the design space to determine the optimal values of the variables. Striking a balance between exploration of new points and estimation of potentially good points is critical for computationally efficient algorithms. Ideally one would perform exactly one simulation per design point, or single observation simulation optimization. This award supports fundamental research in proving that it is possible to estimate the objective function at a point by averaging observed values from nearby points. The research will lead to new algorithms with theoretical foundations that potentially change the way a diverse set of users make system-wide decisions. The PIs are committed to fostering diversity and will recruit and mentor underrepresented groups, and participate in the Women in Science and Engineering program and the summer Minority Scholars Engineering Program at the University of Washington.\r\n \r\nThe idea of simulating a single observation per design has roots in classic stochastic approximation algorithms, although their convergence proofs were to a local optimum. Since we do not presume that the objective function for a simulated system is convex, we seek a global optimum. Previous research introduced the idea of estimating the objective function at a specific design point using other designs within shrinking balls around it, thus never repeating a simulation at a design vector. However, the analysis assumed that the optimization algorithm generated independently sampled random points, thus avoiding dependencies among errors. However, the computational performance of such non-adaptive algorithms is known to scale badly (e.g., exponentially) in terms of the dimension of the problem. If successful, this award will help create a class of adaptive random search algorithms that converge to a global optimum in probability using a single observation per candidate point. The challenge is in accounting for the complex dependencies and their influence in exploring new candidates. By eliminating inherent biases in adaptive algorithms, the new methodology will contribute to intellectual merit by integrating optimization and simulation for convergent global algorithms with theoretical foundations.  By decreasing computational effort, a broad range of applications will benefit by being able to optimize system performance.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zelda",
   "pi_last_name": "Zabinsky",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Zelda B Zabinsky",
   "pi_email_addr": "zelda@u.washington.edu",
   "nsf_id": "000430964",
   "pi_start_date": "2016-07-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Robert",
   "pi_last_name": "Smith",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Robert L Smith",
   "pi_email_addr": "rlsmith@umich.edu",
   "nsf_id": "000421605",
   "pi_start_date": "2016-07-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Washington",
  "inst_street_address": "4333 BROOKLYN AVE NE",
  "inst_street_address_2": "",
  "inst_city_name": "SEATTLE",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "2065434043",
  "inst_zip_code": "981951016",
  "inst_country_name": "United States",
  "cong_dist_code": "07",
  "st_cong_dist_code": "WA07",
  "org_lgl_bus_name": "UNIVERSITY OF WASHINGTON",
  "org_prnt_uei_num": "",
  "org_uei_num": "HD1WMN6945W6"
 },
 "perf_inst": {
  "perf_inst_name": "University of Washington",
  "perf_str_addr": "Industrial and Systems Engr Dept",
  "perf_city_name": "Seattle",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "981952650",
  "perf_ctry_code": "US",
  "perf_cong_dist": "07",
  "perf_st_cong_dist": "WA07",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "006Y00",
   "pgm_ele_name": "OE Operations Engineering"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "071E",
   "pgm_ref_txt": "MFG ENTERPRISE OPERATIONS"
  },
  {
   "pgm_ref_code": "072E",
   "pgm_ref_txt": "NETWORKS & QUEUING SYSTEMS"
  },
  {
   "pgm_ref_code": "073E",
   "pgm_ref_txt": "OPTIMIZATION & DECISION MAKING"
  },
  {
   "pgm_ref_code": "076E",
   "pgm_ref_txt": "SERVICE ENTERPRISE SYSTEMS"
  },
  {
   "pgm_ref_code": "077E",
   "pgm_ref_txt": "SIMULATION MODELS"
  },
  {
   "pgm_ref_code": "078E",
   "pgm_ref_txt": "ENTERPRISE DESIGN & LOGISTICS"
  },
  {
   "pgm_ref_code": "8023",
   "pgm_ref_txt": "Health Care Enterprise Systems"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 294548.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Complex systems are often modeled with computer simulations, which are used by decision makers to optimize design choices, resource allocation policies, and operational procedures. The challenge is to integrate optimization with simulation in a computationally efficient manner. This research has combined the search effort for optimization with statistical estimation of performance by running a single simulation at any design point, and averaging objective function values of nearby design points. This approach simultaneously estimates and explores as the algorithm progresses.&nbsp; A class of Single Observation Search Algorithms (SOSA) has been proven to satisfy convergence properties to a global optimum on a broad class of problems including continuous, integer, and mixed continuous-integer variables. This has broad impact by widening the class of algorithms that can be used for simulation optimization with theoretical properties.</p>\n<p>Empirical testing has established the effectiveness of several instances of SOSA. A combination of simulation optimization methods has been applied to problems in health care, including staffing, panel sizing and geographic location of physicians, where a discrete-event simulation models the flow of patients to seek medical care and accounts for uncertainty in wait times.&nbsp; Another application optimizes the operations across a water pump network for urban water distribution. And the research has recently explored integrating simulation optimization methods with deep learning in neural networks that preserves convergence properties.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/13/2019<br>\n\t\t\t\t\tModified by: Zelda&nbsp;B&nbsp;Zabinsky</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565311642426_SOSAfig--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565311642426_SOSAfig--rgov-800width.jpg\" title=\"Single Observation Search Algorithms (SOSA)\"><img src=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565311642426_SOSAfig--rgov-66x44.jpg\" alt=\"Single Observation Search Algorithms (SOSA)\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The class of single observation search algorithms (SOSA) estimates the function value at a point by averaging values of nearby points, instead of using multiple replications. This combines exploration with estimation. As the ball shrinks, the algorithm converges to a global optimum w.p.1.</div>\n<div class=\"imageCredit\">Zabinsky, Smith, Kiatsupaibul</div>\n<div class=\"imageSubmitted\">Zelda&nbsp;B&nbsp;Zabinsky</div>\n<div class=\"imageTitle\">Single Observation Search Algorithms (SOSA)</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565312220059_PBnBfig--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565312220059_PBnBfig--rgov-800width.jpg\" title=\"Probabilistic Branch and Bound (PBnB):  Approximation of a Level Set\"><img src=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565312220059_PBnBfig--rgov-66x44.jpg\" alt=\"Probabilistic Branch and Bound (PBnB):  Approximation of a Level Set\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Probabilistic Branch and Bound (PBnB) iteratively samples points and estimates quantiles with confidence intervals over boxes. PBnB classifies a box as inside or outside a target level set with confidence, or decides more points are needed. This provides a set of best solutions.</div>\n<div class=\"imageCredit\">Zabinsky, Huang</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Zelda&nbsp;B&nbsp;Zabinsky</div>\n<div class=\"imageTitle\">Probabilistic Branch and Bound (PBnB):  Approximation of a Level Set</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565312451579_PBnBNeuralNetsfig--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565312451579_PBnBNeuralNetsfig--rgov-800width.jpg\" title=\"Probabilistic Branch and Bound (PBnB) Applied  to Deep Neural Networks\"><img src=\"/por/images/Reports/POR/2019/1632793/1632793_10441787_1565312451579_PBnBNeuralNetsfig--rgov-66x44.jpg\" alt=\"Probabilistic Branch and Bound (PBnB) Applied  to Deep Neural Networks\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Use PBnB to obtain solutions that are globally optimum for deep neural networks.</div>\n<div class=\"imageCredit\">Zabinsky, Ho</div>\n<div class=\"imageSubmitted\">Zelda&nbsp;B&nbsp;Zabinsky</div>\n<div class=\"imageTitle\">Probabilistic Branch and Bound (PBnB) Applied  to Deep Neural Networks</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nComplex systems are often modeled with computer simulations, which are used by decision makers to optimize design choices, resource allocation policies, and operational procedures. The challenge is to integrate optimization with simulation in a computationally efficient manner. This research has combined the search effort for optimization with statistical estimation of performance by running a single simulation at any design point, and averaging objective function values of nearby design points. This approach simultaneously estimates and explores as the algorithm progresses.  A class of Single Observation Search Algorithms (SOSA) has been proven to satisfy convergence properties to a global optimum on a broad class of problems including continuous, integer, and mixed continuous-integer variables. This has broad impact by widening the class of algorithms that can be used for simulation optimization with theoretical properties.\n\nEmpirical testing has established the effectiveness of several instances of SOSA. A combination of simulation optimization methods has been applied to problems in health care, including staffing, panel sizing and geographic location of physicians, where a discrete-event simulation models the flow of patients to seek medical care and accounts for uncertainty in wait times.  Another application optimizes the operations across a water pump network for urban water distribution. And the research has recently explored integrating simulation optimization methods with deep learning in neural networks that preserves convergence properties.\n\n \n\n\t\t\t\t\tLast Modified: 08/13/2019\n\n\t\t\t\t\tSubmitted by: Zelda B Zabinsky"
 }
}