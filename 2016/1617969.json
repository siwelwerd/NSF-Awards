{
 "awd_id": "1617969",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Scalable Schema-Based Event Extraction",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 391188.0,
 "awd_amount": 391188.0,
 "awd_min_amd_letter_date": "2016-08-30",
 "awd_max_amd_letter_date": "2016-08-30",
 "awd_abstract_narration": "One of the major bottlenecks in current language understanding algorithms is the lack of commonsense knowledge about how the world works. When we communicate through language, we implicitly assume that the readers will use this common sense knowledge and make the necessary inferences.  Computers, on the other hand, do not have access to this shared common knowledge, and as a result are often unable to understand text well enough to perform important tasks such as question answering. This project will study methods to learn one type of common sense knowledge about event scenarios: the series of events (actions) and the types of entities involved. For example, an arrest scenario typically involves a crime event, and an arrest event, with an arresting agent (say police), a suspect, and possibly a victim of the crime. Language understanding algorithms need to be explicitly told to look for these specific types of events and entities. This approach does not scale to the many possible real world event scenarios. This project will develop machine learning algorithms that automatically acquire this type of knowledge covering a broad range of domains in large text collections. Such algorithms can form the basis of a wide variety of assistive technology that enables public access to information. Examples include the generation of schemas from historical documents to assist students in targeted learning about historical events, or extraction of events and actors involved in current world events from streaming news sources. More generally, access to the event structure of documents will enable better question answering capabilities that, embedded appropriately into search engines, can lead to a more informed public.\r\n\r\nThe project will pursue three central research thrusts to learning commonsense event schemas. The first thrust develops new probabilistic algorithms for inducing event schemas that represent real-world scenarios (e.g., a Suspect is arrested by Police, pleads to a Judge, and is later convicted). The second thrust will develop new models that extract instances of these learned schemas from text (e.g., John is the Suspect). This project is unique to previous work by formalizing these as separate tasks, and thus enabling deeper research into knowledge learning apart from traditional relation extraction. Finally, the third thrust will standardize potential evaluation frameworks for event schema research. Due to the young nature of this research area, formal evaluation and analysis is inconsistent across previous work. This project will produce the largest and most diverse set of event schemas through crowd-sourcing, enabling consistent and clear evaluation of future models.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Niranjan",
   "pi_last_name": "Balasubramanian",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Niranjan Balasubramanian",
   "pi_email_addr": "niranjan@cs.stonybrook.edu",
   "nsf_id": "000678413",
   "pi_start_date": "2016-08-30",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Stony Brook",
  "inst_street_address": "W5510 FRANKS MELVILLE MEMORIAL LIBRARY",
  "inst_street_address_2": "",
  "inst_city_name": "STONY BROOK",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6316329949",
  "inst_zip_code": "117940001",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "NY01",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "M746VC6XMNH9",
  "org_uei_num": "M746VC6XMNH9"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Stony Brook",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "117946999",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "NY01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 391188.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-fc93b31b-7fff-0f2b-9b70-aed626980b13\">\n<p dir=\"ltr\">In order to create useful and robust artificial intelligence systems, these systems need to first have a representation of how the world works. This research focused on methods to learn common-sense knowledge about the world so that we can build natural language understanding systems that are able to interpret human language and draw basic conclusions from what was written or said. As an example, when someone enters a bank, the system should be able to reason about the likely events to follow, such as opening an account or withdrawing money. If the person deviates from these common-sense expected actions, an intelligent system should be able to detect the aberration. This research focused on how to represent events and actions, as well as how to generate and recognize stereotypical sequences of common-sense events.</p>\n<br />\n<p dir=\"ltr\"><span>One of the difficulties in representing world knowledge for AI systems is the choice of an internal representation that can flexibly handle unexpected input. This project created a new way of representing events that are described in text (&ldquo;he threw a football&rdquo;), by projecting the entire event into a high-dimensional space by combining the arguments (he and football) with the verb (threw). The result allows reasoning systems to naturally discover related events (&ldquo;he caught the pass&rdquo;), yet also separate completely different events that still share words (&ldquo;she threw the dynamite&rdquo;). Our tensor-based model does well on both these challenging tasks, and we showed that such knowledge can generate sequences of accurate common-sense events.</span></p>\n<br />\n<p dir=\"ltr\"><span>Another challenge in common-sense learning is the ability to identify hierarchical structure in the world, thus enabling systems to understand the broader context even when presented with new situations. For example, many things in the world can catch on fire, and all of them carry the risk of the fire spreading, burning, and destroying. However, the behavior of specific types of fire might differ (forest fires burn trees, but city fires burn buildings), so there is both commonality and difference based on the context. We researched a new neural network architecture called a Hierarchical Quantized Autoencoder (HAQAE) that uses latent variables to represent different levels of generality with the ability to represent general topics (fires) and specific topics (forest fires) at the same time. We showed that this approach generates more coherent sequences of events than prior non-hierarchical models. Building on this success, we also created a new neural architecture to generate stories based on a hidden model of narrative structure. This architecture allows each generated events in the story to switch between narrative states, allowing us to model likely story sequences as well as the language that corresponds to each state. This model is called a Switching Linear Dynamical System (SLDS) and we showed that more coherent stories are created than in non-switching architectures.</span></p>\n<br />\n<p dir=\"ltr\"><span>A core thrust of this work above focused on better event representations and understanding of context, but we also investigated the impact of events on the people involved in the events, and likewise how the emotional state of those actors might affect what is expected to unfold. This is another type of common-sense knowledge that proves important to event understanding. We build on prior sentiment work that identified the sentiment of entities in a narrative (&ldquo;Sara lost the match&rdquo; results in Sarah being unhappy), and created new models of automatic sentiment identification based on an explicit representation of the sentiment labels themselves. The sentiment &ldquo;unhappy&rdquo; has its own meaning, so we integrated neural representations of the emotions to assist in drawing attention to critical sentiment-bearing words in the sentences. We showed significant improvements in the state-of-the-art for sentiment classification.</span></p>\n<br />\n<p dir=\"ltr\"><span>Overall this project resulted in several new neural architectures to learn and infer common-sense knowledge about events in the world and how situations unfold. We presented state-of-the-art results on several event representation tasks, new results on event schema generation, and improved results on sentiment classification of the actors involved in those events.</span></p>\n<div><span><br /></span></div>\n</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/21/2020<br>\n\t\t\t\t\tModified by: Niranjan&nbsp;Balasubramanian</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n\nIn order to create useful and robust artificial intelligence systems, these systems need to first have a representation of how the world works. This research focused on methods to learn common-sense knowledge about the world so that we can build natural language understanding systems that are able to interpret human language and draw basic conclusions from what was written or said. As an example, when someone enters a bank, the system should be able to reason about the likely events to follow, such as opening an account or withdrawing money. If the person deviates from these common-sense expected actions, an intelligent system should be able to detect the aberration. This research focused on how to represent events and actions, as well as how to generate and recognize stereotypical sequences of common-sense events.\n\n\nOne of the difficulties in representing world knowledge for AI systems is the choice of an internal representation that can flexibly handle unexpected input. This project created a new way of representing events that are described in text (\"he threw a football\"), by projecting the entire event into a high-dimensional space by combining the arguments (he and football) with the verb (threw). The result allows reasoning systems to naturally discover related events (\"he caught the pass\"), yet also separate completely different events that still share words (\"she threw the dynamite\"). Our tensor-based model does well on both these challenging tasks, and we showed that such knowledge can generate sequences of accurate common-sense events.\n\n\nAnother challenge in common-sense learning is the ability to identify hierarchical structure in the world, thus enabling systems to understand the broader context even when presented with new situations. For example, many things in the world can catch on fire, and all of them carry the risk of the fire spreading, burning, and destroying. However, the behavior of specific types of fire might differ (forest fires burn trees, but city fires burn buildings), so there is both commonality and difference based on the context. We researched a new neural network architecture called a Hierarchical Quantized Autoencoder (HAQAE) that uses latent variables to represent different levels of generality with the ability to represent general topics (fires) and specific topics (forest fires) at the same time. We showed that this approach generates more coherent sequences of events than prior non-hierarchical models. Building on this success, we also created a new neural architecture to generate stories based on a hidden model of narrative structure. This architecture allows each generated events in the story to switch between narrative states, allowing us to model likely story sequences as well as the language that corresponds to each state. This model is called a Switching Linear Dynamical System (SLDS) and we showed that more coherent stories are created than in non-switching architectures.\n\n\nA core thrust of this work above focused on better event representations and understanding of context, but we also investigated the impact of events on the people involved in the events, and likewise how the emotional state of those actors might affect what is expected to unfold. This is another type of common-sense knowledge that proves important to event understanding. We build on prior sentiment work that identified the sentiment of entities in a narrative (\"Sara lost the match\" results in Sarah being unhappy), and created new models of automatic sentiment identification based on an explicit representation of the sentiment labels themselves. The sentiment \"unhappy\" has its own meaning, so we integrated neural representations of the emotions to assist in drawing attention to critical sentiment-bearing words in the sentences. We showed significant improvements in the state-of-the-art for sentiment classification.\n\n\nOverall this project resulted in several new neural architectures to learn and infer common-sense knowledge about events in the world and how situations unfold. We presented state-of-the-art results on several event representation tasks, new results on event schema generation, and improved results on sentiment classification of the actors involved in those events.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 01/21/2020\n\n\t\t\t\t\tSubmitted by: Niranjan Balasubramanian"
 }
}