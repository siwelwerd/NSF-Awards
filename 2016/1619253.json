{
 "awd_id": "1619253",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Collaborative Research: ALETHEIA: A Framework for Automatic Detection/Correction of Corruptions in Extreme Scale Scientific Executions",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2016-06-15",
 "awd_exp_date": "2021-05-31",
 "tot_intn_awd_amt": 244197.0,
 "awd_amount": 244197.0,
 "awd_min_amd_letter_date": "2016-06-03",
 "awd_max_amd_letter_date": "2019-03-07",
 "awd_abstract_narration": "Trusting scientific applications requires guaranteeing the validity of computed results. Unfortunately, many examples of scientific computations have led to incorrect results, sometimes with catastrophic consequences. Currently known validation techniques cover only a fraction of the possible corruptions that numerical simulation and data analytics applications may suffer during execution. As science processes grow in size and complexity, the reliability and validity of their constituent steps is increasingly difficult to ascertain. Assessing validity in the presence of potential data corruptions is a serious and insufficiently recognized problem. Corruption may occur at all levels of computing, from the hardware to the application. An important aspect of these corruptions is that until they are discovered, all executions are at risk of being corrupted silently. In some documented cases, months have elapsed between the discovery of a corruption and notification to users. In the meantime, a potentially large number of executions may be corrupted, and incorrect conclusions may result. It may be difficult, after the fact, to check whether executions have actually been corrupted or not, so that even if corruptions do not lead to mistakes, they may lead to significant productivity losses. Virtually all simulations producing very large results need to reduce their data volume in some way before saving it --one technique is called lossy compression. \r\nThis project strives to validate the end result of the simulation coupled with lossy compression. This approach is useful for scientific simulations in such diverse areas as climate, cosmology, fluid dynamics, weather, and astrophysics --the drivers of this project. \r\nThis collaborative project applies the principle of an external algorithmic observer (EAO), where the product of a scientific application is compared with that of a surrogate function of much lower complexity. Corruptions are corrected using a variation of triple modular redundancy: if a corruption is detected, a second surrogate function is executed, and the correct value is chosen from the two results that are most in agreement. This new online detection/correction approach involves approximate comparison of the lossy compressed results of the scientific application and the surrogate function. The project explores the detection performance of surrogate functions, lossy compressors, and approximate comparison techniques. The project also explores how to select the surrogate, lossy compression, and approximate functions to optimize objectives and constraints set by the users. The evaluation considers a set of five applications spanning different computational methods, producing large datasets with I/O bottlenecks, and covering a variety of science problem domains relevant to the NSF. \r\nIn addition to serving the needs of scientists working in the fields listed above, this project will enhance the research experience of undergraduate students. A summer school focused on resilience is planned for summer 2016, and corruption detection/correction will be a major topic. The project is also organizing tutorials in major science conferences that include online detection/correction of numerical simulations.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Tom",
   "pi_last_name": "Peterka",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Tom Peterka",
   "pi_email_addr": "tpeterka@mcs.anl.gov",
   "nsf_id": "000510756",
   "pi_start_date": "2016-06-03",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sheng",
   "pi_last_name": "Di",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sheng Di",
   "pi_email_addr": "sdi@uchicago.edu",
   "nsf_id": "000796586",
   "pi_start_date": "2019-01-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Northwestern University",
  "inst_street_address": "633 CLARK ST",
  "inst_street_address_2": "",
  "inst_city_name": "EVANSTON",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "3125037955",
  "inst_zip_code": "602080001",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IL09",
  "org_lgl_bus_name": "NORTHWESTERN UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "EXZVPWZBLUE8"
 },
 "perf_inst": {
  "perf_inst_name": "Argonne National Laboratory",
  "perf_str_addr": "9700 South Cass Ave.",
  "perf_city_name": "Lemont",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "604394847",
  "perf_ctry_code": "US",
  "perf_cong_dist": null,
  "perf_st_cong_dist": "IL",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 244197.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>This project aims to develop a framework, called ALETHEIA, for dramatically improving the validity of scientific executions by detecting and potentially correcting silent data corruptions (SDCs) especially for the applications equipped with lossy compression techniques; and also keep the compression quality and performance at a very high level, or improve it if possible.</span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>In this project, not only did we complete the planned target (improving the resilience against SDCs for error-bounded scientific data compression use-cases), but we also significantly improve</span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>d</span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span> the compression quality and performance during the research work. We summarize the key achievement as follows:</span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>(1) We developed a new resilient error-bounded lossy compression framework, which can protect the lossy compression against SDCs very effectively with only 10% time overhead and with a very limited degradation of compression ratio (&sim;5%). For the data loading/saving on a parallel file system (PFS), the fault-tolerance overhead is only 6~7%. For the data transfer over Wide Area Network (WAN), our solution introduces only 2% overhead, and can reduce the transferring time by 50%~68% compared with transferring original non-compressed data. This work is to appear in the </span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">top</span></span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span> conference IEEE/ACM SC2021.</span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>(2) We also developed an end-to-end SDC resilient lossy compression method and evaluated its resilience and performance using multiple different real-world scientific application datasets. </span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">Such</span></span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span> an end-to-end SDC resilient method integrates the state-of-the-art SDC detection software ? adaptive impact driven SDC detector (AID), and also takes into account the impact of different lossy compressors (such as SZ and ZFP). </span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-US\">W</span></span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>e evaluate both performance overhead and reliability of execution results, by running the experiments on the Argonne Bebop supercomputer using four widely used scientific simulations (FLASH, Nek5000, EXAALT and CESM) based on SZ and ZFP. Our parallel experiments with up to 1,024 cores confirm that the time overheads could be limited within 7.9%. This work is published in IEEE International Conference on Cluster (CLUSTER20), 2020.</span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>(3) As for the SDC detection, we also received several significant achievements. In particular, we exploited various fault tolerance methods for specific commonly-used algorithms, such as sorting algorithm and deep neural network (DNN), which were published in IEEE/ACM SC2019 and IEEE TPDS2020, respectively. We also developed a machine learning (ML) based approach to automatically build a sentiment lexicon, based on the system log message templates. Experiments show that our error detection algorithm can identify error messages with an average Matthew?s correlation coefficient (MCC) score and f -score of 91% and 96% respectively, while state of the art ML/deep learning model (LSTM) obtains only 67% and 84%. This work is published in DSN2021.</span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span>(4) As for the lossy compression for scientific datasets, we significantly improved the compression quality and performance for diverse applications and use-cases during the project. Specifically, </span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">for</span></span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span> the same compression error bound, the overall compression ratio has been improved by 5X~10X and the compression time is reduced 50%. The overall I/O performance also significantly increased because of the considerably </span></span></span></span><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">improved compression ratios. The related publications appeared in many prestigious conferences/journals, including ACM HPDC2018, TPDS2018/2020, SC2019/2021, IJHPCA2018/2019, PACT2020, MSST20, TPDS2020, CLUSTER2017~2020, ICDE2021, IPDPS2020/2021, PPoPP2020, etc.</span></span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">Attached figures:</span></span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">Figure 1: Results of our resilient lossy compression method vs. non-resilient compressor (SZ)</span></span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">Figure 2: Design architecture of the end-to-end resilience for lossy compression in scientific datasets</span></span></span></span></span></p>\n<p class=\"western\"><span><span style=\"color: #000000;\"><span style=\"font-family: Arial, serif;\"><span><span lang=\"en-GB\">Figure 3: Experimental results of error detection using sentiment lexicon based on Ranger system log (operated by Texas Advanced Computing Center (TACC))</span></span></span></span></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/30/2021<br>\n\t\t\t\t\tModified by: Sheng&nbsp;Di</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665913237_end-to-end-design--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665913237_end-to-end-design--rgov-800width.jpg\" title=\"end-to-end resilient compression design\"><img src=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665913237_end-to-end-design--rgov-66x44.jpg\" alt=\"end-to-end resilient compression design\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Design architecture of the end-to-end resilience for lossy compression in scientific datasets</div>\n<div class=\"imageCredit\">Sheng Di</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Sheng&nbsp;Di</div>\n<div class=\"imageTitle\">end-to-end resilient compression design</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665876877_resilient-SZ-experiments--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665876877_resilient-SZ-experiments--rgov-800width.jpg\" title=\"resilient-SZ-experiments\"><img src=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665876877_resilient-SZ-experiments--rgov-66x44.jpg\" alt=\"resilient-SZ-experiments\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Results of our resilient lossy compression method vs. non-resilient compressor (SZ)</div>\n<div class=\"imageCredit\">Sheng Di</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Sheng&nbsp;Di</div>\n<div class=\"imageTitle\">resilient-SZ-experiments</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665977822_Sentiment-Lexicon-detection--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665977822_Sentiment-Lexicon-detection--rgov-800width.jpg\" title=\"sentiment-lexicon-results\"><img src=\"/por/images/Reports/POR/2021/1619253/1619253_10431073_1627665977822_Sentiment-Lexicon-detection--rgov-66x44.jpg\" alt=\"sentiment-lexicon-results\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Experimental results of error detection using sentiment lexicon based on Ranger system log (operated by Texas Advanced Computing Center (TACC))Experimental results of error detection using sentiment lexicon based on Ranger system log (operated by Texas Advanced Computing Center (TACC))</div>\n<div class=\"imageCredit\">Sheng Di</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Sheng&nbsp;Di</div>\n<div class=\"imageTitle\">sentiment-lexicon-results</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "This project aims to develop a framework, called ALETHEIA, for dramatically improving the validity of scientific executions by detecting and potentially correcting silent data corruptions (SDCs) especially for the applications equipped with lossy compression techniques; and also keep the compression quality and performance at a very high level, or improve it if possible.\nIn this project, not only did we complete the planned target (improving the resilience against SDCs for error-bounded scientific data compression use-cases), but we also significantly improved the compression quality and performance during the research work. We summarize the key achievement as follows:\n(1) We developed a new resilient error-bounded lossy compression framework, which can protect the lossy compression against SDCs very effectively with only 10% time overhead and with a very limited degradation of compression ratio (&sim;5%). For the data loading/saving on a parallel file system (PFS), the fault-tolerance overhead is only 6~7%. For the data transfer over Wide Area Network (WAN), our solution introduces only 2% overhead, and can reduce the transferring time by 50%~68% compared with transferring original non-compressed data. This work is to appear in the top conference IEEE/ACM SC2021.\n(2) We also developed an end-to-end SDC resilient lossy compression method and evaluated its resilience and performance using multiple different real-world scientific application datasets. Such an end-to-end SDC resilient method integrates the state-of-the-art SDC detection software ? adaptive impact driven SDC detector (AID), and also takes into account the impact of different lossy compressors (such as SZ and ZFP). We evaluate both performance overhead and reliability of execution results, by running the experiments on the Argonne Bebop supercomputer using four widely used scientific simulations (FLASH, Nek5000, EXAALT and CESM) based on SZ and ZFP. Our parallel experiments with up to 1,024 cores confirm that the time overheads could be limited within 7.9%. This work is published in IEEE International Conference on Cluster (CLUSTER20), 2020.\n(3) As for the SDC detection, we also received several significant achievements. In particular, we exploited various fault tolerance methods for specific commonly-used algorithms, such as sorting algorithm and deep neural network (DNN), which were published in IEEE/ACM SC2019 and IEEE TPDS2020, respectively. We also developed a machine learning (ML) based approach to automatically build a sentiment lexicon, based on the system log message templates. Experiments show that our error detection algorithm can identify error messages with an average Matthew?s correlation coefficient (MCC) score and f -score of 91% and 96% respectively, while state of the art ML/deep learning model (LSTM) obtains only 67% and 84%. This work is published in DSN2021.\n(4) As for the lossy compression for scientific datasets, we significantly improved the compression quality and performance for diverse applications and use-cases during the project. Specifically, for the same compression error bound, the overall compression ratio has been improved by 5X~10X and the compression time is reduced 50%. The overall I/O performance also significantly increased because of the considerably improved compression ratios. The related publications appeared in many prestigious conferences/journals, including ACM HPDC2018, TPDS2018/2020, SC2019/2021, IJHPCA2018/2019, PACT2020, MSST20, TPDS2020, CLUSTER2017~2020, ICDE2021, IPDPS2020/2021, PPoPP2020, etc.\nAttached figures:\nFigure 1: Results of our resilient lossy compression method vs. non-resilient compressor (SZ)\nFigure 2: Design architecture of the end-to-end resilience for lossy compression in scientific datasets\nFigure 3: Experimental results of error detection using sentiment lexicon based on Ranger system log (operated by Texas Advanced Computing Center (TACC))\n\n \n\n\t\t\t\t\tLast Modified: 07/30/2021\n\n\t\t\t\t\tSubmitted by: Sheng Di"
 }
}