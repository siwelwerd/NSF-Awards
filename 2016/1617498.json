{
 "awd_id": "1617498",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "AF: Small: Dynamic Reasoning",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2020-06-30",
 "tot_intn_awd_amt": 399734.0,
 "awd_amount": 407034.0,
 "awd_min_amd_letter_date": "2016-06-28",
 "awd_max_amd_letter_date": "2017-05-16",
 "awd_abstract_narration": "Descriptive Complexity measures the richness of a language needed to describe a given property. The languages are variants of first-order logic describing finite structures.  All major complexity classes have been shown to have natural descriptive characterizations, providing a deep and profound relationship between the traditional computational complexity of a problem and the descriptive complexity of the problem.  Thus complexity can be understood entirely from a logical point of view. Important new understandings about complexity have arisen from the descriptive point of view.  In particular, the trade-off between parallel time and amount of hardware, a fundamental issue in computation, has been characterized as the trade-off between formula size and number of variables. There are four broader impacts from the above work. (1) This project will extend knowledge concerning the complexity of problems as well as providing new methods to automatically check the correctness of programs.  This work will lead to tools useful for teaching logic and complexity. (2) The project will improve the understanding of the fundamental nature of computation.  (3) Results from this project will be widely distributed and will be presented at conferences, published in journals, and taught in seminars. (4) The PI will also train graduate students to do research in this combination of pure and applied theory.\r\n\r\nIn this project, the PI will continue to extend the understanding of computational complexity using descriptive complexity.  The PI will also expand the recent use of modern SAT solvers to automatically prove that programs meet their correctness conditions or find runs on which they do not. The intellectual merit of this project is that it will extend the understanding of computational complexity and it will improve the ability and understanding of how to automatically reason about the correctness of programs. The research in this project has several specific thrusts: (1) The PI will extend the methodology for automatically generating correctness conditions for programs in simple languages which are automatically checkable, (2) The PI will extend the current understanding of dynamic complexity, especially for reachability properties, (3) The PI will develop a theory of dynamic reasoning, identifying when it is possible to reason about program states in an essentially propositional way and when it is not, (4) The PI will study the dichotomy phenomon from a descriptive point of view. In particular, starting with binary Constraint Satisfaction Problems, the PI will explain where dichotomies lie and in particular why natural computational problems tend to be complete for a small number of important complexity classes.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Neil",
   "pi_last_name": "Immerman",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Neil Immerman",
   "pi_email_addr": "immerman@cs.umass.edu",
   "nsf_id": "000178321",
   "pi_start_date": "2016-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Massachusetts Amherst",
  "inst_street_address": "101 COMMONWEALTH AVE",
  "inst_street_address_2": "",
  "inst_city_name": "AMHERST",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "4135450698",
  "inst_zip_code": "010039252",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MA02",
  "org_lgl_bus_name": "UNIVERSITY OF MASSACHUSETTS",
  "org_prnt_uei_num": "VGJHK59NMPK9",
  "org_uei_num": "VGJHK59NMPK9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Massachusetts Amherst",
  "perf_str_addr": "140 Governors Drive",
  "perf_city_name": "Amherst",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "010039264",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7927",
   "pgm_ref_txt": "COMPLEXITY & CRYPTOGRAPHY"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 399734.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 7300.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In older papers, we introduced the resilience of a boolean query. The resilience of a query with respect to a database, D, is the minimum number of tuples that must be removed from D to make the query false.&nbsp; Computing resilience is important for understanding why a tuple is present in a query or view, and to compute how to change it in the simplest way. For conjunctive queries without self joins, we developed a natural criterion that classifies queries according to the complexity of their resilience problem, showing that this problem exhibits a dichotomy.&nbsp; We defined the triad and showed that resilience is NP complete in the presence of a triad; whereas in the absence of a triad resilience is efficiently computable: it is reducible to Network Flow and thus well inside P.</p>\n<p>As for most questions about conjunctive queries, this classification problem becomes much more subtle in the presence of self joins. In the above paper, we extended our previous results to allow the presence of self joins.&nbsp; We explain most of the ensuing complications and we prove a characterization of the resilience of conjunctive queries with self-joins, in a restricted case.&nbsp; We show that in this case a similar dichtomy holds as in the sj-free case. The main value of this paper is in explaining how the problem gets significantly more complicated in the presence of self joins -- a very common phenomenon -- but laying out a roadmap to completely solve the reslience problem in the presence of self joins.<br /><br />Much promising work, including some of ours, employs SAT solvers to automatically check whether or not given programs meet certain correctness conditions. In order to do this, we need to be given a program that includes loop or program invariants.&nbsp; We describe progress that we made on the problem of automatically computing such invariants.</p>\n<p>Quantified first-order formulas, with alternating quantifiers are often needed as program invariants. There had been no way to infer them automatically.&nbsp; In this paper we consider the problem of finding a first-order separator for two sets of structures, P, N, namely a formula of a given quantifier depth, d, that is true for all the positive structures and false for all the negative ones.&nbsp; We show that for each fixed d, this problem is NP complete.&nbsp; We also show a practical algorithm using a SAT solver which finds such separators and thus infers quantified program invariants.&nbsp; We have thus introduced a promising new method of infering quantified program invariants.&nbsp;</p>\n<p>In a second paper on inductive inference we address the complexity of SAT-based invariant inference.&nbsp; We consider the problem of inferring an inductive invariant of polynomial length given a transition system and a safety property. We analyze the complexity of this problem in a black-box model, called the Hoare-query model, which is general enough to capture algorithms such as IC3/PDR and its variants, We show that any algorithm that uses the Hoare-query model requires exponentially many queries in the worst case to derive a polynomial-length invariant.</p>\n<p>We then show, that approaches such as PDR which use Hoare queries, can be exponentially more efficient than approaches such as ICE learning which only utilize inductiveness checks of candidates.&nbsp; These results shed light on the general complexity of invariant inference.</p>\n<p>In a third paper on inductive inference, we consider the important practical problem of proving that a proposed invariant is inductive for a block of code.&nbsp; The formula is inductive if it follows from the initial conditions, is preserved by the code, and it also implies a given safety condition.&nbsp; In general, when the proposed invariant is a first-order formula with quantifier alternation, checking if it is inductive is undecidable.&nbsp; However we show that when we restrict the possible terms to be instantiated to have bounded depth (of nesting of skolem functions), the procedure becomes decidable and it turns out to be practical in some interesting settings.&nbsp; In fact, we show the striking fact that depth one suffices to automatically simulate a natural class of instrumentations -- rewritings of formulas which are often used by hand to transform such invariants to universal invariants. The advantage of universal invariants is that it is decidable to check that they are inductive.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2020<br>\n\t\t\t\t\tModified by: Neil&nbsp;Immerman</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn older papers, we introduced the resilience of a boolean query. The resilience of a query with respect to a database, D, is the minimum number of tuples that must be removed from D to make the query false.  Computing resilience is important for understanding why a tuple is present in a query or view, and to compute how to change it in the simplest way. For conjunctive queries without self joins, we developed a natural criterion that classifies queries according to the complexity of their resilience problem, showing that this problem exhibits a dichotomy.  We defined the triad and showed that resilience is NP complete in the presence of a triad; whereas in the absence of a triad resilience is efficiently computable: it is reducible to Network Flow and thus well inside P.\n\nAs for most questions about conjunctive queries, this classification problem becomes much more subtle in the presence of self joins. In the above paper, we extended our previous results to allow the presence of self joins.  We explain most of the ensuing complications and we prove a characterization of the resilience of conjunctive queries with self-joins, in a restricted case.  We show that in this case a similar dichtomy holds as in the sj-free case. The main value of this paper is in explaining how the problem gets significantly more complicated in the presence of self joins -- a very common phenomenon -- but laying out a roadmap to completely solve the reslience problem in the presence of self joins.\n\nMuch promising work, including some of ours, employs SAT solvers to automatically check whether or not given programs meet certain correctness conditions. In order to do this, we need to be given a program that includes loop or program invariants.  We describe progress that we made on the problem of automatically computing such invariants.\n\nQuantified first-order formulas, with alternating quantifiers are often needed as program invariants. There had been no way to infer them automatically.  In this paper we consider the problem of finding a first-order separator for two sets of structures, P, N, namely a formula of a given quantifier depth, d, that is true for all the positive structures and false for all the negative ones.  We show that for each fixed d, this problem is NP complete.  We also show a practical algorithm using a SAT solver which finds such separators and thus infers quantified program invariants.  We have thus introduced a promising new method of infering quantified program invariants. \n\nIn a second paper on inductive inference we address the complexity of SAT-based invariant inference.  We consider the problem of inferring an inductive invariant of polynomial length given a transition system and a safety property. We analyze the complexity of this problem in a black-box model, called the Hoare-query model, which is general enough to capture algorithms such as IC3/PDR and its variants, We show that any algorithm that uses the Hoare-query model requires exponentially many queries in the worst case to derive a polynomial-length invariant.\n\nWe then show, that approaches such as PDR which use Hoare queries, can be exponentially more efficient than approaches such as ICE learning which only utilize inductiveness checks of candidates.  These results shed light on the general complexity of invariant inference.\n\nIn a third paper on inductive inference, we consider the important practical problem of proving that a proposed invariant is inductive for a block of code.  The formula is inductive if it follows from the initial conditions, is preserved by the code, and it also implies a given safety condition.  In general, when the proposed invariant is a first-order formula with quantifier alternation, checking if it is inductive is undecidable.  However we show that when we restrict the possible terms to be instantiated to have bounded depth (of nesting of skolem functions), the procedure becomes decidable and it turns out to be practical in some interesting settings.  In fact, we show the striking fact that depth one suffices to automatically simulate a natural class of instrumentations -- rewritings of formulas which are often used by hand to transform such invariants to universal invariants. The advantage of universal invariants is that it is decidable to check that they are inductive.\n\n \n\n\t\t\t\t\tLast Modified: 11/25/2020\n\n\t\t\t\t\tSubmitted by: Neil Immerman"
 }
}