{
 "awd_id": "1553485",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Advancing the Frontier in System Architectures for Artificially Intelligent Services and Applications",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2016-01-15",
 "awd_exp_date": "2020-12-31",
 "tot_intn_awd_amt": 470000.0,
 "awd_amount": 470000.0,
 "awd_min_amd_letter_date": "2016-01-19",
 "awd_max_amd_letter_date": "2019-09-09",
 "awd_abstract_narration": "The way society interacts with today's mobile technologies is rapidly changing as such devices - omnipresent in our lives - become increasingly personal and knowledgeable. Intelligent assistants (IAs), such as Apple's Siri, Google's Google Now, Microsoft's Cortana, and Amazon's Echo, are continuing to become more sophisticated and are expected to grow in popularity as wearables continue to gain traction. The computing capabilities required to support these technology trends continue to evolve toward intelligent systems that use sophisticated machine learning and computer vision algorithms on the critical path of audio and vision interactions. In this proposed work, PI Jason Mars aims to understand how future cloud and mobile systems should be designed (and co-designed) to support increasing demand from users. This proposed work advances both 1) the efficiency of current computing platforms to reduce their energy, cost, and environmental footprint, and 2) the expansion of open end-to-end systems with state-of-the-art algorithmic capabilities to enable new, more sophisticated, intelligent technologies and usher in future research and inquiry. \r\n\r\n\r\nPI Mars' technical approach incorporates three pillars of innovation. These pillars span application insights, to inform the design of underlying systems, vertical innovation to advance the cross-layer design of the system stack for emerging applications and services, and horizontal innovation to reason about a computational fabric spanning mobile hardware and cloud hardware to create a unified platform for computation. In addition to having impact on national interests, economic advancement, and technology in general, this proposed work incorporates significant innovation in undergraduate, and graduate education. The Intelleco and DeepSirius systems described in this proposal will be used to design an undergraduate and graduate course for state-of-the-art datacenter design. In addition all artifacts and teaching materials will be disseminated broadly through open source and creative commons.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jason",
   "pi_last_name": "Mars",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jason Mars",
   "pi_email_addr": "profmars@umich.edu",
   "nsf_id": "000629579",
   "pi_start_date": "2016-01-19",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "2260 Hayward",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481092121",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7798",
   "pgm_ref_txt": "SOFTWARE & HARDWARE FOUNDATION"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 182049.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 93089.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 194862.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The outcomes of this proposed work includes many notable contributions.</p>\n<p>Firstly, we attack the area of new emerging applications.&nbsp;<span>With the growing popularity of cloud gaming and cloud virtual reality (VR), interactive 3D applications have become a major class of workloads for the cloud. However, despite their growing importance, there is limited public research on how to design cloud systems to efficiently support these applications due to the lack of an open and reliable research infrastructure, including benchmarks and performance analysis tools. The challenges of generating human-like inputs under various system/application nondeterminism and dissecting the performance of complex graphics systems make it very difficult to design such an infrastructure. In this paper, we present the design of a novel research infrastructure, Pictor, for cloud 3D applications and systems. Pictor employs AI to mimic human interactions with complex 3D applications. It can also track the processing of user inputs to provide in-depth performance measurements for the complex software and hardware stack used for cloud 3D-graphics rendering. With Pictor, we designed a benchmark suite with six interactive 3D applications. Performance analyses were conducted with these benchmarks, which show that cloud system designs, including both system software and hardware designs, are crucial to the performance of cloud 3D applications. The analyses also show that energy consumption can be reduced by at least 37% when two 3D applications share a could server. To demonstrate the effectiveness of Pictor, we also implemented two optimizations to address two performance bottlenecks discovered in a state-of-the-art cloud 3D-graphics rendering system. These two optimizations improved the frame rate by 57.7% on average.</span></p>\n<p>Secondly we look at an expanding set of conversational Agents. With the increasing volume of commercially available conversational agents (CAs) such as Apple Siri and Amazon Alexa, users are taxed with the burden of learning and adopting multiple agents to accomplish various tasks, thus resulting in an increase in cognitive load. Though prior work has explored combining multiple domains within the design and implementation of a single agent, the task of integrating multiple production black-box agents into a unified experience remains an open problem.</p>\n<p>In this work, we introduce a new task of agent integration, focusing on integrating multiple black-box CAs at scale.We formulate a set of question agent pairing and question response pairing techniques for this task. Leveraging these techniques, we design and deploy One For All (OFA), a scalable system that provides a unified interface to interact with multiple CAs. Additionally, we introduce the OFA encoder, a new cross-encoder model that jointly encodes user question and agent response pairs.&nbsp;We demonstrate that the OFA system automatically and accurately extracts the best response from an ensemble of commercially available CAs spanning disparate domains.&nbsp;Specifically, the OFA encoder achieves 95% response selection accuracy on the new agent integration task, outperforming strong baselines and surpassing the best single CA by over 29%.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/03/2021<br>\n\t\t\t\t\tModified by: Jason&nbsp;Mars</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe outcomes of this proposed work includes many notable contributions.\n\nFirstly, we attack the area of new emerging applications. With the growing popularity of cloud gaming and cloud virtual reality (VR), interactive 3D applications have become a major class of workloads for the cloud. However, despite their growing importance, there is limited public research on how to design cloud systems to efficiently support these applications due to the lack of an open and reliable research infrastructure, including benchmarks and performance analysis tools. The challenges of generating human-like inputs under various system/application nondeterminism and dissecting the performance of complex graphics systems make it very difficult to design such an infrastructure. In this paper, we present the design of a novel research infrastructure, Pictor, for cloud 3D applications and systems. Pictor employs AI to mimic human interactions with complex 3D applications. It can also track the processing of user inputs to provide in-depth performance measurements for the complex software and hardware stack used for cloud 3D-graphics rendering. With Pictor, we designed a benchmark suite with six interactive 3D applications. Performance analyses were conducted with these benchmarks, which show that cloud system designs, including both system software and hardware designs, are crucial to the performance of cloud 3D applications. The analyses also show that energy consumption can be reduced by at least 37% when two 3D applications share a could server. To demonstrate the effectiveness of Pictor, we also implemented two optimizations to address two performance bottlenecks discovered in a state-of-the-art cloud 3D-graphics rendering system. These two optimizations improved the frame rate by 57.7% on average.\n\nSecondly we look at an expanding set of conversational Agents. With the increasing volume of commercially available conversational agents (CAs) such as Apple Siri and Amazon Alexa, users are taxed with the burden of learning and adopting multiple agents to accomplish various tasks, thus resulting in an increase in cognitive load. Though prior work has explored combining multiple domains within the design and implementation of a single agent, the task of integrating multiple production black-box agents into a unified experience remains an open problem.\n\nIn this work, we introduce a new task of agent integration, focusing on integrating multiple black-box CAs at scale.We formulate a set of question agent pairing and question response pairing techniques for this task. Leveraging these techniques, we design and deploy One For All (OFA), a scalable system that provides a unified interface to interact with multiple CAs. Additionally, we introduce the OFA encoder, a new cross-encoder model that jointly encodes user question and agent response pairs. We demonstrate that the OFA system automatically and accurately extracts the best response from an ensemble of commercially available CAs spanning disparate domains. Specifically, the OFA encoder achieves 95% response selection accuracy on the new agent integration task, outperforming strong baselines and surpassing the best single CA by over 29%.\n\n\t\t\t\t\tLast Modified: 08/03/2021\n\n\t\t\t\t\tSubmitted by: Jason Mars"
 }
}