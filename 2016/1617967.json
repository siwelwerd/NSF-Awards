{
 "awd_id": "1617967",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CSR: Small: Collaborative Research: Exploring Portable Data Placement on Massively Parallel Platforms with Heterogeneous Memory Architectures",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Matt Mutka",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-02-28",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2016-08-02",
 "awd_max_amd_letter_date": "2016-08-02",
 "awd_abstract_narration": "Heterogeneous computing is becoming crucial for many computational fields, including simulations of the galaxy, analysis of social networks, modeling of stock transactions, and so on. Programming heterogeneous memory systems is a grand challenge, and creates a major obstacle between heterogeneous hardware and applications because of the programming complexity and fast hardware evolution. This project aims to address this obstacle, and is expected to significantly relieve programmers from handling the underlying memory system heterogeneity. The outcome from this research will also enable continuous enhancement of the computing efficiency of a number of applications on future heterogeneous systems, which is a critical condition for sustained advancement of science, health, security and other aspects of humanity.\r\n\r\nTo address the programming challenges on heterogeneous memory systems, the project investigates a software framework, consisting of a hardware specification language, a set of novel compiler and runtime techniques, and advanced memory performance modeling. The goal is to develop a systematic solution to automatically place data given a complex heterogeneous memory system, especially on massively parallel platforms. With the proposed framework, programmers are relieved from tailoring their programs to different memory systems, and at the same time, the sophisticated memory systems can get fully translated into high computing efficiency.  The framework transforms the programs such that they are customized -  in terms of where data are placed in memory, when and how to migrate, etc. - to the underlying heterogeneous memory system at runtime and attain a near optimal memory usage.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dong",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dong Li",
   "pi_email_addr": "dli35@ucmerced.edu",
   "nsf_id": "000690232",
   "pi_start_date": "2016-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California - Merced",
  "inst_street_address": "5200 N LAKE RD",
  "inst_street_address_2": "",
  "inst_city_name": "MERCED",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2092012039",
  "inst_zip_code": "953435001",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "CA13",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, MERCED",
  "org_prnt_uei_num": "",
  "org_uei_num": "FFM7VPAG8P92"
 },
 "perf_inst": {
  "perf_inst_name": "University of California, Merced",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "953435001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "CA13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Memory heterogeneity means multiple memory components with different properties (such as memory bandwidth, latency, capacity, and computing ability) form a memory system. Memory heterogeneity is becoming common because of the needs of increasing memory capacity or providing higher performance in a cost-effective way. Memory heterogeneity raises challenges on deciding the optimal placement of data objects on heterogeneous memory (HM). Recent studies indicate substantial difficulty of matching applications with HM because of the complex and fast changing nature of HM as well as application input sensitivity and phase behaviors.</p>\n<p>&nbsp;</p>\n<p><strong>Intellectual merit.</strong> We study system-level solutions to make best usage of HM for high performance. Our solutions are essentially based on the ideas of introducing limited application semantics information to direct data migration and allocation. Using application semantics, we are able to break fundamental tradeoff between memory profiling overhead and accuracy, and decide when to trigger data migration to maximize the overlap between data migration and computation to minimize data migration overhead.</p>\n<p>&nbsp;</p>\n<p>Furthermore, we study application-level solutions to make best usage of HM for high performance. &nbsp;We propose new data structures and algorithms to reduce expensive accesses to slow memory as much as possible. Those solutions are application-specific, but bring much higher performance than system-level solutions; Those solutions focus on critical and common applications, which justifies highly customization of the solutions for those applications. Both the system-level solutions and application-level solutions investigate principles on how a large amount of memory pages should be profiled to capture spatial and temporal localities without paying large overhead and how page migration should happen to fully utilize fast memory.</p>\n<p>&nbsp;</p>\n<p><strong>Broader impact</strong>. This project enables applications to fully tap the large memory capacity provided by HM. Some of those applications are critical to the nation interests (such as the DOE application WarpX, a large-scale plasma simulation code); Some of them are critical to the business (such as deep learning training and fast information retrieval). With our solutions, those applications are able to run in unprecedented scales on a single machine, even performing better than on multiple machines. This project has been highlighted by several medias and companies (e.g., towardsdatascience.com, Microsoft, and linkreseacher.com). This project lays foundation for many HPC applications (including compute-intensive applications with small memory) to leverage HM with large memory capacity. This project is among the first efforts that reveal using limited application semantics can be significantly helpful to improve application performance on HM.</p>\n<p>&nbsp;</p>\n<p>Furthermore, this project provides research opportunities to undergraduate students to gain hands-on experiences on software-hardware co-designs. This project is also based on collaboration with Lawrence Berkeley National Lab and Lawrence Livermore National Lab. The project has impacts on how the future supercomputer infrastructure should be built. Collaborating with the national labs, we provide training opportunities to graduate students and prepare them for future career in the HPC field. Since the HPC field, which is critical to the national interests, lacks workforce. Our project is helpful to address this pressing problem.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/13/2021<br>\n\t\t\t\t\tModified by: Dong&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMemory heterogeneity means multiple memory components with different properties (such as memory bandwidth, latency, capacity, and computing ability) form a memory system. Memory heterogeneity is becoming common because of the needs of increasing memory capacity or providing higher performance in a cost-effective way. Memory heterogeneity raises challenges on deciding the optimal placement of data objects on heterogeneous memory (HM). Recent studies indicate substantial difficulty of matching applications with HM because of the complex and fast changing nature of HM as well as application input sensitivity and phase behaviors.\n\n \n\nIntellectual merit. We study system-level solutions to make best usage of HM for high performance. Our solutions are essentially based on the ideas of introducing limited application semantics information to direct data migration and allocation. Using application semantics, we are able to break fundamental tradeoff between memory profiling overhead and accuracy, and decide when to trigger data migration to maximize the overlap between data migration and computation to minimize data migration overhead.\n\n \n\nFurthermore, we study application-level solutions to make best usage of HM for high performance.  We propose new data structures and algorithms to reduce expensive accesses to slow memory as much as possible. Those solutions are application-specific, but bring much higher performance than system-level solutions; Those solutions focus on critical and common applications, which justifies highly customization of the solutions for those applications. Both the system-level solutions and application-level solutions investigate principles on how a large amount of memory pages should be profiled to capture spatial and temporal localities without paying large overhead and how page migration should happen to fully utilize fast memory.\n\n \n\nBroader impact. This project enables applications to fully tap the large memory capacity provided by HM. Some of those applications are critical to the nation interests (such as the DOE application WarpX, a large-scale plasma simulation code); Some of them are critical to the business (such as deep learning training and fast information retrieval). With our solutions, those applications are able to run in unprecedented scales on a single machine, even performing better than on multiple machines. This project has been highlighted by several medias and companies (e.g., towardsdatascience.com, Microsoft, and linkreseacher.com). This project lays foundation for many HPC applications (including compute-intensive applications with small memory) to leverage HM with large memory capacity. This project is among the first efforts that reveal using limited application semantics can be significantly helpful to improve application performance on HM.\n\n \n\nFurthermore, this project provides research opportunities to undergraduate students to gain hands-on experiences on software-hardware co-designs. This project is also based on collaboration with Lawrence Berkeley National Lab and Lawrence Livermore National Lab. The project has impacts on how the future supercomputer infrastructure should be built. Collaborating with the national labs, we provide training opportunities to graduate students and prepare them for future career in the HPC field. Since the HPC field, which is critical to the national interests, lacks workforce. Our project is helpful to address this pressing problem.\n\n\t\t\t\t\tLast Modified: 04/13/2021\n\n\t\t\t\t\tSubmitted by: Dong Li"
 }
}