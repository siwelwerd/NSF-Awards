{
 "awd_id": "1643056",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Application-driven Data Precision Selection Methods",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2018-07-31",
 "tot_intn_awd_amt": 299970.0,
 "awd_amount": 299970.0,
 "awd_min_amd_letter_date": "2016-07-21",
 "awd_max_amd_letter_date": "2016-07-21",
 "awd_abstract_narration": "Numerical algorithms used in Cyber Physical Systems, decision-making systems, financial processing, and other HPC applications that use real numbers are prone to introduce computational errors because of a well-known reason: real numbers do not exist in computers, and we must use floating-point data types to approximate such computations. As data movement costs energy, the lowest precision of floating-point data must be allocated without compromising the computational integrity. This project implements methods to reduce the amount of energy consumed by numerical computations running on computing devices at all scales including supercomputers for scientific research all the  way to embedded and mobile devices finding uses in many walks of real life including medical devices and robots.  A key thrust of the work is to perform energy reduction through reduced transfers between computing units. The project studies how the number of bits used to represent data introduce errors in computations, and whether these errors affect the correctness of results.\r\n\r\nThe PIs propose to develop new formal methods tools to automatically estimate error bounds, develop auto-tuning compilers to carefully select precision, and build new superoptimizers to generate more efficient code. These new technologies will be applied to improve software in the domains of machine learning and high-performance computing. The PIs shall develop suitable criteria for errors in high performance computing systems and machine learning systems. They will develop tools that allocate precision optimally while staying within the bounds of acceptable answers. Their tools will be released to a community of researchers interested in working toward exascale computing, and deploying machine learning applications in safety-critical devices. This work represents a synergistic combination of PI skills ranging through high performance computing, machine learning, formal methods, and compiler technologies.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ganesh",
   "pi_last_name": "Gopalakrishnan",
   "pi_mid_init": "L",
   "pi_sufx_name": "",
   "pi_full_name": "Ganesh L Gopalakrishnan",
   "pi_email_addr": "ganesh@cs.utah.edu",
   "nsf_id": "000160895",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Mary",
   "pi_last_name": "Hall",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Mary Hall",
   "pi_email_addr": "mhall@cs.utah.edu",
   "nsf_id": "000367228",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Zvonimir",
   "pi_last_name": "Rakamaric",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zvonimir Rakamaric",
   "pi_email_addr": "zvonimir@cs.utah.edu",
   "nsf_id": "000623290",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Hari",
   "pi_last_name": "Sundar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Hari Sundar",
   "pi_email_addr": "hari.sundar@tufts.edu",
   "nsf_id": "000671836",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vivek",
   "pi_last_name": "Srikumar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vivek Srikumar",
   "pi_email_addr": "svivek@cs.utah.edu",
   "nsf_id": "000676145",
   "pi_start_date": "2016-07-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Utah",
  "inst_street_address": "201 PRESIDENTS CIR",
  "inst_street_address_2": "",
  "inst_city_name": "SALT LAKE CITY",
  "inst_state_code": "UT",
  "inst_state_name": "Utah",
  "inst_phone_num": "8015816903",
  "inst_zip_code": "841129049",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "UT01",
  "org_lgl_bus_name": "UNIVERSITY OF UTAH",
  "org_prnt_uei_num": "",
  "org_uei_num": "LL8GLEVH6MG3"
 },
 "perf_inst": {
  "perf_inst_name": "University of Utah",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "UT",
  "perf_st_name": "Utah",
  "perf_zip_code": "841129205",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "UT01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "8206",
   "pgm_ref_txt": "Formal Methods and Verification"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 299970.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>When developing computer representations of continuous quantities (real numbers), a designer allocates enough data bits to model the data with the requisite precision. However, allocating more than the required number of bits leads to excessive memory consumption (especially the cache memory that is a precious resource). It also increases energy consumption which is proportional to the amount of data moved. In this research project, we studied the precision allocation problem from a number of different perspectives.&nbsp; We chose two primary application domains: machine learning, and high performance computing.</p>\n<p><br />Our first major finding is that conducting rigorous precision allocation requires tools for accurate roundoff error analysis. Our second major finding is that the nature of the application -- machine learning or high performance computing -- has a significant impact on the impact of precision allocation on application behavior. Our third major finding is that even within a domain such as high performance computing, the nature of the task carried out -- whether it involves discrete decisions or involves primarily arithmetic operations --decides how one can optimally trim precision in order to reduce energy costs without affecting application behavior. In the domain of machine learning, the decision space is is even more complex, and depends on whether precision tuning is being done while training or during deployment of a trained system.</p>\n<p><br />The major tool related contribution of this project is a tool called FPTaylor that has been engineered to high standards, and has been downloaded and studied by a number of groups. A comprehensive journal article presents a detailed comparative study of FPTaylor against other tools in its class. The project was instrumental in training five PhD students and one MS student in this area of critical national importance.<br /><br /><br /><br /></p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/01/2018<br>\n\t\t\t\t\tModified by: Ganesh&nbsp;L&nbsp;Gopalakrishnan</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849753178_FPTaylorFlow--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849753178_FPTaylorFlow--rgov-800width.jpg\" title=\"FPTaylor tool flow\"><img src=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849753178_FPTaylorFlow--rgov-66x44.jpg\" alt=\"FPTaylor tool flow\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">FPTaylor tool flow</div>\n<div class=\"imageCredit\">Alexey Solovyev</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div>\n<div class=\"imageTitle\">FPTaylor tool flow</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849675927_improvedrounding--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849675927_improvedrounding--rgov-800width.jpg\" title=\"Error plot under improved rounding\"><img src=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849675927_improvedrounding--rgov-66x44.jpg\" alt=\"Error plot under improved rounding\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Error plot under improved rounding of the Jet Engine benchmark of Darulova</div>\n<div class=\"imageCredit\">Eva Darulova and Alexey Solovyev</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div>\n<div class=\"imageTitle\">Error plot under improved rounding</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849596520_Demonstrationofnoncompositionalityofrounding--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849596520_Demonstrationofnoncompositionalityofrounding--rgov-800width.jpg\" title=\"Demonstration of noncompositionality\"><img src=\"/por/images/Reports/POR/2018/1643056/1643056_10442829_1535849596520_Demonstrationofnoncompositionalityofrounding--rgov-66x44.jpg\" alt=\"Demonstration of noncompositionality\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Demonstration of noncompositionality of rounding error</div>\n<div class=\"imageCredit\">Ganesh L Gopalakrishnan</div>\n<div class=\"imagePermisssions\">Public Domain</div>\n<div class=\"imageSubmitted\">Ganesh&nbsp;L&nbsp;Gopalakrishnan</div>\n<div class=\"imageTitle\">Demonstration of noncompositionality</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nWhen developing computer representations of continuous quantities (real numbers), a designer allocates enough data bits to model the data with the requisite precision. However, allocating more than the required number of bits leads to excessive memory consumption (especially the cache memory that is a precious resource). It also increases energy consumption which is proportional to the amount of data moved. In this research project, we studied the precision allocation problem from a number of different perspectives.  We chose two primary application domains: machine learning, and high performance computing.\n\n\nOur first major finding is that conducting rigorous precision allocation requires tools for accurate roundoff error analysis. Our second major finding is that the nature of the application -- machine learning or high performance computing -- has a significant impact on the impact of precision allocation on application behavior. Our third major finding is that even within a domain such as high performance computing, the nature of the task carried out -- whether it involves discrete decisions or involves primarily arithmetic operations --decides how one can optimally trim precision in order to reduce energy costs without affecting application behavior. In the domain of machine learning, the decision space is is even more complex, and depends on whether precision tuning is being done while training or during deployment of a trained system.\n\n\nThe major tool related contribution of this project is a tool called FPTaylor that has been engineered to high standards, and has been downloaded and studied by a number of groups. A comprehensive journal article presents a detailed comparative study of FPTaylor against other tools in its class. The project was instrumental in training five PhD students and one MS student in this area of critical national importance.\n\n\n\n\n\n\t\t\t\t\tLast Modified: 09/01/2018\n\n\t\t\t\t\tSubmitted by: Ganesh L Gopalakrishnan"
 }
}