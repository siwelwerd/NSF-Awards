{
 "awd_id": "1648973",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "INSPIRE: Tradeoffs in the Thermodynamics of Computation: A New Paradigm for Biological Information-Processing",
 "cfda_num": "47.049",
 "org_code": "03090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Robin McCarley",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 999947.0,
 "awd_amount": 999947.0,
 "awd_min_amd_letter_date": "2016-09-01",
 "awd_max_amd_letter_date": "2016-09-01",
 "awd_abstract_narration": "This INSPIRE project is jointly funded by the Chemistry of Life Processes Program in the Division of Chemistry in the Directorate for Mathematical and Physical Sciences, the Physics of Living Systems and Computational Physics Programs in the Division of Physics in the Directorate for Mathematical and Physical Sciences, the Systems and Synthetic Biology Cluster in the Division of Molecular and Cellular Biosciences in the Directorate for Biological Sciences, the INSPIRE Program and the Office of International Science and Engineering in the Office of Integrative Activities. \r\n\r\nThis award is funding Dr. David Wolpert from the Santa Fe Institute, Dr. Seth Lloyd from the Massachusetts Institute of Technology, and Dr. Sebastian Deffner from the University of Maryland, to exploit the powerful new tools of non-equilibrium statistical physics that analyzing the energy tradeoffs inherent in all computation. Energy (thermodynamic) costs of computational systems play a role in everything from human-engineered computers (which release heat energy equal to about 5% of the annual energy expenditure in the US) to biological systems (which must harvest enough energy from their environment to fulfill their needs to think and move). To investigate these energy costs, this project pursues three, synergistic research thrusts.  The research analyzes the fundamental energy tradeoffs faced by intracellular biochemical networks.  The project analyzes the energy tradeoffs that engineers face when designing new computer technologies.  Finally, the research integrate the energy tradeoffs of computational processes into the theory of computation. This project allows graduate students and postdoctoral fellows to acquire the skills needed for expanding what is known about the energy requirements of computation. In addition, the workshops held under the auspices of this project are building intellectual bridges connecting the multiple scientific disciplines that involve computational systems.  Such brides are crucial to the development of a broadly applicable theory of thermodynamics of computation.\r\n \r\nThis research project is undertaken to quantitatively analyze the tradeoffs relating the minimal free energy requirements and dissipation of a computer on the one hand, to several high-level properties of that computer on the other.  This analysis considers the speed of the computer; the number of hidden internal states the computer can use as buffers; the variability of the inputs to the computer and the degree and type of noise in the computer. In addition to theoretical aspects of these issues and their consequences for computation theory, this research into the thermodynamics of computation is conducted in several domains that include: chromatin computers, the computation performed during RNA folding, the computation performed by biochemical networks and post-Moore computers that exploit \"hybrid computation\" involving both quantum and classical components. It is expected that, in addition to providing major insight into the role of the thermodynamics of computation in all those domains, this project may lay the foundation for an overarching theory of thermodynamics of computation in general.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "CHE",
 "org_div_long_name": "Division Of Chemistry",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "David",
   "pi_last_name": "Wolpert",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "David Wolpert",
   "pi_email_addr": "dhw@santafe.edu",
   "nsf_id": "000711099",
   "pi_start_date": "2016-09-01",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Seth",
   "pi_last_name": "Lloyd",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Seth Lloyd",
   "pi_email_addr": "slloyd@mit.edu",
   "nsf_id": "000108554",
   "pi_start_date": "2016-09-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Santa Fe Institute",
  "inst_street_address": "1399 HYDE PARK RD",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA FE",
  "inst_state_code": "NM",
  "inst_state_name": "New Mexico",
  "inst_phone_num": "5059462727",
  "inst_zip_code": "875018943",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "NM03",
  "org_lgl_bus_name": "SANTA FE INSTITUTE OF SCIENCE",
  "org_prnt_uei_num": "",
  "org_uei_num": "M8SBQ7NVNAH4"
 },
 "perf_inst": {
  "perf_inst_name": "Santa Fe Institute",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "NM",
  "perf_st_name": "New Mexico",
  "perf_zip_code": "875018943",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "NM03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "125300",
   "pgm_ele_name": "OFFICE OF MULTIDISCIPLINARY AC"
  },
  {
   "pgm_ele_code": "688300",
   "pgm_ele_name": "Chemistry of Life Processes"
  },
  {
   "pgm_ele_code": "724400",
   "pgm_ele_name": "COMPUTATIONAL PHYSICS"
  },
  {
   "pgm_ele_code": "724600",
   "pgm_ele_name": "PHYSICS OF LIVING SYSTEMS"
  },
  {
   "pgm_ele_code": "801100",
   "pgm_ele_name": "Systems and Synthetic Biology"
  },
  {
   "pgm_ele_code": "807800",
   "pgm_ele_name": "INSPIRE"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "5936",
   "pgm_ref_txt": "GERMANY (F.R.G.)"
  },
  {
   "pgm_ref_code": "7281",
   "pgm_ref_txt": "QUATM INFO & REVOLUTIONARY COM"
  },
  {
   "pgm_ref_code": "7465",
   "pgm_ref_txt": "NANOSCALE BIO CORE"
  },
  {
   "pgm_ref_code": "8007",
   "pgm_ref_txt": "BioMaPS"
  },
  {
   "pgm_ref_code": "8653",
   "pgm_ref_txt": "INSPIRE Track-1 Creative"
  },
  {
   "pgm_ref_code": "9150",
   "pgm_ref_txt": "EXP PROG TO STIM COMP RES"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 999947.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Existing results in statistical physics show that there are certain unavoidable energetic costs that must be incurred by any physical system -- whether a man-made computer, a biological cell, or a nervous system -- that performs computations. We extended these foundational results concerning the thermodynamics of computation to analyze how energetic requirements depend on a rich set of trade-off between different aspects of the computation. Some of our main findings include:</p>\n<p>- A universal information-theoretic expression for how the energetic costs of running a fixed physical system that performs a computation vary as one changes the initial conditions of the physical system.&nbsp;</p>\n<p>To illustrate the significance of this, first note that modern digital computers comprise many billions of \"sub-computers\", e.g., digital gates. The overall computer operates by shunting information (in the form of electricity) among those sub-computers, along with instructions for what precisely each of those sub-computers must do. In essence, a modern digital computer is a huge community of digital devices, working in perfect lockstep to solve the overall information-processing task.</p>\n<p>Now consider any single one of those sub-computers. It is a physical system. Therefore, by our results, the energetic costs of running it will vary depending on its inputs. That in turn implies that if the overall computer shuttle the information and instructions and among its sub-computers in a different way - while still performing the same overall computation - the overall energetic costs could be reduced drastically.</p>\n<p>Our analysis for the first time derives the equations governing this phenomenon. Unfortunately, it will be a highly nontrivial effort to exploit these equations, to change the \"layout\" of modern computers - the precise way that they shuttle information among their sub-computers - in order to reduce the energetic costs.&nbsp;</p>\n<p>- A fundamental trade-off between memory available to a physical system and the number of steps it needs to carry out a given computation, which applies to any classical system governed by so-called \"master equation\".</p>\n<p>- A set of \"quantum speed limits\", which posit a fundamental trade-off between energy and speed of a computation that arises from quantum physics.</p>\n<p>- Fundamental limits on processes that harvest free energy from their environment. &nbsp; Consider, for example, a photosynthetic bacterium whose 'strategy' for harvesting free energy and using that free energy to do work consists of a (genetically programmed) probabilistic dynamics for interacting with its environment.&nbsp; We derive conditions on the optimal strategies for harvesting free energy and performing work, and give exact expressions -- analogous to Crooks theorem and the Jarzynski equality -- that govern the free energy deficit that results from suboptimal strategies. &nbsp; We show that the problem of devising an optimal probabilistic strategy is a convex optimization problem on the space of possible strategies, so that optimal strategies can be found by, e.g., straightforward methods of gradient descent.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/13/2020<br>\n\t\t\t\t\tModified by: David&nbsp;Wolpert</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nExisting results in statistical physics show that there are certain unavoidable energetic costs that must be incurred by any physical system -- whether a man-made computer, a biological cell, or a nervous system -- that performs computations. We extended these foundational results concerning the thermodynamics of computation to analyze how energetic requirements depend on a rich set of trade-off between different aspects of the computation. Some of our main findings include:\n\n- A universal information-theoretic expression for how the energetic costs of running a fixed physical system that performs a computation vary as one changes the initial conditions of the physical system. \n\nTo illustrate the significance of this, first note that modern digital computers comprise many billions of \"sub-computers\", e.g., digital gates. The overall computer operates by shunting information (in the form of electricity) among those sub-computers, along with instructions for what precisely each of those sub-computers must do. In essence, a modern digital computer is a huge community of digital devices, working in perfect lockstep to solve the overall information-processing task.\n\nNow consider any single one of those sub-computers. It is a physical system. Therefore, by our results, the energetic costs of running it will vary depending on its inputs. That in turn implies that if the overall computer shuttle the information and instructions and among its sub-computers in a different way - while still performing the same overall computation - the overall energetic costs could be reduced drastically.\n\nOur analysis for the first time derives the equations governing this phenomenon. Unfortunately, it will be a highly nontrivial effort to exploit these equations, to change the \"layout\" of modern computers - the precise way that they shuttle information among their sub-computers - in order to reduce the energetic costs. \n\n- A fundamental trade-off between memory available to a physical system and the number of steps it needs to carry out a given computation, which applies to any classical system governed by so-called \"master equation\".\n\n- A set of \"quantum speed limits\", which posit a fundamental trade-off between energy and speed of a computation that arises from quantum physics.\n\n- Fundamental limits on processes that harvest free energy from their environment.   Consider, for example, a photosynthetic bacterium whose 'strategy' for harvesting free energy and using that free energy to do work consists of a (genetically programmed) probabilistic dynamics for interacting with its environment.  We derive conditions on the optimal strategies for harvesting free energy and performing work, and give exact expressions -- analogous to Crooks theorem and the Jarzynski equality -- that govern the free energy deficit that results from suboptimal strategies.   We show that the problem of devising an optimal probabilistic strategy is a convex optimization problem on the space of possible strategies, so that optimal strategies can be found by, e.g., straightforward methods of gradient descent.\n\n\t\t\t\t\tLast Modified: 04/13/2020\n\n\t\t\t\t\tSubmitted by: David Wolpert"
 }
}