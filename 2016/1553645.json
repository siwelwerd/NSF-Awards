{
 "awd_id": "1553645",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Application-centric, Reliable and Efficient High Performance Computing",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2016-02-01",
 "awd_exp_date": "2023-01-31",
 "tot_intn_awd_amt": 499989.0,
 "awd_amount": 507989.0,
 "awd_min_amd_letter_date": "2015-12-31",
 "awd_max_amd_letter_date": "2020-02-11",
 "awd_abstract_narration": "Mission-critical scientific simulations (e.g., climate simulation and fluid dynamics simulation) and enterprise workloads (e.g., search and encryption) running on large-scale computing systems are jeopardized by the increase of faults and errors in hardware and software. Understanding the vulnerability of these large-scale applications is important to minimize performance and power. Lack of the knowledge of application vulnerability forms a major bottleneck of execution efficiency, and jeopardizes HPC simulation capabilities. Previous works rely on random fault injection or detailed architecture analysis to evaluate application vulnerability. They can be slow and inaccurate. There is a big gap between the needs of reliable and efficient HPC and what the current methodologies can provide. \r\nThis research explores a new methodology to understand application vulnerability. It investigates new analytical and statistical models to quantify and characterize application vulnerability based on a novel metric and application semantics (including algorithm semantics and data semantics). The PI integrates modeling techniques into a broader context for vulnerability analysis to improve the modeling accuracy and explore reliable and efficient protection for applications while examine the interplay between reliability, power, and performance.\r\n\r\nThe outcome from this research will provide support for execution correctness and efficiency of large-scale applications running on future computing systems that demand high data integrity. The proposed research will affect design of reliable applications and algorithms. Built upon the collaboration with industry, the research outcome is expected to be tangible and have direct impact on realistic scientific problems. Furthermore, the tight coupling between research components and education components creates a HPC learning culture to engage students in HPC, addressing HPC workforce shortage in the nation.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Dong",
   "pi_last_name": "Li",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Dong Li",
   "pi_email_addr": "dli35@ucmerced.edu",
   "nsf_id": "000690232",
   "pi_start_date": "2015-12-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California - Merced",
  "inst_street_address": "5200 N LAKE RD",
  "inst_street_address_2": "",
  "inst_city_name": "MERCED",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "2092012039",
  "inst_zip_code": "953435001",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "CA13",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, MERCED",
  "org_prnt_uei_num": "",
  "org_uei_num": "FFM7VPAG8P92"
 },
 "perf_inst": {
  "perf_inst_name": "University of California, Merced",
  "perf_str_addr": "5200 N. Lake Road",
  "perf_city_name": "Merced",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "953435001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "CA13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 219073.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 108725.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 60848.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 111343.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Mission-critical scientific simulations (e.g., climate simulation and fluid dynamics simulation) and enterprise workloads (e.g., search and machine learning) running on large-scale computing systems are jeopardized by the increase of faults and errors in hardware and software. Understanding the vulnerability of these large-scale applications is important to minimize performance and power. Lack of the knowledge of application vulnerability forms a major bottleneck of execution efficiency and jeopardizes HPC simulation capabilities.</p>\n<p>The traditional approaches rely on random fault injection or detailed architecture analysis to evaluate application vulnerability. These approaches can be slow and inaccurate. Hence, there is a big gap between the needs of reliable and efficient HPC and what the current methodologies can provide.</p>\n<p>In this project, we explore a new methodology to understand application vulnerability. We introduce new analytical and statistical models to quantify and characterize application vulnerability based on a novel metric and application semantics (including algorithm semantics and data semantics). We integrate modeling techniques into a broader context for vulnerability analysis to improve the modeling accuracy and explore reliable and efficient protection for applications.</p>\n<p>Built upon our research results (modeling techniques and metrics), we study (1) how to use machine learning-based approximate to accelerate HPC applications (including power grid simulation and Eulerian fluid dynamics simulation), (2) how to use memoization to accelerate the self-attention mechanism in transformer models, and (3) how to use emerging persistent memory to handle system failures and avoid data loss without losing data consistency.</p>\n<p>Our research generates high impacts on HPC system infrastructure and HPC application designs. From the infrastructure perspective, based upon our collaboration with national labs (such as Lawrence Livermore National Lab, Pacific Northwest National Lab, and Argonne National Lab) and industry (HP), our research provides guidance on how the HPC data centers should be built to handle potential faults and errors. From the application perspective, our work is able to bring huge performance benefits to HPC applications. For example, our work that used our modeling techniques for machine learning-based approximation brought more than 200x performance improvement to some Eulerian fluid dynamics simulation. Our work to accelerate the power grid simulation (a mission-critical application) has been reported and highlighted by a DOE website. Our work on resilience modeling based on machine learning and MPI fault tolerance benchmarks have been highlighted by HPCWire (the number 1 media to report HPC news) twice.&nbsp;&nbsp;</p>\n<p>Our research involved undergraduate students (including under-represented students at Merced) by the REU program. We integrated our research outcomes (e.g., compile techniques) into undergraduate and graduate student classes. We provided student internship every year. We provided abundant hands-on experiences to graduate and undergraduate students through research and teaching. We frequently advertised our work in scientific conferences and attracted students to computer science research. A couple of undergraduate students who worked in our project continued working with us as PhD students.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/19/2023<br>\n\t\t\t\t\tModified by: Dong&nbsp;Li</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMission-critical scientific simulations (e.g., climate simulation and fluid dynamics simulation) and enterprise workloads (e.g., search and machine learning) running on large-scale computing systems are jeopardized by the increase of faults and errors in hardware and software. Understanding the vulnerability of these large-scale applications is important to minimize performance and power. Lack of the knowledge of application vulnerability forms a major bottleneck of execution efficiency and jeopardizes HPC simulation capabilities.\n\nThe traditional approaches rely on random fault injection or detailed architecture analysis to evaluate application vulnerability. These approaches can be slow and inaccurate. Hence, there is a big gap between the needs of reliable and efficient HPC and what the current methodologies can provide.\n\nIn this project, we explore a new methodology to understand application vulnerability. We introduce new analytical and statistical models to quantify and characterize application vulnerability based on a novel metric and application semantics (including algorithm semantics and data semantics). We integrate modeling techniques into a broader context for vulnerability analysis to improve the modeling accuracy and explore reliable and efficient protection for applications.\n\nBuilt upon our research results (modeling techniques and metrics), we study (1) how to use machine learning-based approximate to accelerate HPC applications (including power grid simulation and Eulerian fluid dynamics simulation), (2) how to use memoization to accelerate the self-attention mechanism in transformer models, and (3) how to use emerging persistent memory to handle system failures and avoid data loss without losing data consistency.\n\nOur research generates high impacts on HPC system infrastructure and HPC application designs. From the infrastructure perspective, based upon our collaboration with national labs (such as Lawrence Livermore National Lab, Pacific Northwest National Lab, and Argonne National Lab) and industry (HP), our research provides guidance on how the HPC data centers should be built to handle potential faults and errors. From the application perspective, our work is able to bring huge performance benefits to HPC applications. For example, our work that used our modeling techniques for machine learning-based approximation brought more than 200x performance improvement to some Eulerian fluid dynamics simulation. Our work to accelerate the power grid simulation (a mission-critical application) has been reported and highlighted by a DOE website. Our work on resilience modeling based on machine learning and MPI fault tolerance benchmarks have been highlighted by HPCWire (the number 1 media to report HPC news) twice.  \n\nOur research involved undergraduate students (including under-represented students at Merced) by the REU program. We integrated our research outcomes (e.g., compile techniques) into undergraduate and graduate student classes. We provided student internship every year. We provided abundant hands-on experiences to graduate and undergraduate students through research and teaching. We frequently advertised our work in scientific conferences and attracted students to computer science research. A couple of undergraduate students who worked in our project continued working with us as PhD students. \n\n \n\n\t\t\t\t\tLast Modified: 03/19/2023\n\n\t\t\t\t\tSubmitted by: Dong Li"
 }
}