{
 "awd_id": "1618398",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "TWC: Small: Evidence of Presence for Intelligent Vehicles using Environment-Based Security",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922981",
 "po_email": "pregalia@nsf.gov",
 "po_sign_block_name": "Phillip Regalia",
 "awd_eff_date": "2016-08-15",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 416938.0,
 "awd_amount": 416938.0,
 "awd_min_amd_letter_date": "2016-08-08",
 "awd_max_amd_letter_date": "2016-08-08",
 "awd_abstract_narration": "Emerging intelligent automobiles will be able to harness advance on-car sensors to support new applications such as pollution detection, road condition monitoring, and traffic control. All these applications require the ability to verify both the location and the time of a reading. This project involves the design of verification methods that make use of environment factors, such as the presence of light and shadows and the measured wireless signal strength, instead of conventional public key infrastructure-based methods, in order to verify when and where data was collected.  This new environment-based paradigm is resilient against insider attacks, easier to deploy, and protects the individual car owner's privacy.  This research will help in realizing applications arising from the increasing presence of smarter vehicles on our roads which can benefit the public's wellbeing. The project also incorporates outreach components for high school and college students through the organization of science competitions, national undergraduate workshops, and summer research camp activities.  \r\n\r\nThis project is the first effort to use the wireless communication and video recording abilities of modern automobiles to capture natural environment characteristics to securely verify spatial-temporal claims in a vehicular network setting. This is an interdisciplinary research effort combining wireless networking and computer vision to address vehicular network security. The main project goals are: (1) explore new vision analytic algorithms in order to identify the location and time images are captured by an automobile camera;  (2) research new algorithms for identifying optimal roadside unit locations for location disambiguation to support wireless spatial-temporal verification; (3) develop new techniques for utilizing encounters with public vehicles for verifying spatial-temporal claims; (4) developing a fusion framework to combine wireless measurements, vehicular encounters, and visual images for spatial-temporal verification; and (5) perform realistic experiments on real roads and vehicular test bed to collect image and wireless datasets and evaluate the research. These datasets are of interest to both wireless networking and computer vision research communities, and will be made available to the public.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Chiu",
   "pi_last_name": "Tan",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "Chiu C Tan",
   "pi_email_addr": "cctan@temple.edu",
   "nsf_id": "000584104",
   "pi_start_date": "2016-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Haibin",
   "pi_last_name": "Ling",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Haibin Ling",
   "pi_email_addr": "hling@cs.stonybrook.edu",
   "nsf_id": "000516498",
   "pi_start_date": "2016-08-08",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jie",
   "pi_last_name": "Wu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jie Wu",
   "pi_email_addr": "jiewu@temple.edu",
   "nsf_id": "000519190",
   "pi_start_date": "2016-08-08",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Temple University",
  "inst_street_address": "1805 N BROAD ST",
  "inst_street_address_2": "",
  "inst_city_name": "PHILADELPHIA",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "2157077547",
  "inst_zip_code": "191226104",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "PA02",
  "org_lgl_bus_name": "TEMPLE UNIVERSITY-OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION",
  "org_prnt_uei_num": "QD4MGHFDJKU1",
  "org_uei_num": "QD4MGHFDJKU1"
 },
 "perf_inst": {
  "perf_inst_name": "Temple University",
  "perf_str_addr": "1925 N. 12th Street",
  "perf_city_name": "Philadelphia",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "191221801",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "PA02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 416938.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>&nbsp;The modern automobile is equipped with cameras to help with navigation, as well as wireless radios to support communication with roadside access points (APs). The goal of this project is to make use of these two features, wireless communication and the camera, to verify the location and time of a particular car. The intuition is that environmental factors, such as the weather, traffic, etc., will have an impact on the wireless signal propagation and images captured by a vehicle, and we can harness these differences to help in the verification process. As part of this project, we have developed new algorithms to determine where to install these APs so as to support this verification.&nbsp; This includes algorithms that can balance between the traffic density and the detour probability, as well as algorithms that determine the minimum number of APs needed for a stretch of road and their ideal locations. Since vehicles often travel in less than ideal environmental conditions, e.g. snow, rain, fog, etc., we have also developed new computer vision algorithms that are suitable when the camera is operating these poor weather conditions. &nbsp;We have developed an efficient and effective lowlight image enhancement technique for processing pictures captured in poor light environments, as well as a framework to track a vehicle?s headlights in nighttime traffic scene. Our framework is robust to ambiguities due to light reflection, similarity of vehicular headlights, dense or fast moving traffic environments. We also designed a new deep-learning based architecture to enable a vehicle to track multiple vehicles and landmarks simultaneously. &nbsp;Finally, we have also proposed a recruitment system to help crowdsource these images to help with the verification process. Simply collecting photographs from users is not ideal because there could be a mismatch between what was collected, compared to photographs that are actually needed to understand an environment. Our algorithm is able to identify the ideal set of users based on their location and predicted mobility to request information.&nbsp; Finally, while working on the project, we found there was a lack of datasets of poor weather conditions available to the research community. We created a new vehicular dataset that captures different weather/illumination conditions (e.g. sunny, overcast, snow, etc.). The dataset consists of over 1,000 traffic scenes from over 200 different locations. For each location, there are six images taken by a vehicle mounted camera under different weather/illumination conditions.&nbsp; This dataset will help support research in computer vision research in areas such as autonomous driving and advanced driver assistance.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/03/2020<br>\n\t\t\t\t\tModified by: Chiu&nbsp;C&nbsp;Tan</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n The modern automobile is equipped with cameras to help with navigation, as well as wireless radios to support communication with roadside access points (APs). The goal of this project is to make use of these two features, wireless communication and the camera, to verify the location and time of a particular car. The intuition is that environmental factors, such as the weather, traffic, etc., will have an impact on the wireless signal propagation and images captured by a vehicle, and we can harness these differences to help in the verification process. As part of this project, we have developed new algorithms to determine where to install these APs so as to support this verification.  This includes algorithms that can balance between the traffic density and the detour probability, as well as algorithms that determine the minimum number of APs needed for a stretch of road and their ideal locations. Since vehicles often travel in less than ideal environmental conditions, e.g. snow, rain, fog, etc., we have also developed new computer vision algorithms that are suitable when the camera is operating these poor weather conditions.  We have developed an efficient and effective lowlight image enhancement technique for processing pictures captured in poor light environments, as well as a framework to track a vehicle?s headlights in nighttime traffic scene. Our framework is robust to ambiguities due to light reflection, similarity of vehicular headlights, dense or fast moving traffic environments. We also designed a new deep-learning based architecture to enable a vehicle to track multiple vehicles and landmarks simultaneously.  Finally, we have also proposed a recruitment system to help crowdsource these images to help with the verification process. Simply collecting photographs from users is not ideal because there could be a mismatch between what was collected, compared to photographs that are actually needed to understand an environment. Our algorithm is able to identify the ideal set of users based on their location and predicted mobility to request information.  Finally, while working on the project, we found there was a lack of datasets of poor weather conditions available to the research community. We created a new vehicular dataset that captures different weather/illumination conditions (e.g. sunny, overcast, snow, etc.). The dataset consists of over 1,000 traffic scenes from over 200 different locations. For each location, there are six images taken by a vehicle mounted camera under different weather/illumination conditions.  This dataset will help support research in computer vision research in areas such as autonomous driving and advanced driver assistance.\n\n \n\n\t\t\t\t\tLast Modified: 10/03/2020\n\n\t\t\t\t\tSubmitted by: Chiu C Tan"
 }
}