{
 "awd_id": "1628401",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: EXPL: Cache Management for Data Parallel Architecture",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2016-08-22",
 "awd_max_amd_letter_date": "2016-08-22",
 "awd_abstract_narration": "Current advances in computer science and other disciplines rely on the massive computation horsepower of data parallel architectures, such as GPUs. Programming data parallel architecture is not easy, as it requires the efficient handling of data movements across the memory hierarchy of thousands of processing cores. \r\n\r\nTo date, data movement problems have been primarily studied in uni-core and multi-core programming systems.  Thus, shifting to a many-core programming paradigm presents the new challenges of 1) scalability, 2) software and hardware interface, and 3) addressing the trade-off between performance and energy. First, the data movement models in uni-core and multi-core processors do not scale well, thus, this project develops scalable analytical models and yet provides powerful heuristics in practice. Second, it is important to redefine the responsibilities of software and hardware. Given the complexity of many-core architecture, it is impossible to solve data movement problems using software-only or hardware-only approaches. This project optimizes data movements with a cross-stack design principle that aims to combine the strengths of software and hardware. Third, previous studies have focused on performance without much consideration to issues of power and energy efficiency. This project targets both performance and energy, models the energy cost of data movement and integrates this information into the power/energy model for the entire system. Overall, this project can help shape future software-hardware cache interfaces and lay the foundation for the design of next-generation cache systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Zheng",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Zheng Zhang",
   "pi_email_addr": "eddy.zhengzhang@cs.rutgers.edu",
   "nsf_id": "000630494",
   "pi_start_date": "2016-08-22",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Rutgers University New Brunswick",
  "inst_street_address": "3 RUTGERS PLZ",
  "inst_street_address_2": "",
  "inst_city_name": "NEW BRUNSWICK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "8489320150",
  "inst_zip_code": "089018559",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "RUTGERS, THE STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "M1LVPE5GLSD9"
 },
 "perf_inst": {
  "perf_inst_name": "Rutgers University New Brunswick",
  "perf_str_addr": "110 Frelinghuysen Road",
  "perf_city_name": "Piscataway",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "088548072",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "NJ06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span class=\"s1\">Massively parallel computing systems such as GPUs have been driving innovations in business, education, and recreational computation applications. In these massively parallel systems, data movement is a performance and energy bottleneck. To take advantage of the tremendous computation horsepower, programmers must efficiently handle data movements across the memory hierarchy of thousands of processing cores. However it is challenging to accomplish this goal without domain expertise in low level hardware details. This project develops analytical models and software tools to help programmers manage data movements in an automatic way. It takes a cross-stack design principle, combining the strengths of both software and hardware. I</span><span class=\"s2\">t has resulted in extensive experiment data sets for understanding the performance tradeoff of various cache design techniques. Overall, the research work accomplished in this project lays foundation for the design of next-generation cache systems in massively parallel systems.&nbsp;</span></p>\n<p class=\"p2\"><span class=\"s3\">&nbsp;</span></p>\n<p class=\"p3\"><span class=\"s3\">The PI and the students involved in this project have disseminated research results through publications in premium research venues and presentations at prestigious international conferences. Further, this proposal has yielded two open-source software infrastructure tools for the research community to take advantage of massively computing platforms. &nbsp;</span>The grant has trained both undergraduate and graduate students. In particular, the project has encouraged and enhanced the representation of minority groups in STEM research by training and attracting an African American undergraduate student to computer science profession.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/30/2021<br>\n\t\t\t\t\tModified by: Zheng&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Massively parallel computing systems such as GPUs have been driving innovations in business, education, and recreational computation applications. In these massively parallel systems, data movement is a performance and energy bottleneck. To take advantage of the tremendous computation horsepower, programmers must efficiently handle data movements across the memory hierarchy of thousands of processing cores. However it is challenging to accomplish this goal without domain expertise in low level hardware details. This project develops analytical models and software tools to help programmers manage data movements in an automatic way. It takes a cross-stack design principle, combining the strengths of both software and hardware. It has resulted in extensive experiment data sets for understanding the performance tradeoff of various cache design techniques. Overall, the research work accomplished in this project lays foundation for the design of next-generation cache systems in massively parallel systems. \n \nThe PI and the students involved in this project have disseminated research results through publications in premium research venues and presentations at prestigious international conferences. Further, this proposal has yielded two open-source software infrastructure tools for the research community to take advantage of massively computing platforms.  The grant has trained both undergraduate and graduate students. In particular, the project has encouraged and enhanced the representation of minority groups in STEM research by training and attracting an African American undergraduate student to computer science profession.\n\n \n\n\t\t\t\t\tLast Modified: 03/30/2021\n\n\t\t\t\t\tSubmitted by: Zheng Zhang"
 }
}