{
 "awd_id": "1613295",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Integrative Multivariate Analysis of Multi-View Data",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2016-08-15",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2016-08-04",
 "awd_max_amd_letter_date": "2016-08-04",
 "awd_abstract_narration": "Multi-view data, or the measuring of several distinct yet interrelated sets of characteristics pertaining to a single set of subjects and possibly collected from an array of sources, has become increasingly common in the fields of engineering and scientific research. This project innovates new methodologies, statistical theories, and scalable computational tools to tackle a range of statistical learning problems with multi-view data. An integrated statistical analysis of the multi-view data generation mechanisms, enabled by this project, will allow us to gain extraordinary insight of real-world phenomena by utilizing information obtained from different lenses and from different angles. \r\n\r\nThe PI will develop several generalizations of the reduced-rank matrix structure, to enable a spectrum of multivariate statistical methods for multi-view learning. The general methodology of reduced-rank estimation is one of the most critical ingredients in modern multivariate analysis. However, for handling multi-view data, the potential of the reduced-rank methodology is far from being fully realized or understood. This project presents the following overarching objectives: (1) develop integrative multivariate regression for joint learning, which entails the exploitation of multiple sets of features to build an integrated predictive model of multivariate response; (2) develop integrative canonical correlation analysis for shared learning, by combining the exploration of shared low-dimensional association structures between multiple sets of features and the development of coherent predictive models for multivariate response; (3) develop integrative dimension reduction for multi-scale learning, by utilizing both the global and local low-dimensional structures among sub-matrices of a high-dimensional matrix object; (4) develop diagnostic measures for robust learning, which would enable reliable multi-view data integration and data quality assessment.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Kun",
   "pi_last_name": "Chen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Kun Chen",
   "pi_email_addr": "kun.chen@uconn.edu",
   "nsf_id": "000614146",
   "pi_start_date": "2016-08-04",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Connecticut",
  "inst_street_address": "438 WHITNEY RD EXTENSION UNIT 1133",
  "inst_street_address_2": "",
  "inst_city_name": "STORRS",
  "inst_state_code": "CT",
  "inst_state_name": "Connecticut",
  "inst_phone_num": "8604863622",
  "inst_zip_code": "062699018",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "CT02",
  "org_lgl_bus_name": "UNIVERSITY OF CONNECTICUT",
  "org_prnt_uei_num": "",
  "org_uei_num": "WNTPS995QBM7"
 },
 "perf_inst": {
  "perf_inst_name": "University of Connecticut",
  "perf_str_addr": "215 Glenbrook Road",
  "perf_city_name": "Storrs",
  "perf_st_code": "CT",
  "perf_st_name": "Connecticut",
  "perf_zip_code": "062694120",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "CT02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 150000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project has innovated a range of new methodologies, theories, and scalable computational tools to advance statistical learning with multivariate and multi-view data. Multi-view data, or the measuring of several distinct yet interrelated sets of characteristics pertaining to a single set of subjects and possibly collected from an array of sources, has become increasingly common in the fields of engineering and scientific research. Integrative learning using the tools developed in this project has allowed us to gain important insights in a variety of real-world applications in genetics, finance, population health, among others.&nbsp;</p>\n<p>Throughout the project, we have pursued a comprehensive investigation and generalization of the so-called reduced-rank methodology, one of the most critical ingredients in modern multivariate statistical techniques, in order to advance it for large-scale multivariate/multi-view learning. We have progressed on three aspects. First, we investigated the fundamental properties of reduced-rank estimation, including its complexity measure (degrees of freedom) and unbiased risk estimation, model selection and diagnostics, robustification and outlier detection, nested or multi-scale reduced-rank structure, adaptive nuclear-norm penalization for improving bias-variance tradeoff, and composite nuclear-norm penalization for dimension reduction with multi-view feature sets. Second, we investigated the integration of reduced-rank structure with other indispensable data attributes and modeling elements, such as sparsity, feature grouping, dynamic association, missing data, data heterogeneity, etc. For example, we have developed a series of sparse and low-rank methods for simultaneous dimension reduction and variable selection, such as sparse and orthogonal factor regression for association network learning, Bayesian sparse and low-rank models for inference making, generalized sparse and low-rank models with mixed-type responses, divide-and-conquer and stagewise learning approaches for scalable computation, among others. Third, we investigated the integration of disparate but interrelated learning objectives with multi-view data, such as simultaneous feature construction and predictive modeling. With this project, the potentials of the reduced-rank methodology have been better realized and understood for handling multivariate and multi-view data in joint learning, shared learning, multi-scale learning and robust learning.&nbsp;</p>\n<p>The project has involved training of several Ph.D. students. More than 20 papers have been published in leading statistical and machine learning journals, and several R packages have been developed and distributed on CRAN.&nbsp;</p>\n<div>\n<div>\n<div></div>\n</div>\n</div>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/11/2020<br>\n\t\t\t\t\tModified by: Kun&nbsp;Chen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project has innovated a range of new methodologies, theories, and scalable computational tools to advance statistical learning with multivariate and multi-view data. Multi-view data, or the measuring of several distinct yet interrelated sets of characteristics pertaining to a single set of subjects and possibly collected from an array of sources, has become increasingly common in the fields of engineering and scientific research. Integrative learning using the tools developed in this project has allowed us to gain important insights in a variety of real-world applications in genetics, finance, population health, among others. \n\nThroughout the project, we have pursued a comprehensive investigation and generalization of the so-called reduced-rank methodology, one of the most critical ingredients in modern multivariate statistical techniques, in order to advance it for large-scale multivariate/multi-view learning. We have progressed on three aspects. First, we investigated the fundamental properties of reduced-rank estimation, including its complexity measure (degrees of freedom) and unbiased risk estimation, model selection and diagnostics, robustification and outlier detection, nested or multi-scale reduced-rank structure, adaptive nuclear-norm penalization for improving bias-variance tradeoff, and composite nuclear-norm penalization for dimension reduction with multi-view feature sets. Second, we investigated the integration of reduced-rank structure with other indispensable data attributes and modeling elements, such as sparsity, feature grouping, dynamic association, missing data, data heterogeneity, etc. For example, we have developed a series of sparse and low-rank methods for simultaneous dimension reduction and variable selection, such as sparse and orthogonal factor regression for association network learning, Bayesian sparse and low-rank models for inference making, generalized sparse and low-rank models with mixed-type responses, divide-and-conquer and stagewise learning approaches for scalable computation, among others. Third, we investigated the integration of disparate but interrelated learning objectives with multi-view data, such as simultaneous feature construction and predictive modeling. With this project, the potentials of the reduced-rank methodology have been better realized and understood for handling multivariate and multi-view data in joint learning, shared learning, multi-scale learning and robust learning. \n\nThe project has involved training of several Ph.D. students. More than 20 papers have been published in leading statistical and machine learning journals, and several R packages have been developed and distributed on CRAN. \n\n\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 11/11/2020\n\n\t\t\t\t\tSubmitted by: Kun Chen"
 }
}