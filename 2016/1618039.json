{
 "awd_id": "1618039",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Latency Tolerance Aware Runtime Optimization for General-Purpose GPU Architectures",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yuanyuan Yang",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2021-07-31",
 "tot_intn_awd_amt": 330000.0,
 "awd_amount": 346000.0,
 "awd_min_amd_letter_date": "2016-07-28",
 "awd_max_amd_letter_date": "2017-05-15",
 "awd_abstract_narration": "Computing touches almost all aspects of our modern day lives -- from gene sequencing to physics simulations to powering the Internet, from real-time image and voice recognition to predicting stock market trends. The programmability advancement of high-performance accelerators, such as graphics processors, has enabled a large, diverse set of general-purpose algorithms to enjoy performance acceleration on GPUs. However, because the unique latency tolerance GPU design feature is often not taken into account, the state-of-the-art solutions lead to sub-optimal performance improvement. The proposed Latency Tolerance Aware runtime optimization framework (LATTE) can help the computing industry realize its high performance and high energy efficiency vision. Performance acceleration of important general-purpose algorithms with large and diverse input data sets has a profound impact on the advancement of all research domains and on society. The research agenda is complemented by an education agenda focusing on heterogeneous computing.\r\n\r\nThe LATTE framework proposed in this project aims to explore and propose architectural solutions and to create system supports to accelerate the execution of important general-purpose applications on GPUs. The proposed LATTE runtime optimization framework revolves around identifying and designing optimization techniques that are fully latency tolerance aware in order to maximize performance improvement for GPGPUs. The pitfalls for directly adapting CPU-centric optimization to GPU architectures are analyzed and used to motivate the need to proactively manage the highly time-multiplexed computation and memory resources considering the critical latency tolerance characteristic of GPUs. The findings can serve as foundations for future performance optimization research to avoid blind replication, leading to important scientific research contributions for GPGPU acceleration.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Carole-Jean",
   "pi_last_name": "Wu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Carole-Jean Wu",
   "pi_email_addr": "carole-jean.wu@asu.edu",
   "nsf_id": "000635542",
   "pi_start_date": "2016-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Arizona State University",
  "inst_street_address": "660 S MILL AVENUE STE 204",
  "inst_street_address_2": "",
  "inst_city_name": "TEMPE",
  "inst_state_code": "AZ",
  "inst_state_name": "Arizona",
  "inst_phone_num": "4809655479",
  "inst_zip_code": "852813670",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "AZ04",
  "org_lgl_bus_name": "ARIZONA STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NTLHJXM55KZ6"
 },
 "perf_inst": {
  "perf_inst_name": "Arizona State University",
  "perf_str_addr": "P.O. Box 876011",
  "perf_city_name": "Tempe",
  "perf_st_code": "AZ",
  "perf_st_name": "Arizona",
  "perf_zip_code": "852876011",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "AZ04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 330000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"p1\"><span>Graphic processing units (GPUs) have gradually emerged as one of the main general purpose computing resources in modern computer architecture. GPU, originally designed for accelerating graphics computations, is an efficient alternative to traditional chip-multiprocessors for executing general purpose parallel workloads (GPGPU). The availability of programming and architecture support for executing general purpose computations on GPUs enables the acceleration of a diverse set of important and large problems, such as environmental and disaster modeling and prediction, real-time image-based learning and prediction by deep neural network learning algorithms, material discovery with a large database of material properties, ribonucleic acid (RNA) structure prediction, weather forecasting and climate research, molecular dynamics, cosmology, medical image processing, stock market trading trends, and many applications in other domains.</span><br /><br /><span>With the ubiquity of GPGPU applications, it is natural to port and adapt existing CPU-centric performance optimization techniques to GPU architectures, in the hope to accelerate these general purpose workloads even more when running on GPUs. However, some of these CPU-centric optimization techniques work well on GPUs while others do not. This research revolves around designs and optimization techniques to improve GPGPU performance by increasing computation resource utilization while taking full advantage of the latency tolerance design feature of modern GPU architectures. During the project period, we explore a wide range of optimization techniques to improve the performance of GPGPU code by improving the performance and/or energy efficiency of the GPU architectures and the memory subsystems while exploiting the latency-tolerance nature of GPU architectures [1]-[6].&nbsp;</span></p>\n<p class=\"p1\"><span><br /></span></p>\n<p class=\"p1\">\n<div>Furthermore, we expand the research to explore automatic post-compilation code optimization techniques.&nbsp;Optimizing GPU codes requires application developers to have significant knowledge in parallel programming and GPU architectures, and in-depth application understanding. This combination makes it challenging to find performance optimizations for algorithms.&nbsp;To tackle the performance optimization challenge, we demonstrate that significant speedups can be achieved using evolutionary computation methods to improve human-optimized sequence alignment code. We develop an automatic post-compilation performance optimization tool to find code edits to improve GPU code performance. The real GPU system performance results show significant execution time improvement for both the GPGPU benchmark suite and a widely-adopted sequence alignment library.&nbsp;The results showcase the potential of automated program optimization tools to help reduce the optimization burden for application developers. In this research, we also delve deeply into the code edits uncovered by the evolutionary computing-based framework to explain how the optimizations are discovered and investigate the role of epistasis, or interdependencies, in the discovered optimizations. The detailed research outcomes are available in [7][8].&nbsp;<br /><br /><br />[1] S.-Y. Lee and C.-J. Wu, &ldquo;Ctrl-C: Control Loop Based Adaptive Cache Bypassing for GPUs,&rdquo; In Proceedings of the International Conference on Computer Design (ICCD), 2016.<br /><br />[2] A. Arunkumar, S.-Y. Lee, and C.-J. Wu, &ldquo;ID-Cache: Instruction and Memory Divergence Based Management for GPGPU Caches&rdquo; In Proceedings of the IEEEInternational Symposium on Workload Characterization (IISWC), 2016.<br /><br />[3] A. Arunkumar, E. Bolotin, B. Cho, U. Milic, E. Ebrahimi, O. Villa, A. Jaleel, C.-J. Wu,and D. Nellans, &ldquo;MCM-GPU: Multi-Chip-Module GPUs for Continued Performance Scalability,&rdquo; In Proceedings of the ACM/IEEE International Symposium on Computer Architecture (ISCA), 2017.<br /><br />[4] A. Arunkumar, S.-Y. Lee, V. Soundararajan, and C.-J. Wu. LATTE-CC: Latency Tolerance Aware Adaptive Cache Compression Management for Energy Efficient GPUs. In Proceedings of the IEEE International Symposium on High Performance Computer Architecture (HPCA), 2018.<br /><br />[5] H.-M. Chen, S.-Y. Lee, T. Mudge, C.-J. Wu, and C. Chakrabarti. Configurable-ECC: Architecting a Flexible ECC Scheme to Support Different Sized Accesses in High Bandwidth Memory Systems. In Proceedings of the IEEE Transactions on Computers (TOC), 2018.<br /><br />[6] A. Arunkumar, E. Bolotin, D. Nellans, and C.-J. Wu. Understanding the Future of Energy Efficiency in Multi-Module GPUs. In Proceedings of the 25th IEEE International Symposium on High Performance Computer Architecture (HPCA), 2019.<br /><br />[7] J.-Y. Liou, S. Forrest, and C.-J. Wu. Genetic Improvement of GPU Code. In Proceedings of the Annual Workshop on Genetic Improvement (GI) in conjunction with ICSE, 2019.<br /><br />[8] J.-Y. Liou, X. Wang, S. Forrest, and C.-J. Wu. GEVO: GPU Code Optimization Using Evolutionary Computation. In Proceedings of the ACMTransactions on Architecture and Code Optimization (TACO), 2020.</div>\n<div></div>\n</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/23/2021<br>\n\t\t\t\t\tModified by: Carole-Jean&nbsp;Wu</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Graphic processing units (GPUs) have gradually emerged as one of the main general purpose computing resources in modern computer architecture. GPU, originally designed for accelerating graphics computations, is an efficient alternative to traditional chip-multiprocessors for executing general purpose parallel workloads (GPGPU). The availability of programming and architecture support for executing general purpose computations on GPUs enables the acceleration of a diverse set of important and large problems, such as environmental and disaster modeling and prediction, real-time image-based learning and prediction by deep neural network learning algorithms, material discovery with a large database of material properties, ribonucleic acid (RNA) structure prediction, weather forecasting and climate research, molecular dynamics, cosmology, medical image processing, stock market trading trends, and many applications in other domains.\n\nWith the ubiquity of GPGPU applications, it is natural to port and adapt existing CPU-centric performance optimization techniques to GPU architectures, in the hope to accelerate these general purpose workloads even more when running on GPUs. However, some of these CPU-centric optimization techniques work well on GPUs while others do not. This research revolves around designs and optimization techniques to improve GPGPU performance by increasing computation resource utilization while taking full advantage of the latency tolerance design feature of modern GPU architectures. During the project period, we explore a wide range of optimization techniques to improve the performance of GPGPU code by improving the performance and/or energy efficiency of the GPU architectures and the memory subsystems while exploiting the latency-tolerance nature of GPU architectures [1]-[6]. \n\n\n\nFurthermore, we expand the research to explore automatic post-compilation code optimization techniques. Optimizing GPU codes requires application developers to have significant knowledge in parallel programming and GPU architectures, and in-depth application understanding. This combination makes it challenging to find performance optimizations for algorithms. To tackle the performance optimization challenge, we demonstrate that significant speedups can be achieved using evolutionary computation methods to improve human-optimized sequence alignment code. We develop an automatic post-compilation performance optimization tool to find code edits to improve GPU code performance. The real GPU system performance results show significant execution time improvement for both the GPGPU benchmark suite and a widely-adopted sequence alignment library. The results showcase the potential of automated program optimization tools to help reduce the optimization burden for application developers. In this research, we also delve deeply into the code edits uncovered by the evolutionary computing-based framework to explain how the optimizations are discovered and investigate the role of epistasis, or interdependencies, in the discovered optimizations. The detailed research outcomes are available in [7][8]. \n\n\n[1] S.-Y. Lee and C.-J. Wu, \"Ctrl-C: Control Loop Based Adaptive Cache Bypassing for GPUs,\" In Proceedings of the International Conference on Computer Design (ICCD), 2016.\n\n[2] A. Arunkumar, S.-Y. Lee, and C.-J. Wu, \"ID-Cache: Instruction and Memory Divergence Based Management for GPGPU Caches\" In Proceedings of the IEEEInternational Symposium on Workload Characterization (IISWC), 2016.\n\n[3] A. Arunkumar, E. Bolotin, B. Cho, U. Milic, E. Ebrahimi, O. Villa, A. Jaleel, C.-J. Wu,and D. Nellans, \"MCM-GPU: Multi-Chip-Module GPUs for Continued Performance Scalability,\" In Proceedings of the ACM/IEEE International Symposium on Computer Architecture (ISCA), 2017.\n\n[4] A. Arunkumar, S.-Y. Lee, V. Soundararajan, and C.-J. Wu. LATTE-CC: Latency Tolerance Aware Adaptive Cache Compression Management for Energy Efficient GPUs. In Proceedings of the IEEE International Symposium on High Performance Computer Architecture (HPCA), 2018.\n\n[5] H.-M. Chen, S.-Y. Lee, T. Mudge, C.-J. Wu, and C. Chakrabarti. Configurable-ECC: Architecting a Flexible ECC Scheme to Support Different Sized Accesses in High Bandwidth Memory Systems. In Proceedings of the IEEE Transactions on Computers (TOC), 2018.\n\n[6] A. Arunkumar, E. Bolotin, D. Nellans, and C.-J. Wu. Understanding the Future of Energy Efficiency in Multi-Module GPUs. In Proceedings of the 25th IEEE International Symposium on High Performance Computer Architecture (HPCA), 2019.\n\n[7] J.-Y. Liou, S. Forrest, and C.-J. Wu. Genetic Improvement of GPU Code. In Proceedings of the Annual Workshop on Genetic Improvement (GI) in conjunction with ICSE, 2019.\n\n[8] J.-Y. Liou, X. Wang, S. Forrest, and C.-J. Wu. GEVO: GPU Code Optimization Using Evolutionary Computation. In Proceedings of the ACMTransactions on Architecture and Code Optimization (TACO), 2020.\n\n\n\n \n\n\t\t\t\t\tLast Modified: 12/23/2021\n\n\t\t\t\t\tSubmitted by: Carole-Jean Wu"
 }
}