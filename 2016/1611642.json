{
 "awd_id": "1611642",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Fellowship Award",
 "awd_titl_txt": "NSF Postdoctoral Fellowship in Biology FY 2016",
 "cfda_num": "47.074",
 "org_code": "08080000",
 "po_phone": "7032928165",
 "po_email": "asimcox@nsf.gov",
 "po_sign_block_name": "Amanda Simcox",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 138000.0,
 "awd_amount": 138000.0,
 "awd_min_amd_letter_date": "2016-05-25",
 "awd_max_amd_letter_date": "2016-05-25",
 "awd_abstract_narration": "William R. Kuhn\r\n\r\nProposal Number: 1611642\r\n\r\nThis action funds an NSF Postdoctoral Research Fellowship in Biology for FY 2016, Research Using Biological Collections. The fellowship supports a research and training plan for the Fellow to take transformative approaches to grand challenges in biology that employ biological collections in highly innovative ways.  The title of the research plan for this fellowship to William R. Kuhn is \"Leveraging face-detection methods to identify insects from field photos, automatically.\" The host institution for this fellowship is the University of Tennessee (Knoxville), and the sponsoring scientist is Dr. Mongi Abidi.  \r\n\r\nThis work aims to automate the identification of species, thereby helping to alleviate the 'taxonomic impediment,' i.e., an urgent need for more taxonomy from fewer taxonomists. The impetus for doing this research is that although understanding Earth's species is one of the grand challenges of the twenty-first century, training and funding for the field of taxonomy (identifying and describing species) has declined markedly over the past several decades. The Fellow is integrating existing computer vision and machine-learning methods to build an automatic system for identifying species from photographs of them in their habitat.  The Fellow has three main research objectives: (1) develop and train a model to locate the subjects in images by modifying an existing method for detecting human faces in photographs; (2) characterize the images based on the appearance of the subjects' body parts by adapting an algorithm for describing the key features of an image; and (3) predict species identity by comparing features from unknown images to those of known species, utilizing a robust machine-learning framework. The Fellow is developing a system to identify dragonfly and damselfly (Odonata) species, but the underlying code will allow researchers to train systems for other organisms. The Fellow is utilizing citizen scientist data on OdonataCentral (odonatacentral.org), a digital collection of species records and imagery of Odonata from the Western Hemisphere. Images of the 600+ species included in this digital collection are being used to train the most taxonomically-broad automatic identification system ever created, and the ability of this software to accept field-based images makes it extremely versatile.\r\n\r\nThe Fellow is receiving advanced training in image analysis, computer vision, and machine learning, and becoming proficient in software design and programming. The Fellow will be able use these skills to solve problems in biology in the future, when he is running his own lab. The Fellow is also developing his skills as a mentor and scientific communicator. He is mentoring two undergraduates and one graduate student in computer science, encouraging them to focus on solving biological problems. The odonate identification system is being integrated into OdonataCentral as well the mobile app that it powers, Dragonfly ID. This will allows both researchers and citizen scientists to make rapid identifications in the field, for applications such as assessing biodiversity and monitoring water quality. Ultimately this research will benefit taxonomists studying other organisms, since the Fellow is releasing his source code, allowing others to train and implement their own automatic identification systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "BIO",
 "org_dir_long_name": "Directorate for Biological Sciences",
 "div_abbr": "DBI",
 "org_div_long_name": "Division of Biological Infrastructure",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "William",
   "pi_last_name": "Kuhn",
   "pi_mid_init": "R",
   "pi_sufx_name": "",
   "pi_full_name": "William R Kuhn",
   "pi_email_addr": "",
   "nsf_id": "000707339",
   "pi_start_date": "2016-05-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Kuhn                    William        R",
  "inst_street_address": "",
  "inst_street_address_2": "",
  "inst_city_name": "Bloomfield",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "",
  "inst_zip_code": "07003",
  "inst_country_name": "United States",
  "cong_dist_code": "08",
  "st_cong_dist_code": "NJ08",
  "org_lgl_bus_name": "",
  "org_prnt_uei_num": "",
  "org_uei_num": ""
 },
 "perf_inst": {
  "perf_inst_name": "University of Tennessee",
  "perf_str_addr": null,
  "perf_city_name": "Knoxville",
  "perf_st_code": "TN",
  "perf_st_name": "Tennessee",
  "perf_zip_code": "379960001",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "TN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "001Y00",
   "pgm_ele_name": "Collections Postdocs"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 138000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to develop software for automatically identifying dragonflies and damselflies (Odonata) from photographs, facilitating rapid biodiversity assessments and helping the public identify these insects. At the heart of this project was a digital collection of 110,000 photographs, which were submitted to OdonataCentral (OC; <a href=\"https://odonatacentral.org/\">https://odonatacentral.org</a>) by odonatologists and dragonfly enthusiasts. The Odonata in these images were carefully identified by experts and citizen scientists. To add value to this digital collection, the Fellow developed a crowd-sourcing project on the Zooniverse platform (<a href=\"https://zooniverse.org/\">https://zooniverse.org</a>) called <em>Zen of Dragons</em>, in which 1500+ volunteers manually located dragonflies and damselflies in some 14,000 images from OC. As an intermediate step, this subset of manually-annotated images was used train a deep neural network (Faster-R-CNN) to automatically locate these insects in new images. Although this work is ongoing, this intermediate network will be used to annotate the remaining ~96,000 images from OC that were not included in <em>Zen or Dragons</em>. The subsequent, fully-annotated OC dataset will be used to train a final network to locate and classify Odonata in photographs, the final product of this project. The Fellow has compiled the OC image dataset with the <em>Zen of Dragons</em> annotations into a new dataset, Fine-Grained Visual Categorization of Odonata, which will be made publicly available via the CyVerse Data Commons (<a href=\"http://datacommons.cyverse.org/\">http://datacommons.cyverse.org/</a>, an NSF-supported cyberinfrastructure); code and models developed under the project will be shared on GitHub (<a href=\"https://github.com/\">https://github.com</a>).</p>\n<p>The Fellow has presented this work at three conferences:<strong> </strong>the International Congress of Entomology in Orlando, FL (2016), the International Congress of Odonatology in Cambridge, UK (2017), the Entomological Society of America annual meeting in Denver, CO (2017), as well as in an invited talk to the Entomology Department at Virginia Tech in 2017. Three master?s students and four undergraduate students were mentored under this award, and this work was included in a master?s thesis (expected graduation, Spring 2019). The Fellow gave five additional talks to broad audiences in eastern Tennessee, including a school group and visitors to Great Smoky Mountains National Park, and was able to serve on the board of and volunteer for a biodiversity-focused nonprofit called Discover Life in America. Under this award, the Fellow improved his understanding of machine learning, computer vision, and related topics. He improved his programming skills, learned to perform computational analyses on high-performance cloud computing systems, and attended CyVerse?s Container Camp workshop (2018, Tucson, AZ).</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/21/2018<br>\n\t\t\t\t\tModified by: William&nbsp;R&nbsp;Kuhn</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project was to develop software for automatically identifying dragonflies and damselflies (Odonata) from photographs, facilitating rapid biodiversity assessments and helping the public identify these insects. At the heart of this project was a digital collection of 110,000 photographs, which were submitted to OdonataCentral (OC; https://odonatacentral.org) by odonatologists and dragonfly enthusiasts. The Odonata in these images were carefully identified by experts and citizen scientists. To add value to this digital collection, the Fellow developed a crowd-sourcing project on the Zooniverse platform (https://zooniverse.org) called Zen of Dragons, in which 1500+ volunteers manually located dragonflies and damselflies in some 14,000 images from OC. As an intermediate step, this subset of manually-annotated images was used train a deep neural network (Faster-R-CNN) to automatically locate these insects in new images. Although this work is ongoing, this intermediate network will be used to annotate the remaining ~96,000 images from OC that were not included in Zen or Dragons. The subsequent, fully-annotated OC dataset will be used to train a final network to locate and classify Odonata in photographs, the final product of this project. The Fellow has compiled the OC image dataset with the Zen of Dragons annotations into a new dataset, Fine-Grained Visual Categorization of Odonata, which will be made publicly available via the CyVerse Data Commons (http://datacommons.cyverse.org/, an NSF-supported cyberinfrastructure); code and models developed under the project will be shared on GitHub (https://github.com).\n\nThe Fellow has presented this work at three conferences: the International Congress of Entomology in Orlando, FL (2016), the International Congress of Odonatology in Cambridge, UK (2017), the Entomological Society of America annual meeting in Denver, CO (2017), as well as in an invited talk to the Entomology Department at Virginia Tech in 2017. Three master?s students and four undergraduate students were mentored under this award, and this work was included in a master?s thesis (expected graduation, Spring 2019). The Fellow gave five additional talks to broad audiences in eastern Tennessee, including a school group and visitors to Great Smoky Mountains National Park, and was able to serve on the board of and volunteer for a biodiversity-focused nonprofit called Discover Life in America. Under this award, the Fellow improved his understanding of machine learning, computer vision, and related topics. He improved his programming skills, learned to perform computational analyses on high-performance cloud computing systems, and attended CyVerse?s Container Camp workshop (2018, Tucson, AZ).\n\n \n\n\t\t\t\t\tLast Modified: 12/21/2018\n\n\t\t\t\t\tSubmitted by: William R Kuhn"
 }
}