{
 "awd_id": "1611254",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Robotic See-Through Imaging with Everyday RF Signals",
 "cfda_num": "47.041",
 "org_code": "07010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Mohammod Ali",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2020-08-31",
 "tot_intn_awd_amt": 300000.0,
 "awd_amount": 300000.0,
 "awd_min_amd_letter_date": "2016-07-14",
 "awd_max_amd_letter_date": "2016-07-14",
 "awd_abstract_narration": "The overall goal of this proposal is to introduce a new multi-disciplinary foundation for see-through imaging with everyday RF signals using unmanned autonomous vehicles.  See-through imaging with everyday RF signals can considerably impact many different areas such as search and rescue operations, surveillance and security, detection/classification of occluded objects, infrastructure assessment, medical imaging, and archaeological exploration, just to name a few.  Robotic networks, on the other hand, can have a tremendous impact in many different areas such as disaster relief, emergency response, environmental monitoring, surveillance, and security.  This proposed work at the intersection of RF sensing and robotics can considerably advance the state-of-the-art in RF sensing by jointly and successively optimizing robotic path planning and RF imaging, and can thus have a transformative impact on our society.  The proposal also has a significant educational component targeting under-represented students. \r\n\r\nMore specifically, in this research effort, a new multi-disciplinary paradigm is proposed to equip a number of unmanned vehicles with see-through imaging of completely unknown areas using everyday RF signals. Along this line, the first major task focuses on the interplay between motion patterns and RF imaging performance, in order to understand and mathematically characterize robotic motion patterns most informative for RF imaging. The second task then develops the foundation of jointly and successively co-designing the path planning and imaging of the robots while considering the dynamics of the vehicles, environmental navigation constraints, motion energy budget, and operation time.  Finally, the proposed theories and design paradigm are extensively validated with ground and aerial vehicles. Overall, the proposed research can make a significant contribution to enhancing the state-of-the-art in both RF imaging and robotics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "ECCS",
 "org_div_long_name": "Division of Electrical, Communications and Cyber Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yasamin",
   "pi_last_name": "Mostofi",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yasamin Mostofi",
   "pi_email_addr": "ymostofi@ece.ucsb.edu",
   "nsf_id": "000488554",
   "pi_start_date": "2016-07-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of California-Santa Barbara",
  "inst_street_address": "3227 CHEADLE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "SANTA BARBARA",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "8058934188",
  "inst_zip_code": "931060001",
  "inst_country_name": "United States",
  "cong_dist_code": "24",
  "st_cong_dist_code": "CA24",
  "org_lgl_bus_name": "UNIVERSITY OF CALIFORNIA, SANTA BARBARA",
  "org_prnt_uei_num": "",
  "org_uei_num": "G9QBQDH39DF4"
 },
 "perf_inst": {
  "perf_inst_name": "University of California-Santa Barbara",
  "perf_str_addr": "ECE Department",
  "perf_city_name": "Santa Barbara",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "931069560",
  "perf_ctry_code": "US",
  "perf_cong_dist": "24",
  "perf_st_cong_dist": "CA24",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "756400",
   "pgm_ele_name": "CCSS-Comms Circuits & Sens Sys"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "153E",
   "pgm_ref_txt": "Wireless comm & sig processing"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 300000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Here we summarize four key outcomes of this work.</p>\n<p>1) As part of this research effort, we have developed a theoretical and experimental framework that has enabled the first demonstration of 3D imaging through walls with only WiFi signals and drones. In this proposed approach, two unmanned air vehicles fly outside of the unknown area of interest.&nbsp; They only have WiFi transceivers for sensing, and are interested in imaging this area through walls. This is an extremely challenging multidisciplinary problem, which involves wireless communications, robotics, wave propagation, and signal processing.&nbsp; We have shown how to solve this problem by proposing an approach that consists of novel robotic path planning, efficient wave propagation approximation, and sparse information processing.&nbsp;&nbsp; We have validated the proposed approach by a number of experiments where two drones image through thick brick walls on our campus.&nbsp; We have released a Youtube video of this work, which went viral, and several reputable news agencies (e.g., BBC) covered the new invention.&nbsp;</p>\n<p>2) Angle of Arrival (AoA) estimation/beamforming is an important problem for many communication and sensing applications.&nbsp; Typical AoA estimation requires the phase of the signal.&nbsp; However, accurate phase measurement may not be possible on off-the-shelf transceivers (such as WiFi or Bluetooth). As part of this research effort, we have then developed a new approach that has enabled AoA estimation and beamforming with only signal magnitude, and without any phase information.&nbsp; This in turn has enabled new possibilities for many applications that can only measure the signal magnitude. For instance, this has enabled unmanned vehicles to do beamforming with only their onboard RF signal magnitude measurements. Furthermore, this new approach has enabled new possibilities for localization and tracking.&nbsp; More specifically, we have further extended our magnitude-only AoA estimation framework to a dual setting to show how moving targets (both active transmitters and passive robots/humans) can be tracked, based on only the received signal magnitude measurements of a small number of fixed receivers. We extensively validated our proposed AoA estimation, localization and tracking framework with several experiments in both indoor and outdoor areas.</p>\n<p>3) We have developed a new framework that has enabled, for the first time, identifying a person through walls from a candidate video footage, using only WiFi signals.&nbsp; Consider the case that a video footage of a person is available.&nbsp; A pair of WiFi transceivers (for instance of a pair of laptops) are inserted outside of a building and are tasked with figuring out if the person in the video is behind these walls.&nbsp; We have shown, for the first time, that this is indeed possible.&nbsp; More specifically, we have proposed a framework that can translate the video content into the RF domain by proposing a novel combination of mesh recovery algorithms and electromagnetic wave approximation.&nbsp; Then, our signal processing pipeline extracts several key features from both the real RF signal, measured on the WiFi cards, and the video-to-RF one, and establishes if they belong to the same person.&nbsp; We have released a Youtube video of this work, which went viral, and several reputable news agencies covered the new invention.&nbsp;</p>\n<p class=\"Default\">4) In terms of outreach, the PI has partnered with the UCSB Center for Science and Engineering Partnerships (CSEP) and has hosted a number of minority community college students in her lab over the course of this project.&nbsp; Each student then participated in research experiments and was mentored by a graduate student of the lab during the visit. At the end of the visit, the hosted student had to do a presentation of the accomplished work as part of CSEP. Minority graduate students have also been involved in this research in PI?s lab and one Ph.D. thesis was completed by a minority student with the support of this grant.&nbsp; Finally, undergraduate students have also been consistently involved in different aspects of this research by helping the graduate students (and learning from them) during the experiments.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/24/2021<br>\n\t\t\t\t\tModified by: Yasamin&nbsp;Mostofi</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583173847_DroneImagingThroughWalls--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583173847_DroneImagingThroughWalls--rgov-800width.jpg\" title=\"Drone Imaging Through Walls with WiFi\"><img src=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583173847_DroneImagingThroughWalls--rgov-66x44.jpg\" alt=\"Drone Imaging Through Walls with WiFi\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Drone Imaging Through Walls with WiFi</div>\n<div class=\"imageCredit\">Yasamin Mostofi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yasamin&nbsp;Mostofi</div>\n<div class=\"imageTitle\">Drone Imaging Through Walls with WiFi</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583297063_ImagingResults--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583297063_ImagingResults--rgov-800width.jpg\" title=\"Sample Result of Drone Imaging Through Walls\"><img src=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583297063_ImagingResults--rgov-66x44.jpg\" alt=\"Sample Result of Drone Imaging Through Walls\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This is a sample result of drones imaging through walls with only their onboard WiFi signals</div>\n<div class=\"imageCredit\">Yasamin Mostofi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yasamin&nbsp;Mostofi</div>\n<div class=\"imageTitle\">Sample Result of Drone Imaging Through Walls</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583414831_ThroughWallID--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583414831_ThroughWallID--rgov-800width.jpg\" title=\"Person Identification with WiFi\"><img src=\"/por/images/Reports/POR/2021/1611254/1611254_10440473_1616583414831_ThroughWallID--rgov-66x44.jpg\" alt=\"Person Identification with WiFi\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">A pair of WiFi can identify the person behind the door.</div>\n<div class=\"imageCredit\">Yasamin Mostofi</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Yasamin&nbsp;Mostofi</div>\n<div class=\"imageTitle\">Person Identification with WiFi</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nHere we summarize four key outcomes of this work.\n\n1) As part of this research effort, we have developed a theoretical and experimental framework that has enabled the first demonstration of 3D imaging through walls with only WiFi signals and drones. In this proposed approach, two unmanned air vehicles fly outside of the unknown area of interest.  They only have WiFi transceivers for sensing, and are interested in imaging this area through walls. This is an extremely challenging multidisciplinary problem, which involves wireless communications, robotics, wave propagation, and signal processing.  We have shown how to solve this problem by proposing an approach that consists of novel robotic path planning, efficient wave propagation approximation, and sparse information processing.   We have validated the proposed approach by a number of experiments where two drones image through thick brick walls on our campus.  We have released a Youtube video of this work, which went viral, and several reputable news agencies (e.g., BBC) covered the new invention. \n\n2) Angle of Arrival (AoA) estimation/beamforming is an important problem for many communication and sensing applications.  Typical AoA estimation requires the phase of the signal.  However, accurate phase measurement may not be possible on off-the-shelf transceivers (such as WiFi or Bluetooth). As part of this research effort, we have then developed a new approach that has enabled AoA estimation and beamforming with only signal magnitude, and without any phase information.  This in turn has enabled new possibilities for many applications that can only measure the signal magnitude. For instance, this has enabled unmanned vehicles to do beamforming with only their onboard RF signal magnitude measurements. Furthermore, this new approach has enabled new possibilities for localization and tracking.  More specifically, we have further extended our magnitude-only AoA estimation framework to a dual setting to show how moving targets (both active transmitters and passive robots/humans) can be tracked, based on only the received signal magnitude measurements of a small number of fixed receivers. We extensively validated our proposed AoA estimation, localization and tracking framework with several experiments in both indoor and outdoor areas.\n\n3) We have developed a new framework that has enabled, for the first time, identifying a person through walls from a candidate video footage, using only WiFi signals.  Consider the case that a video footage of a person is available.  A pair of WiFi transceivers (for instance of a pair of laptops) are inserted outside of a building and are tasked with figuring out if the person in the video is behind these walls.  We have shown, for the first time, that this is indeed possible.  More specifically, we have proposed a framework that can translate the video content into the RF domain by proposing a novel combination of mesh recovery algorithms and electromagnetic wave approximation.  Then, our signal processing pipeline extracts several key features from both the real RF signal, measured on the WiFi cards, and the video-to-RF one, and establishes if they belong to the same person.  We have released a Youtube video of this work, which went viral, and several reputable news agencies covered the new invention. \n4) In terms of outreach, the PI has partnered with the UCSB Center for Science and Engineering Partnerships (CSEP) and has hosted a number of minority community college students in her lab over the course of this project.  Each student then participated in research experiments and was mentored by a graduate student of the lab during the visit. At the end of the visit, the hosted student had to do a presentation of the accomplished work as part of CSEP. Minority graduate students have also been involved in this research in PI?s lab and one Ph.D. thesis was completed by a minority student with the support of this grant.  Finally, undergraduate students have also been consistently involved in different aspects of this research by helping the graduate students (and learning from them) during the experiments.\n\n \n\n\t\t\t\t\tLast Modified: 03/24/2021\n\n\t\t\t\t\tSubmitted by: Yasamin Mostofi"
 }
}