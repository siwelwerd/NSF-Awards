{
 "awd_id": "1628878",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Honest Inference and Efficiency Bounds for Nonparametric Regression and Approximate Moment Condition Models",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927280",
 "po_email": "nlutz@nsf.gov",
 "po_sign_block_name": "Nancy Lutz",
 "awd_eff_date": "2016-09-15",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 199260.0,
 "awd_amount": 199260.0,
 "awd_min_amd_letter_date": "2016-08-31",
 "awd_max_amd_letter_date": "2016-08-31",
 "awd_abstract_narration": "In analyzing economic data, researchers use models and assumptions that are typically best thought of as approximations of reality.  This project will develop statistical methods that are valid when these models are only approximately correct, rather than exactly correct.  The methods developed in this project can also be used to provide simple ways of assessing the sensitivity of the conclusions of an empirical study to its underlying assumptions.  These methods can be applied to numerous commonly studied problems that are relevant for policy and for understanding the economy.\r\n\r\nThis project will develop confidence intervals in approximate moment condition models with convex parameter spaces, as well as sharp efficiency bounds showing that they are as tight as possible in a certain precise sense. The setup covers inference on a linear functional of a nonparametric regression function, such as its value at a point, the regression discontinuity parameter, or an average treatment effect under unconfoundedness. The setup also covers parameter constraints in the linear regression model as well as moment condition models such as generalized method of moments (GMM) or minimum distance models in which the moment condition is locally misspecified. The confidence intervals are simple to construct, and valid in an \"honest\" or uniform sense. As special cases of the results, the project obtains optimal kernels for inference in nonparametric regression models, and optimal weights for GMM under misspecification.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michal",
   "pi_last_name": "Kolesar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Michal Kolesar",
   "pi_email_addr": "mkolesar@princeton.edu",
   "nsf_id": "000714505",
   "pi_start_date": "2016-08-31",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Woodrow Wilson School",
  "perf_str_addr": "203 Fisher Hall",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085442020",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "139700",
   "pgm_ele_name": "Cross-Directorate  Activities"
  },
  {
   "pgm_ele_code": "132000",
   "pgm_ele_name": "Economics"
  },
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1333",
   "pgm_ref_txt": "METHOD, MEASURE & STATS"
  },
  {
   "pgm_ref_code": "1397",
   "pgm_ref_txt": "CROSS-DIRECTORATE  ACTIV PROGR"
  },
  {
   "pgm_ref_code": "1320",
   "pgm_ref_txt": "ECONOMICS"
  },
  {
   "pgm_ref_code": "040Z",
   "pgm_ref_txt": "Robust and Reliable Science"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 199260.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>In many models commonly used by practitioners, estimates of parameters of interest display finite-sample bias. The bias may arise because the model is misspecified, or because the researcher uses smoothing or regularization. A regularization bias arises in non-parametric and semi-parametric models, including regression discontinuity or regression kink designs, estimation of average treatment effects under unconfoundedness, or in modern high-dimensional regression models. The standard approach to quantifying uncertainty about the parameter estimates in these models is to employ large-sample approximations in which the bias becomes negligible relative to the sampling variability of the estimator: this can be achieved, for instance, by \"undersmoothing\". However, since the theory of undersmoothing only restricts the rate at which tuning parameters, such as bandwidths, must shrink with sample size, the practical prescriptions of this theory are unclear: one can justify any tuning parameter choice by promising to shrink it sufficiently fast if one had more data.<br /><br />In this project, we developed an alternative approach to inference in a class of regression models that includes regression discontinuity designs, linear or partly linear regression, estimation of average treatment effects under unconfoundedness, or high-dimensional regression. Rather than assuming that the bias will be asymptotically negligible, our confidence intervals (CIs) explicitly take into account the potential bias of the estimator by using a larger critical value than the usual 1.96 critical value. We are able to calculate the necessary adjustment by making explicit the smoothness assumptions that the researcher imposes, including any smoothness constants. This approach is \"honest\" in the sense that its validity doesn't rely on any asymptotic promises about the tuning parameters; our CIs are valid uniformly over the parameter space that the researcher specifies by their smoothness assumptions.<br /><br />We show that the explicit specification of the smoothness conditions cannot be avoided by the researcher: we derive a sharp efficiency bound which implies that one cannot start with a conservative specification for the smoothness, and use the data to tighten the CIs if the regression function turns out to be smooth. We also show that, in the context of inference in regression discontinuity designs, a practically attractive implementation of our CIs is to simply center them around an estimator with MSE-optimal bandwidth, rather than reoptimizing the bandwidth for CI length. This approach also works when the covariates are discrete; in contrast, as we show in work with Christoph Rothe, the standard practice of clustering the standard errors by the running variable can in this context be highly misleading.<br /><br />We also consider the case in which the source of bias is model misspecification. In particular, we consider inference in generalized method of moments (GMM) models under the weaker assumption that the model is only approximately correct. Our key insight is that because valid CIs need to be widened to account for the potential model misspecification, the optimal weighting matrix differs from the one that is optimal under correct specification: one needs to trade off the precision of the moments against their potential misspecification.<br /><br />Our work provides practitioners with novel and more robust ways of quantifying uncertainty in common economic models. We have developed software implementing our methods, adding directly to the toolkit of applied researchers in economics and other social sciences.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/25/2019<br>\n\t\t\t\t\tModified by: Michal&nbsp;Kolesar</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nIn many models commonly used by practitioners, estimates of parameters of interest display finite-sample bias. The bias may arise because the model is misspecified, or because the researcher uses smoothing or regularization. A regularization bias arises in non-parametric and semi-parametric models, including regression discontinuity or regression kink designs, estimation of average treatment effects under unconfoundedness, or in modern high-dimensional regression models. The standard approach to quantifying uncertainty about the parameter estimates in these models is to employ large-sample approximations in which the bias becomes negligible relative to the sampling variability of the estimator: this can be achieved, for instance, by \"undersmoothing\". However, since the theory of undersmoothing only restricts the rate at which tuning parameters, such as bandwidths, must shrink with sample size, the practical prescriptions of this theory are unclear: one can justify any tuning parameter choice by promising to shrink it sufficiently fast if one had more data.\n\nIn this project, we developed an alternative approach to inference in a class of regression models that includes regression discontinuity designs, linear or partly linear regression, estimation of average treatment effects under unconfoundedness, or high-dimensional regression. Rather than assuming that the bias will be asymptotically negligible, our confidence intervals (CIs) explicitly take into account the potential bias of the estimator by using a larger critical value than the usual 1.96 critical value. We are able to calculate the necessary adjustment by making explicit the smoothness assumptions that the researcher imposes, including any smoothness constants. This approach is \"honest\" in the sense that its validity doesn't rely on any asymptotic promises about the tuning parameters; our CIs are valid uniformly over the parameter space that the researcher specifies by their smoothness assumptions.\n\nWe show that the explicit specification of the smoothness conditions cannot be avoided by the researcher: we derive a sharp efficiency bound which implies that one cannot start with a conservative specification for the smoothness, and use the data to tighten the CIs if the regression function turns out to be smooth. We also show that, in the context of inference in regression discontinuity designs, a practically attractive implementation of our CIs is to simply center them around an estimator with MSE-optimal bandwidth, rather than reoptimizing the bandwidth for CI length. This approach also works when the covariates are discrete; in contrast, as we show in work with Christoph Rothe, the standard practice of clustering the standard errors by the running variable can in this context be highly misleading.\n\nWe also consider the case in which the source of bias is model misspecification. In particular, we consider inference in generalized method of moments (GMM) models under the weaker assumption that the model is only approximately correct. Our key insight is that because valid CIs need to be widened to account for the potential model misspecification, the optimal weighting matrix differs from the one that is optimal under correct specification: one needs to trade off the precision of the moments against their potential misspecification.\n\nOur work provides practitioners with novel and more robust ways of quantifying uncertainty in common economic models. We have developed software implementing our methods, adding directly to the toolkit of applied researchers in economics and other social sciences.\n\n\t\t\t\t\tLast Modified: 11/25/2019\n\n\t\t\t\t\tSubmitted by: Michal Kolesar"
 }
}