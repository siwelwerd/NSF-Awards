{
 "awd_id": "1565338",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: ACI: Accelerating In-Situ Scientific Data Analysis Using Software-Defined Storage Resource Enclaves",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alan Sussman",
 "awd_eff_date": "2016-06-01",
 "awd_exp_date": "2019-05-31",
 "tot_intn_awd_amt": 173999.0,
 "awd_amount": 189999.0,
 "awd_min_amd_letter_date": "2016-05-27",
 "awd_max_amd_letter_date": "2017-04-30",
 "awd_abstract_narration": "Data intensive knowledge discovery requires scientific applications to run concurrently with analytics and visualization codes, executing in situ for timely output inspection and knowledge extraction. Consequently, the Input/Output (I/O) pipelines for large scientific data analysis can be long and complex because they comprise many \"stages\" of analytics across different layers of the I/O stack of high-performance computing systems. Performance limitations at any I/O layer can cause an I/O bottleneck resulting in longer than expected end-to-end I/O latency. In this project, PI aims to implement a novel data management infrastructure called Software-defined Storage Resource Enclaves (SIREN) at system levels to enforce end-to-end policies that dictate an I/O pipeline's performance. The cross-cutting nature of the technologies developed in the project can help large scientific data analytics leverage the full capability of memory and storage devices on supercomputers. The project will facilitate the development of a graduate level data-intensive computing course at Washington State University Vancouver, and contribute to the education of undergraduate, female, and under-representative students.  Therefore, this research aligns with the NSF mission to promote the progress of science and to advance the national prosperity and welfare.\r\n\r\nThe technical objectives of the project are three-fold. First, SIREN aims to allow administrators to set allocations for enclaves to manage a group of applications that belong to the same I/O pipeline. Second, it intends to enforce I/O policies (e.g., proportional sharing) at more than one layer of I/O stacks simultaneously considering characteristics of storage devices (e.g., disparity of read/write capacity for SSDs and performance sensitivity to data locality for disks) to achieve optimal performance. Third, PI aims to solve storage-specific implementation issues, including design of user-friendly interfaces, enclave naming and resolution, metadata management, failure handling, and admission control. The introduction of SIREN can fundamentally change the execution model of data staging services widely used on supercomputers. It will also contribute to the understanding of performance characteristics of I/O pipelines under external I/O interference during data staging.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xuechen",
   "pi_last_name": "Zhang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xuechen Zhang",
   "pi_email_addr": "xuechen.zhang@wsu.edu",
   "nsf_id": "000701735",
   "pi_start_date": "2016-05-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Washington State University",
  "inst_street_address": "240 FRENCH ADMINISTRATION BLDG",
  "inst_street_address_2": "",
  "inst_city_name": "PULLMAN",
  "inst_state_code": "WA",
  "inst_state_name": "Washington",
  "inst_phone_num": "5093359661",
  "inst_zip_code": "991640001",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "WA05",
  "org_lgl_bus_name": "WASHINGTON STATE UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "XRJSGX384TD6"
 },
 "perf_inst": {
  "perf_inst_name": "WSU Vancouver",
  "perf_str_addr": "14204 NE SALMON CREEK AVE",
  "perf_city_name": "Vancouver",
  "perf_st_code": "WA",
  "perf_st_name": "Washington",
  "perf_zip_code": "986869600",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "WA03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  },
  {
   "pgm_ele_code": "113900",
   "pgm_ele_name": "RSCH EXPER FOR UNDERGRAD SITES"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 173999.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Data intensive knowledge discovery requires scientific applications to run concurrently with analytics and visualization codes, executing in situ for timely output inspection and knowledge extraction. Consequently, I/O pipelines for large scientific data analysis can be long and complex because they comprise many \"stages\" of analytics across different layers of the I/O stack (e.g., staging buffers and parallel file systems) of high-performance computing systems. Performance limitations at any I/O layer can cause an I/O bottleneck resulting in longer than expected end-to-end I/O latency. The investigator attributes the causes of such performance issues to missing a performance guarantee (e.g., lower bounds of I/O throughput) across stages of I/O pipelines and across layers of the I/O stacks. To provide performance guarantee for in-situ scientific data analysis, we developed a novel data management infrastructure called Software-defined Storage Resource Enclaves (SIREN) at system levels to enforce end-to-end policies that dictate an I/O pipeline's performance.</p>\n<p>First, we designed a novel performance interface for I/O resource management in HPC systems. End users can use it to logically partition I/O resources among storage resource enclaves shared by a group of applications in a hierarchical manner. SIREN can guarantee resource reservations and shares for storage resource enclaves to enforce end-to-end I/O policies for performance-sensitive in-situ data analytics.</p>\n<p>Second, we designed a distributed scheduling system to effectively manage storage resource enclaves, which are organized a tree. The algorithm takes end-users' QoS requirements, current I/O demands of applications, and enclave autonomy into account to provide performance guarantee, high resource usage, and software scalability.</p>\n<p>Third, an enclave migration framework was designed to map enclaves to heterogeneous storage device by considering how characteristics of devices and workloads affect system I/O efficiency. In this framework, a machine-learning-based algorithm is used to automatically identify the opportunities for enclave migration. To reduce the migration overhead, SIREN supports dynamic mapping of logical file domains to physical locations.</p>\n<p>Finally, we implemented SIREN at two key I/O layers---staging nodes and storage servers. Extensive evaluation of SIREN with real-world scientific workflows shows that it can effectively implement performance goals in terms of throughput reservations and shares with strong isolation among enclaves sharing burst buffers and parallel file systems.</p>\n<p>Many of the research results have been integrated with the education curricula (e.g., course projects for CS 501 Cloud Systems) at Washington State University Vancouver. We trained up to 5 graduate students using the course projects as of 2019. The project has supported two M.S. students working on their thesis and three undergraduate students working on their summer research projects. The undergraduate students published two journal papers. They continue pursuing Master degree at WSU Vancouver. We released SIREN as an open source software.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/03/2019<br>\n\t\t\t\t\tModified by: Xuechen&nbsp;Zhang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nData intensive knowledge discovery requires scientific applications to run concurrently with analytics and visualization codes, executing in situ for timely output inspection and knowledge extraction. Consequently, I/O pipelines for large scientific data analysis can be long and complex because they comprise many \"stages\" of analytics across different layers of the I/O stack (e.g., staging buffers and parallel file systems) of high-performance computing systems. Performance limitations at any I/O layer can cause an I/O bottleneck resulting in longer than expected end-to-end I/O latency. The investigator attributes the causes of such performance issues to missing a performance guarantee (e.g., lower bounds of I/O throughput) across stages of I/O pipelines and across layers of the I/O stacks. To provide performance guarantee for in-situ scientific data analysis, we developed a novel data management infrastructure called Software-defined Storage Resource Enclaves (SIREN) at system levels to enforce end-to-end policies that dictate an I/O pipeline's performance.\n\nFirst, we designed a novel performance interface for I/O resource management in HPC systems. End users can use it to logically partition I/O resources among storage resource enclaves shared by a group of applications in a hierarchical manner. SIREN can guarantee resource reservations and shares for storage resource enclaves to enforce end-to-end I/O policies for performance-sensitive in-situ data analytics.\n\nSecond, we designed a distributed scheduling system to effectively manage storage resource enclaves, which are organized a tree. The algorithm takes end-users' QoS requirements, current I/O demands of applications, and enclave autonomy into account to provide performance guarantee, high resource usage, and software scalability.\n\nThird, an enclave migration framework was designed to map enclaves to heterogeneous storage device by considering how characteristics of devices and workloads affect system I/O efficiency. In this framework, a machine-learning-based algorithm is used to automatically identify the opportunities for enclave migration. To reduce the migration overhead, SIREN supports dynamic mapping of logical file domains to physical locations.\n\nFinally, we implemented SIREN at two key I/O layers---staging nodes and storage servers. Extensive evaluation of SIREN with real-world scientific workflows shows that it can effectively implement performance goals in terms of throughput reservations and shares with strong isolation among enclaves sharing burst buffers and parallel file systems.\n\nMany of the research results have been integrated with the education curricula (e.g., course projects for CS 501 Cloud Systems) at Washington State University Vancouver. We trained up to 5 graduate students using the course projects as of 2019. The project has supported two M.S. students working on their thesis and three undergraduate students working on their summer research projects. The undergraduate students published two journal papers. They continue pursuing Master degree at WSU Vancouver. We released SIREN as an open source software.\n\n \n\n \n\n \n\n\t\t\t\t\tLast Modified: 06/03/2019\n\n\t\t\t\t\tSubmitted by: Xuechen Zhang"
 }
}