{
 "awd_id": "1626116",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Acquisition of a 3d Photogrammetry Light Stage System for Scanning Shape, Motion and Appearance",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032922935",
 "po_email": "dmedhi@nsf.gov",
 "po_sign_block_name": "Deepankar Medhi",
 "awd_eff_date": "2016-10-01",
 "awd_exp_date": "2022-09-30",
 "tot_intn_awd_amt": 298426.0,
 "awd_amount": 298426.0,
 "awd_min_amd_letter_date": "2016-09-15",
 "awd_max_amd_letter_date": "2021-11-10",
 "awd_abstract_narration": "This project, acquiring a 3D photogrammetric light stage instrument with automatic synchronization and registration for instantaneous scanning of 3D shapes with submillimeter accuracy, motion capture, and capture reflectance properties, aims to capture image samples up to 128 viewing angles and 156 lighting angles simultaneously. It will afford the instantaneous scanning of 3D shape with sub-millimeter accuracy in a range of sizes from a few cm up to several meters and will also afford capture of motion over time. Unlike most other photogrammetry systems, the device can also capture reflectance properties giving rise to accurate appearance. This instrument would contribute to a wide range of interdisciplinary projects and research (both at Stout and at neighboring Ph.D. granting institutions) as well as broader enrichment of the public through partnerships with art and history museums and non-profits. Photogrammetry-based systems acquire information about an object?s shape and appearance via images of the object from multiple angles. With a proper array of cameras the object can be captured in a fraction of a second and no markers or modification of the material of the object is necessary. Moreover, the precision and density of the data is comparable to laser scanning devices. Even more compelling is the similarity of this data to that captured by more complex and custom light stages used in computer graphics light field research. However, a gap still exists between these areas that this instrument, and the research it enables, will endeavor to eliminate. This instrument will support collaboration with photographers at the Minneapolis Institute of Art and with the director of the Goldstein Museum of Design. These museums are open to the public and have a common desire to spread their works into the wider community. This instrument will also contribute to the work of the company Xan Scan that seeks to capture objects of significant historical value (including Native American and ancient Chinese artifacts) from smaller public museums. Xan Scan shares these scans with schools providing broadening the access of students that would otherwise not be able to visit these museums in a very cost effective manner. The instrument will be used in several courses at the institution to enhance education of undergraduate students in design, computer science, and digital humanities. Students will have access to the facility and be better trained for research in these areas. The impact should spread further. \r\n\r\nDue to the difficulty of entry into this area, commercial photogrammetry software and hardware has not realized the potential to connect to light field rendering research. The work enabled by this instrument seeks a remedy and provides an open standard for representing, rendering, and sharing this data. Some project examples are discussed, including work with designers to introduce photogrammetry based objects into the design process and museum curators, to scan objects for advanced archeological and historical research, as well as the development of digital exhibits for wider access to their artifacts. Despite the usefulness, photogrammetry has not been embraced by the archival preservation group, possibly because of insufficient understanding of the data and format and storage standards. Hence, archivists and historical personnel will be involved specifically with the goal of addressing these issues and establishing or expanding standards for metadata, photogrammetry images and 3D models.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Seth",
   "pi_last_name": "Berrier",
   "pi_mid_init": "F",
   "pi_sufx_name": "",
   "pi_full_name": "Seth F Berrier",
   "pi_email_addr": "berriers@uwstout.edu",
   "nsf_id": "000690612",
   "pi_start_date": "2016-09-15",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Wisconsin-Stout",
  "inst_street_address": "712 BROADWAY ST S",
  "inst_street_address_2": "",
  "inst_city_name": "MENOMONIE",
  "inst_state_code": "WI",
  "inst_state_name": "Wisconsin",
  "inst_phone_num": "7152321123",
  "inst_zip_code": "547512458",
  "inst_country_name": "United States",
  "cong_dist_code": "03",
  "st_cong_dist_code": "WI03",
  "org_lgl_bus_name": "UNIVERSITY OF WISCONSIN SYSTEM",
  "org_prnt_uei_num": "",
  "org_uei_num": "C6K4GK8PJYT4"
 },
 "perf_inst": {
  "perf_inst_name": "University of Wisconsin-Stout",
  "perf_str_addr": "712 S. Broadway Ave.",
  "perf_city_name": "Menomonie",
  "perf_st_code": "WI",
  "perf_st_name": "Wisconsin",
  "perf_zip_code": "547510790",
  "perf_ctry_code": "US",
  "perf_cong_dist": "03",
  "perf_st_cong_dist": "WI03",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "171400",
   "pgm_ele_name": "Special Projects - CNS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1189",
   "pgm_ref_txt": "MAJOR RESEARCH INSTRUMENTATION"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 298426.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The UW Stout PARSEC project is a human-scale scanning system installed in the Fabrication Lab on the campus of UW Stout.&nbsp; It has two major components:</p>\n<ol>\n<li>For scanning the shape of a person or object: 120 cameras that can fire simultaneously to view an object from many angles.</li>\n<li>For scanning complex appearance and materials: 156 lights that can be sequentially turned off or on in time with a camera to light an object from many angles.</li>\n</ol>\n<p>The equipment can be utilized by any undergraduate student at Stout as well as any faculty or staff for enhancing research and education.&nbsp; It is also available for the public to use, with prior arrangement.</p>\n<p>PARSEC stands for \"Photogrammetry and Reflectance Scanning for STEAM Education in the Chippewa valley.\"&nbsp; The primary research goal is to help combine the separate areas of \"reflection fields\" (which samples and reconstructs complex appearance properties from lighting angles) and \"photogrammetry\" (which reconstructs shape and simple appearance from viewing angles).&nbsp; The work towards this is ongoing and the equipment and software developed for PARSEC was built with this goal in mind.</p>\n<p>PARSEC is new, and it has only just begun to be utilized by students and instructors.&nbsp; With its completion, we have also released free and open-source software for controlling the off-the-shelf hardware involved.&nbsp; This software enables controlling many (100+) cameras remotely and is specifically designed with a photogrammetry workflow in mind.&nbsp; Prior software for this purpose targeted the movie and video games industries and had restrictive and costly licenses making entry into this field difficult for academics.&nbsp; Another goal of PARSEC is to lower this barrier to entry and the supporting software already released represents our largest effort to date to enable this work.</p>\n<p>The PARSEC project will continue to expand this software package and make available interesting data sets for others to explore and process.&nbsp; We will document and catalog our hardware and our experience using it in a university environment.&nbsp; We will publish guides and documentation as we use this equipment and make it all available publicly so you can do the same.</p>\n<p>Follow our progress and access all of this at https://uwstout.github.io/PARSEC-project/</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/15/2023<br>\n\t\t\t\t\tModified by: Seth&nbsp;Berrier</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676331953865_MainPhotogrametryScan--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676331953865_MainPhotogrametryScan--rgov-800width.jpg\" title=\"Human Scale Photogrammetry Scanning Setup\"><img src=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676331953865_MainPhotogrametryScan--rgov-66x44.jpg\" alt=\"Human Scale Photogrammetry Scanning Setup\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The main space for capturing human scale objects.</div>\n<div class=\"imageCredit\">Seth Berrier, Photographer</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Seth&nbsp;Berrier</div>\n<div class=\"imageTitle\">Human Scale Photogrammetry Scanning Setup</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332089316_ReflectanceSampleScanSetup--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332089316_ReflectanceSampleScanSetup--rgov-800width.jpg\" title=\"Multi-lighting angle scanning setup\"><img src=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332089316_ReflectanceSampleScanSetup--rgov-66x44.jpg\" alt=\"Multi-lighting angle scanning setup\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">The secondary scanning space for PARSEC where multiple lighting angles are applied to the subject while capturing from just a few angles.</div>\n<div class=\"imageCredit\">Seth Berrier, Photographer</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Seth&nbsp;Berrier</div>\n<div class=\"imageTitle\">Multi-lighting angle scanning setup</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332209934_SmallScaleScanSetup--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332209934_SmallScaleScanSetup--rgov-800width.jpg\" title=\"PARSEC's main scanning space setup for smaller than human scale capture\"><img src=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332209934_SmallScaleScanSetup--rgov-66x44.jpg\" alt=\"PARSEC's main scanning space setup for smaller than human scale capture\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Here a small corner of the PARSEC multi viewing-angle scanning space is separated off with the camera's re-aimed for a smaller object (about 4 inches square).</div>\n<div class=\"imageCredit\">Seth Berrier, Photographer</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Seth&nbsp;Berrier</div>\n<div class=\"imageTitle\">PARSEC's main scanning space setup for smaller than human scale capture</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332542171_greenBionacle--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332542171_greenBionacle--rgov-800width.jpg\" title=\"Small Lego figure captured and reconstructed with the PARSEC scanner.\"><img src=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332542171_greenBionacle--rgov-66x44.jpg\" alt=\"Small Lego figure captured and reconstructed with the PARSEC scanner.\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This lego model was scanned using the small scale setup of the main PARSEC multi viewing-angle space.  View the interactive model at https://sketchfab.com/3d-models/green-and-yellow-lego-bionicle-31da84f62844409988d0c3a849cfd306</div>\n<div class=\"imageCredit\">Seth Berrier, Creator</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Seth&nbsp;Berrier</div>\n<div class=\"imageTitle\">Small Lego figure captured and reconstructed with the PARSEC scanner.</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332689002_FullBodyScan--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332689002_FullBodyScan--rgov-800width.jpg\" title=\"The first scan ever captured by PARSEC\"><img src=\"/por/images/Reports/POR/2023/1626116/1626116_10462523_1676332689002_FullBodyScan--rgov-66x44.jpg\" alt=\"The first scan ever captured by PARSEC\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">This is a full body scan of the creator of PARSEC, Dr. Seth Berrier. It is represents a first deliverable with visible flaws that have been eliminated in later scans. View interactive model here: https://sketchfab.com/3d-models/self-scan-83544282906b45318bc188a98e0b42e6</div>\n<div class=\"imageCredit\">Seth Berrier, Creator</div>\n<div class=\"imagePermisssions\">Creative Commons</div>\n<div class=\"imageSubmitted\">Seth&nbsp;Berrier</div>\n<div class=\"imageTitle\">The first scan ever captured by PARSEC</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nThe UW Stout PARSEC project is a human-scale scanning system installed in the Fabrication Lab on the campus of UW Stout.  It has two major components:\n\nFor scanning the shape of a person or object: 120 cameras that can fire simultaneously to view an object from many angles.\nFor scanning complex appearance and materials: 156 lights that can be sequentially turned off or on in time with a camera to light an object from many angles.\n\n\nThe equipment can be utilized by any undergraduate student at Stout as well as any faculty or staff for enhancing research and education.  It is also available for the public to use, with prior arrangement.\n\nPARSEC stands for \"Photogrammetry and Reflectance Scanning for STEAM Education in the Chippewa valley.\"  The primary research goal is to help combine the separate areas of \"reflection fields\" (which samples and reconstructs complex appearance properties from lighting angles) and \"photogrammetry\" (which reconstructs shape and simple appearance from viewing angles).  The work towards this is ongoing and the equipment and software developed for PARSEC was built with this goal in mind.\n\nPARSEC is new, and it has only just begun to be utilized by students and instructors.  With its completion, we have also released free and open-source software for controlling the off-the-shelf hardware involved.  This software enables controlling many (100+) cameras remotely and is specifically designed with a photogrammetry workflow in mind.  Prior software for this purpose targeted the movie and video games industries and had restrictive and costly licenses making entry into this field difficult for academics.  Another goal of PARSEC is to lower this barrier to entry and the supporting software already released represents our largest effort to date to enable this work.\n\nThe PARSEC project will continue to expand this software package and make available interesting data sets for others to explore and process.  We will document and catalog our hardware and our experience using it in a university environment.  We will publish guides and documentation as we use this equipment and make it all available publicly so you can do the same.\n\nFollow our progress and access all of this at https://uwstout.github.io/PARSEC-project/\n\n\t\t\t\t\tLast Modified: 02/15/2023\n\n\t\t\t\t\tSubmitted by: Seth Berrier"
 }
}