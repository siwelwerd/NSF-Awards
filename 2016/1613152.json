{
 "awd_id": "1613152",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Computational and Communication Efficient Distributed Statistical Methods with Theoretical Guarantees",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Gabor Szekely",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 375000.0,
 "awd_amount": 475000.0,
 "awd_min_amd_letter_date": "2016-08-23",
 "awd_max_amd_letter_date": "2018-08-13",
 "awd_abstract_narration": "In many contemporary data-analysis settings, it is expensive and/or infeasible to assume that the entire data set is available at a central location. In recent works of computational mathematics and machine learning, great strides have been made in distributed optimization and distributed learning (i.e., machine learning). On the other hand, classical statistical methodology, theory, and computation are typically based on the assumption that the entire data are available at a central location; this is a significant shortcoming in modern statistical knowledge. The statistical methodology and theory for distributed inference are underdeveloped. The PI will develop new distributed statistical methods that are computation and communication efficient. He will study the theoretical guarantees of these distributed statistical estimators. The applicability and need of these methods in a wide spectrum of application domains will be explored and demonstrated. This research can have impacts in healthcare, supply chain industries, retail and services, and many more. \r\n\r\nBased on recent works in applied mathematics and machine learning, the PI is to explore theory, algorithms, and applications of statistical procedures that are developed for distributed data and aggregated inference (i.e., distributed inference), with considerations on the storage, computational complexity, and statistical properties of the relevant estimators. The project will develop practical models, statistical theory, and computationally efficient and provably correct algorithms that can help scientists to conduct more effective distributed data analysis. Statistical properties of these methods will be thoroughly studied, including analysis of asymptotic properties, simulation studies in finite sample cases, and establishment of effectiveness in some real applications. PhD students will be involved in the research. Course modules will be developed and made available publicly.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaoming",
   "pi_last_name": "Huo",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaoming Huo",
   "pi_email_addr": "xiaoming@isye.gatech.edu",
   "nsf_id": "000276730",
   "pi_start_date": "2016-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Georgia Tech Research Corporation",
  "inst_street_address": "926 DALNEY ST NW",
  "inst_street_address_2": "",
  "inst_city_name": "ATLANTA",
  "inst_state_code": "GA",
  "inst_state_name": "Georgia",
  "inst_phone_num": "4048944819",
  "inst_zip_code": "303186395",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "GA05",
  "org_lgl_bus_name": "GEORGIA TECH RESEARCH CORP",
  "org_prnt_uei_num": "EMW9FC8J3HN4",
  "org_uei_num": "EMW9FC8J3HN4"
 },
 "perf_inst": {
  "perf_inst_name": "Georgia Institute of Technology",
  "perf_str_addr": "225 North Avenue, NW",
  "perf_city_name": "Atlanta",
  "perf_st_code": "GA",
  "perf_st_name": "Georgia",
  "perf_zip_code": "303320002",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "GA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  },
  {
   "pgm_ele_code": "150400",
   "pgm_ele_name": "GOALI-Grnt Opp Acad Lia wIndus"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "019Z",
   "pgm_ref_txt": "Grad Prep APG:Enhan. Experience"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 125000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 125000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 225000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Distributed statistical inference has recently attracted enormous attention. Many existing works focuses on the averaging estimator. In the paper titled \"A Distributed One-Step Estimator\" (https://arxiv.org/abs/1511.01443), we propose a one-step approach to enhance a simple-averaging based distributed estimator. We derive the corresponding asymptotic properties of the newly proposed estimator. We find that the proposed one-step estimator enjoys the same asymptotic properties as the centralized estimator. The proposed one-step approach merely requires one additional round of communication in relative to the averaging estimator; therefore, the extra communication burden is insignificant. In finite sample cases, numerical examples show that the proposed estimator outperforms the simple averaging estimator with a large margin in terms of the mean squared errors. A potential application of the one-step approach is that one can use multiple machines to speed up large scale statistical inference with little compromise in the quality of estimators. The proposed method becomes more valuable when data can only be available at distributed machines with limited communication bandwidth.&nbsp;</p>\n<p>In general, the PI explores theory, algorithms, and applications of statistical procedures that are developed for distributed data and aggregated inference (i.e., distributed inference), with considerations on the storage, computational complexity, and statistical properties of the relevant estimators. The project develops practical models, statistical theory, and computationally efficient and provably correct algorithms that can help scientists to conduct more effective distributed data analysis. A positioning article titled \"Scattered Data and Aggregated Inference\" is on the related topic and can be found at <a href=\"https://link.springer.com/chapter/10.1007/978-3-319-18284-1_4\">https://link.springer.com/chapter/10.1007/978-3-319-18284-1_4</a>, which is a part of Handbook of Big Data Analytics (pp 75-102), a part of the Springer Handbooks of Computational Statistics book series (SHCS).</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/02/2019<br>\n\t\t\t\t\tModified by: Xiaoming&nbsp;Huo</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDistributed statistical inference has recently attracted enormous attention. Many existing works focuses on the averaging estimator. In the paper titled \"A Distributed One-Step Estimator\" (https://arxiv.org/abs/1511.01443), we propose a one-step approach to enhance a simple-averaging based distributed estimator. We derive the corresponding asymptotic properties of the newly proposed estimator. We find that the proposed one-step estimator enjoys the same asymptotic properties as the centralized estimator. The proposed one-step approach merely requires one additional round of communication in relative to the averaging estimator; therefore, the extra communication burden is insignificant. In finite sample cases, numerical examples show that the proposed estimator outperforms the simple averaging estimator with a large margin in terms of the mean squared errors. A potential application of the one-step approach is that one can use multiple machines to speed up large scale statistical inference with little compromise in the quality of estimators. The proposed method becomes more valuable when data can only be available at distributed machines with limited communication bandwidth. \n\nIn general, the PI explores theory, algorithms, and applications of statistical procedures that are developed for distributed data and aggregated inference (i.e., distributed inference), with considerations on the storage, computational complexity, and statistical properties of the relevant estimators. The project develops practical models, statistical theory, and computationally efficient and provably correct algorithms that can help scientists to conduct more effective distributed data analysis. A positioning article titled \"Scattered Data and Aggregated Inference\" is on the related topic and can be found at https://link.springer.com/chapter/10.1007/978-3-319-18284-1_4, which is a part of Handbook of Big Data Analytics (pp 75-102), a part of the Springer Handbooks of Computational Statistics book series (SHCS).\n\n\t\t\t\t\tLast Modified: 12/02/2019\n\n\t\t\t\t\tSubmitted by: Xiaoming Huo"
 }
}