{
 "awd_id": "1632582",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SBIR Phase II:  Automated Public Speaking Assessment",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032922174",
 "po_email": "rmehta@nsf.gov",
 "po_sign_block_name": "Rajesh Mehta",
 "awd_eff_date": "2016-08-15",
 "awd_exp_date": "2020-06-30",
 "tot_intn_awd_amt": 747422.0,
 "awd_amount": 1009443.0,
 "awd_min_amd_letter_date": "2016-08-05",
 "awd_max_amd_letter_date": "2019-05-29",
 "awd_abstract_narration": "This Phase II project aims to develop software to automatically assess public speaking skills and prepare students with better oral communications skills necessary to perform job tasks. Oral expression is the most highly valued ability throughout the economy and ranks as the second most highly-valued skill for high-wage, high-growth, high-skill occupations. Approximately 4.5 million college students take a basic communications course each year, however, as class sizes get larger and online learning becomes more common, public speaking instruction becomes increasingly difficult.  Practice and feedback are essential aspects of these courses, yet it is a struggle for teachers to find enough time to sufficiently interact with students. This SBIR project aims to develop the key concepts of automated public speaking assessment such that a student?s vocal delivery can be objectively measured and presented in a manner that creates an independent, personalized learning experience. Unlike traditional methods of public speaking assessment, the proposed system can be available at any time, provide objective feedback and track student practice and improvement. The proposed Software-as-a-Service is projected to generate $16 Million in revenue over five years and create more than 25 high-paying, US-based jobs. \r\n\r\n\r\nThis Small Business Innovative Research (SBIR) Phase II project proposes to develop an automated assessment system for public speaking that determines how a speaker would be perceived by an audience.  Automated assessment for speech has already occurred in spoken language proficiency, which leverages Automated Speech Recognition (ASR) and semantic analysis. Automated voice assessment has also been utilized in lie detection and emotion detection, which focus on autonomic responses in the user?s voice, such as when stress affects the vocal cords. The hypothesis behind this SBIR project is that speakers can consciously use and modify non-semantic speech behaviors to produce more desirable listener perceptions. Automatically linking listener perception to speech behaviors represents a novel direction in automated assessment for speech. The Phase II objective is to develop software sufficient for automated public speaking assessment such that a student?s vocal delivery can be objectively measured and presented in a manner that creates an independent, personalized learning experience. Voice analytics capability investigated in Phase I will be enhanced and developed into a cloud-based service which helps students practice, track, and improve their public speaking habits.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Debra",
   "pi_last_name": "Cancro",
   "pi_mid_init": "B",
   "pi_sufx_name": "Mrs.",
   "pi_full_name": "Debra B Cancro",
   "pi_email_addr": "debra@myvoicevibes.com",
   "nsf_id": "000716326",
   "pi_start_date": "2016-08-05",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "VoiceVibes, Inc.",
  "inst_street_address": "7224 SHUB FARM RD",
  "inst_street_address_2": "",
  "inst_city_name": "MARRIOTTSVILLE",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "4107461696",
  "inst_zip_code": "211041171",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "MD02",
  "org_lgl_bus_name": "VOICEVIBES, INC.",
  "org_prnt_uei_num": "",
  "org_uei_num": "KXMEC8YAFWW3"
 },
 "perf_inst": {
  "perf_inst_name": "VoiceVibes, Inc.",
  "perf_str_addr": "7224 Shub Farm Road",
  "perf_city_name": "Marriottsville",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "211041171",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "MD02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "537300",
   "pgm_ele_name": "SBIR Phase II"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "118E",
   "pgm_ref_txt": "GRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "165E",
   "pgm_ref_txt": "SBIR Phase IIB"
  },
  {
   "pgm_ref_code": "169E",
   "pgm_ref_txt": "SBIR Tech Enhan Partner (TECP)"
  },
  {
   "pgm_ref_code": "5373",
   "pgm_ref_txt": "SMALL BUSINESS PHASE II"
  },
  {
   "pgm_ref_code": "8031",
   "pgm_ref_txt": "Education Products"
  },
  {
   "pgm_ref_code": "8032",
   "pgm_ref_txt": "Software Services and Applications"
  },
  {
   "pgm_ref_code": "8039",
   "pgm_ref_txt": "Information, Communication & Computing"
  },
  {
   "pgm_ref_code": "8240",
   "pgm_ref_txt": "SBIR/STTR CAP"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 747422.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 159484.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 102537.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Oral communication is the most highly valued skill in our economy. In fact, when a speaker sounds extremely confident and authentic, listeners are 5 times more likely to say they believe in them and 13 times more likely to want to buy from them!&nbsp; This SBIR project enabled VoiceVibes, Inc. to develop an AI-powered, coaching platform that is helping thousands of people to practice and improve their oral communication skills with automated feedback that is personalized, objective and convenient.</p>\n<p><strong>INTELLECTUAL MERRIT:</strong></p>\n<p>The objectives of this project were to identify key features of voice and develop software models that can predict audience perception, sufficient to help a speaker improve their vocal delivery and improve the way they are perceived.&nbsp;Automatically linking listener perception to speech behaviors represented a novel direction in automated assessment for speech. To develop these models, a combination of expert feature extraction, machine learning and deep learning were applied and iteratively tested against a large corpus of actor voices and human perception ratings.&nbsp;</p>\n<p>Automated assessments of speech have been used for many decades in language learning, automated speech recognition (ASR) and semantic analysis. Automated voice assessments have also been utilized in lie detection and emotion detection, which focus on autonomic responses in the user?s voice, such as when stress affects the vocal cords. The novel hypothesis behind this SBIR project was that software can help speakers to consciously use and modify non-semantic speech behaviors to produce more desirable listener perceptions.</p>\n<p><strong>Important Outcomes of this work include three, commercially available products:</strong></p>\n<p><strong>&nbsp;</strong><strong>1. Vibe Models &amp; API</strong>&nbsp; - VoiceVibes developed software that predicts how a speaker would be perceived by an audience (i.e. confident, boring, personable, insincere, belligerent, etc.). AI models were developed that extract over 100 features of voice and rate audio on a scale of 1 (low)-10 (high) for 20 separate audience perception types, called vibes.&nbsp; The features and predictive values are provided in an API that is used in VoiceVibes products as well as other commercial applications.&nbsp;</p>\n<p><strong>2. VoiceVibes AI-Powered Public Speaking Practice Tool -</strong> Web-based dashboards and recording apps for both major smartphone platforms were developed in order to create a convenient and personalized learning experience.&nbsp; This commercial product is used in both academic and corporate learning programs for practice and automated assessment of public speaking.</p>\n<p><strong>3. VoiceVibes AI-Powered Coaching Platform</strong>&nbsp; A coaching platform was developed around the innovative technology to provide a more complete training solution. This platform gives coaches the ability to create assignments, customize completion criteria, track progress and provide additional feedback and scorecards.</p>\n<p><strong>BROADER IMPACTS</strong></p>\n<p>By reinforcing communication skills through self-paced practice and objective feedback, users are better prepared to perform job tasks, communicate their ideas, collaborate with others, and move into management and leadership roles. The software developed during this SBIR project is currently used by thousands of learners in classes, corporate training programs and sales training.&nbsp; Potential future applications for the technology include teacher assessments, call center monitoring, interview training, role play, pre-employment screening, patient care, English as a Second Language (ESL) learning, services for people who are deaf and hard of hearing, and student assessments.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/28/2020<br>\n\t\t\t\t\tModified by: Debra&nbsp;B&nbsp;Cancro</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586799010371_VibesFigure1--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586799010371_VibesFigure1--rgov-800width.jpg\" title=\"VoiceVibes' Measures 20 Vibes\"><img src=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586799010371_VibesFigure1--rgov-66x44.jpg\" alt=\"VoiceVibes' Measures 20 Vibes\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Copyright 2020 VoiceVibes, Inc. - All Rights Reserved.</div>\n<div class=\"imageCredit\">VoiceVibes, Inc.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Debra&nbsp;B&nbsp;Cancro</div>\n<div class=\"imageTitle\">VoiceVibes' Measures 20 Vibes</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586809154584_CoachingPlatform--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586809154584_CoachingPlatform--rgov-800width.jpg\" title=\"VoiceVibes Coach Dashboard Sales Training Example\"><img src=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586809154584_CoachingPlatform--rgov-66x44.jpg\" alt=\"VoiceVibes Coach Dashboard Sales Training Example\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Copyright 2020 VoiceVibes, Inc. - All Rights Reserved</div>\n<div class=\"imageCredit\">VoiceVibes, Inc.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Debra&nbsp;B&nbsp;Cancro</div>\n<div class=\"imageTitle\">VoiceVibes Coach Dashboard Sales Training Example</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586810871552_SpeakerDashboard--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586810871552_SpeakerDashboard--rgov-800width.jpg\" title=\"VoiceVibes Speaker Dashboard\"><img src=\"/por/images/Reports/POR/2020/1632582/1632582_10447157_1586810871552_SpeakerDashboard--rgov-66x44.jpg\" alt=\"VoiceVibes Speaker Dashboard\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Copyright 2020, VoiceVibes, Inc. - All Rights Reserved.</div>\n<div class=\"imageCredit\">VoiceVibes, Inc.</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Debra&nbsp;B&nbsp;Cancro</div>\n<div class=\"imageTitle\">VoiceVibes Speaker Dashboard</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nOral communication is the most highly valued skill in our economy. In fact, when a speaker sounds extremely confident and authentic, listeners are 5 times more likely to say they believe in them and 13 times more likely to want to buy from them!  This SBIR project enabled VoiceVibes, Inc. to develop an AI-powered, coaching platform that is helping thousands of people to practice and improve their oral communication skills with automated feedback that is personalized, objective and convenient.\n\nINTELLECTUAL MERRIT:\n\nThe objectives of this project were to identify key features of voice and develop software models that can predict audience perception, sufficient to help a speaker improve their vocal delivery and improve the way they are perceived. Automatically linking listener perception to speech behaviors represented a novel direction in automated assessment for speech. To develop these models, a combination of expert feature extraction, machine learning and deep learning were applied and iteratively tested against a large corpus of actor voices and human perception ratings. \n\nAutomated assessments of speech have been used for many decades in language learning, automated speech recognition (ASR) and semantic analysis. Automated voice assessments have also been utilized in lie detection and emotion detection, which focus on autonomic responses in the user?s voice, such as when stress affects the vocal cords. The novel hypothesis behind this SBIR project was that software can help speakers to consciously use and modify non-semantic speech behaviors to produce more desirable listener perceptions.\n\nImportant Outcomes of this work include three, commercially available products:\n\n 1. Vibe Models &amp; API  - VoiceVibes developed software that predicts how a speaker would be perceived by an audience (i.e. confident, boring, personable, insincere, belligerent, etc.). AI models were developed that extract over 100 features of voice and rate audio on a scale of 1 (low)-10 (high) for 20 separate audience perception types, called vibes.  The features and predictive values are provided in an API that is used in VoiceVibes products as well as other commercial applications. \n\n2. VoiceVibes AI-Powered Public Speaking Practice Tool - Web-based dashboards and recording apps for both major smartphone platforms were developed in order to create a convenient and personalized learning experience.  This commercial product is used in both academic and corporate learning programs for practice and automated assessment of public speaking.\n\n3. VoiceVibes AI-Powered Coaching Platform  A coaching platform was developed around the innovative technology to provide a more complete training solution. This platform gives coaches the ability to create assignments, customize completion criteria, track progress and provide additional feedback and scorecards.\n\nBROADER IMPACTS\n\nBy reinforcing communication skills through self-paced practice and objective feedback, users are better prepared to perform job tasks, communicate their ideas, collaborate with others, and move into management and leadership roles. The software developed during this SBIR project is currently used by thousands of learners in classes, corporate training programs and sales training.  Potential future applications for the technology include teacher assessments, call center monitoring, interview training, role play, pre-employment screening, patient care, English as a Second Language (ESL) learning, services for people who are deaf and hard of hearing, and student assessments. \n\n \n\n\t\t\t\t\tLast Modified: 09/28/2020\n\n\t\t\t\t\tSubmitted by: Debra B Cancro"
 }
}