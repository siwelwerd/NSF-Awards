{
 "awd_id": "1632154",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "PFI:BIC MAKERPAD: Cognitively Intuitive Shape-Modeling and Design Interface enabling a Distributed Personalized Fabrication Network.",
 "cfda_num": "47.084",
 "org_code": "15030000",
 "po_phone": "7032927795",
 "po_email": "jsoriano@nsf.gov",
 "po_sign_block_name": "Jesus Soriano Molla",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 1000000.0,
 "awd_amount": 1000000.0,
 "awd_min_amd_letter_date": "2016-08-29",
 "awd_max_amd_letter_date": "2016-08-29",
 "awd_abstract_narration": "Currently product design and manufacturing are accessible only to enterprises and professionals such as engineers and designers. Everyone has ideas but only a select few can bring them to fabrication. This is because of lack of intuitive and easy-to-use design tools, detailed knowledge required to make prototypes, help needed for users with difficulties, and access to fabrication facilities. This gap could be seen as a waste of untapped human creative resources and economic potential to the Nation. MAKERPAD will bridge the gaps between the need for design tools for personalized production and the rapid growth of 3D fabrication technologies by providing intuitive tools for designing and access to remote fabrication resources. Using the cloud, MAKERPAD will enable personalized fabrication technology easily accessible and available to makers and students.\r\n\r\nMAKERPAD is enabled by (a) 3D mixed and augmented reality, (b) cloud-powered algorithms (shape modeling, computer vision, human computer interaction), and (c) service models supporting 3D scanning, searching and printing. Using the affordances created by depth sensing cameras that are being embedded into both mobile and intuitive fabrication oriented design modeling, smart algorithms will be enabled to work real-time over the cloud. MAKERPAD will develop and use the human-centric cognitively intuitive design interfaces, digital modeling in the virtual cloud world, thus enabling connectivity to a personalized fabrication network. Using a new robotic toy platform as well as accessories as the use case, the service model design will appropriately support consumers at various levels of capabilities. The workflow at the user and system level will be designed in a seamless fashion for the users to obtain laser cut and 3D printed models of their designs. If successful, this system will support different levels of service, quality and sophistication of digital designs and physical models depending on the user requirements, usage context, budget and time constraints. The smart system will dynamically configure the appropriate technologies, providers and approaches, such as Do-It-Yourself (DIY) as well as concierge services, to deliver the optimal level of solution to the user.\r\n\r\nThis project is a collaboration between Purdue University (Mechanical, Electrical and Computer Engineering, and Business School) and primary implementation partner gesture interface technology ZeroUI (San Jose, CA, small business). Secondary partners for test-beds include a museum (Imagination Station, Lafayette, IN, non-profit) and gifted education research institute (GERI, Purdue University). Other partners include augmented reality - Meta (Portola Valley, CA, medium business); and depth sensing camera - Leap (San Francisco, CA, medium business).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "TIP",
 "org_dir_long_name": "Directorate for Technology, Innovation, and Partnerships",
 "div_abbr": "TI",
 "org_div_long_name": "Translational Impacts",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Karthik",
   "pi_last_name": "Ramani",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Karthik Ramani",
   "pi_email_addr": "ramani@purdue.edu",
   "nsf_id": "000284152",
   "pi_start_date": "2016-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ananth",
   "pi_last_name": "Iyer",
   "pi_mid_init": "V",
   "pi_sufx_name": "",
   "pi_full_name": "Ananth V Iyer",
   "pi_email_addr": "aiyer@purdue.edu",
   "nsf_id": "000169138",
   "pi_start_date": "2016-08-29",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Sanjay",
   "pi_last_name": "Rao",
   "pi_mid_init": "G",
   "pi_sufx_name": "",
   "pi_full_name": "Sanjay G Rao",
   "pi_email_addr": "sanjay@purdue.edu",
   "nsf_id": "000227316",
   "pi_start_date": "2016-08-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Purdue University",
  "inst_street_address": "2550 NORTHWESTERN AVE # 1100",
  "inst_street_address_2": "",
  "inst_city_name": "WEST LAFAYETTE",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "7654941055",
  "inst_zip_code": "479061332",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "IN04",
  "org_lgl_bus_name": "PURDUE UNIVERSITY",
  "org_prnt_uei_num": "YRXVL4JYCEF5",
  "org_uei_num": "YRXVL4JYCEF5"
 },
 "perf_inst": {
  "perf_inst_name": "Purdue University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "479072088",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "IN04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "018Y00",
   "pgm_ele_name": "CM - Cybermanufacturing System"
  },
  {
   "pgm_ele_code": "166200",
   "pgm_ele_name": "PFI-Partnrships for Innovation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1662",
   "pgm_ref_txt": "PARTNRSHIPS FOR INNOVATION-PFI"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 1000000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-ac259feb-7fff-7c3c-6b10-0abef833271f\"> </span></p>\n<p dir=\"ltr\"><span>Everyone has ideas but only a select few can bring them to reality. The primary challenge in product design and fabrication are that the interfaces and methods are not intuitive and too complex for lay persons. They inhibit creative contributions of a large part of the population. This is a tremendous waste of creative human resources and the vast economic potential of society remains untapped. To overcome these challenges and improve accessibility to technology we developed several&nbsp; easy to learn and use metaphors and design tools for shape modeling, electrical circuitry design, and electromechanical product design. We developed new interfaces and intuitive interactions that used the phone and tablets to express ideas quickly and without the need for extensive training. For example we also developed means to transform the user interactions into design and fabricated prototypes with 3D printers and laser cutters. Our design and fabrication pipeline enabled users to quickly transform ordinary household objects into interactive and functional ones, for example through directly designing circuits on top of them. The ordinary objects are scanned and then designed circuits are printed using a low-cost 3D printer. Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We also developed an interactive design support system that allows a novice to transform an existing scanned 3D model into structures using rods and custom 3D printed joints. A recommendation system enables novice users to choose designs that satisfy both loading and their personal design intentions. Novice users can&nbsp; add movable joints to increase functionality and attach a customized appearance to their creations. Our advances also empowers novices to fabricate complex constructions while ensuring structural soundness without any knowledge of sophisticated analysis and modeling programs. We demonstrated that novice users were able to generate a large number of structurally safe designs for fabrication</span><span>. </span><span>Furthermore we developed collaborative and cloud based means to engage users and coaches remotely using augmented reality by connecting up the physical designs with overlaid 3D virtual content.&nbsp;</span></p>\n<p dir=\"ltr\"><span>Our testing of the tools and methods were conducted with the help of museums and summer programs to engage K-12 children in design, build and play exercises across robotics, craft, and maker type fabrication activities. We also integrated augmented reality into interacting with users during the design and fabrication process of electromechanical products and circuits.&nbsp; Smart phones and augmented reality based interactions, through hand-held movement of the phone, were shown to enable smooth and fluid interactions to create parts and accessories as well as build modular robots. In doing so we demonstrated that learners can be engaged in the creation process leading to learning gains. Our toolkit also provides hardware and software that enable haptic feedback to improve user experiences and promote collaboration during learning. We performed user studies in remote collaborative laboratories, where we demonstrated that our augmented reality based labs provided comparable students performance to an in-person laboratory.</span></p>\n<p><span>Our research directly trained five Ph.D. students who are now in the workforce participating in high technology development related to virtual and augmented reality as well as faculty in human-computer interaction. Several undergraduates were trained in modern technology while assisting in the research. Incorporating physical and computing devices alongside AR presents opportunities for shared and remote experiences between users, leading to more engagement. Such shared experiences will create opportunities for social interaction, ideation, and creativity. In pursuit of a future where novice makers can create unique experiences, and subject matter experts can create dynamic, interactive, and engaging AR content, we designed our solutions for shared experiences with augmented reality and internet of things devices to have broad impact beyond our use cases and studies.The results from this project have been disseminated through conference publications, invited presentations, and panels such as in chronicle of higher education, where several educators and industries participated. Several hundreds of students have also participated in our workshops during the years and we continue to sustain them through our summer workshop program done remotely during the pandemic. We also connected the engineering design and computer science communities especially in human computer interaction through the bridges we built between the digital and physical world using dynamic 3D content. The outcomes of the project have applications beyond the domain of engineering design and maker experiences in that we have developed proof of concept of new and engaging remote learning capacities. Our augmented reality based spatial interactions technologies have been embedded into new technology platforms. These modalities of interaction we have demonstrated cater to the need for remote hands-on and engaged learning experiences especially needed during the pandemic</span><span>.</span></p>\n<p><span><br /></span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/07/2022<br>\n\t\t\t\t\tModified by: Karthik&nbsp;Ramani</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImages (<span id=\"selectedPhoto0\">1</span> of <span class=\"totalNumber\"></span>)\t\t\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644277446271_ScreenShot2022-02-07at6.29.30PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644277446271_ScreenShot2022-02-07at6.29.30PM--rgov-800width.jpg\" title=\"An interactive design system for a novice to convert a 3D model to a fabricated bookshelf\"><img src=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644277446271_ScreenShot2022-02-07at6.29.30PM--rgov-66x44.jpg\" alt=\"An interactive design system for a novice to convert a 3D model to a fabricated bookshelf\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to convert 3D models into structures that will take loads.</div>\n<div class=\"imageCredit\">Subramaniam Chidambaram</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Karthik&nbsp;Ramani</div>\n<div class=\"imageTitle\">An interactive design system for a novice to convert a 3D model to a fabricated bookshelf</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644277192227_ScreenShot2022-02-07at6.28.26PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644277192227_ScreenShot2022-02-07at6.28.26PM--rgov-800width.jpg\" title=\"StoryMakAR workflow for interactions with the physical world using a phone\"><img src=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644277192227_ScreenShot2022-02-07at6.28.26PM--rgov-66x44.jpg\" alt=\"StoryMakAR workflow for interactions with the physical world using a phone\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">StoryMakAR (a) Users build electro-mechanical devices, program them using our drag-and-drop environment, DeviceMakAR, and control them with our plug-and-play MakAR Board. (b) Users create events for their story with EventMakAR. (c) Then control physical devices and virtual characters using a phone</div>\n<div class=\"imageCredit\">Terrell Kendall Glenn</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Karthik&nbsp;Ramani</div>\n<div class=\"imageTitle\">StoryMakAR workflow for interactions with the physical world using a phone</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644279324752_ScreenShot2022-02-07at6.30.11PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644279324752_ScreenShot2022-02-07at6.30.11PM--rgov-800width.jpg\" title=\"Overview of our model to provide a user with basic mastery of electrical circuitry\"><img src=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644279324752_ScreenShot2022-02-07at6.30.11PM--rgov-66x44.jpg\" alt=\"Overview of our model to provide a user with basic mastery of electrical circuitry\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">(Left) Electrical circuitry as a wide body of knowledge with multiple concepts and electrical components, even at the basic level. (Right) We break down electrical circuitry into fundamentals or microskills\ufffddelivered through augmented reality on the phone.</div>\n<div class=\"imageCredit\">Ana Villaneuva</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Karthik&nbsp;Ramani</div>\n<div class=\"imageTitle\">Overview of our model to provide a user with basic mastery of electrical circuitry</div>\n</div>\n</li>\n<li>\n<a href=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644279516880_ScreenShot2022-02-07at6.30.42PM--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644279516880_ScreenShot2022-02-07at6.30.42PM--rgov-800width.jpg\" title=\"ColabAR: A Toolkit for Remote Collaboration in Tangible Augmented Reality Laboratories\"><img src=\"/por/images/Reports/POR/2022/1632154/1632154_10456335_1644279516880_ScreenShot2022-02-07at6.30.42PM--rgov-66x44.jpg\" alt=\"ColabAR: A Toolkit for Remote Collaboration in Tangible Augmented Reality Laboratories\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">Overview of the usability of our toolkit to enable remote collaboration in a tangible augmented reality lab. Each module includes a haptic driver for customizable haptic feedback. Students collaborate remotely by using tangibles thatare proxies to virtual object</div>\n<div class=\"imageCredit\">Ana Villanueva</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Karthik&nbsp;Ramani</div>\n<div class=\"imageTitle\">ColabAR: A Toolkit for Remote Collaboration in Tangible Augmented Reality Laboratories</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\n \nEveryone has ideas but only a select few can bring them to reality. The primary challenge in product design and fabrication are that the interfaces and methods are not intuitive and too complex for lay persons. They inhibit creative contributions of a large part of the population. This is a tremendous waste of creative human resources and the vast economic potential of society remains untapped. To overcome these challenges and improve accessibility to technology we developed several  easy to learn and use metaphors and design tools for shape modeling, electrical circuitry design, and electromechanical product design. We developed new interfaces and intuitive interactions that used the phone and tablets to express ideas quickly and without the need for extensive training. For example we also developed means to transform the user interactions into design and fabricated prototypes with 3D printers and laser cutters. Our design and fabrication pipeline enabled users to quickly transform ordinary household objects into interactive and functional ones, for example through directly designing circuits on top of them. The ordinary objects are scanned and then designed circuits are printed using a low-cost 3D printer. Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We also developed an interactive design support system that allows a novice to transform an existing scanned 3D model into structures using rods and custom 3D printed joints. A recommendation system enables novice users to choose designs that satisfy both loading and their personal design intentions. Novice users can  add movable joints to increase functionality and attach a customized appearance to their creations. Our advances also empowers novices to fabricate complex constructions while ensuring structural soundness without any knowledge of sophisticated analysis and modeling programs. We demonstrated that novice users were able to generate a large number of structurally safe designs for fabrication. Furthermore we developed collaborative and cloud based means to engage users and coaches remotely using augmented reality by connecting up the physical designs with overlaid 3D virtual content. \nOur testing of the tools and methods were conducted with the help of museums and summer programs to engage K-12 children in design, build and play exercises across robotics, craft, and maker type fabrication activities. We also integrated augmented reality into interacting with users during the design and fabrication process of electromechanical products and circuits.  Smart phones and augmented reality based interactions, through hand-held movement of the phone, were shown to enable smooth and fluid interactions to create parts and accessories as well as build modular robots. In doing so we demonstrated that learners can be engaged in the creation process leading to learning gains. Our toolkit also provides hardware and software that enable haptic feedback to improve user experiences and promote collaboration during learning. We performed user studies in remote collaborative laboratories, where we demonstrated that our augmented reality based labs provided comparable students performance to an in-person laboratory.\n\nOur research directly trained five Ph.D. students who are now in the workforce participating in high technology development related to virtual and augmented reality as well as faculty in human-computer interaction. Several undergraduates were trained in modern technology while assisting in the research. Incorporating physical and computing devices alongside AR presents opportunities for shared and remote experiences between users, leading to more engagement. Such shared experiences will create opportunities for social interaction, ideation, and creativity. In pursuit of a future where novice makers can create unique experiences, and subject matter experts can create dynamic, interactive, and engaging AR content, we designed our solutions for shared experiences with augmented reality and internet of things devices to have broad impact beyond our use cases and studies.The results from this project have been disseminated through conference publications, invited presentations, and panels such as in chronicle of higher education, where several educators and industries participated. Several hundreds of students have also participated in our workshops during the years and we continue to sustain them through our summer workshop program done remotely during the pandemic. We also connected the engineering design and computer science communities especially in human computer interaction through the bridges we built between the digital and physical world using dynamic 3D content. The outcomes of the project have applications beyond the domain of engineering design and maker experiences in that we have developed proof of concept of new and engaging remote learning capacities. Our augmented reality based spatial interactions technologies have been embedded into new technology platforms. These modalities of interaction we have demonstrated cater to the need for remote hands-on and engaged learning experiences especially needed during the pandemic.\n\n\n\n\n \n\n\t\t\t\t\tLast Modified: 02/07/2022\n\n\t\t\t\t\tSubmitted by: Karthik Ramani"
 }
}