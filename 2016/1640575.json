{
 "awd_id": "1640575",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CIF21 DIBBs: EI: Continuous Capture of Metadata for Statistical Data",
 "cfda_num": "47.070",
 "org_code": "05090000",
 "po_phone": "7032924538",
 "po_email": "awalton@nsf.gov",
 "po_sign_block_name": "Amy Walton",
 "awd_eff_date": "2016-10-01",
 "awd_exp_date": "2021-09-30",
 "tot_intn_awd_amt": 2565643.0,
 "awd_amount": 3076213.0,
 "awd_min_amd_letter_date": "2016-08-02",
 "awd_max_amd_letter_date": "2019-07-18",
 "awd_abstract_narration": "As the research community responds to increasing demands for public access to scientific data, the need for improvement in data documentation has become critical.  Accurate and complete metadata is essential for data sharing and for interoperability across different data types.  However, the process of describing and documenting scientific data has remained a tedious, manual process even when data collection is fully automated.  General purpose statistical packages (SPSS, SAS, Stata, R) are fundamental to research in the social and behavioral sciences, environmental sciences, biomedical research, and many other fields, but these packages lack tools for documenting how data are modified and new variables created.  By creating tools to capture data transformations from statistical analysis packages, this project creates efficiencies and reduces the costs of data collection, preparation, and re-use.  Two research communities with strong metadata standards and heavy reliance on statistical analysis software (social and behavioral sciences and earth observation sciences) are targeted, but the approach is generalizable to other scientific domains.\r\n\r\nAutomating documentation of data transformations involves three main steps. First, the most common data transformation operators are standardized and mapped to the Validation and Transformation Language (VTL), an emerging independent standard for describing operations on data in detail.  Second, software parses command scripts for the most widely used statistics packages and translates data transformation operations into VTL.  Third, software tools modify metadata files adhering to existing standards to reflect changes to the data.  This approach embeds detailed variable-level provenance information into standard metadata, and makes it available for data discovery services and automated data analysis tools.   \r\n\r\nThis award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and the NSF Directorate for Social, Behavioral and Economic Sciences (Division of Social and Economic Sciences).",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "OAC",
 "org_div_long_name": "Office of Advanced Cyberinfrastructure (OAC)",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "George",
   "pi_last_name": "Alter",
   "pi_mid_init": "C",
   "pi_sufx_name": "",
   "pi_full_name": "George C Alter",
   "pi_email_addr": "altergc@umich.edu",
   "nsf_id": "000206718",
   "pi_start_date": "2016-08-02",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Jared",
   "pi_last_name": "Lyle",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Jared Lyle",
   "pi_email_addr": "lyle@umich.edu",
   "nsf_id": "000719890",
   "pi_start_date": "2016-08-02",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Regents of the University of Michigan - Ann Arbor",
  "inst_street_address": "1109 GEDDES AVE STE 3300",
  "inst_street_address_2": "",
  "inst_city_name": "ANN ARBOR",
  "inst_state_code": "MI",
  "inst_state_name": "Michigan",
  "inst_phone_num": "7347636438",
  "inst_zip_code": "481091015",
  "inst_country_name": "United States",
  "cong_dist_code": "06",
  "st_cong_dist_code": "MI06",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MICHIGAN",
  "org_prnt_uei_num": "",
  "org_uei_num": "GNJ7BBP73WE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Michigan Ann Arbor",
  "perf_str_addr": "3003 South State St. Room 1062",
  "perf_city_name": "Ann Arbor",
  "perf_st_code": "MI",
  "perf_st_name": "Michigan",
  "perf_zip_code": "481091274",
  "perf_ctry_code": "US",
  "perf_cong_dist": "06",
  "perf_st_cong_dist": "MI06",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "116500",
   "pgm_ele_name": "ADVANCES IN BIO INFORMATICS"
  },
  {
   "pgm_ele_code": "772600",
   "pgm_ele_name": "Data Cyberinfrastructure"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7433",
   "pgm_ref_txt": "CyberInfra Frmwrk 21st (CIF21)"
  },
  {
   "pgm_ref_code": "8048",
   "pgm_ref_txt": "Data Infrstr Bldg Blocks-DIBBs"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 2565643.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 510570.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Continuous Capture of Metadata (C?Metadata) Project makes research methods more transparent by improving documentation of data transformations performed by statistical analysis software.&nbsp; Many scientists use statistical analysis packages to manage and prepare data. &nbsp;Programs executed by these software packages select subsets, transform existing variables, and create new variables.&nbsp; Data preparation programs are often long and complicated, which makes them difficult to understand.&nbsp; Our software translates these programs into Structured Data Transformation Language (SDTL), which is a new computer language created by our project.&nbsp; SDTL provides a common intermediate language for five different statistical analysis packages (SPSS, Stata, SAS, R, Python) widely used by scientists.&nbsp; SDTL is much easier for computers to process than the original programming languages, and we have a tool that makes SDTL easy for humans to read.&nbsp; When SDTL is added to documentation about a data set, researchers can easily understand how new variables were derived from the original data.&nbsp;&nbsp; For example, we can create a concise history of all of the steps involved in creating a new variable.&nbsp; We have also created tools for adding SDTL to documentation files that are used in data catalogs and codebooks.&nbsp; All of the steps in creating SDTL and new documentation files can be executed from a simple website, so that it is very easy to use.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/20/2021<br>\n\t\t\t\t\tModified by: George&nbsp;C&nbsp;Alter</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Continuous Capture of Metadata (C?Metadata) Project makes research methods more transparent by improving documentation of data transformations performed by statistical analysis software.  Many scientists use statistical analysis packages to manage and prepare data.  Programs executed by these software packages select subsets, transform existing variables, and create new variables.  Data preparation programs are often long and complicated, which makes them difficult to understand.  Our software translates these programs into Structured Data Transformation Language (SDTL), which is a new computer language created by our project.  SDTL provides a common intermediate language for five different statistical analysis packages (SPSS, Stata, SAS, R, Python) widely used by scientists.  SDTL is much easier for computers to process than the original programming languages, and we have a tool that makes SDTL easy for humans to read.  When SDTL is added to documentation about a data set, researchers can easily understand how new variables were derived from the original data.   For example, we can create a concise history of all of the steps involved in creating a new variable.  We have also created tools for adding SDTL to documentation files that are used in data catalogs and codebooks.  All of the steps in creating SDTL and new documentation files can be executed from a simple website, so that it is very easy to use. \n\n\t\t\t\t\tLast Modified: 11/20/2021\n\n\t\t\t\t\tSubmitted by: George C Alter"
 }
}