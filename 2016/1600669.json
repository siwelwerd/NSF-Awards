{
 "awd_id": "1600669",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CNS: CSR: Small: Runtime System, Architecture, and Technology Codesign Approach for Heterogeneous Many-Core Processors and Clusters",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032925197",
 "po_email": "mmcclure@nsf.gov",
 "po_sign_block_name": "Marilyn McClure",
 "awd_eff_date": "2015-08-21",
 "awd_exp_date": "2016-08-31",
 "tot_intn_awd_amt": 222526.0,
 "awd_amount": 222526.0,
 "awd_min_amd_letter_date": "2015-10-14",
 "awd_max_amd_letter_date": "2015-10-14",
 "awd_abstract_narration": "The performance of computers has improved tremendously in the past four decades, which has enabled innumerable applications that have major roles in our daily lives. However, without dramatic innovations in improving performance and power efficiency of computing, the continued semiconductor device scaling alone will fail to provide computing capabilities needed for future applications. One of the main performance bottlenecks of traditional computing systems has been the high cost of communications between central processing unit (CPU) and graphics processing unit (GPU). The on-chip integration of CPU and GPU dramatically reduces the cost of communications, but it also worsens power, thermal, and bandwidth issues for chip design.  Nonetheless, it also allows new approaches to be explored that previously were not practical.  Given the potential and challenges of on-chip integrated CPU+GPU processors, this project undertakes a multidisciplinary effort to improve performance and power efficiency of computers. Specifically, the project aims to (i) develop runtime algorithms for scheduling workload and memory accesses under power, thermal, bandwidth constraints; (ii) explore micoarchitectures for improving memory system performance under bandwidth constraints; and (iii) optimize heterogeneous technology choices for integrated CPU+GPU processors. \r\n\r\nThis project is expected to have significant impact on the technology, circuit, architecture, and runtime system communities, and it is leading to state-of-the-art research infrastructure. The project also contributes state-of-the art workforce training. The outcomes of this project benefit economic growth through technology advances that will provide increased computing capability at a lower cost.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Nam Sung",
   "pi_last_name": "Kim",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nam Sung Kim",
   "pi_email_addr": "nskim@illinois.edu",
   "nsf_id": "000512015",
   "pi_start_date": "2015-10-14",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Illinois at Urbana-Champaign",
  "inst_street_address": "506 S WRIGHT ST",
  "inst_street_address_2": "",
  "inst_city_name": "URBANA",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "2173332187",
  "inst_zip_code": "618013620",
  "inst_country_name": "United States",
  "cong_dist_code": "13",
  "st_cong_dist_code": "IL13",
  "org_lgl_bus_name": "UNIVERSITY OF ILLINOIS",
  "org_prnt_uei_num": "V2PHZ2CSCH63",
  "org_uei_num": "Y8CWNJRCNN91"
 },
 "perf_inst": {
  "perf_inst_name": "University of Illinois at Urbana-Champaign",
  "perf_str_addr": "1901 S. First St. Suite A",
  "perf_city_name": "Champaign",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "618207473",
  "perf_ctry_code": "US",
  "perf_cong_dist": "13",
  "perf_st_cong_dist": "IL13",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "735400",
   "pgm_ele_name": "CSR-Computer Systems Research"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0112",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001213DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2012,
   "fund_oblg_amt": 222526.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The computing industry is at a cross-roads today because scaling of silicon technology, which has been a major driving force for enabling high-performance computing, is rapidly approaching the fundamental limits. As Gordon Moore recently noted, &ldquo;No exponential is forever, but can be only delayed.&rdquo; On the other hand, the potentials of new emerging technologies are yet to be explored and these technologies are not mature enough to be economically used for mass production of computing devices. From an architecture point of view, a heterogeneous computing system comprised of heterogeneous processors such as CPU, GPU, and accelerators has emerged as a plausible practical solution to meet increasing performance demand under power, thermal, and bandwidth constraints.</p>\n<p>Faced with such challenges and opportunities, in this project we aim to dramatically improve performance and energy-efficiency of heterogeneous computing systems with various techniques cutting across multiple levels of computing stacks (i.e., device, circuit, architecture, and runtime algorithm). Toward this goal, we first developed an architectural simulator to evaluate the performance of heterogeneous computing systems and released the simulator to the public (http://cpu-gpu-sim.ece.wisc.edu). Second, we developed a model that can evaluate the energy consumption of GPUs, which is an integral component of heterogeneous computing systems with two other collaborators from the University of Texas and University of British Columbia, and released it to the public (http://www.gpgpu-sim.org/gpuwattch). This energy model is currently the de facto model to evaluate the energy consumption of GPUs and the widely used model in the world, benefiting many researchers around the world. According to Google Scholar, more than 200 research papers have used this model. Third, based on these simulator and model we have developed many architecture and runtime algorithms to improve performance and energy efficiency of heterogeneous computing systems. For example, we developed a runtime algorithm that jointly adapts the operating voltage/frequency, the number of cores, and the workload allocated to the CPU and the GPU in a heterogeneous computing system. This algorithm allows us to maximize the performance under a given power constraint. We also developed various architectures that exploit the similarity of values&nbsp;that are processed by GPUs to further improve performance and energy efficiency while exploiting some unique characteristics of emerging applications running on heterogeneous computing systems. Moreover, we explored a practical but innovative heterogeneous computing architecture that moves computations near the memory considering the bandwidth constraint and energy efficiency, as it becomes more expensive to move data from memory to processors than processing data. This recent work, which significantly improves performance and energy consumption compared to traditional heterogeneous computing systems, has been widely cited by many recently published research papers in very a short time period.</p>\n<p>Lastly, this project allowed us to support and train graduate students including under-represented ones. They are now working for large companies in the U.S.A. and contributing to developing the next-generation, state-of-the-art computers that will ensure the U.S.A. to maintain the leading position in computing and economy. Besides, the products of this project allowed us to enhance the contents of undergraduate and graduate-level computer architecture courses such that the students can learn state-of-the-art computing technologies and be better prepared for their jobs in industry and academia.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/29/2016<br>\n\t\t\t\t\tModified by: Nam Sung&nbsp;Kim</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe computing industry is at a cross-roads today because scaling of silicon technology, which has been a major driving force for enabling high-performance computing, is rapidly approaching the fundamental limits. As Gordon Moore recently noted, \"No exponential is forever, but can be only delayed.\" On the other hand, the potentials of new emerging technologies are yet to be explored and these technologies are not mature enough to be economically used for mass production of computing devices. From an architecture point of view, a heterogeneous computing system comprised of heterogeneous processors such as CPU, GPU, and accelerators has emerged as a plausible practical solution to meet increasing performance demand under power, thermal, and bandwidth constraints.\n\nFaced with such challenges and opportunities, in this project we aim to dramatically improve performance and energy-efficiency of heterogeneous computing systems with various techniques cutting across multiple levels of computing stacks (i.e., device, circuit, architecture, and runtime algorithm). Toward this goal, we first developed an architectural simulator to evaluate the performance of heterogeneous computing systems and released the simulator to the public (http://cpu-gpu-sim.ece.wisc.edu). Second, we developed a model that can evaluate the energy consumption of GPUs, which is an integral component of heterogeneous computing systems with two other collaborators from the University of Texas and University of British Columbia, and released it to the public (http://www.gpgpu-sim.org/gpuwattch). This energy model is currently the de facto model to evaluate the energy consumption of GPUs and the widely used model in the world, benefiting many researchers around the world. According to Google Scholar, more than 200 research papers have used this model. Third, based on these simulator and model we have developed many architecture and runtime algorithms to improve performance and energy efficiency of heterogeneous computing systems. For example, we developed a runtime algorithm that jointly adapts the operating voltage/frequency, the number of cores, and the workload allocated to the CPU and the GPU in a heterogeneous computing system. This algorithm allows us to maximize the performance under a given power constraint. We also developed various architectures that exploit the similarity of values that are processed by GPUs to further improve performance and energy efficiency while exploiting some unique characteristics of emerging applications running on heterogeneous computing systems. Moreover, we explored a practical but innovative heterogeneous computing architecture that moves computations near the memory considering the bandwidth constraint and energy efficiency, as it becomes more expensive to move data from memory to processors than processing data. This recent work, which significantly improves performance and energy consumption compared to traditional heterogeneous computing systems, has been widely cited by many recently published research papers in very a short time period.\n\nLastly, this project allowed us to support and train graduate students including under-represented ones. They are now working for large companies in the U.S.A. and contributing to developing the next-generation, state-of-the-art computers that will ensure the U.S.A. to maintain the leading position in computing and economy. Besides, the products of this project allowed us to enhance the contents of undergraduate and graduate-level computer architecture courses such that the students can learn state-of-the-art computing technologies and be better prepared for their jobs in industry and academia.\n\n \n\n\t\t\t\t\tLast Modified: 11/29/2016\n\n\t\t\t\t\tSubmitted by: Nam Sung Kim"
 }
}