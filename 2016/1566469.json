{
 "awd_id": "1566469",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: Cyberlearning: Lived Science Narratives: Meaningful Elementary Science through Wearable Technologies",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 174989.0,
 "awd_amount": 190989.0,
 "awd_min_amd_letter_date": "2016-08-23",
 "awd_max_amd_letter_date": "2017-04-30",
 "awd_abstract_narration": "A key goal of the Next Generation Science Standards is to shift the focus of science instruction away from the classroom and out into the world. This research aims to extend what students learn in their science classes beyond the formal context of the school. The project will investigate an approach whereby students will be encouraged to think critically about how science is present and applicable in their daily life experiences through the use of smartwatches. The approach consists of three main parts. First, students will use smartwatches to voice-record observations related to a science topic in their everyday lives. Second, students will be able to reflect on their \"lived science stories\" and edit them into fuller narratives via a web interface, thus contributing to their language arts learning. Third, the students' science stories will be presented to the school teacher via a web application that will help that teacher to diagnose and correct their misconceptions and make science teaching more relevant and meaningful in the classroom. This work could have lasting benefits to society, not only in terms of the support of children's engagement and interest in STEM topics but also in the practice of listening, reading and writing at a critical period of their development.\r\n\r\nA server-based system will be designed that integrates (1) a smartwatch interface for children to audio-record science stories, (2) a web-based storytelling interface to allow them to transcribe and edit their audio story snippets, and (3) a web-based instructional support interface in the form of a curation board that draws together the students' edited science stories for the teacher. The project will employ an iterative design methodology to develop the lived-stories interfaces and test them for usability. A school study will be conducted in two 4th-grade science classes over two science topics at an elementary school with a high percentage of students from populations typically underrepresented in STEM fields. The same science classes will be taught with and without the lived-science narrative technology in a counterbalanced experimental design. Pre-/post-test quizzes, interviews, self-report questionnaires, and video-based analysis will be used to assess whether and how the lived-stories approach may enhance not only students' understanding of science concepts and their motivation to study science but also the teacher's instructional strategies. This project will advance our understanding of how children's narrative way of thinking about their everyday embodied experiences may be used to scaffold their understanding of science concepts gained from formal instruction. The research will also contribute knowledge on the design of novel instructional strategies for elementary science teaching that are anchored in students' personal experiences as well as guidelines and technical frameworks for the design of wearables to support science learning.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Sharon Lynn",
   "pi_last_name": "Chu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Sharon Lynn Chu",
   "pi_email_addr": "s.chuyewyee@ufl.edu",
   "nsf_id": "000679134",
   "pi_start_date": "2016-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Texas A&M University",
  "inst_street_address": "400 HARVEY MITCHELL PKY S STE 300",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE STATION",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "9798626777",
  "inst_zip_code": "778454375",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "TX10",
  "org_lgl_bus_name": "TEXAS A & M UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "JF6XLNB4CDJ5"
 },
 "perf_inst": {
  "perf_inst_name": "Texas A&M University Main Campus",
  "perf_str_addr": "3137 TAMU",
  "perf_city_name": "College Station",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "778433137",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "TX10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  },
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 69530.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 0.0
  }
 ],
 "por": null
}