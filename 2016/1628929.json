{
 "awd_id": "1628929",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "XPS: EXPL: Enabling An Ecosystem of Parallel Programming Abstractions",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927885",
 "po_email": "abanerje@nsf.gov",
 "po_sign_block_name": "Anindya Banerjee",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-12-31",
 "tot_intn_awd_amt": 295821.0,
 "awd_amount": 359821.0,
 "awd_min_amd_letter_date": "2016-07-11",
 "awd_max_amd_letter_date": "2021-08-20",
 "awd_abstract_narration": "All modern computers, from smart phones to supercomputers, have multiple processing units.  Since writing programs that effectively use these resources is notoriously difficult, many programming languages, displaying a wide variety of linguistic abstractions, have been created.  The \"right\" set of abstractions depends on many factors, ranging from the nature of the application at hand, the sophistication of the programmer, and the degree of performance desired and effort required to achieve it.  For this research, the intellectual merits are in the creation of tools and language specifications that support an ecosystem of parallel programming language abstractions.  These are to be developed by independent parties and safely and automatically imported into a programmer's compiler so that programmers can pick and choose the language features that they feel best meet their needs.  The project's broader significance and importance are in a transformative methodology and supporting tools for writing parallel programs, one which dramatically simplifies the development of new parallel programming and domain-specific language features because it allows researchers to focus their efforts on the design and implementation of new abstractions. By making it easier for programmers to use and experiment with new features, distributed as composeable language extensions, they can write performant and correct parallel programs with less effort.\r\n\r\nThe proposed approach will use a specification of the C programming language based on context free grammars (for specifying concrete syntax) and attribute grammars (for specifying semantic analysis, optimization, and code generation). This defines the host language into which parallel programming language extensions are imported.  Language extensions are also specified in these formalisms as they easily compose with the host language and other extensions.  Modular analyses of the language extensions ensure that the composition of the programmer's chosen extensions will be successful and result in a working compiler that will not terminate abnormally. Of interest is the degree to which new and existing language abstractions can be realized in this composable approach to language extension.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Eric",
   "pi_last_name": "Van Wyk",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Eric Van Wyk",
   "pi_email_addr": "evw@umn.edu",
   "nsf_id": "000389599",
   "pi_start_date": "2016-07-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Minnesota-Twin Cities",
  "inst_street_address": "2221 UNIVERSITY AVE SE STE 100",
  "inst_street_address_2": "",
  "inst_city_name": "MINNEAPOLIS",
  "inst_state_code": "MN",
  "inst_state_name": "Minnesota",
  "inst_phone_num": "6126245599",
  "inst_zip_code": "554143074",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MN05",
  "org_lgl_bus_name": "REGENTS OF THE UNIVERSITY OF MINNESOTA",
  "org_prnt_uei_num": "",
  "org_uei_num": "KABJZBBJ4B54"
 },
 "perf_inst": {
  "perf_inst_name": "University of Minnesota-Twin Cities",
  "perf_str_addr": "200 Union Street SE",
  "perf_city_name": "Minneapolis",
  "perf_st_code": "MN",
  "perf_st_name": "Minnesota",
  "perf_zip_code": "554550167",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MN05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  },
  {
   "pgm_ele_code": "828300",
   "pgm_ele_name": "Exploiting Parallel&Scalabilty"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7943",
   "pgm_ref_txt": "PROGRAMMING LANGUAGES"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 295821.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 16000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>For decades there has been significant research in new programming languages and language features to simplify the complex task of writing performant parallel programs. With treads and locks seen as too low-level and error-prone, most of the efforts have focused on higher-level abstractions for specifying and exploiting parallelism. There is a great deal of diversity in these linguistic abstractions, and this diversity reflects the understanding that there is no single \"right\" set of abstractions for all parallel programming tasks. What is \"right\" depends on many factors: the application or problem at hand, sophistication and personal preferences of the programmer, and the degree of performance desired and effort required to achieve it.<br /><br />The central hypothesis of the work carried out for this award was that an extensible language framework in which programmers can pick and choose the parallel programming abstractions that best fit their task at hand has many benefits over traditional approaches. This allows programmers to more easily experiment with and adopt language abstractions for parallel programming. For researchers and language developers it allows them to focus on the parallel programming abstractions without needing to construct an entire general purpose language as a host for their new features. Thus these benefits are reaped by both the programmers and the language abstraction developers. This mutually beneficial system can lead to an ecosystem of abstractions (along with their efficient implementations) that spurs both the adoption and development of the new parallel programming language features that are needed to address the programming requirements driven by modern architectures.<br /><br />Towards these ends the project built upon and improved an extensible specification of C, called ableC, to act as the \"host\" language for parallel programming abstractions. Language extensions to this add new syntactic constructs and new semantic analysis (for example to check for domain-specific) errors.&nbsp; Programmers can then import various extensions into the ableC host language to create a new extended language tailored to their needs.&nbsp; Programs written in an extended language are analyzed to check for errors or optimization opportunities and then translated down to plain C code. From here a traditional C compiler is used to generate an executable program. Additions to ableC include a facility in the host language so that new type qualifiers to variable declarations can be specified in extensions in order to add static and dynamic correctness checks to the generated C code. We developed several such qualifiers as language extensions. For example, a non-null qualifier can be added that inserts checks, both static and dynamic, to ensure that a null pointer is never dereferenced.<br /><br />We also developed ableC Parallel, an ableC extension that provides a common framework which other extensions introducing parallel programming constructs can further extend. This provides syntax for common low-level parallel programming constructs for spawning and synchronizing tasks. Extensions built on top of this can provide different implementations for these constructs. We built, for example, implementations for these constructs that realize threads as POSIX threads, Cilk-like work-stealing threads, and threads from a thread pool. These different extensions provide different performance characteristics for these abstractions, allowing programmers to choose the one best suited to their needs.<br /><br />On top of ableC Parallel, one can build a wide variety of abstractions for parallel programming and we developed several of these. Various incarnations of map-reduce style abstractions were developed. When these extend ableC Parallel, the map-reduce constructs can also specify the implementation of the underlying low-level thread constructs from the implementations described above. A version of the Halide domain-specific language using these constructs was also developed. Another extension provides a type constructor for synchronized types.&nbsp; These behave like regular types except that they provide customizable mechanisms for exclusive access to the values of these types.<br /><br />The end result of ableC, ableC Parallel, and the extensions built on top of these is a system in which programmers can pick the parallel programming abstractions that best suit their needs. This allows them to write programs at a higher level of abstraction yet still control some of the underlying low-level performance characteristics of the chosen language abstracts.<br /><br />This project also trained several graduate students now working in high-performance computing in industry and undergraduate students, some of whom are now enrolled in graduate programs.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/01/2022<br>\n\t\t\t\t\tModified by: Eric&nbsp;Van Wyk</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nFor decades there has been significant research in new programming languages and language features to simplify the complex task of writing performant parallel programs. With treads and locks seen as too low-level and error-prone, most of the efforts have focused on higher-level abstractions for specifying and exploiting parallelism. There is a great deal of diversity in these linguistic abstractions, and this diversity reflects the understanding that there is no single \"right\" set of abstractions for all parallel programming tasks. What is \"right\" depends on many factors: the application or problem at hand, sophistication and personal preferences of the programmer, and the degree of performance desired and effort required to achieve it.\n\nThe central hypothesis of the work carried out for this award was that an extensible language framework in which programmers can pick and choose the parallel programming abstractions that best fit their task at hand has many benefits over traditional approaches. This allows programmers to more easily experiment with and adopt language abstractions for parallel programming. For researchers and language developers it allows them to focus on the parallel programming abstractions without needing to construct an entire general purpose language as a host for their new features. Thus these benefits are reaped by both the programmers and the language abstraction developers. This mutually beneficial system can lead to an ecosystem of abstractions (along with their efficient implementations) that spurs both the adoption and development of the new parallel programming language features that are needed to address the programming requirements driven by modern architectures.\n\nTowards these ends the project built upon and improved an extensible specification of C, called ableC, to act as the \"host\" language for parallel programming abstractions. Language extensions to this add new syntactic constructs and new semantic analysis (for example to check for domain-specific) errors.  Programmers can then import various extensions into the ableC host language to create a new extended language tailored to their needs.  Programs written in an extended language are analyzed to check for errors or optimization opportunities and then translated down to plain C code. From here a traditional C compiler is used to generate an executable program. Additions to ableC include a facility in the host language so that new type qualifiers to variable declarations can be specified in extensions in order to add static and dynamic correctness checks to the generated C code. We developed several such qualifiers as language extensions. For example, a non-null qualifier can be added that inserts checks, both static and dynamic, to ensure that a null pointer is never dereferenced.\n\nWe also developed ableC Parallel, an ableC extension that provides a common framework which other extensions introducing parallel programming constructs can further extend. This provides syntax for common low-level parallel programming constructs for spawning and synchronizing tasks. Extensions built on top of this can provide different implementations for these constructs. We built, for example, implementations for these constructs that realize threads as POSIX threads, Cilk-like work-stealing threads, and threads from a thread pool. These different extensions provide different performance characteristics for these abstractions, allowing programmers to choose the one best suited to their needs.\n\nOn top of ableC Parallel, one can build a wide variety of abstractions for parallel programming and we developed several of these. Various incarnations of map-reduce style abstractions were developed. When these extend ableC Parallel, the map-reduce constructs can also specify the implementation of the underlying low-level thread constructs from the implementations described above. A version of the Halide domain-specific language using these constructs was also developed. Another extension provides a type constructor for synchronized types.  These behave like regular types except that they provide customizable mechanisms for exclusive access to the values of these types.\n\nThe end result of ableC, ableC Parallel, and the extensions built on top of these is a system in which programmers can pick the parallel programming abstractions that best suit their needs. This allows them to write programs at a higher level of abstraction yet still control some of the underlying low-level performance characteristics of the chosen language abstracts.\n\nThis project also trained several graduate students now working in high-performance computing in industry and undergraduate students, some of whom are now enrolled in graduate programs.\n\n\t\t\t\t\tLast Modified: 05/01/2022\n\n\t\t\t\t\tSubmitted by: Eric Van Wyk"
 }
}