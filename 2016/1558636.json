{
 "awd_id": "1558636",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Inference Methods for Machine Learning and High-Dimensional Data in Policy Evaluation and Structural Economic Models",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927280",
 "po_email": "nlutz@nsf.gov",
 "po_sign_block_name": "Nancy Lutz",
 "awd_eff_date": "2016-05-15",
 "awd_exp_date": "2019-04-30",
 "tot_intn_awd_amt": 191462.0,
 "awd_amount": 191462.0,
 "awd_min_amd_letter_date": "2016-05-03",
 "awd_max_amd_letter_date": "2016-05-03",
 "awd_abstract_narration": "Much of empirical economics focuses on estimating and drawing credible inferences about the causal effects of economic policies or about features of underlying economic models such as elasticities.  The type of data that researchers have at their disposal to aid in this task is increasingly rich and complex.  While these increased data resources open up many new opportunities, they also pose additional challenges as researchers must employ data-reduction techniques - for example, techniques from the analysis of \"big data\" - to make analyzing complex data and models feasible and informative, and na\u00efve application of such techniques may render conclusions drawn about economic effects invalid.  This research project will establish a general, formal framework to provide guidance about construction of estimation and inference devices coupled with appropriate use of tools from \"big data\" or data-mining that will deliver reliable conclusions about economic objects of interest.  The proposed research will present the methods and corresponding theoretic guarantees to cover a variety of situations encountered in empirical research in economics and the social sciences, offer empirical applications, and provide usable software in statistical packages popular within the social sciences.  The theoretical and empirical work will thus help bridge the gap between social science practice and \"big data\", and will provide methods that will enhance the credibility of the drawn scientific conclusions.  \r\n\r\nThe proposed research will provide bridges between high-dimensional statistical modeling and applied social science research.  Integrating high-dimensional methods with economically relevant modeling frameworks and targets is important in providing researchers tools which can be used to analyze modern, complex data and provide reliable inferential statements about the objects of interest.  The proposed research will advance the theory of inference following regularization which is a key element to inference in modern, large data sets.  The main goal of this research project is to generalize available results about inference for a low-dimensional target parameter of interest by providing an encompassing framework that will include interesting nonlinear models and estimation procedures such as maximum likelihood and generalized method of moments.  We will also provide an extension to cover cases where the target of interest is function valued, such as when interest is in a set quantile treatment effects across a range of quantile indices.  This advancement will expand the frontier for applications of high-dimensional methods in applications where inference about sets of model parameters is the goal.  This expansion is useful even in low-dimensional models and is likely to become crucial as large, complicated data sets become more readily available.  In addition to providing theoretical results, the research aims to provide illustrative empirical examples and software in both R and Stata for application of these methods.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Christian",
   "pi_last_name": "Hansen",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Christian Hansen",
   "pi_email_addr": "christian.hansen@chicagobooth.edu",
   "nsf_id": "000700067",
   "pi_start_date": "2016-05-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Chicago",
  "inst_street_address": "5801 S ELLIS AVE",
  "inst_street_address_2": "",
  "inst_city_name": "CHICAGO",
  "inst_state_code": "IL",
  "inst_state_name": "Illinois",
  "inst_phone_num": "7737028669",
  "inst_zip_code": "606375418",
  "inst_country_name": "United States",
  "cong_dist_code": "01",
  "st_cong_dist_code": "IL01",
  "org_lgl_bus_name": "UNIVERSITY OF CHICAGO",
  "org_prnt_uei_num": "ZUE9HKT2CLC9",
  "org_uei_num": "ZUE9HKT2CLC9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Chicago",
  "perf_str_addr": "5807 South Woodlawn Avenue",
  "perf_city_name": "Chicago",
  "perf_st_code": "IL",
  "perf_st_name": "Illinois",
  "perf_zip_code": "606371610",
  "perf_ctry_code": "US",
  "perf_cong_dist": "01",
  "perf_st_cong_dist": "IL01",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132000",
   "pgm_ele_name": "Economics"
  },
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1320",
   "pgm_ref_txt": "ECONOMICS"
  },
  {
   "pgm_ref_code": "1333",
   "pgm_ref_txt": "METHOD, MEASURE & STATS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 191462.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The focus of this project was in providing methods that supply formally correct statistical inferential statements about a small set of pre-specified objects of interest, such as the average effect of some treatment, in an environment where high-dimensional estimation (e.g. machine learning) is be applied as part of the estimation process. Such problems are common, for example, in policy evaluation and structural estimation in economics.</p>\n<p>The project contributed toward expanding the theoretical understanding of the statistical properties of estimators of scientifically pre-specified targets of interest when high-dimensional estimation algorithms are used as part of the estimation procedure. During the course of the project, several research papers were produced and published and the co-PIs presented related work in a variety of academic and non-academic settings.</p>\n<p>Notable among the theoretical contributions is a general procedure that relies on appropriate use of sample splitting and careful construction of estimating equations. The approach is applicable in many leading cases and (semi-parametrically) efficient. Imprtantly, valid statistical inference is easily provided for the resulting estimator while allowing for a wide variety of machine learning estimators to be used as inputs in the construction of the estimator.</p>\n<p>Code for R and Stata implementing procedures developed as part of the project in leading cases have been developed. The code is available from the PI as well as through R (CRAN) and Stata.</p>\n<p>In addition to these contributions, the grant provided partial funding for three research assistants working with this PI.&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 05/07/2019<br>\n\t\t\t\t\tModified by: Christian&nbsp;Hansen</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe focus of this project was in providing methods that supply formally correct statistical inferential statements about a small set of pre-specified objects of interest, such as the average effect of some treatment, in an environment where high-dimensional estimation (e.g. machine learning) is be applied as part of the estimation process. Such problems are common, for example, in policy evaluation and structural estimation in economics.\n\nThe project contributed toward expanding the theoretical understanding of the statistical properties of estimators of scientifically pre-specified targets of interest when high-dimensional estimation algorithms are used as part of the estimation procedure. During the course of the project, several research papers were produced and published and the co-PIs presented related work in a variety of academic and non-academic settings.\n\nNotable among the theoretical contributions is a general procedure that relies on appropriate use of sample splitting and careful construction of estimating equations. The approach is applicable in many leading cases and (semi-parametrically) efficient. Imprtantly, valid statistical inference is easily provided for the resulting estimator while allowing for a wide variety of machine learning estimators to be used as inputs in the construction of the estimator.\n\nCode for R and Stata implementing procedures developed as part of the project in leading cases have been developed. The code is available from the PI as well as through R (CRAN) and Stata.\n\nIn addition to these contributions, the grant provided partial funding for three research assistants working with this PI. \n\n \n\n\t\t\t\t\tLast Modified: 05/07/2019\n\n\t\t\t\t\tSubmitted by: Christian Hansen"
 }
}