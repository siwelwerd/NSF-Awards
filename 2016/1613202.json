{
 "awd_id": "1613202",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Adaptive Thresholding for Hierarchical Clustering of Variables, with Connections to Scan Statistics",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Pena Edsel",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2020-07-31",
 "tot_intn_awd_amt": 150000.0,
 "awd_amount": 150000.0,
 "awd_min_amd_letter_date": "2016-08-01",
 "awd_max_amd_letter_date": "2018-08-13",
 "awd_abstract_narration": "In modern data analysis with large data sets, a common goal is to detect groups of variables that exhibit similar behavior.  This task is usually referred to as clustering.  In genetics and proteomics, for instance, clustering can reveal structures of scientific interest, such as potential biological pathways.  On top of detecting scientifically relevant structure in the data, clustering can also be used to simplify data representations and analysis.  One of the most widely used approaches to clustering is called hierarchical clustering.  In hierarchical clustering, a measure of similarity, like correlation, is computed between each pair of variables, and then similar groups of variables are repeatedly merged.  This leads to a fundamental question: how much grouping should be done?  The proposed research consists of several projects aimed at developing broadly applicable methods for determining the appropriate amount of clustering, based on the degree of similarity present in the data.  The resulting procedures will also provide statistical guarantees on the meaning of the resulting groups.\r\n\r\nThis proposal aims to develop practical procedures for adaptive thresholding of hierarchical clustering dendrograms, when applied to pairwise similarities of variables.  These procedures will be connected to inferential guarantees about the false cluster error rate of the resulting clustering.  The results will target a range of common linkages and variable similarity measures.  The PI will also demonstrate these procedures in a modern genetics application.To support these procedures, new theory will be developed describing the large order statistics of variable similarity measures, including new asymptotic bounds on their joint distributions and new finite-sample bounds on their maxima.  The techniques proposed here will also have application to other threshold-based procedures in statistics; in particular, connections may be made between the proposed work and adaptive thresholding procedures for scan statistics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Max",
   "pi_last_name": "G'Sell",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Max G'Sell",
   "pi_email_addr": "mgsell@andrew.cmu.edu",
   "nsf_id": "000682802",
   "pi_start_date": "2016-08-01",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "5000 Forbes Avenue",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133890",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "126900",
   "pgm_ele_name": "STATISTICS"
  }
 ],
 "pgm_ref": null,
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 24556.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 72806.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 52638.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This grant supported the development of a variety of new statistical methods for statistical inference after model selection in the presence of dependence structure.&nbsp; The results spanned the range from the development of new statistical theory and statistical methology, to the application of novel statistical methodology to cutting-edge applied scientific problems in genetics and cellular biology. &nbsp;<br /><br />In terms of new statistical theory and methodolgy, we developed new selective inference tools for conducting valid statistical testing of jumps in a sequence, conditional on the selection of those jumps by popular changepoint detection methods.&nbsp;&nbsp; As part of this work, we developed similar methodology for testing hypotheses generated by the solutions to generalized lasso problems.&nbsp; This captures a range of popular estimation methods, including the graph fused lasso (used to estimate connected components of a graph on which a function is constant) and trend filtering (used to approximate a signal by a function with piecewise-constant k-th derivatives).&nbsp; Along with providing new methodology, these works both offered practical advice for the application of these approaches.<br /><br />In contrast to the above work, which relies on reasonably strong distributional assumptions, we also developed new methodology and theory for conducting inference under weak assumptions and with misspecified models.&nbsp; The first of these works focused on obtaining inference about model predictions, even when the models are not accurate reflections of the data.&nbsp; This is important in real applications of machine learning, where we do not believe strong assumptions about the correctness of the model.&nbsp; The second work focused on the special case of linear regression, and provided novel theoretical results to understand and improve the accuracy of inference when the linear model is not actually correct.&nbsp; Together, this pair of papers give insight into different statistical approaches to understanding inference and uncertainty when the true models and data generating distributions are unknown.<br /><br />In collaboration with Kathryn Roeder and Bernie Devlin, we carefully adapted and applied selective inference methods to large-scale multiple testing problems in genetics, with a focus on psychiatric disorders.&nbsp; These are particularly challenging associations to detect, because the signal tends to be weak and diffuse.&nbsp; We developed novel statistical approaches to leverage side-information about particular genes or single-nucleotide polymorphisms (SNPs) through predictive modeling, dramatically boosting power to discover new genetic associations.&nbsp; These methods included a novel hypothesis clustering approach to reduce dependence between hypotheses and improve the interpretability and reliablity of the resulting inference.<br /><br />In the course of our genetics work, we also discovered that the most popular software for constructing gene and gene-set test statistics, MAGMA, was fundamentally flawed in its statistical construction.&nbsp; This software aimed to account for dependence between statistical tests of individual SNP associations to construct a single, valid test of a group of SNPs, and was cited in over 800 papers at the time of our work.&nbsp; However, the correction for dependence in MAGMA was incorrect in a way that was dramatically amplified when the resulting tests were incorporated into false discovery rate controlling methods.&nbsp; Our publication resulted in a correction to the MAGMA software by the authors, helping to improve future scientific studies.<br /><br />Finally, toward the end of the project, we launched a new branch of research that combines many of the themes above.&nbsp; Inspired by cellular transport experiments, we became interested in making statistical inference about label-shift changes in the distribution of data in classification problems.&nbsp; Label shift occurs when the prevalence of classes changes in a classification problem, but the appearance of observations from each class stays the same.&nbsp; Disease outbreak provides one classic example, where the symptoms of a disease may not change during an outbreak, but the fraction of cases could shift considerably, changing the posterior probabilities of disease produced by a model.&nbsp; We developed a new, nonparametric changepoint method for rapid detection of these changes, based on shifts in scores from classification models, and proved that the method was asymptotically optimal.<br /><br />This grant provided educational opportunities for three doctoral students and partial support for two of them.&nbsp; All of these students have since graduated and continuted their careers in academia as statistics faculty members.&nbsp; The research projects themselves were also used as examples in my courses on statistical machine learning at the undergraduate and masters levels.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/19/2022<br>\n\t\t\t\t\tModified by: Max&nbsp;G'sell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis grant supported the development of a variety of new statistical methods for statistical inference after model selection in the presence of dependence structure.  The results spanned the range from the development of new statistical theory and statistical methology, to the application of novel statistical methodology to cutting-edge applied scientific problems in genetics and cellular biology.  \n\nIn terms of new statistical theory and methodolgy, we developed new selective inference tools for conducting valid statistical testing of jumps in a sequence, conditional on the selection of those jumps by popular changepoint detection methods.   As part of this work, we developed similar methodology for testing hypotheses generated by the solutions to generalized lasso problems.  This captures a range of popular estimation methods, including the graph fused lasso (used to estimate connected components of a graph on which a function is constant) and trend filtering (used to approximate a signal by a function with piecewise-constant k-th derivatives).  Along with providing new methodology, these works both offered practical advice for the application of these approaches.\n\nIn contrast to the above work, which relies on reasonably strong distributional assumptions, we also developed new methodology and theory for conducting inference under weak assumptions and with misspecified models.  The first of these works focused on obtaining inference about model predictions, even when the models are not accurate reflections of the data.  This is important in real applications of machine learning, where we do not believe strong assumptions about the correctness of the model.  The second work focused on the special case of linear regression, and provided novel theoretical results to understand and improve the accuracy of inference when the linear model is not actually correct.  Together, this pair of papers give insight into different statistical approaches to understanding inference and uncertainty when the true models and data generating distributions are unknown.\n\nIn collaboration with Kathryn Roeder and Bernie Devlin, we carefully adapted and applied selective inference methods to large-scale multiple testing problems in genetics, with a focus on psychiatric disorders.  These are particularly challenging associations to detect, because the signal tends to be weak and diffuse.  We developed novel statistical approaches to leverage side-information about particular genes or single-nucleotide polymorphisms (SNPs) through predictive modeling, dramatically boosting power to discover new genetic associations.  These methods included a novel hypothesis clustering approach to reduce dependence between hypotheses and improve the interpretability and reliablity of the resulting inference.\n\nIn the course of our genetics work, we also discovered that the most popular software for constructing gene and gene-set test statistics, MAGMA, was fundamentally flawed in its statistical construction.  This software aimed to account for dependence between statistical tests of individual SNP associations to construct a single, valid test of a group of SNPs, and was cited in over 800 papers at the time of our work.  However, the correction for dependence in MAGMA was incorrect in a way that was dramatically amplified when the resulting tests were incorporated into false discovery rate controlling methods.  Our publication resulted in a correction to the MAGMA software by the authors, helping to improve future scientific studies.\n\nFinally, toward the end of the project, we launched a new branch of research that combines many of the themes above.  Inspired by cellular transport experiments, we became interested in making statistical inference about label-shift changes in the distribution of data in classification problems.  Label shift occurs when the prevalence of classes changes in a classification problem, but the appearance of observations from each class stays the same.  Disease outbreak provides one classic example, where the symptoms of a disease may not change during an outbreak, but the fraction of cases could shift considerably, changing the posterior probabilities of disease produced by a model.  We developed a new, nonparametric changepoint method for rapid detection of these changes, based on shifts in scores from classification models, and proved that the method was asymptotically optimal.\n\nThis grant provided educational opportunities for three doctoral students and partial support for two of them.  All of these students have since graduated and continuted their careers in academia as statistics faculty members.  The research projects themselves were also used as examples in my courses on statistical machine learning at the undergraduate and masters levels.\n\n\t\t\t\t\tLast Modified: 10/19/2022\n\n\t\t\t\t\tSubmitted by: Max G'sell"
 }
}