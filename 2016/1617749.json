{
 "awd_id": "1617749",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "SHF: Small: Virtualization of Heterogeneous and Non-Uniform Memory Hierarchy",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2022-01-31",
 "tot_intn_awd_amt": 297664.0,
 "awd_amount": 313264.0,
 "awd_min_amd_letter_date": "2016-07-27",
 "awd_max_amd_letter_date": "2020-12-11",
 "awd_abstract_narration": "Hardware memory devices are hierarchically structured and increasingly heterogeneous (in terms of volatility, energy efficiency, and reliability) and non-uniform (in terms of latency and bandwidth). However, existing memory virtualization technology only provides each virtual machine with a flat, homogeneous, and uniform memory space, which is an opaque and distorted abstraction of hardware memory resources.  This abstraction poses great challenges for applications in virtual machines to make efficient utilization of memory resources. Cloud computing platforms and other virtualized platforms form the backbone of the modern computing infrastructures used by industry, military, academia, and the wider population. The project substantially improves memory virtualization technology, so that applications on these platforms can fully leverage the heterogeneity, non-uniformity, and other features of hardware memory resources to improve performance, energy efficiency, and reliability. The project involves undergraduate and graduate students to work with virtualization and the cloud. This will provide them with strong programming and system capabilities to work in the cloud computing industry.\r\n\r\nThe project explores novel memory virtualization techniques to provide each virtual machine with a complete virtual memory hierarchy that consists of virtual cache devices and heterogeneous virtual memory devices. The virtual memory hierarchy effectively serves as an expressive interface between a virtual machine and the virtual machine monitor. For a virtual machine, it faithfully reflects the features and architectures of underlying hardware memory resources, based on which memory-aware and cache-aware optimization techniques can be effectively applied. For the virtual machine monitor, the usage of virtual devices reflects the demand of the workload on a virtual machine for different types of memory resources, based on which the sharing of memory resources can be well coordinated. The investigation focuses on 1) the software framework and critical hardware support that can build virtual devices in virtual memory hierarchy on top of diverse types of hardware memory devices and maintain their features and structures with low cost; 2) the techniques to efficiently share different types of memory resources between virtual machines; and 3) validating existing cache-aware and memory-aware techniques on virtual memory hierarchy. To spur the dissemination of results, the expected framework and techniques will be built into Linux OS and virtual machine monitor such as Kernel-based Virtual Machine (KVM), and be open to the community for sharing.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Xiaoning",
   "pi_last_name": "Ding",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Xiaoning Ding",
   "pi_email_addr": "xiaoning.ding@njit.edu",
   "nsf_id": "000636718",
   "pi_start_date": "2016-07-27",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "New Jersey Institute of Technology",
  "inst_street_address": "323 DR MARTIN LUTHER KING JR BLVD",
  "inst_street_address_2": "",
  "inst_city_name": "NEWARK",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "9735965275",
  "inst_zip_code": "071021824",
  "inst_country_name": "United States",
  "cong_dist_code": "10",
  "st_cong_dist_code": "NJ10",
  "org_lgl_bus_name": "NEW JERSEY INSTITUTE OF TECHNOLOGY",
  "org_prnt_uei_num": "",
  "org_uei_num": "SGBMHQ7VXNH5"
 },
 "perf_inst": {
  "perf_inst_name": "New Jersey Institute of Technology",
  "perf_str_addr": "323 DOCTOR MARTIN LUTHER",
  "perf_city_name": "Newark",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "071021982",
  "perf_ctry_code": "US",
  "perf_cong_dist": "10",
  "perf_st_cong_dist": "NJ10",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  },
  {
   "pgm_ref_code": "7941",
   "pgm_ref_txt": "COMPUTER ARCHITECTURE"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 297664.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 15600.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project improved the performance of data-intensive applications in clouds. It enhanced virtualization technology to accelerate data accesses of the applications running on virtual machines. To effectively accelerate data accesses, the project focused on the key system components in the memory hierarch, such as caches and translation lookaside buffers (TLBs), which play critical roles in accelerating data accesses, investigated how virtualization affects their effectiveness, and designed novel techniques to fully leverage these components to achieve fast data movements through memory hierarch.</p>\n<p>The novel research outcomes cover three main aspects of data accesses, which were not efficiently handled previously in virtualization: 1) memory address translation; 2) CPU caches for the data accesses to main memory; and 3) generating and processing I/O requests for the data accesses to storage. Specifically, the project designed, built, and evaluated the following system solutions in the virtualization of memory hierarch:</p>\n<p>* Gemini, a cross-layer page coalescing mechanism for virtualized systems, to make best utilization of TLBs in accelerating memory address translations. &nbsp;</p>\n<p>* Coplace, a page placement mechanism with low overhead and high portability for virtualized clouds, to effectively reduce conflicts in CPU caches.</p>\n<p>* Ptlbmalloc2, a novel memory allocator, to substantially reduce the overhead caused by TLB Shootdowns on virtualized multicore systems.</p>\n<p>* vSMT-IO, a scheduling framework customized for Simultaneous Multi-Threading (SMT) processors, to process storage I/O requests with high performance and high efficiency to accelerate data accesses to storages in virtualized clouds.</p>\n<p>* vMigrater, a user-level software utility, to effectively mitigate I/O inactivity problem caused by virtualization that may significantly slow down I/O request generation and reduce data access speed.&nbsp;&nbsp;</p>\n<p>In addition, the project performed a quantitative study of virtualization overhead for multi-threaded computation-intensive workloads. In the study, the performance limiting factors besides data movements in memory hierarchy were investigated on virtualized platforms based on controlled experiments. These factors include synchronizations, system timers, etc. Based on the study, paratick, a virtual scheduler tick mechanism, was designed and implemented in Linux/KVM, to reduce timer overhead in virtual machines; and a polling-then-blocking CPU-GPU synchronization primitive was proposed and evaluated to reduce the delay caused by CPU-GPU synchronizations on virtualized systems and improve the computation throughputs.</p>\n<p>The results of this research have been widely disseminated in over 20 papers published in top conferences and journals, including USENIX ATC, PACT, and IEEE TPDS.</p>\n<p>This project provided training and exposure to state-of-the-art research in computer systems and cloud computing to 10 students (4 Ph.D. students and 6 undergraduate students). Two of these students have already graduated with Ph.D. degrees on topics directly related to this project, and another one is graduating soon. 3 of the undergraduate students have been admitted by PHD programs after their graduation.</p>\n<p>The project also allowed the team to start international collaborations with researchers from Hong Kong and Belgium. In addition, the team has been involved with the broader international research community in several leadership positions in the organization of IEEE Cloud Summit.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 06/11/2022<br>\n\t\t\t\t\tModified by: Xiaoning&nbsp;Ding</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project improved the performance of data-intensive applications in clouds. It enhanced virtualization technology to accelerate data accesses of the applications running on virtual machines. To effectively accelerate data accesses, the project focused on the key system components in the memory hierarch, such as caches and translation lookaside buffers (TLBs), which play critical roles in accelerating data accesses, investigated how virtualization affects their effectiveness, and designed novel techniques to fully leverage these components to achieve fast data movements through memory hierarch.\n\nThe novel research outcomes cover three main aspects of data accesses, which were not efficiently handled previously in virtualization: 1) memory address translation; 2) CPU caches for the data accesses to main memory; and 3) generating and processing I/O requests for the data accesses to storage. Specifically, the project designed, built, and evaluated the following system solutions in the virtualization of memory hierarch:\n\n* Gemini, a cross-layer page coalescing mechanism for virtualized systems, to make best utilization of TLBs in accelerating memory address translations.  \n\n* Coplace, a page placement mechanism with low overhead and high portability for virtualized clouds, to effectively reduce conflicts in CPU caches.\n\n* Ptlbmalloc2, a novel memory allocator, to substantially reduce the overhead caused by TLB Shootdowns on virtualized multicore systems.\n\n* vSMT-IO, a scheduling framework customized for Simultaneous Multi-Threading (SMT) processors, to process storage I/O requests with high performance and high efficiency to accelerate data accesses to storages in virtualized clouds.\n\n* vMigrater, a user-level software utility, to effectively mitigate I/O inactivity problem caused by virtualization that may significantly slow down I/O request generation and reduce data access speed.  \n\nIn addition, the project performed a quantitative study of virtualization overhead for multi-threaded computation-intensive workloads. In the study, the performance limiting factors besides data movements in memory hierarchy were investigated on virtualized platforms based on controlled experiments. These factors include synchronizations, system timers, etc. Based on the study, paratick, a virtual scheduler tick mechanism, was designed and implemented in Linux/KVM, to reduce timer overhead in virtual machines; and a polling-then-blocking CPU-GPU synchronization primitive was proposed and evaluated to reduce the delay caused by CPU-GPU synchronizations on virtualized systems and improve the computation throughputs.\n\nThe results of this research have been widely disseminated in over 20 papers published in top conferences and journals, including USENIX ATC, PACT, and IEEE TPDS.\n\nThis project provided training and exposure to state-of-the-art research in computer systems and cloud computing to 10 students (4 Ph.D. students and 6 undergraduate students). Two of these students have already graduated with Ph.D. degrees on topics directly related to this project, and another one is graduating soon. 3 of the undergraduate students have been admitted by PHD programs after their graduation.\n\nThe project also allowed the team to start international collaborations with researchers from Hong Kong and Belgium. In addition, the team has been involved with the broader international research community in several leadership positions in the organization of IEEE Cloud Summit.\n\n \n\n\t\t\t\t\tLast Modified: 06/11/2022\n\n\t\t\t\t\tSubmitted by: Xiaoning Ding"
 }
}