{
 "awd_id": "1626655",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "MRI: Acquisition of Dynamic Immersive Virtual Environment for Research in Human-Machine Interaction",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Joanne Culbertson",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2019-08-31",
 "tot_intn_awd_amt": 381075.0,
 "awd_amount": 381075.0,
 "awd_min_amd_letter_date": "2016-08-09",
 "awd_max_amd_letter_date": "2016-08-09",
 "awd_abstract_narration": "This Major Research Instrumentation Award supports the acquisition of an immersive virtual reality (VR) environment with synchronized full-body motion tracking system to facilitate interdisciplinary research in human-machine interactions and enhanced teaching and student research training. This room-size virtual reality system provides multiple computer-generated displays that allow users to fully immerse and collaboratively interact with the simulated environment in real-time while the motion tracking system captures the user's physical movements. The VR system will enable several research studies across multiple disciplines to gain a better understanding of human-machine interactions and human motor skills and learning. This will lead to the development of technologies that enhance human mobility and function and foster collaborative operations between robots and humans. The research activities envisioned to be impacted by the acquisition of this system include those in rehabilitation, sports training, advanced manufacturing, and design of human-machine interfaces such as intelligent cockpits. The activities have a strong potential for technology transfer that can directly improve the quality of life for individuals in the community. Additionally, the instrumentation will provide an attractive resource for several outreach activities to motivate students to pursue a college career in STEM disciplines. \r\n\r\nThe instrument is a turnkey, well-integrated CAVE virtual reality environment with a four-wall projection system, eight-camera real-time motion capture system with finger tracking capability, and a control software suite for customized software development and additional hardware integration.  The instrumentation will enable fundamental research activities in several key areas.  Researchers will investigate interaction models between humans and robots in a dynamic environment to develop effective control strategies for human-robot collaboration.  Additional projects will study human perception, biomechanics of human movement under various stimuli, and development of assistive technologies and training protocols to enhance motor skills and learning. The instrumentation will also enable researchers to develop models and evaluation metrics for human interactions in complex environments that include multisensory feedback, perturbations, advanced modes of display, and multiple users. The VR system provides a cost-effective design solution that can be adapted, utilized, and evaluated to fit the needs of different projects that require a rich visual display that captures the dynamic variation in the real world.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Panadda",
   "pi_last_name": "Marayong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Panadda Marayong",
   "pi_email_addr": "panadda.marayong@csulb.edu",
   "nsf_id": "000504832",
   "pi_start_date": "2016-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Praveen",
   "pi_last_name": "Shankar",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Praveen Shankar",
   "pi_email_addr": "praveen.shankar@csulb.edu",
   "nsf_id": "000612363",
   "pi_start_date": "2016-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Emel",
   "pi_last_name": "Demircan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Emel Demircan",
   "pi_email_addr": "Emel.Demircan@csulb.edu",
   "nsf_id": "000707481",
   "pi_start_date": "2016-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Vennila",
   "pi_last_name": "Krishnan",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Vennila Krishnan",
   "pi_email_addr": "Vennila.krishnan@csulb.edu",
   "nsf_id": "000707483",
   "pi_start_date": "2016-08-09",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Will",
   "pi_last_name": "Wu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Will Wu",
   "pi_email_addr": "will.wu@csulb.edu",
   "nsf_id": "000715764",
   "pi_start_date": "2016-08-09",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "California State University-Long Beach Foundation",
  "inst_street_address": "6300 E STATE UNIVERSITY DR STE 332",
  "inst_street_address_2": "",
  "inst_city_name": "LONG BEACH",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "5629858051",
  "inst_zip_code": "908154670",
  "inst_country_name": "United States",
  "cong_dist_code": "42",
  "st_cong_dist_code": "CA42",
  "org_lgl_bus_name": "CALIFORNIA STATE UNIVERSITY LONG BEACH RESEARCH FOUNDATION",
  "org_prnt_uei_num": "",
  "org_uei_num": "P2TDH1JCJD31"
 },
 "perf_inst": {
  "perf_inst_name": "California State University-Long Beach",
  "perf_str_addr": "1250 Bellflower Blvd",
  "perf_city_name": "Long Beach",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "908400004",
  "perf_ctry_code": "US",
  "perf_cong_dist": "42",
  "perf_st_cong_dist": "CA42",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "118900",
   "pgm_ele_name": "Major Research Instrumentation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 381075.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>California State University, Long Beach (CSULB) acquired a Cave Automatic Virtual Environment (CAVE) system through the funding support from the National Science Foundation Major Research Instrumentation Program. The CAVE system provides an immersive room-sized virtual environment with synchronized full-body motion tracking capabilities. The acquired system is the VisCube<sup>TM</sup> M4 CAVE Immersive 3D Display (Visbox, Inc., IL), which includes a four-wall projection system covering an approximate volume of 12.5ft W x 8ft D x 9ft H, eight-camera real-time motion capture system (Advanced Realtime Tracking (ART) GmbH, Germany), and a control software suite that allows customized software development and additional hardware integration. The use of virtual reality (VR) provides a cost-effective design solution that can be customized for different applications. Additional input devices, including programmable haptic flight control joystick and driving steering wheel, have been integrated to enhance the capabilities of original system. Since the acquisition of the system, multiple VR environments have been created, such as an Urban Air Mobility (UAM) testbed for the city of San Francisco for research in human-automation teaming in unmanned aerial systems, a virtual rehabilitation clinic, and a driving simulator for human factors research. The system provides an important infrastructure to support interdisciplinary research relating to human-automation teaming and human-machine interactions and has enabled new research activities, teaching opportunities, and student research training at CSULB.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 11/18/2019<br>\n\t\t\t\t\tModified by: Panadda&nbsp;Marayong</p>\n</div>\n<div class=\"porSideCol\">\n<div class=\"each-gallery\">\n<div class=\"galContent\" id=\"gallery0\">\n<div class=\"photoCount\" id=\"photoCount0\">\n\t\t\t\t\t\t\t\t\tImage\n\t\t\t\t\t\t\t\t</div>\n<div class=\"galControls onePhoto\" id=\"controls0\"></div>\n<div class=\"galSlideshow\" id=\"slideshow0\"></div>\n<div class=\"galEmbox\" id=\"embox\">\n<div class=\"image-title\"></div>\n</div>\n</div>\n<div class=\"galNavigation onePhoto\" id=\"navigation0\">\n<ul class=\"thumbs\" id=\"thumbs0\">\n<li>\n<a href=\"/por/images/Reports/POR/2019/1626655/1626655_10448570_1574099219098_CSULB_CAVE--rgov-214x142.jpg\" original=\"/por/images/Reports/POR/2019/1626655/1626655_10448570_1574099219098_CSULB_CAVE--rgov-800width.jpg\" title=\"BeachCAVE virtual reality system\"><img src=\"/por/images/Reports/POR/2019/1626655/1626655_10448570_1574099219098_CSULB_CAVE--rgov-66x44.jpg\" alt=\"BeachCAVE virtual reality system\"></a>\n<div class=\"imageCaptionContainer\">\n<div class=\"imageCaption\">CAVE virtual reality system at California State University, Long Beach</div>\n<div class=\"imageCredit\">MAE Department, CSU Long Beach</div>\n<div class=\"imagePermisssions\">Copyrighted</div>\n<div class=\"imageSubmitted\">Panadda&nbsp;Marayong</div>\n<div class=\"imageTitle\">BeachCAVE virtual reality system</div>\n</div>\n</li>\n</ul>\n</div>\n</div>\n</div>\n</div>",
  "por_txt_cntn": "\nCalifornia State University, Long Beach (CSULB) acquired a Cave Automatic Virtual Environment (CAVE) system through the funding support from the National Science Foundation Major Research Instrumentation Program. The CAVE system provides an immersive room-sized virtual environment with synchronized full-body motion tracking capabilities. The acquired system is the VisCubeTM M4 CAVE Immersive 3D Display (Visbox, Inc., IL), which includes a four-wall projection system covering an approximate volume of 12.5ft W x 8ft D x 9ft H, eight-camera real-time motion capture system (Advanced Realtime Tracking (ART) GmbH, Germany), and a control software suite that allows customized software development and additional hardware integration. The use of virtual reality (VR) provides a cost-effective design solution that can be customized for different applications. Additional input devices, including programmable haptic flight control joystick and driving steering wheel, have been integrated to enhance the capabilities of original system. Since the acquisition of the system, multiple VR environments have been created, such as an Urban Air Mobility (UAM) testbed for the city of San Francisco for research in human-automation teaming in unmanned aerial systems, a virtual rehabilitation clinic, and a driving simulator for human factors research. The system provides an important infrastructure to support interdisciplinary research relating to human-automation teaming and human-machine interactions and has enabled new research activities, teaching opportunities, and student research training at CSULB.\n\n\t\t\t\t\tLast Modified: 11/18/2019\n\n\t\t\t\t\tSubmitted by: Panadda Marayong"
 }
}