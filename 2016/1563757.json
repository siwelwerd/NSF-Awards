{
 "awd_id": "1563757",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "AF: Medium: Collaborative Research: The Power of Randomness for Approximate Counting",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "A. Funda Ergun",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 399999.0,
 "awd_amount": 415999.0,
 "awd_min_amd_letter_date": "2016-04-21",
 "awd_max_amd_letter_date": "2020-07-22",
 "awd_abstract_narration": "The study of the complexity of counting problems has a long and rich history in theoretical computer science. Counting problems (and closely related sampling problems) arise naturally in many different fields, for example in statistical physics they correspond to partition functions and for studies of the equilibrium states of idealized models of physical systems, and in Bayesian inference they arise for the study of posterior distributions or maximum likelihood distributions. The specific questions addressed here are long-standing open problems, progress on which will be of wide interest. The project will develop new tools for approximate counting and is likely to make new and useful connections between statistical physics, probability and computational complexity. The research results will be disseminated via course notes, a summer school and workshops. Any practical algorithms that result will be made publicly available.\r\n\r\nThe overall goal of the project is to extend the known boundary of polynomial-time tractability for counting problems, to understand whether randomness is essential and how it could be eliminated, and to push the limits of the current fastest randomized algorithms towards practicality. Specific aims include: (1) Polynomial-time randomized approximation schemes for some fundamental problems that have thus far eluded efficient solutions, (2) Deterministic polynomial-time approximation schemes for some central problems that have celebrated randomized algorithms and (3) Faster randomized algorithms for classical counting problems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Daniel",
   "pi_last_name": "Stefankovic",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Daniel Stefankovic",
   "pi_email_addr": "stefanko@cs.rochester.edu",
   "nsf_id": "000314308",
   "pi_start_date": "2016-04-21",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Rochester",
  "inst_street_address": "910 GENESEE ST",
  "inst_street_address_2": "STE 200",
  "inst_city_name": "ROCHESTER",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "5852754031",
  "inst_zip_code": "146113847",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "NY25",
  "org_lgl_bus_name": "UNIVERSITY OF ROCHESTER",
  "org_prnt_uei_num": "",
  "org_uei_num": "F27KDXZMF9Y8"
 },
 "perf_inst": {
  "perf_inst_name": "University of Rochester",
  "perf_str_addr": "518 Hylan",
  "perf_city_name": "Rochester",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "146270140",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "NY25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "287800",
   "pgm_ele_name": "Special Projects - CCF"
  },
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7924",
   "pgm_ref_txt": "MEDIUM PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 223996.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 87122.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 88881.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 16000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>One of the main objectives of computer science theory is understanding conditions under which problems can be efficiently solved. For example, for optimization problems, convexity is a condition that allows efficient optimization algorithms (an example of an efficient optimization algorithm is gradient descent).</p>\n<p><br />The project focused on efficient computation in the context of sampling, counting, and learning problems. Sampling (and related counting) problems on graphical models are an important primitive in machine learning, statistics, and statistical physics. There are several conditions (analogs of convexity for optimization) in this domain that are conjectured to allow efficient algorithms. The first condition is the absence of long-range correlations (usually called spatial mixing). The second condition is the absence of complex zeros of a polynomial related to the counting-sampling problem. An even more optimistic conjecture is that these conditions guarantee that Markov chain algorithms are efficient (this would provide a universal efficient algorithm analogous to the gradient descent in optimization).</p>\n<p><br />The project made progress on these conjectures for several classes of sampling problems. As a consequence we now have 1) new efficient algorithms for sampling problems on homogeneous graphical models, and 2) have examples of graphical models where efficient algorithms are unlikely to exist. Concrete outcomes of the research are the following.</p>\n<p><br />1) The simplest graphical model from statistical physics is the so-called hard-core model. We established efficiency (rapid mixing) of the Markov chain for the hard-core model in the absence of long-range correlations. To establish the result we developed new techniques for establishing rapid mixingof Markov chains (connecting loopy belief propagation with designing a distance function for a coupling argument).</p>\n<p><br />2) To investigate the connection between complex zeros and efficient computation we showed a hardness result for evaluating the partition function of the hard-core model in the region corresponding to long-range correlations. To establish the result we developed a new connection between complex dynamics and complexity theory. For the special case of line graphs we prove a complementary easiness result:&nbsp; an efficient approximation algorithm for the partition function of the monomer-dimer model for all complex values of the parameter on graphs with bounded connective constant.</p>\n<p><br />3) We design methods for analyzing Markov chain algorithms on several classes of \"homogeneous\" graphs; this includes complete graphs (so-called mean-field model from statistical physics), random graphs, and more generally graphons.</p>\n<p><br />4) We make (negative) progress on the open problem of sampling perfect matchings in general graphs---ruling out certain algorithms that were previously used for bipartite graphs.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/03/2022<br>\n\t\t\t\t\tModified by: Daniel&nbsp;Stefankovic</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nOne of the main objectives of computer science theory is understanding conditions under which problems can be efficiently solved. For example, for optimization problems, convexity is a condition that allows efficient optimization algorithms (an example of an efficient optimization algorithm is gradient descent).\n\n\nThe project focused on efficient computation in the context of sampling, counting, and learning problems. Sampling (and related counting) problems on graphical models are an important primitive in machine learning, statistics, and statistical physics. There are several conditions (analogs of convexity for optimization) in this domain that are conjectured to allow efficient algorithms. The first condition is the absence of long-range correlations (usually called spatial mixing). The second condition is the absence of complex zeros of a polynomial related to the counting-sampling problem. An even more optimistic conjecture is that these conditions guarantee that Markov chain algorithms are efficient (this would provide a universal efficient algorithm analogous to the gradient descent in optimization).\n\n\nThe project made progress on these conjectures for several classes of sampling problems. As a consequence we now have 1) new efficient algorithms for sampling problems on homogeneous graphical models, and 2) have examples of graphical models where efficient algorithms are unlikely to exist. Concrete outcomes of the research are the following.\n\n\n1) The simplest graphical model from statistical physics is the so-called hard-core model. We established efficiency (rapid mixing) of the Markov chain for the hard-core model in the absence of long-range correlations. To establish the result we developed new techniques for establishing rapid mixingof Markov chains (connecting loopy belief propagation with designing a distance function for a coupling argument).\n\n\n2) To investigate the connection between complex zeros and efficient computation we showed a hardness result for evaluating the partition function of the hard-core model in the region corresponding to long-range correlations. To establish the result we developed a new connection between complex dynamics and complexity theory. For the special case of line graphs we prove a complementary easiness result:  an efficient approximation algorithm for the partition function of the monomer-dimer model for all complex values of the parameter on graphs with bounded connective constant.\n\n\n3) We design methods for analyzing Markov chain algorithms on several classes of \"homogeneous\" graphs; this includes complete graphs (so-called mean-field model from statistical physics), random graphs, and more generally graphons.\n\n\n4) We make (negative) progress on the open problem of sampling perfect matchings in general graphs---ruling out certain algorithms that were previously used for bipartite graphs.\n\n \n\n\t\t\t\t\tLast Modified: 01/03/2022\n\n\t\t\t\t\tSubmitted by: Daniel Stefankovic"
 }
}