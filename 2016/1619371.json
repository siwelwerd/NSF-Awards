{
 "awd_id": "1619371",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "III: Small: Collaborative Research: Global Event and Trend Archive Research (GETAR)",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": "7032927347",
 "po_email": "sspengle@nsf.gov",
 "po_sign_block_name": "Sylvia Spengler",
 "awd_eff_date": "2017-01-01",
 "awd_exp_date": "2019-12-31",
 "tot_intn_awd_amt": 54000.0,
 "awd_amount": 54000.0,
 "awd_min_amd_letter_date": "2016-07-28",
 "awd_max_amd_letter_date": "2016-07-28",
 "awd_abstract_narration": "This project will devise interactive, integrated, digital library/archive systems coupled with linked and expert-curated webpage/tweet collections, covering key parts of the 1997-2020 timeframe, supporting research on urgent global challenge events and initiatives. It will allow diverse stakeholder communities to interactively collect, organize, browse, visualize, study, analyze, summarize, and explore content and sources related to biodiversity, climate change, crises, disasters, elections, energy policy, environmental policy/planning, geospatial information, green engineering, human rights, inequality, migrations, nuclear power, population growth, resiliency, shootings, sustainability, violence, etc. Studying and addressing important global issues, by scholars, the public, and K-12 students, will be enhanced through tailored interfaces coupled with important collections that will be primary resources for understanding the modern world and its challenges, as well as initiatives, trends, and solutions.\r\n\r\nResearch will extend work on modeling trends, events, and sources, to guide focused crawling, information extraction, tagging, and collaboration. Domain experts will leverage rich event models, exploiting the generality of the 5S framework (Societies, Scenarios, Spaces, Structure, Streams), extending from word, n-gram, topic, concept, and language models. This research will enable efficient assembly of knowledge bases, rapid prototyping of interfaces, gathering/curation of collections with high precision and recall, and flexible discovery in support of research and learning. Interdisciplinary research advances will address digital humanities, web archiving, information retrieval, natural language processing, machine learning, and the construction of valuable interactive/collaborative interfaces. For further information see the project web site at eventsarchive.org.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Jefferson",
   "pi_last_name": "Bailey",
   "pi_mid_init": "J",
   "pi_sufx_name": "",
   "pi_full_name": "Jefferson J Bailey",
   "pi_email_addr": "jefferson@archive.org",
   "nsf_id": "000705884",
   "pi_start_date": "2016-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Internet Archive",
  "inst_street_address": "300 FUNSTON AVE",
  "inst_street_address_2": "",
  "inst_city_name": "SAN FRANCISCO",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "4155616767",
  "inst_zip_code": "941182116",
  "inst_country_name": "United States",
  "cong_dist_code": "11",
  "st_cong_dist_code": "CA11",
  "org_lgl_bus_name": "INTERNET ARCHIVE",
  "org_prnt_uei_num": "NNDFZDC3GPT7",
  "org_uei_num": "NNDFZDC3GPT7"
 },
 "perf_inst": {
  "perf_inst_name": "Internet Archive",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "941182116",
  "perf_ctry_code": "US",
  "perf_cong_dist": "11",
  "perf_st_cong_dist": "CA11",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "736400",
   "pgm_ele_name": "Info Integration & Informatics"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7364",
   "pgm_ref_txt": "INFO INTEGRATION & INFORMATICS"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 54000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Integrated Digital Event Archiving and Library (IDEAL) project, with more than 27 collaborators and 7 collaborating institutions, developed tweet and webpage collections, datasets, services, software, systems, and methods. In addition tomany publications (e.g., 2 books, 4 dissertations - leading to faculty positions at Louisiana State University and Radford&nbsp;University as well as universities in Egypt and Jordan, 3 theses, and 31 other works), there were 49 student reports across 12offerings in 5 different courses. Advances have been made in big data handling, computational linguistics, digital libraries, information retrieval, information visualization, machine learning, and Web archiving. More than 22 computers are connected,mostly in a Hadoop cluster. This network was constructed to support collection, processing, and access to almost 2 billion tweets across over 1300 collections, along with millions of webpages, covering hundreds of important events. The Internet Archive has expanded its collections and technology support, as well as outreach activities. It hosts, preserves, and provides public access with attribution to web collections created by the project team through its public Wayback Machine interfaceand Archive-It service. The latter may be browsed by descriptive metadata and searched through Archive-It&rsquo;s newly deployed full-text Elasticsearch engine. New or updated Internet Archive and Archive-It API documentation and workshops provideproject stakeholders with several means to query the data from and about these collections, and to derive datasets for furthertextual and visual analyses. Three workshops on Web Archiving and Digital Libraries were coordinated, further disseminating project results. Collaborations and/or presentations have involved multiple countries including Canada, Egypt, Jordan,Mexico, Philippines, Qatar, Saudi Arabia, and Tunisia.</p>\n<div></div>\n<div>Collection building and analysis (of both tweets and webpages) has improved through advances in classification, big dataworkflows, focused crawling (to identify webpages focused on an event of interest), inferring the location of tweets from their text when GPS data is unavailable, topic analysis, and natural language processing (including Arabic). Insights gained have been shared regarding juvenile delinquency, school shootings, and the use of information during conflicts, crises, elections, and uprisings. Collections are available to support other research and exploration regarding important events since 2007 such as the above, as well as attacks, bombings, celebrations, climate change, collapses,community activities, crashes, disease outbreaks, earthquakes, eclipses, environmental disruptions, erosion, explosions,fires, floods, hurricanes, innovations, judicial decisions, pollution, power outages, protests, revolutions, shootings, sports, storms, summits, tornadoes, transportation failures, tsunamis, typhoons, and veteran activities. In addition to the insights and collections associated with the library and archive, the IDEAL project has developed novelmethodology and workflows, tailored to addressing the challenging problem of working with events. The TweetURLsWorkflow covers the broad flow of data: collecting tweets, using the URLs present therein as seeds to our event focused crawler, and leading in part to our Web collection. TheEventFocusedCrawler manages part of that flow, i.e., how seeds lead to an event model that guides theselection and focused crawling for webpages. Other work includes the methods developed to analyze and accordingly add value (and metadata) to the collected content. The project developed new approach to find topics in webpages; it generalizes beyond the webpage content through searching, combining and analyzing results, and summarizing/extracting topics. Regarding our processing of tweets, the project created software built to streamline a variety of tweet analysis and transformation workflows. a LearningOptimizer can perform iterative processing with minimal human effort abd can yield high quality classification of tweets into collections for particular real world events. The LIW Prediction process handles the methodology for associating locations with tweets based on location indicative words; this is essential since few tweets have a specific location stored with their metadata. All of these tools and workflows come from IDEAL project work, supported in part by this grant from NSF.</div><br>\n<p>\n\t\t\t\t      \tLast Modified: 04/29/2020<br>\n\t\t\t\t\tModified by: Jefferson&nbsp;J&nbsp;Bailey</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Integrated Digital Event Archiving and Library (IDEAL) project, with more than 27 collaborators and 7 collaborating institutions, developed tweet and webpage collections, datasets, services, software, systems, and methods. In addition tomany publications (e.g., 2 books, 4 dissertations - leading to faculty positions at Louisiana State University and Radford University as well as universities in Egypt and Jordan, 3 theses, and 31 other works), there were 49 student reports across 12offerings in 5 different courses. Advances have been made in big data handling, computational linguistics, digital libraries, information retrieval, information visualization, machine learning, and Web archiving. More than 22 computers are connected,mostly in a Hadoop cluster. This network was constructed to support collection, processing, and access to almost 2 billion tweets across over 1300 collections, along with millions of webpages, covering hundreds of important events. The Internet Archive has expanded its collections and technology support, as well as outreach activities. It hosts, preserves, and provides public access with attribution to web collections created by the project team through its public Wayback Machine interfaceand Archive-It service. The latter may be browsed by descriptive metadata and searched through Archive-It\u2019s newly deployed full-text Elasticsearch engine. New or updated Internet Archive and Archive-It API documentation and workshops provideproject stakeholders with several means to query the data from and about these collections, and to derive datasets for furthertextual and visual analyses. Three workshops on Web Archiving and Digital Libraries were coordinated, further disseminating project results. Collaborations and/or presentations have involved multiple countries including Canada, Egypt, Jordan,Mexico, Philippines, Qatar, Saudi Arabia, and Tunisia.\n\nCollection building and analysis (of both tweets and webpages) has improved through advances in classification, big dataworkflows, focused crawling (to identify webpages focused on an event of interest), inferring the location of tweets from their text when GPS data is unavailable, topic analysis, and natural language processing (including Arabic). Insights gained have been shared regarding juvenile delinquency, school shootings, and the use of information during conflicts, crises, elections, and uprisings. Collections are available to support other research and exploration regarding important events since 2007 such as the above, as well as attacks, bombings, celebrations, climate change, collapses,community activities, crashes, disease outbreaks, earthquakes, eclipses, environmental disruptions, erosion, explosions,fires, floods, hurricanes, innovations, judicial decisions, pollution, power outages, protests, revolutions, shootings, sports, storms, summits, tornadoes, transportation failures, tsunamis, typhoons, and veteran activities. In addition to the insights and collections associated with the library and archive, the IDEAL project has developed novelmethodology and workflows, tailored to addressing the challenging problem of working with events. The TweetURLsWorkflow covers the broad flow of data: collecting tweets, using the URLs present therein as seeds to our event focused crawler, and leading in part to our Web collection. TheEventFocusedCrawler manages part of that flow, i.e., how seeds lead to an event model that guides theselection and focused crawling for webpages. Other work includes the methods developed to analyze and accordingly add value (and metadata) to the collected content. The project developed new approach to find topics in webpages; it generalizes beyond the webpage content through searching, combining and analyzing results, and summarizing/extracting topics. Regarding our processing of tweets, the project created software built to streamline a variety of tweet analysis and transformation workflows. a LearningOptimizer can perform iterative processing with minimal human effort abd can yield high quality classification of tweets into collections for particular real world events. The LIW Prediction process handles the methodology for associating locations with tweets based on location indicative words; this is essential since few tweets have a specific location stored with their metadata. All of these tools and workflows come from IDEAL project work, supported in part by this grant from NSF.\n\n\t\t\t\t\tLast Modified: 04/29/2020\n\n\t\t\t\t\tSubmitted by: Jefferson J Bailey"
 }
}