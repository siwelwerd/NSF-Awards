{
 "awd_id": "1565387",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "TWC: Large: Collaborative: Computing Over Distributed Sensitive Data",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": "7032927991",
 "po_email": "namla@nsf.gov",
 "po_sign_block_name": "Nina Amla",
 "awd_eff_date": "2016-05-01",
 "awd_exp_date": "2021-04-30",
 "tot_intn_awd_amt": 1700000.0,
 "awd_amount": 1750061.0,
 "awd_min_amd_letter_date": "2016-04-25",
 "awd_max_amd_letter_date": "2020-05-11",
 "awd_abstract_narration": "Information about individuals is collected by a variety of organizations including government agencies, banks, hospitals, research institutions, and private companies. In many cases, sharing this data among organizations can bring benefits in social, scientific, business, and security domains, as the collected information is of similar nature, of about similar populations. However, much of this collected data is sensitive as it contains personal information, or information that could damage an organization's reputation or competitiveness. Sharing of data is hence often curbed for ethical, legal, or business reasons. \r\n\r\nThis project develops a collection of tools that will enable the benefits of data sharing without having the data owners share the data. The techniques developed respect principles of data ownership and privacy requirement, and draw on recent scientific developments in privacy, cryptography, machine learning, computational statistics, program verification, and system security. The tools developed in this project will contribute to the existing research and business infrastructure, and hence enable new ways to create value in information whose use would have been otherwise restricted. The project supports the development of new curricula material and train a new generation of researchers and citizens with the multidisciplinary perspectives required to address the complex issues surrounding data privacy.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Chong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen Chong",
   "pi_email_addr": "chong@seas.harvard.edu",
   "nsf_id": "000535045",
   "pi_start_date": "2018-07-27",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Principal Investigator",
   "pi_first_name": "Yaacov",
   "pi_last_name": "Nissim Kobliner",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yaacov Nissim Kobliner",
   "pi_email_addr": "kobbi.nissim@georgetown.edu",
   "nsf_id": "000701169",
   "pi_start_date": "2016-04-25",
   "pi_end_date": "2017-02-28"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Salil",
   "pi_last_name": "Vadhan",
   "pi_mid_init": "P",
   "pi_sufx_name": "",
   "pi_full_name": "Salil P Vadhan",
   "pi_email_addr": "salil_vadhan@harvard.edu",
   "nsf_id": "000138824",
   "pi_start_date": "2016-04-25",
   "pi_end_date": null
  },
  {
   "pi_role": "Former Co-Principal Investigator",
   "pi_first_name": "Stephen",
   "pi_last_name": "Chong",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Stephen Chong",
   "pi_email_addr": "chong@seas.harvard.edu",
   "nsf_id": "000535045",
   "pi_start_date": "2016-04-25",
   "pi_end_date": "2017-02-28"
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "James",
   "pi_last_name": "Honaker",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "James Honaker",
   "pi_email_addr": "honaker@seas.harvard.edu",
   "nsf_id": "000571383",
   "pi_start_date": "2016-04-25",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Harvard University",
  "inst_street_address": "1033 MASSACHUSETTS AVE STE 3",
  "inst_street_address_2": "",
  "inst_city_name": "CAMBRIDGE",
  "inst_state_code": "MA",
  "inst_state_name": "Massachusetts",
  "inst_phone_num": "6174955501",
  "inst_zip_code": "021385366",
  "inst_country_name": "United States",
  "cong_dist_code": "05",
  "st_cong_dist_code": "MA05",
  "org_lgl_bus_name": "PRESIDENT AND FELLOWS OF HARVARD COLLEGE",
  "org_prnt_uei_num": "",
  "org_uei_num": "LN53LCFJFL45"
 },
 "perf_inst": {
  "perf_inst_name": "Harvard Paulson School",
  "perf_str_addr": "29 Oxford Street",
  "perf_city_name": "Cambridge",
  "perf_st_code": "MA",
  "perf_st_name": "Massachusetts",
  "perf_zip_code": "021382933",
  "perf_ctry_code": "US",
  "perf_cong_dist": "05",
  "perf_st_cong_dist": "MA05",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779600",
   "pgm_ele_name": "Algorithmic Foundations"
  },
  {
   "pgm_ele_code": "806000",
   "pgm_ele_name": "Secure &Trustworthy Cyberspace"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "025Z",
   "pgm_ref_txt": "SaTC: Secure and Trustworthy Cyberspace"
  },
  {
   "pgm_ref_code": "7434",
   "pgm_ref_txt": "CNCI"
  },
  {
   "pgm_ref_code": "7925",
   "pgm_ref_txt": "LARGE PROJECT"
  },
  {
   "pgm_ref_code": "7926",
   "pgm_ref_txt": "ALGORITHMS"
  },
  {
   "pgm_ref_code": "7927",
   "pgm_ref_txt": "COMPLEXITY & CRYPTOGRAPHY"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 430270.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 575549.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 27111.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 475929.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 241202.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-ba58765f-7fff-2f3d-4850-c6b054a61cd0\"> </span></p>\n<p dir=\"ltr\"><span>This project sought to enable the many benefits of data sharing between organizations even in settings where the data is sensitive and can not be directly shared. The project made substantial progress through research in foundations of privacy in distributed settings, statistical methods, programming languages, and verification. We briefly describe some of the key results and outcomes of this project.</span></p>\n<p><br /><br /></p>\n<p dir=\"ltr\"><strong>Foundations of Differential Privacy: </strong><span>The project made numerous advances in our understanding of differential privacy, a framework for providing strong guarantees that information specific to individuals does not leak when carrying out statistical analysis.&nbsp; Considering a variety of statistical and machine learning tasks and asking which of these tasks can be performed with differential privacy and with what costs, the project team studied both the centralized model of differential privacy, where all the data is collected and analyzed by a trusted curator, as well as a variety of distributed forms of differential privacy - including the local, hybrid, and the shuffle models of differential privacy - where the data is held by a number of different parties who engage in a protocol to carry out the analysis. We also considered how to create differentially private confidence intervals for statistical inference in this setting. These results have implications for use of differential privacy by technology companies and statistical government agencies.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Open-Source Libraries for Differential Privacy:</strong><span> We developed two iterations of open source libraries aimed at broad adoption among researchers and systems builders.&nbsp; The first, PSI: a Private data Sharing Interface, was a library in R.&nbsp; Advancing on this, we built SmartNoise-Core, this time in Rust with Python bindings, which became the core library used by Microsoft on their commercial deployment SmartNoise, a tool for differential privacy as a service on Azure.&nbsp; We used the experiences of these two libraries to start architecting a third iteration, the OpenDP library.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>CoreR and Automated Verification of Relational Properties: </strong><span>We developed a simplified version of the R programming language that supports a significant portion of R data analysis programs that we examined. This CoreR language makes it easier to write program analyses for R programs. With CoreR in mind, we developed an automated program analysis to verify whether a program satisfies differential privacy and other relational properties.</span></p>\n<p>&nbsp;</p>\n<p dir=\"ltr\"><strong>Language Support for Trusted Execution Environments (TEEs): </strong><span>We developed useful programming language abstractions to make it easier to write programs for TEEs such as Intel's SGX enclaves. This helps enable infrastructure for programs with provable information security properties to run on remote machines and access sensitive data.</span></p>\n<p><br /><span>This project was lead by 1 PD/PI, 2 Co PD/PI and a Co-Investigator. This project supported the professional development and training for 24 individuals, including 4 postdoctoral positions, 9 graduate students, 7 undergraduate students and 4 other professionals.&nbsp; The project supported the publication of 21 journals or juried conference papers, 8 other conference presentations and papers and an education aid document.&nbsp; The patent submission </span><span><em>Locally private determination of heavy hitters</em> (Patent No. 20180336357)</span><span> was also supported by this project. </span></p>\n<p>&nbsp;</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 08/25/2021<br>\n\t\t\t\t\tModified by: Stephen&nbsp;Chong</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nThis project sought to enable the many benefits of data sharing between organizations even in settings where the data is sensitive and can not be directly shared. The project made substantial progress through research in foundations of privacy in distributed settings, statistical methods, programming languages, and verification. We briefly describe some of the key results and outcomes of this project.\n\n\n\n\nFoundations of Differential Privacy: The project made numerous advances in our understanding of differential privacy, a framework for providing strong guarantees that information specific to individuals does not leak when carrying out statistical analysis.  Considering a variety of statistical and machine learning tasks and asking which of these tasks can be performed with differential privacy and with what costs, the project team studied both the centralized model of differential privacy, where all the data is collected and analyzed by a trusted curator, as well as a variety of distributed forms of differential privacy - including the local, hybrid, and the shuffle models of differential privacy - where the data is held by a number of different parties who engage in a protocol to carry out the analysis. We also considered how to create differentially private confidence intervals for statistical inference in this setting. These results have implications for use of differential privacy by technology companies and statistical government agencies.\n\n \nOpen-Source Libraries for Differential Privacy: We developed two iterations of open source libraries aimed at broad adoption among researchers and systems builders.  The first, PSI: a Private data Sharing Interface, was a library in R.  Advancing on this, we built SmartNoise-Core, this time in Rust with Python bindings, which became the core library used by Microsoft on their commercial deployment SmartNoise, a tool for differential privacy as a service on Azure.  We used the experiences of these two libraries to start architecting a third iteration, the OpenDP library.\n\n \nCoreR and Automated Verification of Relational Properties: We developed a simplified version of the R programming language that supports a significant portion of R data analysis programs that we examined. This CoreR language makes it easier to write program analyses for R programs. With CoreR in mind, we developed an automated program analysis to verify whether a program satisfies differential privacy and other relational properties.\n\n \nLanguage Support for Trusted Execution Environments (TEEs): We developed useful programming language abstractions to make it easier to write programs for TEEs such as Intel's SGX enclaves. This helps enable infrastructure for programs with provable information security properties to run on remote machines and access sensitive data.\n\n\nThis project was lead by 1 PD/PI, 2 Co PD/PI and a Co-Investigator. This project supported the professional development and training for 24 individuals, including 4 postdoctoral positions, 9 graduate students, 7 undergraduate students and 4 other professionals.  The project supported the publication of 21 journals or juried conference papers, 8 other conference presentations and papers and an education aid document.  The patent submission Locally private determination of heavy hitters (Patent No. 20180336357) was also supported by this project. \n\n \n\n \n\n\t\t\t\t\tLast Modified: 08/25/2021\n\n\t\t\t\t\tSubmitted by: Stephen Chong"
 }
}