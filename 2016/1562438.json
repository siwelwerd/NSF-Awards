{
 "awd_id": "1562438",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Collaborative Research: Living Building Information Model (BIM): A Layered Approach for Automatic and Continuous Built Environment Model Update",
 "cfda_num": "47.041",
 "org_code": "07030000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Yueyue Fan",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 200000.0,
 "awd_amount": 276000.0,
 "awd_min_amd_letter_date": "2016-02-29",
 "awd_max_amd_letter_date": "2020-04-30",
 "awd_abstract_narration": "Infrastructure and buildings are designed to have long life cycles - on the order of decades. Many buildings in the world are still in operation after centuries amid numerous renovation efforts. This long operational phase represents the majority of a building's lifecycle, yet the information regarding maintenance and renovation is rarely kept up to date. Building Information Models (BIMs) can alleviate this data shortage by centrally storing this data. However, even with a BIM, building updates are not kept due to the difficulty of continuous manual updates over a building's lifetime. This research will create a method to automatically update a BIM by exploiting recent advancements in machine vision. This automation process can systematically and continuously analyze the built environment, detecting changes from a previous assessment. It can distill and update the critical building information with minimal human error and effort. This research will result in a fundamental change in construction record keeping and benefit building operators by enabling maintenance and renovation activities to more easily be planned throughout a building's lifetime. The findings of this work will be integrated into undergraduate and graduate educational modules. Videos created for YouTube will also be developed to attract high school and underrepresented persons to a career in civil engineering.\r\n\r\nThe project will generate contextual-data relationships for use by an active illumination range camera-based, machine-vision system for automatically updating a BIM database with construction changes and leveraging metadata distilled from BIM object-oriented database models, the Computer-Aided Facilities Management (CAFM) database, and expert knowledge input by human operators. The project will tackle several intellectual challenges.  A primary challenge resides in the machine vision component of the work, which will need to provide additional meta-data beyond a 3D geometric model of an object, pushing the boundary of machine vision for the context of civil engineering systems. Another challenge is to extend data modeling capabilities for the built environment. Specifically, capabilities to translate meta-data from machine vision to identify and obtain meaningful contextual data that is specific for the objects will be created. A specific logical component, the Contextual Decision Maker (CDM), will also be developed to merge meta-data from multiple data sources. Finally, the entire system will be tested in an indoor renovation project to provide a realistic machine-learning process that will grow more robust over time.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "ENG",
 "org_dir_long_name": "Directorate for Engineering",
 "div_abbr": "CMMI",
 "org_div_long_name": "Division of Civil, Mechanical, and Manufacturing Innovation",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Fernanda",
   "pi_last_name": "Leite",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Fernanda Leite",
   "pi_email_addr": "fernanda.leite@austin.utexas.edu",
   "nsf_id": "000550414",
   "pi_start_date": "2016-02-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121532",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "150400",
   "pgm_ele_name": "GOALI-Grnt Opp Acad Lia wIndus"
  },
  {
   "pgm_ele_code": "163100",
   "pgm_ele_name": "CIS-Civil Infrastructure Syst"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "019Z",
   "pgm_ref_txt": "Grad Prep APG:Enhan. Experience"
  },
  {
   "pgm_ref_code": "029E",
   "pgm_ref_txt": "INFRASTRUCTURE SYSTEMS MGT"
  },
  {
   "pgm_ref_code": "036E",
   "pgm_ref_txt": "CIVIL INFRASTRUCTURE"
  },
  {
   "pgm_ref_code": "039E",
   "pgm_ref_txt": "STRUCTURAL SYSTEMS"
  },
  {
   "pgm_ref_code": "116E",
   "pgm_ref_txt": "RESEARCH EXP FOR UNDERGRADS"
  },
  {
   "pgm_ref_code": "9102",
   "pgm_ref_txt": "WOMEN, MINORITY, DISABLED, NEC"
  },
  {
   "pgm_ref_code": "9178",
   "pgm_ref_txt": "UNDERGRADUATE EDUCATION"
  },
  {
   "pgm_ref_code": "9231",
   "pgm_ref_txt": "SUPPL FOR UNDERGRAD RES ASSIST"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 200000.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 8000.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 48000.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 20000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p class=\"Body\"><span>Buildings represent the backbone of the world&rsquo;s cities, often standing for decades, and sometimes even centuries. However, they are far from static, changing and evolving over time the same way cities do. People and businesses move in and move out. Buildings get new paint jobs, remodels, seismic upgrades, new amenities and so many other changes during their lifetimes.</span></p>\n<p class=\"Body\">The evolution of buildings is an important aspect of Building Information Modeling (BIM), a trend in architecture and construction of creating and maintaining 3D digital representations of structures. The vast scale of buildings poses many challenges to the flow of information. Automatically creating and updating building information models will require the adoption of computer vision systems capable of parsing a comprehensive set of building components all the while being resilient to imperfections inherent in large-scale data collection.</p>\n<p class=\"Body\">Existing visual recognition methods have essentially been limited to recognizing floors, walls, ceilings, doors, and windows. To address this limitation, this research shows how a deep convolutional neural network can be trained to semantically segment RGB-D (i.e. color and depth) images into thirteen building component classes using a new annotated dataset called 3DFacilities. The dataset was designed using a common building taxonomy to ensure comprehensive semantic coverage and was collected from a diversity of buildings to ensure intra-class diversity. Transfer learning, class balancing, and prevention of overfitting are used to effectively overcome the dataset&rsquo;s borderline adequate class representation.</p>\n<p class=\"Body\">&nbsp;</p>\n<p class=\"Body\"><span>&nbsp;</span></p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/27/2021<br>\n\t\t\t\t\tModified by: Fernanda&nbsp;Leite</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "Buildings represent the backbone of the world\u2019s cities, often standing for decades, and sometimes even centuries. However, they are far from static, changing and evolving over time the same way cities do. People and businesses move in and move out. Buildings get new paint jobs, remodels, seismic upgrades, new amenities and so many other changes during their lifetimes.\nThe evolution of buildings is an important aspect of Building Information Modeling (BIM), a trend in architecture and construction of creating and maintaining 3D digital representations of structures. The vast scale of buildings poses many challenges to the flow of information. Automatically creating and updating building information models will require the adoption of computer vision systems capable of parsing a comprehensive set of building components all the while being resilient to imperfections inherent in large-scale data collection.\nExisting visual recognition methods have essentially been limited to recognizing floors, walls, ceilings, doors, and windows. To address this limitation, this research shows how a deep convolutional neural network can be trained to semantically segment RGB-D (i.e. color and depth) images into thirteen building component classes using a new annotated dataset called 3DFacilities. The dataset was designed using a common building taxonomy to ensure comprehensive semantic coverage and was collected from a diversity of buildings to ensure intra-class diversity. Transfer learning, class balancing, and prevention of overfitting are used to effectively overcome the dataset\u2019s borderline adequate class representation.\n \n \n\n \n\n\t\t\t\t\tLast Modified: 09/27/2021\n\n\t\t\t\t\tSubmitted by: Fernanda Leite"
 }
}