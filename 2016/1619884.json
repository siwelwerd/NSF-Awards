{
 "awd_id": "1619884",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "Efficient Methods for Large-Scale Self-Concordant Convex Minimization",
 "cfda_num": "47.049",
 "org_code": "03040000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Leland Jameson",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2020-06-30",
 "tot_intn_awd_amt": 239840.0,
 "awd_amount": 239840.0,
 "awd_min_amd_letter_date": "2016-06-20",
 "awd_max_amd_letter_date": "2018-06-19",
 "awd_abstract_narration": "The literature on the formulation, analysis and applications of convex optimization is ever expanding due to its broad applications in signal processing, machine learning, statistics, and other fields of data science. In theory, many convex problems have a well-understood structure, and hence state-of-the-art first order and interior-point methods can obtain high accurate solutions. In practice, however, modern applications present a host of increasingly larger-scale and nonsmooth optimization problems that can render these methods impractical. Fortunately, recent advances in convex optimization offer a surprising new angle to fundamentally re-examine the theory and practice of large-scale convex optimization models in a unified fashion. Successful development of the PI's ideas will have several broad impacts in data analysis and computational science. While existing state-of-the-art approaches focus on certain classes of convex problems, the PI strongly believes that the approach proposed in this project can be expand to cover a wide range of unexploited convex optimization applications. The obtained theory and methods can be specified and customized to solve various problems in different fields, including massive data analysis, machine learning, high-resolution imaging science, operations research, networks, and control. Successful real-world applications and software development can create a major impact to practicians in academic and industry. The PI's broad collaborations are expected to make a significant progress in the application of convex optimization techniques. Several research topics in this project will be integrated into graduate training programs through special topic courses and PhD research directions, whereas undergraduate training activities can also benefit from this research via internship training and interdisciplinary collaborations.\r\n\r\nThis project focuses on exploiting and generalizing a prominent concept so-called self-concordance to develop new efficient convex optimization techniques to attack two classes of large-scale convex optimization problems, and will be integrated into three work packages (WPs). WP1. Composite self-concordant convex optimization: While existing convex optimization methods essentially rely on the Lipschitz gradient assumption which unfortunately excludes many important applications such as Poisson and graphical learning models, the PI instead focuses on the self-concordance structure and its generalizations. Such a concept is key to the theory of interior-point methods, but has remained unexploited in composite minimization. Grounded in this structure, the PI will develop novel and provable convex optimization algorithms for solving several subclasses of large-scale composite convex problems. He also plans to generalize this self-concordant notion to other subclasses of problems such as logistic loss functions and entropy models to cover a broader range of applications.  WP2. Constrained convex optimization involving self-concordant barriers: Various constrained convex applications are integrated with a self-concordant barrier structure, while other convex constraints often have a \"simple\" structure. Existing general-purpose convex algorithms solve these problems by mainly employing either a standard interior-point method or an augmented Lagrangian framework. The PI alternatively concentrates on exploiting special structures of these problems using the theory of self-concordant barriers and combining them with both the interior-point idea and the proximal framework to develop new and scalable algorithms equipped with a rigorous convergence guarantee, while offering a parallel and distributed implementation. WP3. Implementation and applications: This WP aims at investigating the implementation aspects of the proposed algorithms and upgrading the PI's SCOPT solver. The methods developed in this project will be validated through three concrete real-world applications: image processing involving Poisson models, graphical learning problems, and large-scale max-cut and graph clustering problems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "MPS",
 "org_dir_long_name": "Directorate for Mathematical and Physical Sciences",
 "div_abbr": "DMS",
 "org_div_long_name": "Division Of Mathematical Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Quoc",
   "pi_last_name": "Tran-Dinh",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Quoc Tran-Dinh",
   "pi_email_addr": "quoctd@email.unc.edu",
   "nsf_id": "000708485",
   "pi_start_date": "2016-06-20",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of North Carolina at Chapel Hill",
  "inst_street_address": "104 AIRPORT DR STE 2200",
  "inst_street_address_2": "",
  "inst_city_name": "CHAPEL HILL",
  "inst_state_code": "NC",
  "inst_state_name": "North Carolina",
  "inst_phone_num": "9199663411",
  "inst_zip_code": "275995023",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "NC04",
  "org_lgl_bus_name": "UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL",
  "org_prnt_uei_num": "D3LHU66KBLD5",
  "org_uei_num": "D3LHU66KBLD5"
 },
 "perf_inst": {
  "perf_inst_name": "University of North Carolina at Chapel Hill",
  "perf_str_addr": "104 AIRPORT DR STE 2200",
  "perf_city_name": "Chapel Hill",
  "perf_st_code": "NC",
  "perf_st_name": "North Carolina",
  "perf_zip_code": "275993260",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "NC04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "127100",
   "pgm_ele_name": "COMPUTATIONAL MATHEMATICS"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "9263",
   "pgm_ref_txt": "COMPUTATIONAL SCIENCE & ENGING"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 72691.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 74530.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 92619.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>This project aims at developing novel and efficient optimization algorithms for solving large-scale convex optimization problems involving self-concordance structures and related problems. The&nbsp;self-concordance notion was introduced by Nesterov and Nemirovski in the 1990s to form the foundation of modern polynomial-time interior-point methods. However, it has not been widely exploited in other optimization methods as well as new research areas. This notion naturally covers key applications in computational sciences such as Poisson image reconstruction, Poisson regression, inverse covariance estimation in graph learning, and semidefinite programming, where existing first-order methods do not have a theoretical guarantee in general. This project focuses on establishing the foundation theory, algorithmic development, convergence guarantees, implementation aspects, and applications by exploiting, advancing, and extending the self-concordant notion into different directions. The algorithms developed in this project rely on novel combinations of the new theory and existing ideas such as homotopy strategies, proximal-point schemes, accelerated gradient algorithms, and Newton-type methods. The research tasks proposed in this project are divided into four work-packages (WPs). These tasks have been completed as planned during the project period.</p>\n<p>WP1 focuses on a wide class of composite convex minimization problems, where existing first-order and second-order methods do not have theoretical guarantees, or require restricted assumptions. The PI and his collaborators have developed a novel class of homotopy-based algorithms to solve three subclasses of composite convex minimization problems which can achieve polynomial-time complexity. These algorithms have state-of-the-art performance compared to existing methods. He has also extended the standard self-concordance notion to the generalized self-concordance one that forms the foundation of Newton-type methods. The new notion can cover a larger class of convex functions, which often arises in modern applications. This notion can also be used to unify smoothing techniques in nonsmooth convex optimization. Moreover, the PI also studied methods for composite convex minimization problems under inexact oracles, which are very important in practice.&nbsp;</p>\n<p>WP2 is devoted to studying constrained convex optimization problems involving self-concordant barriers. These problems cover cone constrained convex optimization (e.g., semidefinite programming) as a special case. The PI has developed a class of generalized Newton-based methods to solve a class of monotone variational inequalities involving self-concordant barriers. This framework covers two important sub-classes of constrained optimization problems as special cases: cone constrained optimization and convex-concave saddle-point problems. The new algorithms achieve polynomial-time iteration-complexity while preserving tractable convex structures by using proximal operators or resolvents. The PI has also proposed and investigated a new class of primal-dual methods under inexact oracles rendered from approximately solving the primal subproblems. These methods still achieve polynomial-time iteration-complexity under appropriate choice of accuracy.</p>\n<p>WP3 focuses on implementation aspects as well as applications of the proposed methods. The PI has applied these methods to many applications in machine learning and statistics such as logistic regression, support vector machine, Poisson regression, inverse covariance estimation, nonsmooth semidefinite programming, and network-related optimization. The project has tackled both classical models and extensions of these applications. It has also specified the new algorithms to solve these applications where the new convergence guarantee applies. All the algorithms have been implemented and tested on both synthetic and real datasets. Many algorithms achieve state-of-the-art performance compared to existing methods.&nbsp;</p>\n<p>In summary, the research carried out in this project has led to many interesting findings. In particular, the PI finds that the following three results are remarkable. First, the novel proximal path-following method can handle various subclasses of nonsmooth constrained convex problems and achieves polynomial-time iteration-complexity. Second, the generalized self-concordance forms the foundation to establish global convergence of Newton-type methods for a wide class of convex problems. Third, the homotopy-based method allows one to handle composite convex optimization problems while achieving polynomial-time complexity. Besides these three main results, several other new results have been achieved and have been published in scientific journals and conference proceedings. The PI has also been collaborated with a number of researchers to extend and apply the results of this project to concrete problems and applications such as model predictive control, robust multicategory support matrix machine, and latent supervised clustering. The theory and methods developed in this project have been used by other researchers in different fields.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/09/2020<br>\n\t\t\t\t\tModified by: Quoc&nbsp;Tran-Dinh</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThis project aims at developing novel and efficient optimization algorithms for solving large-scale convex optimization problems involving self-concordance structures and related problems. The self-concordance notion was introduced by Nesterov and Nemirovski in the 1990s to form the foundation of modern polynomial-time interior-point methods. However, it has not been widely exploited in other optimization methods as well as new research areas. This notion naturally covers key applications in computational sciences such as Poisson image reconstruction, Poisson regression, inverse covariance estimation in graph learning, and semidefinite programming, where existing first-order methods do not have a theoretical guarantee in general. This project focuses on establishing the foundation theory, algorithmic development, convergence guarantees, implementation aspects, and applications by exploiting, advancing, and extending the self-concordant notion into different directions. The algorithms developed in this project rely on novel combinations of the new theory and existing ideas such as homotopy strategies, proximal-point schemes, accelerated gradient algorithms, and Newton-type methods. The research tasks proposed in this project are divided into four work-packages (WPs). These tasks have been completed as planned during the project period.\n\nWP1 focuses on a wide class of composite convex minimization problems, where existing first-order and second-order methods do not have theoretical guarantees, or require restricted assumptions. The PI and his collaborators have developed a novel class of homotopy-based algorithms to solve three subclasses of composite convex minimization problems which can achieve polynomial-time complexity. These algorithms have state-of-the-art performance compared to existing methods. He has also extended the standard self-concordance notion to the generalized self-concordance one that forms the foundation of Newton-type methods. The new notion can cover a larger class of convex functions, which often arises in modern applications. This notion can also be used to unify smoothing techniques in nonsmooth convex optimization. Moreover, the PI also studied methods for composite convex minimization problems under inexact oracles, which are very important in practice. \n\nWP2 is devoted to studying constrained convex optimization problems involving self-concordant barriers. These problems cover cone constrained convex optimization (e.g., semidefinite programming) as a special case. The PI has developed a class of generalized Newton-based methods to solve a class of monotone variational inequalities involving self-concordant barriers. This framework covers two important sub-classes of constrained optimization problems as special cases: cone constrained optimization and convex-concave saddle-point problems. The new algorithms achieve polynomial-time iteration-complexity while preserving tractable convex structures by using proximal operators or resolvents. The PI has also proposed and investigated a new class of primal-dual methods under inexact oracles rendered from approximately solving the primal subproblems. These methods still achieve polynomial-time iteration-complexity under appropriate choice of accuracy.\n\nWP3 focuses on implementation aspects as well as applications of the proposed methods. The PI has applied these methods to many applications in machine learning and statistics such as logistic regression, support vector machine, Poisson regression, inverse covariance estimation, nonsmooth semidefinite programming, and network-related optimization. The project has tackled both classical models and extensions of these applications. It has also specified the new algorithms to solve these applications where the new convergence guarantee applies. All the algorithms have been implemented and tested on both synthetic and real datasets. Many algorithms achieve state-of-the-art performance compared to existing methods. \n\nIn summary, the research carried out in this project has led to many interesting findings. In particular, the PI finds that the following three results are remarkable. First, the novel proximal path-following method can handle various subclasses of nonsmooth constrained convex problems and achieves polynomial-time iteration-complexity. Second, the generalized self-concordance forms the foundation to establish global convergence of Newton-type methods for a wide class of convex problems. Third, the homotopy-based method allows one to handle composite convex optimization problems while achieving polynomial-time complexity. Besides these three main results, several other new results have been achieved and have been published in scientific journals and conference proceedings. The PI has also been collaborated with a number of researchers to extend and apply the results of this project to concrete problems and applications such as model predictive control, robust multicategory support matrix machine, and latent supervised clustering. The theory and methods developed in this project have been used by other researchers in different fields.\n\n \n\n\t\t\t\t\tLast Modified: 10/09/2020\n\n\t\t\t\t\tSubmitted by: Quoc Tran-Dinh"
 }
}