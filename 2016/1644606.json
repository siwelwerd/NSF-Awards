{
 "awd_id": "1644606",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Converting Print Dictionaries to Machine-Interpretable Format",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "D.  Langendoen",
 "awd_eff_date": "2016-09-15",
 "awd_exp_date": "2018-02-28",
 "tot_intn_awd_amt": 74816.0,
 "awd_amount": 74816.0,
 "awd_min_amd_letter_date": "2016-06-28",
 "awd_max_amd_letter_date": "2016-06-28",
 "awd_abstract_narration": "A dictionary documents the building blocks of a language -- its words and idiomatic phrases, with descriptions of their pronunciations, grammatical properties, meanings and uses -- and is an essential component of language documentation, together with a reference grammar and transcribed texts and recordings. Until recently, dictionaries were compiled and organized by hand, entered into some kind of typesetting system, and finally rendered in print form for use by scholars and language learners. Contemporary dictionaries are now compiled and organized electronically so that the information they contain can be used not only to produce stand-alone print artifacts, but also be integrated with the other components to ensure greater accuracy of the documentation as a whole, enable updates to be produced at regular intervals, and support the development of natural-language processing tools for the languages that are documented in this way. The goal of this exploratory project is to develop methods for machines to understand the implicit structure of the hundreds of extant print dictionaries of endangered and other low-resource languages as a critical first step in enabling their documentation to be of maximal usefulness to future generations.\r\n\r\n\r\nPrint dictionaries use ordering, typeface and other formatting conventions to indicate the intended structure of dictionary entries. The first task of this project is to use optical character reading (OCR) software to convert those entries to machine-interpretable form so as to preserve the original formatting. The second is to develop software to convert the corrected OCR output into structured, machine-interpretable archive-standard formats. Because print formats vary widely across dictionaries, human intervention is required to inform the software about how to translate the implicit representations for a particular dictionary's entries into explicit ones. But such manual annotation is only required for a small part of the dictionary, as the formatting conventions are consistent across all of its entries, and once learned can be used to identify and correct errors and inconsistencies, and enable automated editing tasks like updating orthographies. The tool will be developed, tested and evaluated using print dictionaries of two indigenous languages of Latin America that were produced in the latter part of the twentieth century. This project is jointly supported by the Documenting Endangered Languages Program in the Behavioral and Cognitive Sciences Division and by the Robust Intelligence Program in the Information and Intelligent Systems Division.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Michael",
   "pi_last_name": "Maxwell",
   "pi_mid_init": "B",
   "pi_sufx_name": "",
   "pi_full_name": "Michael B Maxwell",
   "pi_email_addr": "mmaxwell@casl.umd.edu",
   "nsf_id": "000652178",
   "pi_start_date": "2016-06-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Maryland, College Park",
  "inst_street_address": "3112 LEE BUILDING",
  "inst_street_address_2": "",
  "inst_city_name": "COLLEGE PARK",
  "inst_state_code": "MD",
  "inst_state_name": "Maryland",
  "inst_phone_num": "3014056269",
  "inst_zip_code": "207425100",
  "inst_country_name": "United States",
  "cong_dist_code": "04",
  "st_cong_dist_code": "MD04",
  "org_lgl_bus_name": "UNIVERSITY OF MARYLAND, COLLEGE PARK",
  "org_prnt_uei_num": "NPU8ULVAAS23",
  "org_uei_num": "NPU8ULVAAS23"
 },
 "perf_inst": {
  "perf_inst_name": "University of Maryland College Park",
  "perf_str_addr": "3112 Lee Bldg 7809 Regents Drive",
  "perf_city_name": "College Park",
  "perf_st_code": "MD",
  "perf_st_name": "Maryland",
  "perf_zip_code": "207425141",
  "perf_ctry_code": "US",
  "perf_cong_dist": "04",
  "perf_st_cong_dist": "MD04",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  },
  {
   "pgm_ele_code": "771900",
   "pgm_ele_name": "DEL"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7719",
   "pgm_ref_txt": "DEL"
  },
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 74816.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Dictionaries have a long history, and cover many languages for  which we do not have much other information.&nbsp; These languages range  from Tzeltal, a Mayan language spoken in southern Mexico, to Waziri, a  variety of the Pashto language spoken in the Waziristan region of  Pakistan.&nbsp; Computer technology could enable much easier and faster  access to these dictionaries--if only the dictionaries were in a digital  form, understandable to the computer.&nbsp;&nbsp; But many of them are only available in printed form, limiting distribution and making use harder.<br /> <br />Optical Character Recognition (OCR) provides a way to convert printed item to electronic form, but for dictionaries it is only a first step.&nbsp; Unlike  most books, dictionaries often have a complex structure in each  paragraph, including such things as the spelling of the word, its pronunciation, part of  speech, one or more meanings, and perhaps example sentences and  cross-references.&nbsp; While all these could be treated as so much text,  that is not what most dictionaries do; rather, they use layout and  formatting to help the human user distinguish these different kinds of  information.&nbsp; But computers are not so good at inference structure from  formatting, and prefer explicit labels for each kind of information. <br /> <br />This project developed technology that combines human skill at  understanding layout and formatting with computer technology that  converts an OCRed  text into a database, using the information implicit in the formatting to explicitly label what each field  contains: headwords, parts of speech, definitions or translations,  example sentences, synonyms and so forth.&nbsp; The resulting labeled text  can be used by other computers, both for purely computational tasks like text processing, and as a searchable resource where humans  can easily look up words. <br /> <br />The human who uses this technology to produce labeled text writes rules  to convert the formatting and content into labels and text content for  each field.&nbsp; A simple example of such a rule says that the first part of  a particular dictionary's entries consists of a headword, one or more  space characters, a part of speech (which must be one of the words in a  list of parts of speech used in that dictionary), more space characters, and  a definition; the rule also tells what labels to assign to the headword,  part of speech, and definitions.&nbsp; Another rule specifies what a  definition looks like, perhaps a sequence of white-space separated words  in some language, ending in a period. <br /> <br />The computer tries to use these rules to parse the OCR output, and  reports back both successes and failures.&nbsp; When the rules fail, the  software tells the human exactly where the rules failed, and what the  computer was expecting to see next.&nbsp; In an iterative cycle, the human  improves the rules, and the computer again tests them. <br /> <br />The human can also write simple rules that correct OCR errors, which in  our tests occured frequently.&nbsp; A simple example of this is correcting  'pL' in the OCR output to 'pl.' (an abbreviation for 'plural'); another  is correcting the lower case letter 'l' to the digit '1' in places where  the digit would be expected. <br /> <br />Linguistic researchers, speakers of less documented languages, and  government analysts who deal with foreign languages may want to use our software to convert old print dictionaries into  computer-usable form.&nbsp; Beyond dictionaries, other printed information  (like old phone books and commerce directories) could also be processed  using this system; historians of the early 20th century have expressed  interest in this use case.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 03/18/2018<br>\n\t\t\t\t\tModified by: Michael&nbsp;B&nbsp;Maxwell</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nDictionaries have a long history, and cover many languages for  which we do not have much other information.  These languages range  from Tzeltal, a Mayan language spoken in southern Mexico, to Waziri, a  variety of the Pashto language spoken in the Waziristan region of  Pakistan.  Computer technology could enable much easier and faster  access to these dictionaries--if only the dictionaries were in a digital  form, understandable to the computer.   But many of them are only available in printed form, limiting distribution and making use harder.\n \nOptical Character Recognition (OCR) provides a way to convert printed item to electronic form, but for dictionaries it is only a first step.  Unlike  most books, dictionaries often have a complex structure in each  paragraph, including such things as the spelling of the word, its pronunciation, part of  speech, one or more meanings, and perhaps example sentences and  cross-references.  While all these could be treated as so much text,  that is not what most dictionaries do; rather, they use layout and  formatting to help the human user distinguish these different kinds of  information.  But computers are not so good at inference structure from  formatting, and prefer explicit labels for each kind of information. \n \nThis project developed technology that combines human skill at  understanding layout and formatting with computer technology that  converts an OCRed  text into a database, using the information implicit in the formatting to explicitly label what each field  contains: headwords, parts of speech, definitions or translations,  example sentences, synonyms and so forth.  The resulting labeled text  can be used by other computers, both for purely computational tasks like text processing, and as a searchable resource where humans  can easily look up words. \n \nThe human who uses this technology to produce labeled text writes rules  to convert the formatting and content into labels and text content for  each field.  A simple example of such a rule says that the first part of  a particular dictionary's entries consists of a headword, one or more  space characters, a part of speech (which must be one of the words in a  list of parts of speech used in that dictionary), more space characters, and  a definition; the rule also tells what labels to assign to the headword,  part of speech, and definitions.  Another rule specifies what a  definition looks like, perhaps a sequence of white-space separated words  in some language, ending in a period. \n \nThe computer tries to use these rules to parse the OCR output, and  reports back both successes and failures.  When the rules fail, the  software tells the human exactly where the rules failed, and what the  computer was expecting to see next.  In an iterative cycle, the human  improves the rules, and the computer again tests them. \n \nThe human can also write simple rules that correct OCR errors, which in  our tests occured frequently.  A simple example of this is correcting  'pL' in the OCR output to 'pl.' (an abbreviation for 'plural'); another  is correcting the lower case letter 'l' to the digit '1' in places where  the digit would be expected. \n \nLinguistic researchers, speakers of less documented languages, and  government analysts who deal with foreign languages may want to use our software to convert old print dictionaries into  computer-usable form.  Beyond dictionaries, other printed information  (like old phone books and commerce directories) could also be processed  using this system; historians of the early 20th century have expressed  interest in this use case.\n\n\t\t\t\t\tLast Modified: 03/18/2018\n\n\t\t\t\t\tSubmitted by: Michael B Maxwell"
 }
}