{
 "awd_id": "1651089",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Human-Aware Navigation in Populated Indoor Environments",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Reid Simmons",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2018-08-31",
 "tot_intn_awd_amt": 259396.0,
 "awd_amount": 259396.0,
 "awd_min_amd_letter_date": "2016-08-18",
 "awd_max_amd_letter_date": "2016-08-18",
 "awd_abstract_narration": "Current autonomous mobile robots are able to navigate accurately through sparsely populated areas without bumping into things.  However, they have more trouble in situations that commonly arise in public buildings, such as when passing people in narrow hallways, when moving through open, populated spaces, or when crossing a crowd of people exiting an auditorium.  Thus, for autonomous robots to reach their full potential, in terms of positive impact on society, they will need to improve their navigational abilities to be more \"human-aware.\"  That is, they will explicitly need to take account the characteristics of the people with whom they need to interact in public spaces.  With this motivation in mind, the goal of this research is to understand how best to enable mobile robots to navigate smoothly, robustly, and safely through human-populated indoor environments in pursuit of high-level goals, with varying levels of guidance from a human operator in a fully human-aware manner.\r\n\r\nThis project focuses on two complementary, high-risk, and potentially foundational research thrusts as being crucial to laying the groundwork for eventual development of a robust, human-aware navigation system.  First, it aims to develop formal specifications for safe robot-operator-pedestrian interactions, using probabilistic temporal logics.  Second, it aims to develop methods for generating learned models of operator preferences that can influence the robot's choice of paths with regards to, for example, trajectory smoothness, order of subgoal achievement, task completion time, travel speed, and proximity of trajectory to pedestrians and fixed objects, learning user preferences and determining how to combine them with task-achieving reward functions.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Stone",
   "pi_mid_init": "H",
   "pi_sufx_name": "",
   "pi_full_name": "Peter H Stone",
   "pi_email_addr": "pstone@cs.utexas.edu",
   "nsf_id": "000156504",
   "pi_start_date": "2016-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Luis",
   "pi_last_name": "Sentis",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Luis Sentis",
   "pi_email_addr": "lsentis@austin.utexas.edu",
   "nsf_id": "000570648",
   "pi_start_date": "2016-08-18",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Ufuk",
   "pi_last_name": "Topcu",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Ufuk Topcu",
   "pi_email_addr": "utopcu@utexas.edu",
   "nsf_id": "000690245",
   "pi_start_date": "2016-08-18",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Texas at Austin",
  "inst_street_address": "110 INNER CAMPUS DR",
  "inst_street_address_2": "",
  "inst_city_name": "AUSTIN",
  "inst_state_code": "TX",
  "inst_state_name": "Texas",
  "inst_phone_num": "5124716424",
  "inst_zip_code": "787121139",
  "inst_country_name": "United States",
  "cong_dist_code": "25",
  "st_cong_dist_code": "TX25",
  "org_lgl_bus_name": "UNIVERSITY OF TEXAS AT AUSTIN",
  "org_prnt_uei_num": "",
  "org_uei_num": "V6AFQPN18437"
 },
 "perf_inst": {
  "perf_inst_name": "University of Texas at Austin",
  "perf_str_addr": "2317 Speedway",
  "perf_city_name": "Austin",
  "perf_st_code": "TX",
  "perf_st_name": "Texas",
  "perf_zip_code": "787121757",
  "perf_ctry_code": "US",
  "perf_cong_dist": "25",
  "perf_st_cong_dist": "TX25",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "801300",
   "pgm_ele_name": "NRI-National Robotics Initiati"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "8086",
   "pgm_ref_txt": "Natl Robotics Initiative (NRI)"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 259396.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The goal of this project was to enable autonomous robots to navigate <br />smoothly and confidently in environments where people are present and <br />going about their own business.&nbsp; Towards this end the project focused <br />on two complementary, high-risk, and potentially foundational research <br />thrusts as being crucial to laying the groundwork for eventual <br />development of a robust human-aware navigation system on mobile <br />robots.&nbsp; First, it aims to develop formal specifications for safe <br />robot-operator-pedestrian interactions.&nbsp; Second, it aims to develop <br />methods for generating learned models of operator preferences that can <br />influence the robot's choice of paths with regards to, for example, <br />trajectory smoothness, order of subgoal achievement, task completion <br />time, travel speed, and proximity of trajectory to pedestrians and <br />fixed objects. <br />&nbsp;<br />We have investigated strategies for intelligent collision management <br />in dynamic environments.&nbsp; We have investigated methods for evaluating <br />whether pedestrians are aware the robot is nearby, and considered <br />how that influnces a robot's best navigation plan.&nbsp; <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br />Regarding pedestrian awareness of robots, we introduced an awareness <br />state based on pedestrian gaze detection. We calculate the time <br />duration and frequency that a person looks at a robot. With this <br />information we have devised models of sensor-based awareness and used <br />them for effective and safe mobile navigation. <br />&nbsp;<br />Our results offer (i) better scalability compared to the competing <br />methods in the literature in planning in partially-observable Markov <br />decision processes through reasoning at multiple levels of <br />abstractions (ii) better generalization in inverse reinforcement <br />learning by directly incorporating side information encoded in <br />temporal logic and (iii) better robustness to pedestrian modeling <br />uncertainty in scenarios where robots and people cross paths.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 12/30/2018<br>\n\t\t\t\t\tModified by: Peter&nbsp;H&nbsp;Stone</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe goal of this project was to enable autonomous robots to navigate \nsmoothly and confidently in environments where people are present and \ngoing about their own business.  Towards this end the project focused \non two complementary, high-risk, and potentially foundational research \nthrusts as being crucial to laying the groundwork for eventual \ndevelopment of a robust human-aware navigation system on mobile \nrobots.  First, it aims to develop formal specifications for safe \nrobot-operator-pedestrian interactions.  Second, it aims to develop \nmethods for generating learned models of operator preferences that can \ninfluence the robot's choice of paths with regards to, for example, \ntrajectory smoothness, order of subgoal achievement, task completion \ntime, travel speed, and proximity of trajectory to pedestrians and \nfixed objects. \n \nWe have investigated strategies for intelligent collision management \nin dynamic environments.  We have investigated methods for evaluating \nwhether pedestrians are aware the robot is nearby, and considered \nhow that influnces a robot's best navigation plan.  \n      \nRegarding pedestrian awareness of robots, we introduced an awareness \nstate based on pedestrian gaze detection. We calculate the time \nduration and frequency that a person looks at a robot. With this \ninformation we have devised models of sensor-based awareness and used \nthem for effective and safe mobile navigation. \n \nOur results offer (i) better scalability compared to the competing \nmethods in the literature in planning in partially-observable Markov \ndecision processes through reasoning at multiple levels of \nabstractions (ii) better generalization in inverse reinforcement \nlearning by directly incorporating side information encoded in \ntemporal logic and (iii) better robustness to pedestrian modeling \nuncertainty in scenarios where robots and people cross paths.\n\n\t\t\t\t\tLast Modified: 12/30/2018\n\n\t\t\t\t\tSubmitted by: Peter H Stone"
 }
}