{
 "awd_id": "1642280",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "EAGER: Developing scalable benchmark mini-apps for graph engine comparison",
 "cfda_num": "47.070",
 "org_code": "05010000",
 "po_phone": "7032927498",
 "po_email": "achtchel@nsf.gov",
 "po_sign_block_name": "Almadena Chtchelkanova",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 299869.0,
 "awd_amount": 307369.0,
 "awd_min_amd_letter_date": "2016-07-28",
 "awd_max_amd_letter_date": "2017-05-16",
 "awd_abstract_narration": "The last decade has seen the growth of extremely large, unstructured, and dynamic data sets, loosely termed Big Data. However, there is a growing desire to extract not just specific properties of collections of such facts, but also relationships between the underlying entities in that data. Examples come from a broad swatch of modern life: bioinformatics, financial, recommendation systems, cyber and national security, and social networks. Graphs have emerged as a valuable and productive paradigm for expressing such problems, where a graph is a collection of a set of objects (vertices) where some pairs of objects are connected by links (edges) that represent some relation between the two. \r\nIn the last decade there has been an explosion in support for graphs, with widely differing execution models and targeted applicability. Although numerous graph benchmarks have been proposed, only one has had a rigorous accumulation of performance data from multiple platforms (www.graph500.org). Computation is over a whole static graph, whereas the real world sees applications where update data is streaming into large persistent graphs, and very many small targeted queries may be in progress at once.\r\nGiven the expected productivity increase of using a graph programming paradigm over conventional programming, especially for parallel systems, it is of growing importance to have common mini-apps that can be used for cross-paradigm comparisons. Also, given the continued increase in graph sizes, it is important to understand how the underlying graph engines scale both in the size and type of the target graphs and in the amount and mix of parallelism and concurrency they can support.\r\nThis project addresses this need. In collaboration with commercial and government research labs, the primary objective is on defining a set of mini-apps that reflect complex real-world applications more sophisticated than today's simple benchmarks, converting these mini-apps to the existing major graph packages, and then running them on a wide range of parallel systems. \r\nThe wider impact can be significant. Identification of relevant mini-apps and how they perform across different systems will provide insight into both how to write more complete graph applications in more scalable ways, and which aspects of which programming systems and platforms are best suited. It is also expected that not all mini-apps will be expressible in all the current paradigms, providing insight to the developers of those paradigms on expressibility issues. Given the relative infancy of such graph packages such insight now can radically improve their applicability to real applications in the future.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CCF",
 "org_div_long_name": "Division of Computing and Communication Foundations",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Peter",
   "pi_last_name": "Kogge",
   "pi_mid_init": "M",
   "pi_sufx_name": "",
   "pi_full_name": "Peter M Kogge",
   "pi_email_addr": "kogge@nd.edu",
   "nsf_id": "000235482",
   "pi_start_date": "2016-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Douglas",
   "pi_last_name": "Thain",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Douglas Thain",
   "pi_email_addr": "dthain@nd.edu",
   "nsf_id": "000341714",
   "pi_start_date": "2016-07-28",
   "pi_end_date": null
  },
  {
   "pi_role": "Co-Principal Investigator",
   "pi_first_name": "Nitesh",
   "pi_last_name": "Chawla",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Nitesh Chawla",
   "pi_email_addr": "nchawla@nd.edu",
   "nsf_id": "000484327",
   "pi_start_date": "2016-07-28",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "University of Notre Dame",
  "inst_street_address": "940 GRACE HALL",
  "inst_street_address_2": "",
  "inst_city_name": "NOTRE DAME",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "5746317432",
  "inst_zip_code": "465565708",
  "inst_country_name": "United States",
  "cong_dist_code": "02",
  "st_cong_dist_code": "IN02",
  "org_lgl_bus_name": "UNIVERSITY OF NOTRE DAME DU LAC",
  "org_prnt_uei_num": "FPU6XGFXMBE9",
  "org_uei_num": "FPU6XGFXMBE9"
 },
 "perf_inst": {
  "perf_inst_name": "University of Notre Dame",
  "perf_str_addr": "Fitzpatrick Hall",
  "perf_city_name": "Notre Dame",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "465565637",
  "perf_ctry_code": "US",
  "perf_cong_dist": "02",
  "perf_st_cong_dist": "IN02",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "779800",
   "pgm_ele_name": "Software & Hardware Foundation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7916",
   "pgm_ref_txt": "EAGER"
  },
  {
   "pgm_ref_code": "7942",
   "pgm_ref_txt": "HIGH-PERFORMANCE COMPUTING"
  },
  {
   "pgm_ref_code": "9251",
   "pgm_ref_txt": "REU SUPP-Res Exp for Ugrd Supp"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 299869.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 7500.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The last decade has seen the growth of data sets that are not only extremely large, but also unstructured and very dynamic, with the desire to extract not just specific facts about specific entries in those sets but also relationships between entities represented by those entries. Some examples include recommendations systems as used in e-commerce, and social networks. Graphs have emerged as a productive paradigm for expressing such problems, with an explosion in new graph algorithms, graph query languages, and graph engines that perform such computations. This project had two major goals. First,&nbsp; to define a set of graph-based mini-apps to reflect complex real-world applications that are more sophisticated than simple benchmarks. Second was to expand our understanding of tradeoffs in expressiveness, performance, and scalability in the design of graph processing systems.</p>\n<p>From discussions with external government, industrial, and academic collaborators, several generic problems emerged as targets for special focus. These included finding &ldquo;relationships&rdquo; between entities represented through such graphs (and through such relationships finding &ldquo;communities&rdquo; of related entities), &ldquo;matching up&rdquo; such entities, and &ldquo;higher order networks&rdquo; where what is important is not a relationship but chains of such relationships. Three of these are now part of three different&nbsp; PhD-level projects, with implementations on different parallel computing platforms in progress.</p>\n<p>This set of kernels was enhanced through an experimental 2018 graduate course on &ldquo;Scalable Graph Computing.&rdquo; The students developed baseline implementations of additional mini-apps, mostly of direct relevance to their thesis. They then looked at performance scaling in either the size of the data sets and/or in the level of parallelism. These studies were compiled into a publically available report. We expect to augment this report as the continuing PhD research comes to conclusions.</p>\n<p>The other goal of exploring graph programming paradigms was tackled similarly. A second publically available report with chapters covering various languages, libraries, or runtimes that were relevant to graph computing was started. The students in the same class mentioned above augmented the existing chapters of this report with their own chapters, each of which covered an additional paradigm in a relatively standardized fashion. Additional placeholders for other related topics have since been added to this report and will be fleshed out as time goes on.</p>\n<p>During the timeframe of this project, one graph paradigm has burst into prominence. GraphBLAS supported a modified matrix linear algebra where basic multiplication and addition functions can be replaced by any pair of functions that have certain functional characteristics. A large suite of graph kernels is expressible in this framework by the appropriate choice of function pairs. A second attribute of GraphBLAS is that it was designed from the start to handle very sparse irregular problems where the matrices and vectors are largely &ldquo;zeros.&rdquo; This is exactly what is observed in virtually all real-world graph problems. Studying GraphBLAS led to perhaps the most important outcomes of this project. First, given that real-world problems are often huge, it is important to understand how their processing scales as larger computer systems are employed. Perhaps the key function for such processing, Sparse Matrix Vector Products (SpMV), was extensively studied via multiple implementations on a variety of high end computers. The results (documented in several papers) showed that without exception the architecture of modern systems are poor fits. The intrinsic computation is memory access-limited, not compute--limited. The &ldquo;efficiency&rdquo; of modern cores is low, but computation time by itself does scale well with system size. However, the cost of communicating the pieces of such computations very quickly overwhelms the compute time, so that all systems tested to date eventually actually slows down with bigger systems, often literally by orders of magnitude. Ongoing work is focused on alternative &ldquo;communication-avoiding&rdquo; algorithms where more computation may be performed but communication, and thus overall time, &nbsp;is lowered.</p>\n<p>The second major outcome from this GraphBLAS work grew out of the observation that as currently defined, computation is &ldquo;batched.&rdquo; An entire data set is processed at one time. Real world problems, however, are rapidly becoming incremental; after some initial data set has been processed to derive the desired analytics, it would be significant value to respond quickly to incremental changes provided in real time, without recomputing from the start. A study of how to modify the underlying mathematics of GraphBLAS led to an approach that may be amenable to automated code generation.. This was documented in a conference paper (which was nominated for a best paper) that included examples drawn from several of the graph kernels discussed above. Followon work is planned to try to prototype this process.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/18/2019<br>\n\t\t\t\t\tModified by: Peter&nbsp;M&nbsp;Kogge</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe last decade has seen the growth of data sets that are not only extremely large, but also unstructured and very dynamic, with the desire to extract not just specific facts about specific entries in those sets but also relationships between entities represented by those entries. Some examples include recommendations systems as used in e-commerce, and social networks. Graphs have emerged as a productive paradigm for expressing such problems, with an explosion in new graph algorithms, graph query languages, and graph engines that perform such computations. This project had two major goals. First,  to define a set of graph-based mini-apps to reflect complex real-world applications that are more sophisticated than simple benchmarks. Second was to expand our understanding of tradeoffs in expressiveness, performance, and scalability in the design of graph processing systems.\n\nFrom discussions with external government, industrial, and academic collaborators, several generic problems emerged as targets for special focus. These included finding \"relationships\" between entities represented through such graphs (and through such relationships finding \"communities\" of related entities), \"matching up\" such entities, and \"higher order networks\" where what is important is not a relationship but chains of such relationships. Three of these are now part of three different  PhD-level projects, with implementations on different parallel computing platforms in progress.\n\nThis set of kernels was enhanced through an experimental 2018 graduate course on \"Scalable Graph Computing.\" The students developed baseline implementations of additional mini-apps, mostly of direct relevance to their thesis. They then looked at performance scaling in either the size of the data sets and/or in the level of parallelism. These studies were compiled into a publically available report. We expect to augment this report as the continuing PhD research comes to conclusions.\n\nThe other goal of exploring graph programming paradigms was tackled similarly. A second publically available report with chapters covering various languages, libraries, or runtimes that were relevant to graph computing was started. The students in the same class mentioned above augmented the existing chapters of this report with their own chapters, each of which covered an additional paradigm in a relatively standardized fashion. Additional placeholders for other related topics have since been added to this report and will be fleshed out as time goes on.\n\nDuring the timeframe of this project, one graph paradigm has burst into prominence. GraphBLAS supported a modified matrix linear algebra where basic multiplication and addition functions can be replaced by any pair of functions that have certain functional characteristics. A large suite of graph kernels is expressible in this framework by the appropriate choice of function pairs. A second attribute of GraphBLAS is that it was designed from the start to handle very sparse irregular problems where the matrices and vectors are largely \"zeros.\" This is exactly what is observed in virtually all real-world graph problems. Studying GraphBLAS led to perhaps the most important outcomes of this project. First, given that real-world problems are often huge, it is important to understand how their processing scales as larger computer systems are employed. Perhaps the key function for such processing, Sparse Matrix Vector Products (SpMV), was extensively studied via multiple implementations on a variety of high end computers. The results (documented in several papers) showed that without exception the architecture of modern systems are poor fits. The intrinsic computation is memory access-limited, not compute--limited. The \"efficiency\" of modern cores is low, but computation time by itself does scale well with system size. However, the cost of communicating the pieces of such computations very quickly overwhelms the compute time, so that all systems tested to date eventually actually slows down with bigger systems, often literally by orders of magnitude. Ongoing work is focused on alternative \"communication-avoiding\" algorithms where more computation may be performed but communication, and thus overall time,  is lowered.\n\nThe second major outcome from this GraphBLAS work grew out of the observation that as currently defined, computation is \"batched.\" An entire data set is processed at one time. Real world problems, however, are rapidly becoming incremental; after some initial data set has been processed to derive the desired analytics, it would be significant value to respond quickly to incremental changes provided in real time, without recomputing from the start. A study of how to modify the underlying mathematics of GraphBLAS led to an approach that may be amenable to automated code generation.. This was documented in a conference paper (which was nominated for a best paper) that included examples drawn from several of the graph kernels discussed above. Followon work is planned to try to prototype this process.\n\n\t\t\t\t\tLast Modified: 09/18/2019\n\n\t\t\t\t\tSubmitted by: Peter M Kogge"
 }
}