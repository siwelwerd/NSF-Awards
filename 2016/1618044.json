{
 "awd_id": "1618044",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "RI: Small: Collaborative Research: Unsupervised Transcription of Early Modern Documents",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 249458.0,
 "awd_amount": 249458.0,
 "awd_min_amd_letter_date": "2016-06-03",
 "awd_max_amd_letter_date": "2016-06-03",
 "awd_abstract_narration": "Recently, researchers in the social sciences and humanities have made increasing use of digital technologies in their work, seeking to answer important questions about human artifacts based on new kinds of analyses. However, since many of their methods are statistical in nature, they require a large amount of digitally readable text to operate. For example, to ask statistical questions about how the legal rights of women have changed during the past five centuries, a large and unbiased sample of court proceedings spanning that time period has to be accessible in digital form. Unfortunately, for many time periods this data is not available, not because the historical documents have been lost, but because they cannot be efficiently transcribed. In particular, the 400 years just after the invention of the printing press (the early modern period, ca. 1450-1850) represents a critical dark period for such research because documents from this period are notoriously hard to transcribe into machine-readable text with automatic methods for three reasons: they use obscure and unknown fonts, their text differs from modern language, and historical printing processes were imprecise. This proposal seeks to address these issues by treating transcription as a type of code-breaking and using machine learning to induce font and text structure directly from unannotated document images without relying on annotated examples,  an approach called unsupervised learning. As a result, the proposal aims not just to digitize existing early modern corpora in major libraries, but also to produce a tool that researchers can use to digitize data at scale themselves and that is sufficiently flexible to develop new representations, for example, of non-standard character sets. \r\n\r\nThe proposed approach treats the problem of document transcription as a linguistic decipherment problem, leveraging modeling techniques from work on decrypting historical ciphers. The key idea is that while properties like font and text structure are document-specific and therefore difficult to treat generally with supervised techniques, these phenomena are in fact regular within individual documents. For example, while the shape of a particular character in an obscure historical font may be unknown to the system, that shape is in fact regular;  every time the character is printed it uses the same template. Models that leverage this kind of regularity by incorporating it as an assumption can constrain the otherwise difficult unsupervised learning problem and make it feasible. This proposal introduces a class of generative models with this goal in mind, designed to learn fonts and predict accurate transcriptions in an unsupervised fashion by capturing the core properties of the process that generated the input data: the historical printing process. These models represent the specific types of printing and typesetting noise exhibited by early modern documents, treat typesetting as a latent variable, and jointly consider possible character segmentations and transcriptions during inference. Their parameters can be estimated efficiently, directly from images of historical documents without accompanying transcriptions. Further, by treating damaged portions of the input documents as latent variables, this proposal aims to automatically reconstruct damaged documents using the same approach. The unsupervised techniques developed here may have uses in other areas of natural language processing where annotated training data is hard to obtain; for example, in personalized speech recognition and grounded semantics.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Taylor",
   "pi_last_name": "Berg-Kirkpatrick",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Taylor Berg-Kirkpatrick",
   "pi_email_addr": "tberg@eng.ucsd.edu",
   "nsf_id": "000703627",
   "pi_start_date": "2016-06-03",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Carnegie-Mellon University",
  "inst_street_address": "5000 FORBES AVE",
  "inst_street_address_2": "",
  "inst_city_name": "PITTSBURGH",
  "inst_state_code": "PA",
  "inst_state_name": "Pennsylvania",
  "inst_phone_num": "4122688746",
  "inst_zip_code": "152133815",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "PA12",
  "org_lgl_bus_name": "CARNEGIE MELLON UNIVERSITY",
  "org_prnt_uei_num": "U3NKNFLNQ613",
  "org_uei_num": "U3NKNFLNQ613"
 },
 "perf_inst": {
  "perf_inst_name": "Carnegie-Mellon University",
  "perf_str_addr": "",
  "perf_city_name": "Pittsburgh",
  "perf_st_code": "PA",
  "perf_st_name": "Pennsylvania",
  "perf_zip_code": "152133815",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "PA12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7298",
   "pgm_ref_txt": "COLLABORATIVE RESEARCH"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  },
  {
   "pgm_ref_code": "7923",
   "pgm_ref_txt": "SMALL PROJECT"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 249458.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The Unsupervised Transcription of Early Modern Documents project has focused on developing new artificial intelligence and machine learning techniques to support improved optical character recognition (OCR) of difficult historical printed documents from the Early Modern period. Further, the project has also aimed to develop new tools for analyzing typesetting and font variation in Early Modern books to support analysis related to specific historical questions -- for example, questions about who set the type for and printed Shakespeare's First Folio. The broader goal of this project is to develop new computational techniques that enable digital humanities researchers to investigate new domains of historical book data that, without improved OCR, would be otherwise unfeasible. The outcomes of the project include (a) new machine learning techniques that learn better with less manually labelled data, (b) new artificial intelligence systems for analyzing historical typefaces and typesetting variation, and (c) a new method to achieve improved OCR performance when using small amounts labelled data to train OCR systems. The results of this research, including both the novel machine learning methods developed and the experiments evaluating these techniques, were published in several machine learning and artificial intelligence publication venues and can be accessed online. Further, as part of this research, an open-source system named Ocular for unsupervised Early Modern document transcription is being maintained publicly on github.&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 01/18/2022<br>\n\t\t\t\t\tModified by: Taylor&nbsp;Berg-Kirkpatrick</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe Unsupervised Transcription of Early Modern Documents project has focused on developing new artificial intelligence and machine learning techniques to support improved optical character recognition (OCR) of difficult historical printed documents from the Early Modern period. Further, the project has also aimed to develop new tools for analyzing typesetting and font variation in Early Modern books to support analysis related to specific historical questions -- for example, questions about who set the type for and printed Shakespeare's First Folio. The broader goal of this project is to develop new computational techniques that enable digital humanities researchers to investigate new domains of historical book data that, without improved OCR, would be otherwise unfeasible. The outcomes of the project include (a) new machine learning techniques that learn better with less manually labelled data, (b) new artificial intelligence systems for analyzing historical typefaces and typesetting variation, and (c) a new method to achieve improved OCR performance when using small amounts labelled data to train OCR systems. The results of this research, including both the novel machine learning methods developed and the experiments evaluating these techniques, were published in several machine learning and artificial intelligence publication venues and can be accessed online. Further, as part of this research, an open-source system named Ocular for unsupervised Early Modern document transcription is being maintained publicly on github. \n\n\t\t\t\t\tLast Modified: 01/18/2022\n\n\t\t\t\t\tSubmitted by: Taylor Berg-Kirkpatrick"
 }
}