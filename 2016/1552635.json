{
 "awd_id": "1552635",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Continuing Grant",
 "awd_titl_txt": "CAREER: Interactive Training of Semantic Parsers via Paraphrasing",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2016-02-01",
 "awd_exp_date": "2022-01-31",
 "tot_intn_awd_amt": 550000.0,
 "awd_amount": 550000.0,
 "awd_min_amd_letter_date": "2016-01-29",
 "awd_max_amd_letter_date": "2020-02-10",
 "awd_abstract_narration": "With the increase in popularity of virtual assistants such as Siri, there is a renewed demand for deep and robust language understanding.  Statistical semantic parsing is a promising paradigm for addressing this demand.  The key obstacle in building statistical semantic parsers is obtaining adequate training data.  This CAREER project aims to develop a new interactive framework for building a semantic parser, where the system, acting like a foreign speaker of English, asks users to paraphrase utterances that the computer already understands into ones that the computer doesn't. The framework opens up intriguing applications in education.  One such application is a bidirectional tutoring system, in which the system poses questions to the student.  The student must both answer and paraphrase the question, thereby both practicing the course material and providing training data to the system.  Natural language is a universal entry point, which can increase engagement and promote diversity. High-quality semantic parsers can drastically improve the way humans interact with computers.  In the longer term, this work can also have a significant impact on the way natural language processing systems are built.  Currently, the prevailing paradigm is very much a train-and-deploy one, whereas there are many more opportunities for improvement and personalization if deployed systems were to learn on-the-fly.\r\n\r\nThis project develops a new interactive framework for building a semantic parser, which aims to obtain complete coverage in a given domain.  The key idea is for the system to choose logical forms, generate probe utterances that capture their semantics, and ask users to paraphrase them into natural input utterances.  In the process, the system learns about linguistic variation and novel high-level concepts.  The data is then used to train a paraphrasing-based semantic parsing model.  Existing paraphrasing models are either transformation-based, which excel at capturing structural regularities in language or are vector-based, which excel at capturing soft similarity.  The project develops novel models to capture both. The framework developed in this project improves the state-of-the-art of natural language processing and machine learning in three ways.  First, the framework departs from the classic paradigm of gathering a dataset and learning a model; instead, an interactive system interleaves the two steps.  Second, the framework learns high-level concepts, which is crucial for natural language understanding, since words often represent complex concepts.  Finally, it resolves a classic tension between the rigidity of logical representations and the flexibility of continuous representations by capturing both in a unified model.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Percy",
   "pi_last_name": "Liang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Percy Liang",
   "pi_email_addr": "pliang@cs.stanford.edu",
   "nsf_id": "000630416",
   "pi_start_date": "2016-01-29",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Stanford University",
  "inst_street_address": "450 JANE STANFORD WAY",
  "inst_street_address_2": "",
  "inst_city_name": "STANFORD",
  "inst_state_code": "CA",
  "inst_state_name": "California",
  "inst_phone_num": "6507232300",
  "inst_zip_code": "943052004",
  "inst_country_name": "United States",
  "cong_dist_code": "16",
  "st_cong_dist_code": "CA16",
  "org_lgl_bus_name": "THE LELAND STANFORD JUNIOR UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "HJD6G4D6TJY5"
 },
 "perf_inst": {
  "perf_inst_name": "Stanford University",
  "perf_str_addr": "",
  "perf_city_name": "",
  "perf_st_code": "CA",
  "perf_st_name": "California",
  "perf_zip_code": "943054100",
  "perf_ctry_code": "US",
  "perf_cong_dist": "16",
  "perf_st_cong_dist": "CA16",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "749500",
   "pgm_ele_name": "Robust Intelligence"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1045",
   "pgm_ref_txt": "CAREER-Faculty Erly Career Dev"
  },
  {
   "pgm_ref_code": "7495",
   "pgm_ref_txt": "ROBUST INTELLIGENCE"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0117",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001718DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0118",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001819DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0120",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01002021DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 104064.0
  },
  {
   "fund_oblg_fiscal_yr": 2017,
   "fund_oblg_amt": 106938.0
  },
  {
   "fund_oblg_fiscal_yr": 2018,
   "fund_oblg_amt": 109903.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 112964.0
  },
  {
   "fund_oblg_fiscal_yr": 2020,
   "fund_oblg_amt": 116131.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The top-level vision of the project is to be able to scale up executable semantic parsers that map natural language utterances to programs (logical forms) that can be executed to produce the desired answer or user behavior. Over the last 5 years, we have made significant progress towards this vision.We developed better training methods based on reinforcement learning that can avoid spurious programs (those that get the answer right for the wrong reasons) in weak supervision settings. These ideas were then extended to programs that could perform actions on the web.We developed a novel framework by which naturalizing programming languages, where a user interactively teaches language to a system while they are using it, which allows for use and learning to happen jointly and the language to be co-adapted.We then attempted to scale up the core problem of program synthesis from natural language (pseudocode), which demanded new search algorithms. We developed a graph-based model architecture, strongly leveraging the fact that we could execute programs at test time.We finally developed new self-supervised techniques that leveraged the wealth of unlabeled data along with an executor to bootstrap better systems.Altogether, we believe that we've tackled the problem from many angles, the framework, the data, the models, the training, and today we are able to synthesize programs from natural language (e.g., train semantic parsers) with much greater accuracy and scope than before.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 07/04/2022<br>\n\t\t\t\t\tModified by: Percy&nbsp;Liang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe top-level vision of the project is to be able to scale up executable semantic parsers that map natural language utterances to programs (logical forms) that can be executed to produce the desired answer or user behavior. Over the last 5 years, we have made significant progress towards this vision.We developed better training methods based on reinforcement learning that can avoid spurious programs (those that get the answer right for the wrong reasons) in weak supervision settings. These ideas were then extended to programs that could perform actions on the web.We developed a novel framework by which naturalizing programming languages, where a user interactively teaches language to a system while they are using it, which allows for use and learning to happen jointly and the language to be co-adapted.We then attempted to scale up the core problem of program synthesis from natural language (pseudocode), which demanded new search algorithms. We developed a graph-based model architecture, strongly leveraging the fact that we could execute programs at test time.We finally developed new self-supervised techniques that leveraged the wealth of unlabeled data along with an executor to bootstrap better systems.Altogether, we believe that we've tackled the problem from many angles, the framework, the data, the models, the training, and today we are able to synthesize programs from natural language (e.g., train semantic parsers) with much greater accuracy and scope than before.\n\n\t\t\t\t\tLast Modified: 07/04/2022\n\n\t\t\t\t\tSubmitted by: Percy Liang"
 }
}