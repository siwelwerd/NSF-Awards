{
 "awd_id": "1628918",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "DIP: Collaborative Research: Interactive Science Through Technology Enhanced Play (iSTEP)",
 "cfda_num": "47.070",
 "org_code": "05020000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Tatiana Korelsky",
 "awd_eff_date": "2016-09-01",
 "awd_exp_date": "2021-08-31",
 "tot_intn_awd_amt": 348056.0,
 "awd_amount": 371618.0,
 "awd_min_amd_letter_date": "2016-08-23",
 "awd_max_amd_letter_date": "2019-08-01",
 "awd_abstract_narration": "The iSTEP project addresses a basic research question by exploring the role of the body and physical activity in learning through the design of a new genre of developmentally appropriate learning technologies for young children. There is increasing recognition that the body plays a role in cognition: human beings, especially young children, understand complex concepts in part by relating them to how we move our own bodies. In extending these ideas, the iSTEP project also aims to develop teaching techniques and technological tools that can be used in real classrooms in the near future. Instead of supporting the learning of individual students as many current technological advances attempt to do, the iSTEP project creates opportunities for entire classrooms of students to engage together to model scientific phenomena using their bodies.  For instance, a classroom of students can use their own bodies to model how a state of matter such as liquid is made up of many moving particles and technologically enhance this activity to improve learning. The iSTEP project builds upon the already successful STEP mixed reality platform (IIS-1323767) by adding new forms of interaction - the use of gestures and physical props to control the STEP computer simulation. Adding these new forms of interaction allows us to examine their role in supporting learning.\r\n\r\nThe existing open source STEP platform uses commercially available vision-based sensors to track the motion of up to 12 children in an 8m x 8m space. The children simply walk into the space, are assigned an avatar (i.e., they become a water particle), and that avatar follows them as they move around the room. The children's avatars are then immersed in a virtual simulation that is programed to mimic the scientific concept they are learning. In this case, the state of matter of water (e.g., solid, liquid, or gas) is determined by how fast the children move and the relative distance between them. This allows the students to discover the laws that govern state changes through their collaborative activity. Students can also use the PLAE interface (IIS-1522945) to annotate the simulation and create representations of their peers' activity, helping them all to reflect on the underlying principles inherent in the system.  In iSTEP, students will now also be able to control the simulation by gesturing, posing with their whole body, and by manipulating physical objects in addition to the previous model of interacting with their entire body. In addition, by using smart watches, the project will explore alternative forms of feedback to the students as they can feel vibrations, hear sounds, and even see simple images that are targeted to help them explore the simulation. In the first round of experiments this project will contrast the gesture (and pose) interface with a new interface that uses physical props to see how each contributes to student learning. In the final year, these will be integrated to develop deeper insights into how they can best be used to support the design of learning environments that build on mixed reality systems.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "IIS",
 "org_div_long_name": "Division of Information & Intelligent Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Joshua",
   "pi_last_name": "Danish",
   "pi_mid_init": "A",
   "pi_sufx_name": "",
   "pi_full_name": "Joshua A Danish",
   "pi_email_addr": "jdanish@indiana.edu",
   "nsf_id": "000528547",
   "pi_start_date": "2016-08-23",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Indiana University",
  "inst_street_address": "107 S INDIANA AVE",
  "inst_street_address_2": "",
  "inst_city_name": "BLOOMINGTON",
  "inst_state_code": "IN",
  "inst_state_name": "Indiana",
  "inst_phone_num": "3172783473",
  "inst_zip_code": "474057000",
  "inst_country_name": "United States",
  "cong_dist_code": "09",
  "st_cong_dist_code": "IN09",
  "org_lgl_bus_name": "TRUSTEES OF INDIANA UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "YH86RTW2YVJ4"
 },
 "perf_inst": {
  "perf_inst_name": "Indiana University",
  "perf_str_addr": "201 N. Rose Street",
  "perf_city_name": "Bloomington",
  "perf_st_code": "IN",
  "perf_st_name": "Indiana",
  "perf_zip_code": "474051005",
  "perf_ctry_code": "US",
  "perf_cong_dist": "09",
  "perf_st_cong_dist": "IN09",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "802000",
   "pgm_ele_name": "Cyberlearn & Future Learn Tech"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "8045",
   "pgm_ref_txt": "Cyberlearn & Future Learn Tech"
  },
  {
   "pgm_ref_code": "8842",
   "pgm_ref_txt": "Design and Implementation Projects"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  },
  {
   "app_code": "0119",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001920DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 348056.0
  },
  {
   "fund_oblg_fiscal_yr": 2019,
   "fund_oblg_amt": 23562.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p><span id=\"docs-internal-guid-026211bd-7fff-1223-9f0a-b43feeb1d599\"> </span></p>\n<p dir=\"ltr\"><span>Our prior work on the Science through Technology Enhanced Play (STEP) Platform</span><span> (NSF IIS-1323767 &amp; IIS-1522945) demonstrated how motion-tracking technologies can be used to help first and second-grade students learn about valuable science concepts through embodied, socio-dramatic play. For example, students learned about states of matter by pretending to be water particles, and how honeybees collect nectar and pollinate flowers by pretending to be bees. The iSTEP grant was intended to extend this prior work by adding two new forms of interaction to the STEP system to better understand how they might further impact learning: object and pose tracking. Object tracking involves helping learners interact with the system using new physical props. For example, learners can decide whether to heat up or cool down simulated particles in the particle simulation by using a block that the system recognizes as a heat wand or one that is viewed as a cooling wand respectively. Poses were intended to help learners explore the systems using gestures such as pointing with one hand for a second. In the states of matter unit, this gesture causes the computer system to release new particles into a simulated water tank so that learners can observe how the simulated particles reacted to the current temperature, speeding up or slowing down.</span></p>\n<p dir=\"ltr\"><span>We successfully implemented a version of object tracking that uses foam blocks with colored tape on them, and a version of pose tracking which could identify up to 4 simple poses such as holding your hand above your head. These new technologies were incorporated into the open source openptrack system which is at the core of the STEP platform. To study these new forms of interaction, we also updated the STEP states of matter curricula and software,&nbsp; and the STEP honeybees curricula and software, both of which are also open source and available on GitHub. OVer the duration of this project, we tested these two sets of activities in 8 classrooms at UCLA and Indiana University, with over 210 learners. Analysis was then completed at Vanderbilt and Indiana Universities, and presented at a number of national and international educational research conferences, as well as being submitted to a number of peer reviewed journals.</span></p>\n<p dir=\"ltr\"><span>Our overall findings suggest the following. First, students demonstrated clear learning of the target content in all implementations. Second, the use of props appears to have helped learners to explore invisible and / or microscopic aspects of the systems they were studying in new and valuable ways. For example, physical props helped learners studying the states of matter to explore the role of energy and energy transfer in water changing across states. This was particularly valuable when the props constrained learners? movement as in the case of foam tubes (e.g., pool noodles) that learners used to represent bonds between particles. The props helped them to focus on how bonds limited the particle movement, and how energy could weaken and potentially even break their bonds. In the case of the honeybees, props helped the learners to further explore how different arrangements of flowers would entice bees in unique ways, and thus lead to distinct patterns of nectar collection and pollination (e.g., keeping similar species of flowers together can lead to more pollination then if they are spread far apart). Again, the pattern itself was not the key aspect of learning, but how this pattern emerged from local behaviors - in this case, the learners were able to attend more readily to how the placement of the flowers attract bees. An additional and important finding is that with support, learners were able to continue discussing these key ideas outside of the embodied learning environment, a key transition as we cannot always use these forms of embodiment in traditional testing.</span></p>\n<p>In contrast, the poses proved helpful in supporting learners to articulate and test their hypotheses, but were not as central to the process. That is, using poses to place virtual particles within a tank to see how they reacted to the local temperature was a good kind of experiment, but didn?t appear to benefit from the pose itself in that simply picking a location with the computer interface might have been fine. Similarly, using poses to direct the bees didn?t appear to promote deeper discussion or engagement than simply picking a flower where bees might go. This might have been due to our technical implementation which limited us to a small number of poses that learners needed to hold for several seconds, or due to the content we focused on, which appeared to lend itself better to the use of props.&nbsp;</p>\n<p>Future work might explore how poses can be more productively utilized in embodied learning environments, and how objects might be further enhanced to help support the exploration of invisible concepts that learners find challenging to engage with.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 02/14/2022<br>\n\t\t\t\t\tModified by: Joshua&nbsp;A&nbsp;Danish</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\n \nOur prior work on the Science through Technology Enhanced Play (STEP) Platform (NSF IIS-1323767 &amp; IIS-1522945) demonstrated how motion-tracking technologies can be used to help first and second-grade students learn about valuable science concepts through embodied, socio-dramatic play. For example, students learned about states of matter by pretending to be water particles, and how honeybees collect nectar and pollinate flowers by pretending to be bees. The iSTEP grant was intended to extend this prior work by adding two new forms of interaction to the STEP system to better understand how they might further impact learning: object and pose tracking. Object tracking involves helping learners interact with the system using new physical props. For example, learners can decide whether to heat up or cool down simulated particles in the particle simulation by using a block that the system recognizes as a heat wand or one that is viewed as a cooling wand respectively. Poses were intended to help learners explore the systems using gestures such as pointing with one hand for a second. In the states of matter unit, this gesture causes the computer system to release new particles into a simulated water tank so that learners can observe how the simulated particles reacted to the current temperature, speeding up or slowing down.\nWe successfully implemented a version of object tracking that uses foam blocks with colored tape on them, and a version of pose tracking which could identify up to 4 simple poses such as holding your hand above your head. These new technologies were incorporated into the open source openptrack system which is at the core of the STEP platform. To study these new forms of interaction, we also updated the STEP states of matter curricula and software,  and the STEP honeybees curricula and software, both of which are also open source and available on GitHub. OVer the duration of this project, we tested these two sets of activities in 8 classrooms at UCLA and Indiana University, with over 210 learners. Analysis was then completed at Vanderbilt and Indiana Universities, and presented at a number of national and international educational research conferences, as well as being submitted to a number of peer reviewed journals.\nOur overall findings suggest the following. First, students demonstrated clear learning of the target content in all implementations. Second, the use of props appears to have helped learners to explore invisible and / or microscopic aspects of the systems they were studying in new and valuable ways. For example, physical props helped learners studying the states of matter to explore the role of energy and energy transfer in water changing across states. This was particularly valuable when the props constrained learners? movement as in the case of foam tubes (e.g., pool noodles) that learners used to represent bonds between particles. The props helped them to focus on how bonds limited the particle movement, and how energy could weaken and potentially even break their bonds. In the case of the honeybees, props helped the learners to further explore how different arrangements of flowers would entice bees in unique ways, and thus lead to distinct patterns of nectar collection and pollination (e.g., keeping similar species of flowers together can lead to more pollination then if they are spread far apart). Again, the pattern itself was not the key aspect of learning, but how this pattern emerged from local behaviors - in this case, the learners were able to attend more readily to how the placement of the flowers attract bees. An additional and important finding is that with support, learners were able to continue discussing these key ideas outside of the embodied learning environment, a key transition as we cannot always use these forms of embodiment in traditional testing.\n\nIn contrast, the poses proved helpful in supporting learners to articulate and test their hypotheses, but were not as central to the process. That is, using poses to place virtual particles within a tank to see how they reacted to the local temperature was a good kind of experiment, but didn?t appear to benefit from the pose itself in that simply picking a location with the computer interface might have been fine. Similarly, using poses to direct the bees didn?t appear to promote deeper discussion or engagement than simply picking a flower where bees might go. This might have been due to our technical implementation which limited us to a small number of poses that learners needed to hold for several seconds, or due to the content we focused on, which appeared to lend itself better to the use of props. \n\nFuture work might explore how poses can be more productively utilized in embodied learning environments, and how objects might be further enhanced to help support the exploration of invisible concepts that learners find challenging to engage with.\n\n \n\n\t\t\t\t\tLast Modified: 02/14/2022\n\n\t\t\t\t\tSubmitted by: Joshua A Danish"
 }
}