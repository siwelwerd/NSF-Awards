{
 "awd_id": "1566455",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "CRII: NeTS: Ubiquitous Sensing based Location-aware Driving Safety System",
 "cfda_num": "47.070",
 "org_code": "05050000",
 "po_phone": null,
 "po_email": "",
 "po_sign_block_name": "Alexander Sprintson",
 "awd_eff_date": "2016-07-01",
 "awd_exp_date": "2019-06-30",
 "tot_intn_awd_amt": 175000.0,
 "awd_amount": 175000.0,
 "awd_min_amd_letter_date": "2016-04-11",
 "awd_max_amd_letter_date": "2016-04-11",
 "awd_abstract_narration": "This project exploits mobile sensing and vehicle localization to identify fine-grained abnormal driving behaviors, such as weaving, swerving, and fast U-turns, and further to infer location-aware dangerous vehicular status. Several existing works have tried to detect abnormal driving behaviors by focusing on detecting drivers' status based on pre-deployed infrastructure, such as alcohol sensors, infrared sensors, and cameras. Such approaches incur extra installation cost and are thus difficult to be widely adopted. In order to build pervasive location-aware driving safety systems, this project tries to deploy low power consumption sensing (utilizing mobile devices carried by users in vehicles) and learning techniques based on statistical analysis to localize vehicles and identify fine-grained abnormal driving behaviors. More importantly, the proposed system keeps tracking the drivers' behaviors and determines fine-grained location-related dangerous vehicular status, such as driving on the center line of two-way roads or occupying left lanes for a long time.\r\n\r\nThis project seeks to conduct a comprehensive study to understand to what extent the current mobile devices can model various real-world driving behaviors and corresponding vehicle dynamics. A new real-time mobile sensing system, which combines real-time mobile sensing and heterogeneous driving environments, is developed to address driving safety concerns. The final results will be the abiding principles of cyber-physical architecture that resolve dynamic impacts of complex environments and provide clear guidelines over Internet of Things (IoTs). Specifically, effective features are investigated from mobile sensor readings that are able to depict each type of abnormal driving behaviors. These features can thus be extracted to localize the vehicles and derive the patterns of abnormal driving behaviors (e.g., weaving, swerving, fast U-turn, and sudden breaks) with the consideration of generic driving scenarios and heterogeneous mobile devices. Techniques based on machine learning are developed to generate a classifier model that could clearly identify fine-grained abnormal driving behaviors. The classifier model will be further utilized as a foundation to devise the location-aware driving safety system, which can track users' driving behaviors and realize location-related dangerous vehicular status in real-time using low-computing-capability mobile devices.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "CSE",
 "org_dir_long_name": "Directorate for Computer and Information Science and Engineering",
 "div_abbr": "CNS",
 "org_div_long_name": "Division Of Computer and Network Systems",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Yan",
   "pi_last_name": "Wang",
   "pi_mid_init": "",
   "pi_sufx_name": "",
   "pi_full_name": "Yan Wang",
   "pi_email_addr": "y.wang@temple.edu",
   "nsf_id": "000702932",
   "pi_start_date": "2016-04-11",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "SUNY at Binghamton",
  "inst_street_address": "4400 VESTAL PKWY E",
  "inst_street_address_2": "",
  "inst_city_name": "BINGHAMTON",
  "inst_state_code": "NY",
  "inst_state_name": "New York",
  "inst_phone_num": "6077776136",
  "inst_zip_code": "13902",
  "inst_country_name": "United States",
  "cong_dist_code": "19",
  "st_cong_dist_code": "NY19",
  "org_lgl_bus_name": "THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK",
  "org_prnt_uei_num": "L9ZDVULCHCV3",
  "org_uei_num": "NQMVAAQUFU53"
 },
 "perf_inst": {
  "perf_inst_name": "SUNY at Binghamton",
  "perf_str_addr": "4400 Vestal Parkway East",
  "perf_city_name": "Binghamton",
  "perf_st_code": "NY",
  "perf_st_name": "New York",
  "perf_zip_code": "139026000",
  "perf_ctry_code": "US",
  "perf_cong_dist": "19",
  "perf_st_cong_dist": "NY19",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "026Y00",
   "pgm_ele_name": "CRII CISE Research Initiation"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "7363",
   "pgm_ref_txt": "RES IN NETWORKING TECH & SYS"
  },
  {
   "pgm_ref_code": "8228",
   "pgm_ref_txt": "CISE Resrch Initiatn Initiatve"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 175000.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>The objective of this project is to exploit mobile sensing and vehicle localization to identify fine-grained abnormal driving behaviors and further to infer dangerous vehicle status. The project, therefore, pursued to build a system that can characterize users' driving behaviors by continuously sensing vehicles' dynamics, identifying dangerous driving behaviors, and providing low-cost solutions that can mitigate the dangers. Specifically, the project focused on the following specific goals: 1) developing a finger-level gesture recognition technology which could facilitate various human-computer interactions and driving behavior identification, 2) developing a driver identification system that can differentiate drivers based on their unique driving behaviors during a single turn, and 3) developing a continuous user authentication system by using the PPG on commodity wearable, which enables secured access to users' wearable devices around the clock and facilitates the privacy protection on wearables.</p>\n<p>The finger-level gesture recognition technology used low-cost Photoplethysmography (PPG) in commodity wearable devices to capture the unique blood flow changes in a user&rsquo;s wrist area to distinguish the user&rsquo;s finger and hand movements. The project demonstrated that it is possible to leverage the widely deployed PPG sensors in wrist-worn wearable devices to enable finger-level gesture recognition, which could facilitate emerging human-computer interactions and fine-grained driving behavior recognition. The insight is that hand gestures involve a series of muscle and tendon movements that compress the arterial geometry with different degrees, resulting in significant motion artifacts to the blood flow with different intensity and time duration. Extensive experiments are conducted with over 3600 gestures collected from 10 adults. Despite the significant background noise caused by pulses, the developed technology achieved over 88% accuracy of differentiating nine elementary finger-level gestures from American Sign Language. The project also investigated using accelerometer and gyroscope in wearables to complement finger-level gesture recognition under the scenarios when there is no large body movement, such as walking or moving the forearm arm quickly.</p>\n<p>Recently, smartphones are integrated with various sensors that can facilitate various daily applications. The driver identification system developed in this project exploits motion sensors in smartphones for monitoring driving behaviors and identifying drivers. This project demonstrated that it is possible to utilize low-cost motion sensors in smartphones to capture vehicle dynamics and differentiate drivers. Specifically, the system utilized the accelerometer and gyroscope in a smartphone to capture a vehicle&rsquo;s dynamics during different stages of a turn. The project further developed driving features for each turning stage to capture distinct driving behaviors of different drivers considering different types of turns. Gradient boost tree-based machine technology is used for driver classification. Extensive experiments conducted with 12 drivers on different types of turns demonstrated that our system can achieve driver identification accuracy of 98% and low false-positive rate within one single turn.</p>\n<p>While using wearables and smartphones for driving behavior monitoring and analysis is convenient and promising, the data stored in these mobile devices are sensitive and require access control around the clock. Traditional one-time user authentication causes friction and harms user experience in many frequent-use applications. This is a severe problem for security-sensitive data access if the adversary could obtain unauthorized privileges after the user&rsquo;s initial login. Recently, continuous user authentication (CA) has shown its great advantage by enabling seamless user authentication with low user efforts. This project devised a low-cost system that exploits a user&rsquo;s pulsatile signals from the PPG sensors in commodity wrist-worn wearables for CA. Compared to existing approaches, the PPG-based CA system requires zero user effort and applies to practical scenarios with non-clinical PPG measurements that have motion artifacts (MA). This project explored the uniqueness of the human cardiac system and designed an MA filtering method to mitigate the impact of daily activities. Furthermore, general fiducial features and adaptive classification using the gradient boosting tree are developed to differentiate users continuously with low training effort. Extensive experiments conducted with a prototype of the wrist-worn PPG sensing platform and 20 participants in practical scenarios. The developed system achieved a high CA accuracy of over 90% and a low attack false detection rate of 4% in detecting random attacks.</p>\n<p>The project provided students with rich mentoring and research experience in experiment design, prototyping, and data analysis. Three Ph.D. students got support from this project and gained significant results. Six additional M.S. students and two undergraduate students also participated in the project through summer internship and independent study programs. The results of the project were disseminated through publications in top-tier conference proceedings and journals across the fields of mobile computing and wireless networking. The project has contributed to improving the methods used for fine-grained driving behavior analysis, which is needed for safe driving applications. The developed model in this project will be used as a foundation to develop the real-time location-aware driving safety system using low-computing-capability mobile devices.</p>\n<p>&nbsp;</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 10/28/2019<br>\n\t\t\t\t\tModified by: Yan&nbsp;Wang</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nThe objective of this project is to exploit mobile sensing and vehicle localization to identify fine-grained abnormal driving behaviors and further to infer dangerous vehicle status. The project, therefore, pursued to build a system that can characterize users' driving behaviors by continuously sensing vehicles' dynamics, identifying dangerous driving behaviors, and providing low-cost solutions that can mitigate the dangers. Specifically, the project focused on the following specific goals: 1) developing a finger-level gesture recognition technology which could facilitate various human-computer interactions and driving behavior identification, 2) developing a driver identification system that can differentiate drivers based on their unique driving behaviors during a single turn, and 3) developing a continuous user authentication system by using the PPG on commodity wearable, which enables secured access to users' wearable devices around the clock and facilitates the privacy protection on wearables.\n\nThe finger-level gesture recognition technology used low-cost Photoplethysmography (PPG) in commodity wearable devices to capture the unique blood flow changes in a user?s wrist area to distinguish the user?s finger and hand movements. The project demonstrated that it is possible to leverage the widely deployed PPG sensors in wrist-worn wearable devices to enable finger-level gesture recognition, which could facilitate emerging human-computer interactions and fine-grained driving behavior recognition. The insight is that hand gestures involve a series of muscle and tendon movements that compress the arterial geometry with different degrees, resulting in significant motion artifacts to the blood flow with different intensity and time duration. Extensive experiments are conducted with over 3600 gestures collected from 10 adults. Despite the significant background noise caused by pulses, the developed technology achieved over 88% accuracy of differentiating nine elementary finger-level gestures from American Sign Language. The project also investigated using accelerometer and gyroscope in wearables to complement finger-level gesture recognition under the scenarios when there is no large body movement, such as walking or moving the forearm arm quickly.\n\nRecently, smartphones are integrated with various sensors that can facilitate various daily applications. The driver identification system developed in this project exploits motion sensors in smartphones for monitoring driving behaviors and identifying drivers. This project demonstrated that it is possible to utilize low-cost motion sensors in smartphones to capture vehicle dynamics and differentiate drivers. Specifically, the system utilized the accelerometer and gyroscope in a smartphone to capture a vehicle?s dynamics during different stages of a turn. The project further developed driving features for each turning stage to capture distinct driving behaviors of different drivers considering different types of turns. Gradient boost tree-based machine technology is used for driver classification. Extensive experiments conducted with 12 drivers on different types of turns demonstrated that our system can achieve driver identification accuracy of 98% and low false-positive rate within one single turn.\n\nWhile using wearables and smartphones for driving behavior monitoring and analysis is convenient and promising, the data stored in these mobile devices are sensitive and require access control around the clock. Traditional one-time user authentication causes friction and harms user experience in many frequent-use applications. This is a severe problem for security-sensitive data access if the adversary could obtain unauthorized privileges after the user?s initial login. Recently, continuous user authentication (CA) has shown its great advantage by enabling seamless user authentication with low user efforts. This project devised a low-cost system that exploits a user?s pulsatile signals from the PPG sensors in commodity wrist-worn wearables for CA. Compared to existing approaches, the PPG-based CA system requires zero user effort and applies to practical scenarios with non-clinical PPG measurements that have motion artifacts (MA). This project explored the uniqueness of the human cardiac system and designed an MA filtering method to mitigate the impact of daily activities. Furthermore, general fiducial features and adaptive classification using the gradient boosting tree are developed to differentiate users continuously with low training effort. Extensive experiments conducted with a prototype of the wrist-worn PPG sensing platform and 20 participants in practical scenarios. The developed system achieved a high CA accuracy of over 90% and a low attack false detection rate of 4% in detecting random attacks.\n\nThe project provided students with rich mentoring and research experience in experiment design, prototyping, and data analysis. Three Ph.D. students got support from this project and gained significant results. Six additional M.S. students and two undergraduate students also participated in the project through summer internship and independent study programs. The results of the project were disseminated through publications in top-tier conference proceedings and journals across the fields of mobile computing and wireless networking. The project has contributed to improving the methods used for fine-grained driving behavior analysis, which is needed for safe driving applications. The developed model in this project will be used as a foundation to develop the real-time location-aware driving safety system using low-computing-capability mobile devices.\n\n \n\n\t\t\t\t\tLast Modified: 10/28/2019\n\n\t\t\t\t\tSubmitted by: Yan Wang"
 }
}