{
 "awd_id": "1627660",
 "agcy_id": "NSF",
 "tran_type": "Grant",
 "awd_istr_txt": "Standard Grant",
 "awd_titl_txt": "Three Projects in Econometric Theory",
 "cfda_num": "47.075",
 "org_code": "04050000",
 "po_phone": "7032927280",
 "po_email": "nlutz@nsf.gov",
 "po_sign_block_name": "Nancy Lutz",
 "awd_eff_date": "2016-08-01",
 "awd_exp_date": "2019-07-31",
 "tot_intn_awd_amt": 199260.0,
 "awd_amount": 199260.0,
 "awd_min_amd_letter_date": "2016-07-13",
 "awd_max_amd_letter_date": "2016-07-13",
 "awd_abstract_narration": "Most empirical methods in economics and the social sciences derive their validity from the thought experiment on how they would perform in very large samples. The implicit hope is that ensuring good performance in large samples leads to acceptable performance in moderately small data sets as well. For some inference problems, however, it is known that the standard large sample approximation is too inaccurate to be a reliable guide for the sample sized typically encountered in empirical work. As a constructive remedy, it is sometimes possible to embed the original problem in an alternative large sample approximation that better captures the small sample features. This project aims at developing such alternative large sample approximations in three empirically relevant econometric problems: How to conduct inference with persistent time series; how to account for the presence of a large number of control variates in a linear regression; and how to conduct inference about the probability and properties of extreme events. \r\n\r\nRecent advances in econometric theory often consider sequences of parameter or tuning parameter values that lead to a different form of large sample approximations. Prominent examples include weak instrument asymptotics, local-to-unity time series asymptotics where the largest autoregressive root takes on values ever closer to one, and heteroskedasticity and autocorrelations robust inference with a bandwidth equal to a fixed fraction of the sample size. This research develops similar alternative asymptotics in three distinct inference problems: The first project generalizes the local-to-unity model by letting p autoregressive roots, as well as p-1 MA roots, converge to unity at the appropriate rate. The second project studies inference about a linear regression coefficient in the presence of a large number of potential controls, where the control coefficients are known to satisfy a particular L_2 bound that can be interpreted as a bound on the R^2 in a regression of the outcome on the controls. The third project concerns the problem of inference about tail properties based on an i.i.d. sample, under the sole assumption that extreme value theory to hold for the largest k observations, for a given and fixed k.",
 "awd_arra_amount": 0.0,
 "dir_abbr": "SBE",
 "org_dir_long_name": "Directorate for Social, Behavioral and Economic Sciences",
 "div_abbr": "SES",
 "org_div_long_name": "Division of Social and Economic Sciences",
 "awd_agcy_code": "4900",
 "fund_agcy_code": "4900",
 "pi": [
  {
   "pi_role": "Principal Investigator",
   "pi_first_name": "Ulrich",
   "pi_last_name": "Mueller",
   "pi_mid_init": "K",
   "pi_sufx_name": "",
   "pi_full_name": "Ulrich K Mueller",
   "pi_email_addr": "umueller@princeton.edu",
   "nsf_id": "000488827",
   "pi_start_date": "2016-07-13",
   "pi_end_date": null
  }
 ],
 "inst": {
  "inst_name": "Princeton University",
  "inst_street_address": "1 NASSAU HALL",
  "inst_street_address_2": "",
  "inst_city_name": "PRINCETON",
  "inst_state_code": "NJ",
  "inst_state_name": "New Jersey",
  "inst_phone_num": "6092583090",
  "inst_zip_code": "085442001",
  "inst_country_name": "United States",
  "cong_dist_code": "12",
  "st_cong_dist_code": "NJ12",
  "org_lgl_bus_name": "THE TRUSTEES OF PRINCETON UNIVERSITY",
  "org_prnt_uei_num": "",
  "org_uei_num": "NJ1YPQXQG7U5"
 },
 "perf_inst": {
  "perf_inst_name": "Department of Economics",
  "perf_str_addr": "Fisher Hall",
  "perf_city_name": "Princeton",
  "perf_st_code": "NJ",
  "perf_st_name": "New Jersey",
  "perf_zip_code": "085441045",
  "perf_ctry_code": "US",
  "perf_cong_dist": "12",
  "perf_st_cong_dist": "NJ12",
  "perf_ctry_name": "United States",
  "perf_ctry_flag": "1"
 },
 "pgm_ele": [
  {
   "pgm_ele_code": "132000",
   "pgm_ele_name": "Economics"
  },
  {
   "pgm_ele_code": "133300",
   "pgm_ele_name": "Methodology, Measuremt & Stats"
  }
 ],
 "pgm_ref": [
  {
   "pgm_ref_code": "1320",
   "pgm_ref_txt": "ECONOMICS"
  },
  {
   "pgm_ref_code": "1333",
   "pgm_ref_txt": "METHOD, MEASURE & STATS"
  }
 ],
 "app_fund": [
  {
   "app_code": "0116",
   "app_name": "NSF RESEARCH & RELATED ACTIVIT",
   "app_symb_id": "040100",
   "fund_code": "01001617DB",
   "fund_name": "NSF RESEARCH & RELATED ACTIVIT",
   "fund_symb_id": "040100"
  }
 ],
 "oblg_fy": [
  {
   "fund_oblg_fiscal_yr": 2016,
   "fund_oblg_amt": 199260.0
  }
 ],
 "por": {
  "por_cntn": "<div class=\"porColContainerWBG\">\n<div class=\"porContentCol\"><p>Most empirical methods in economics and the social sciences derive their validity from the thought experiment how they would perform in very large samples. The implicit hope is that ensuring good performance in large samples leads to acceptable performance also in moderately small data sets. For some inference problems, however, it is known that the &ldquo;standard&rdquo; large sample approximation is too inaccurate to be a reliable guide for the sample sized typically encountered in empirical work. As a constructive remedy, it is sometimes possible to embed the original problem in an alternative large sample approximation that better captures the small sample features. This grant has developed such alternative embeddings in three empirically relevant econometric problems: How to conduct inference with persistent time series; how to account for the presence of a large number of control variates in a linear regression; and how to conduct inference about the probability and properties of extreme events. This alternative embedding led to the development of new inference methods, which more reliably allow to learn from data in small samples. As such, the research sponsored in this grant has provided the econometric community with novel and constructive ways of thinking about standard problems, and also added directly to the toolkit of applied researchers in the social sciences.</p><br>\n<p>\n\t\t\t\t      \tLast Modified: 09/13/2019<br>\n\t\t\t\t\tModified by: Ulrich&nbsp;K&nbsp;Mueller</p>\n</div>\n<div class=\"porSideCol\"></div>\n</div>",
  "por_txt_cntn": "\nMost empirical methods in economics and the social sciences derive their validity from the thought experiment how they would perform in very large samples. The implicit hope is that ensuring good performance in large samples leads to acceptable performance also in moderately small data sets. For some inference problems, however, it is known that the \"standard\" large sample approximation is too inaccurate to be a reliable guide for the sample sized typically encountered in empirical work. As a constructive remedy, it is sometimes possible to embed the original problem in an alternative large sample approximation that better captures the small sample features. This grant has developed such alternative embeddings in three empirically relevant econometric problems: How to conduct inference with persistent time series; how to account for the presence of a large number of control variates in a linear regression; and how to conduct inference about the probability and properties of extreme events. This alternative embedding led to the development of new inference methods, which more reliably allow to learn from data in small samples. As such, the research sponsored in this grant has provided the econometric community with novel and constructive ways of thinking about standard problems, and also added directly to the toolkit of applied researchers in the social sciences.\n\n\t\t\t\t\tLast Modified: 09/13/2019\n\n\t\t\t\t\tSubmitted by: Ulrich K Mueller"
 }
}